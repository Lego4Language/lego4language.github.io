<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[李大潜院士：与时俱进，牢牢掌握大学数学学习的主动权]]></title>
    <url>%2F2021%2F06%2F26%2F%E6%9D%8E%E5%A4%A7%E6%BD%9C%E9%99%A2%E5%A3%AB%EF%BC%9A%E4%B8%8E%E6%97%B6%E4%BF%B1%E8%BF%9B%EF%BC%8C%E7%89%A2%E7%89%A2%E6%8E%8C%E6%8F%A1%E5%A4%A7%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%BB%E5%8A%A8%E6%9D%83%2F</url>
    <content type="text"><![CDATA[各位同学，各位老师，大家好！很高兴参加数学学院今年的迎新大会。首先，对新入学的本科生及研究生表示热烈的祝贺和衷心的欢迎。在过去的好几年中，我都曾在这样的场合讲过话。这种开学典礼上的讲话，作为新生入学的第一课，当然是非常重要的。但多年的实践告诉我，如果认为这样的一次讲话就能从根本上解决问题，就能帮助大家顺利地完成从中学阶段向大学阶段的过渡，使大家能主动地适应大学的学习生活，走上良性发展的道路，恐怕是不现实的。从这个意义上看，对数学类专业新生的入学教育，应该做一点长期打算，要至少在大学一年级的整个一年中作为一个重要的任务来抓，才能收到应有的效果，才能为大家以后进一步的发展和成功打下一个坚实可靠的基础，决不可掉以轻心。我们当年从中学进入大学，也有种种的不适应，但是并没有感到面临很大的考验和障碍，可以说轻轻松松就那么过来了。现在的情形实际上已经有了很大的不同。目前中学普遍的情况是：表面上在轰轰烈烈地讲素质教育，而且调子愈唱愈高，而实际上却扎扎实实地在抓应试教育。有几个中学因应试教育效果突出，主要是录取进重点大学的升学率高，在全国声名大振，而那些原先很优秀、现在实际上也很优秀的中学都相形见绌，甚至被压得抬不起头来，也不由自主地慢慢走上了题海战术、加班加点的老套路。不少中学都规定学生上晚自习，周末及节假日也常用来加班补课，有的甚至采用军事化管理的强制手段，目的只有一个：将尽可能多的学生送进大学，特别是那些比较有名的大学。至于这些学生一辈子的成长及发展，家长、老师和校长都不怎么去考虑。一位校长就很直率地说：我只管把学生送进大学，后面的事我就不管了！虽然，从短期来说，应试教育对学生应付现有的考试进入大学，可能会起一定的作用，但是，这些带着应试教育深深烙印的学生，从学习知识、增长才干、立德树人的要求看，大都有一些根本性的缺陷，是不适应大学学习的规律的。如果他们的身子进了大学，思想还停留在应试教育的中学阶段，没有一个根本的转变，是不可能在大学里学得主动、学得生动活泼的，是不可能有后劲的，也是不可能真正成才的。因此，在大学生活一开始，使大家充分认识到学好数学的重要性和深远意义，从学习目标、学习态度、学习方法及学习习惯等方面，促成大家在认识及行动上的升华，就显得十分重要而且刻不容缓了。说到大学与中学的衔接，教师以往想得多的往往只是教学内容上的衔接。的确，现在普遍的情况是：高考不考的内容中学就不讲了，有一些学习高等数学必需的基础知识，例如韦达定理，二、三阶行列式，曲线的参数方程，极坐标，复数的三角表示等等，可能不少中学里都没有讲到，当然要填平补齐。但实际上这并不是太严重的问题，只要心中有数，教师到时候有的放矢地补讲一下，应该不会造成大的困难。对于这种知识结构上的缺失，有人希望一开始上一门小课，把这些遗漏全部补起来，其实，这样做就像炒冷饭，效果必不会好。学生一进大学就补这些本应该在中学阶段就学好的内容，感觉也必定不会太好。还是分散处理，在讲高等数学要用到时再顺水推舟地认真补一下，目的性明确，学了就用，应该更好一些。总之，这个问题要重视，但决不是大学新生以及大学老师要面临的最大问题。什么是大学新生所面临的的最大问题呢？ 01应试教育靠加班加点，靠死打硬拼，靠对同一类型的题目反复操练，要求达到“条件反射”般的敏捷，达到不动脑筋、一看到题目就能做、一做就必对的程度。这样的训练是很使人疲劳的，也必然很使人倒胃口。但是为了实现考上大学这一目标，再疲劳，再无趣，也要忍受；而且天天有老师和家长看着你，不忍受也得忍受。现在考进大学了，不少人会觉得壮志已酬，人生的目标似乎已经达到，又没有老师和家长盯得紧紧的，课业表面上也不太重，一些人还可能相当缺乏自制的能力，很容易在一开始处于一种松垮的状态，优哉游哉一下，甚至沉醉于上网、玩一些无聊的游戏等等。这一放松，时间很快就过去了。等到发觉大事不好，想要抢救过来就难了。为什么这么说呢？除了一般性的道理之外，更是由数学的特点决定的。数学这个学科逻辑性强，整个体系十分严谨，一环扣一环，前面没有很好掌握和理解，后面学习就会有本质上的困难。形象地说，学习数学和在食堂里打饭不同，是不能“插队”的！这一点，学生在中学阶段是很难体会的，这不仅因为中学里学习的内容相对说来要简单得多，而且中学里的课程现在更多是按“知识点”来讲授的，很少注意知识之间的联系，没有着重强调知识之间客观形成的体系，不少内容是相当零乱、分散地出现的，后面讲的内容和前面讲的内容之间的关系显得不大密切，偶尔“插一下队”应该是没有问题的。但大学的数学课程有自己严密的逻辑体系，再想这样“插队”就不可能了。一开始放松，就很难抓得回来，就可能永远被动下去，甚至一蹶不振。一开始不抓紧，往往就可能输在起跑线上！为什么我们常常可以看到：一些中学时代的“龙”，到大学却变成“虫”了呢？！难道不应该从他们的学习态度、学习方法和学习习惯方面认真找一找原因吗？！难道不值得引起大家强烈的警惕和注意吗？！因此，一开始就要提醒大家，一定要有一种紧迫感，对在校的学习岁月要加倍的珍惜。一定要要求大家坚持认真、刻苦的学习，不能松懈。有一分劳动，就有一分收获，这是永恒的真理，学数学更不能例外。将自己的身心献给数学的数学家，我们的不少老师，面对着丰富多彩、广阔无垠的数学世界，面对着百思不得其解的数学课题，面临着即将取得突破的关键时刻，是没有星期六、星期天的。他们享受这样的生活节奏，感受到生命的充实，深深地为之陶醉，不仅造就了他们的事业，也为大家树立了榜样。要学好数学，不出气力，玩小聪明，偷工减料，含糊敷衍，都是不行的。一些勤奋学习、刻苦钻研、奋力拼搏的学生应该成为大家的榜样，大家要认真地向他们学习，努力营造一个良好的学习氛围。 02从中学到大学，学习要求和学习环境都有了重大的变化，但大家一开始可能没有感觉，而一旦感觉到了，往往为时已晚。因此，一定要要求新生将自觉地改变自己的学习方法和学习习惯作为开始阶段的第一（注意，不是第二、第三，而是第一！）要务，力争在转折点处掌握先机，抓住学习的主动权。对怎样才算“数学学得好”这个根本性的问题，中学生中一个相当普遍的看法是：谁题目解得多、解得快，谁就是数学好。更有一种“刷题”的说法，不少的人以每天刷了多少题而自豪。据说一些网站更为在其上刷了多少题建立指标、给以奖励，等等。如果进了大学，仍然以此作为“数学学得好”的标准，那就大错特错了，也必然对数学学习的效果造成极大的负面影响。其实，数学是一门重思考与理解的学科，在入门阶段，数学学习的好坏要看是否理解深入、运作熟练及表达明晰这三个方面，这儿所说的运作泛指运算及推理等环节，而三者中的关键是要深入的理解。只有深入的理解，对数学的概念、方法及结论，不仅知其然，而且知其所以然，才能掌握数学的精神实质和思想方法，才能实现运作熟练和表达明晰这样一些外在层面上的表现。对这一点，习惯于中学阶段应试训练的学生是很少能有深刻的理解的，他们往往被老师牵着、抱着甚至赶着走，很少在深入理解上下功夫，平时也没有认真钻研教材的习惯，把大量的功夫都用在照搬照抄、反复操作大量同一类型的习题上。而如果只满足于会解题，而不知道为什么这样做，即使题刷得再多、再快，充其量只能成为一个熟练的解题工匠，是谈不上和数学真正结缘的，更是不可能培养自己的创新精神和创新能力的。再说，目前中学里平时做的题（特别是考试中做的题），大多是选择题或填充题，简单地写上一个答案就可以了。答案尽管是对的，但如果要求从头到尾将证明或过程写清楚，往往会暴露出不少的问题，就会发现要使表达简明清晰实在是一件很困难的事。别人三言两语就能搞定的，自己却啰啰嗦嗦地写了一大堆，颠三倒四，不得要领，这难道算是学好了数学吗？这样的状态能适应大学的学习生活吗？能保证自己不会输在起跑线上吗？这样看来，学生进了大学，一开始就要求他们并帮助他们自觉地转变思想、转变观念、转变习惯，实在非常重要。 03学生进入大学数学类专业，不免要关心自己的前途和出路。对此有一个明确的定位，是提高他们学习积极性的一个重要的环节。当学生正在开始以数学为专业的系统学习，正在跨进数学科学的殿堂、成为一支数学新军的时候，要使他们了解到：他们将要遨游于博大精深而又美轮美奂的数学王国，品尝并探索数学科学的精义和奥秘，欣赏它特有的美感，并努力为之添砖加瓦；同时，还要籍助于数学这一既神奇又实用的思路、工具和方法，努力揭示大自然和人类社会的种种奥秘和规律，对我们所处的这个世界有更好的了解和认识，进而为国家、为民族、为人类造福。正因为这样，一开始就要鼓励和希望学生树立一个远大的志向，拥有一个美丽的梦想，那就是将数学作为自己毕生的事业，立志将自己培养和造就为一个未来的数学家，为数学的发展与进步、为人才的教育与培养、为人类社会的发展与进步做出自己的建树和贡献，也为中国的数学增光添彩。拿破仑说过：“不想做将军的士兵，不是一个好的士兵！”套用一下他的话，我们应该也可以说：“不想做数学家的学生，不是数学类专业的一个好学生！”我们相信，这是不少学生发自内心的自觉追求，应该给以充分的鼓励和热情的支持。还可能有相当一部分学生，他们虽然对数学有兴趣，也深知数学的重要性，但希望先打好一个数学基础，将来转入到其他各行各业发挥作用。不要认为他们这么想、这么做是离经叛道，将他们打入另册，而应该认识到这也是学习数学的一个良好的出路和动机。众多有着良好数学基础和修养的毕业生进入各行各业，不仅会从根本上改变这些行业的面貌，而且对数学发展本身也提供了良好的外部环境和带来极大的推动，同样是值得鼓励和支持的。但是，这些学生尽管将来要进入各行各业，他们的人生不应该仅仅锁定在找一个高收入的工作这样功利且低俗的目标上，放弃了对数学的热爱与追求。相反，要使他们懂得，他们和其他人相比的优势不在别的地方，而在他们数学上的积淀；他们将来在新的环境中能不能脱颖而出，靠的也只能是他们在数学上的优势，而不是其他！他们将来的着力点，应该是在数学与其他学科交叉与融合的结合部上，这就是现在人们大力提倡的工业与应用数学。他们的奋斗目标同样应该是成为一个数学家，而且是一个真正意义上的工业与应用数学家。总之，尽管刚刚进入大学的新生对自己的未来可以有各不相同的打算和安排，他们将来也一定会走向四面八方、各行各业，但条条道路通罗马，他们都是数学类专业的学生，他们都需要切实打好自己的数学基础。为此，在一开始就要加强专业思想的教育，使大家都能热爱数学，热爱数学类专业，出色地完成大学期间的学习任务。 04怎样在数学学习上做到深入理解？刚刚进入大学数学类专业的学生往往是摸不着门道的，大家一定要高度重视这方面的问题，认真改进自己的学习方法，决不能放任自流。有些学生，学习积极性是很高的，劲头来了，胃口很大，总希望学得更多一些，学得更快一些。他们选修了很多课程，甚至外加了很多额外的负担，把时间排得满满的，但效果往往不好，甚至适得其反，越搞越被动。其实，这不是一个学习数学的正确方法！我在和一些大学生的谈话中，针对他们在学习上贪多求快、不求甚解的情况，曾经总结了一个学习数学的“四字诀”。哪四个字呢？少、慢、精、深。前面已经说过，数学学习的关键是要深入的理解，达到精深的地步。而为了达到精深，不能多、快，只能少、慢。要学好微积分，一本真正好的教材就够了，用不着像文科那样博览群书、一口气看上好多本。平时的学习也要步步为营。一步一个脚印，打下一个据点就牢固占领一个据点。这样，虽然一开始不贪多，但日积月累就会根基扎实地积少成多，不断扩大自己的知识结构和范围，实现由少到多的转化。而只有慢，不片面地追求速度，才能细嚼慢咽，反复思考，才能深入的理解、透彻的领会，真正掌握数学的真谛。我在上大学的时候，陈建功先生给我们上实变函数论的课。这门课很难，一堂课下来，真正弄清楚的不太多。我课后要认真地破译他那本相当浓缩的自编油印讲义，改正一些印刷上的错误，补充不少证明的细节和自己的点滴体会，一直到彻底弄懂为止。这样做，通常要花上二、三倍的时间，可以说是慢到极点。但破译了这一本“天书”，以后碰到再难的“天书”也不害怕了，这在当时就给我带来了深切的感受和极大的愉悦，而且影响和造就了我的一生。应该说，这是我在大学中收获最大的一门课程，因为它不仅锻炼和考验了我的自学能力和方法，而且极大地增加了我的信心和勇气。这不是“快”的功劳，而是“慢”的功劳。精工才能出细活，也才能逐步实现由慢到快的转化。这样得到的快，才是真快，才是无后顾之忧的快，才真正进入到一个新的境界。少、慢的目的是要达到精、深，实现由少到多、由慢到快的转化。怎样达到精、深呢？华罗庚先生提倡的一个读书方法：由薄到厚，由厚到薄，是很有启发性的。首先要由薄到厚，不仅要搞清一些细节，而且要反复思考、分析有关内容的关键和重点，抓住论证的核心和要害，了解材料的来龙去脉，读出自己的体会，读出书本及教师没有直接说出来的深刻的内涵，也包括提出自己的问题与困惑，等等。这样读书，书自然由薄到厚，认识也逐步走向深入了。但这决不是全部，还要在此基础上进一步抓住问题的本质和核心，做到由厚到薄。真理总是朴素的，本质的东西往往是简明扼要的，到了一定阶段，通过认识的升华，就会发现你所面对的这一大堆东西其实很简单，三言两语就可以点出它的本质，这就由厚转向了薄。这样的“薄”，经过了否定之否定的过程，已与原来的“薄”有了本质的不同，可以说，已经在一定程度上达到融会贯通的地步了。应该说，数学科学的发展本身就一直在经历这个“由薄到厚，由厚到薄”的过程，我们自己对数学的学习又怎能不遵守这一规律呢？！当然，要“由薄到厚”，再“由厚到薄”，说说容易，对新入学的学生来说，却完全是一个新的课题，一开始是很不容易做到的，哪怕给他们很多的空余时间，他们可能也不见得会利用。这就需老师认真的启蒙、指导，将学生带进认真思考的大门，这也应该是大学数学入学教育的一个重要的内容。我自己刚上大学的时候，教材都用有关苏联教材的中译本，高等代数的教材是苏联库洛什著、柯召翻译的。在中学里我们没有养成认真钻研教材的习惯，只要能很快地将题目做出来就行了。到了大学，由中学里学过的二阶及三阶行列式一下子跳到n阶行列式，从定义开始就要求认识上的高度升华，由具体且简单的代数运算，进入到抽象而深奥的数学思维，其中还出现了置换及关于哑指标求和这样一些似乎匪夷所思的概念及运算，中学里习以为常、依样画葫芦地解题这一套吃不开了。只有深入的理解，才能熟练的解题；而要深入理解，就离不开认真的阅读、消化及钻研教材的内容。然而，苏联的这本教材以及当时很多其他的数学教材，和中学的教材大不一样。中学教材写得很清楚，定理是什么，证明是什么，证完了还要加上证毕二字，看起来一目了然。而那个教材是一口气写下来的，一眼看去，不知道哪儿是定理，也不知道证明从哪儿开始，到哪儿结束，很难看出一个头绪。教我们高等代数的杨武之先生很细心，看到了我们的困惑，在课上就开导我们：书上的证明是从“事实上”这样的句子开始的，“事实上”以前的一段话就是定理，而“事实上”之后的内容就是证明了。他的这个启示，的确起了画龙点睛的作用，使我们知道了数学语言的这种表达方式，一下子就开窍了。这说明从中学到大学，除了学习内容变了，学习方法也要变，其中，数学的语言及语言习惯都要跟着改变。对大学数学类专业的新生，首先要帮助他们习惯于数学语言的变化，进入一个新的数学类语言环境。数学教材及文献中的这一类特殊语言实际上还有不少，要尽快帮助学生适应并习惯它们。例如说，书上写“显然”的地方，学生如果也想当然地认为“显然”，而不去想一想为什么“显然”，一下子含糊过去，那实质上并没有真正弄懂。又如，“容易证明”、“容易得到”这些字样，也是在数学教材及文献中经常出现的，说起来“容易”，但往往并非如此。以我自己的写作经验，碰到并不太难，但真正写下来却很有些啰嗦，而且会显得节外生枝、喧宾夺主的时候，往往就用上“容易证明”之类的句型，一笔带过。 这种“偷工减料”，其实是很必要的。但学生看到“容易证明”之类的话，如果不去认真思索，听之任之地放过去，实际上往往并没有真正弄懂，就不可能达到一眼看穿、“容易证明”的境界，反而给这种句型糊弄过去了。又如，“不妨碍一般性，可以假设”、“同理可得”、“用类似方法可得”等等之类在数学教材及文献中经常出现的语言，初学者也应该想清楚，认真思考一下，而不能草率而天真地盲目相信它们，这才能慢慢适应数学的语言，逐步掌握数学的思想方法和精神实质。教育学生认真对待这些“细节”，是我们启蒙老师应该尽到的责任。谈到数学的语言，最经典也最常用的莫如微积分中“”，其中文的正确表达应为“对于任意给定的，存在，使得…”。这是一个经过了千锤百炼的表述方式，数学类的学生应该能毫无障碍地表达或书写出来，决不应该似是而非、含糊敷衍。然而，实际上有不少人，甚至到了硕士生、博士生阶段，都未能完整、准确地表述这样的句子，不免使人遗憾。这个表述中的“任意”和“给定”两个词，都是起关键作用的，一个都不能少。事实上，如果没有“任意”二字，就不能体现“误差”可以愈取愈小的这一个过程，极限的意义就无从着落，就不可能进入高等数学的范畴；但如果没有“给定”这两个字，任意的就显得飘忽不定，不可捉摸，从而无从用初等数学的手段或“拐杖”进行具体的估计，来达到所要求的目标。只有同时用上“任意”、“给定”这两个词，才能进入到高等数学的概念，同时又将一切估计及运算纳入初等数学熟知的范围，实现从初等数学到高等数学的转化。这一经典的数学表述，看来咬文嚼字、枯燥无味，但实际上是充满了辩证法的。我们教高等数学的启蒙老师，作为入学教育的一部分，在讲授这一标准的数学表达时，应该捅破这一层窗户纸， 使学生深入理解它的精神，并准确、熟练地加以应用。对数学语言的熟悉和理解，还只是入门的初步。怎样深入地理解课程的内容？怎样深入了解数学定义及定理的内涵？怎样从正反两方面分析定理中所加条件之作用？怎样认识有关数学结论的作用？怎样揭示不同结论与方法之间的深刻联系？怎样考虑是否有可能改进或改善已有的结论？怎样读出自己的体会及心得？则更应是深入思考的内容，也很需启蒙老师在入学教育的阶段，通过启发式的教学帮助学生逐步学习和适应。这是高质量数学教学的应有之义，更是对新生的入学教育不可或缺的内容。抓好了这一点，学生就可顺利地跨入高等数学的大门，他们今后的数学学习就有望进入一个坦途，至少就不应该会遇到不可逾越的困难了。 05根据我们在现有中、小学听课的实际体会，对老师在课堂上组织的讨论，小学生往往抢着发言，且声音洪亮，没有任何顾虑，气氛很活跃；初中生则多了一些矜持，没有那么活跃，声音也小得多；至于高中生，则显得格外拘谨，总是小心翼翼，声音低得有时甚至像蚊子叫。总的印象，在应试教育的大环境下，一切为了升学考试，不考的就不学、也不感兴趣，学生的聪明才智往往被压缩了，他们的好奇心和求知欲似乎没有随着年龄的增加和知识的增长而增长，反而显得退化了。这样的心理素质和学习习惯，在进入大学后，无疑会成为一个极大的负担和障碍。根据培养优秀创新人才的要求，一定要鼓励和启发学生的好奇心和求知欲，要推动学生勇于提问、善于思考，使思维一直处于一种开放的活跃的状态。要使学生明白，不仅要善于学，更要善于问，要不断对老师、对书本、也对自己提出种种问题，而且要问在点子上，问出水平来。以往强调要培养学生分析问题和解决问题的能力，固然十分重要，但单单会得解决别人提出的问题，单单会得熟练解题，单单会得证明别人已经得到得结论，还远远不够，还应该强调要培养学生发现问题和提出问题的能力，使他们逐步具备发明和创新的潜质。从这个意义上说，一门教材和课程（包括入门阶段的教材和课程），如果给学生造成一种尽善尽美、天衣无缝的印象，没有任何缺点，没有什么不足，使学生感到没有任何思考的余地，只需生吞活剥、死记硬背，恰恰是一个不好的表征，也完全不符合实际的状况，是一个明显的误导。每一门学科，都有它的独特优势，有它的拿手好戏，但同时也决不可能十全十美，都必然有它的弱点和软肋，都有它解决不了或解决不彻底的问题。如果在教材中既讲成功的一面，又讲不足的一面，既讲有用的理论和方法，又讲可能面临的、难以完满解决的问题，学生的学习积极性只会得到激发，学生对教材内容的理解只会更深，而创造和探索的愿望更会从他们的内心深处迸发出来，培养优秀的创新人才就更有保障和希望了。如果我们的教材不仅向学生传授知识，而且能激起学生求知的渴望和创造的激情，有助于造就未来出色的创新人才，这是多么值得欢欣鼓舞的事啊！对数学类新生进行入学教育，要从一开始就注意到这一点。 06我们总希望学生通过学习数学，能够启迪心智，使自己变得更加聪明，更具有智慧，更有充分的发展潜力和广阔的发展前途。因此，在进入大学一开始，大家就要树立这样的观念：数学绝不是一大堆定义、公式、定理和证明的堆积，决不要通过死记硬背，费尽心机地把它们灌输进自己的头脑，而是要在学习中着意注意数学最根本的三件事。那三件事呢？ 一是数学知识的来龙去脉，是从哪儿来的，又可以到哪儿去？数学并不是无源之水、无本之木，它发展的最根本的源泉是现实世界的实际需要，是有很丰富的现实背景和需求的；而且，有意义的数学结果和内涵，也一定会在现实世界的方方面面得到广泛的应用。不讲来龙去脉，就割断了数学与生动活泼的现实生活的血肉联系，大家怎么会对数学有深入的领悟，怎么会有学习数学的持续的积极性呢？ 二是数学的精神实质和思想方法，而不仅仅是一些数学知识和证明技巧。只讲知识，不讲精神；只讲技巧，不讲思想，是实际数学教学中常见的通病。这样，大家只能给教师、教材牵着鼻子走，而不可能触类旁通、真正开窍，不可能学到数学的精髓，是不可能真正成才的。 三是数学的人文内涵。数学是人类文明的一个重要组成部分和坚实支柱，整个的人类文明史是和数学的发展史交融在一起的。数学作为一门科学，在人类认识世界和改造世界的过程中起着关键的、不可替代的作用。不关注数学文化的功能和作用，不自觉地接受数学文化的熏陶，大家是不可能真正走近数学、了解数学、领悟数学、并热爱数学的。 抓住了这三点，就抓住了数学的灵魂和精髓，就可以起到画龙点睛的效果，相应的数学学习，就会充满思想和意蕴，变得生动活泼、趣味盎然，大家对数学的认识和理解就会大不一样，学习也就会更有成效了。就讲到这儿了。希望大家尽快地适应大学数学的学习规律，牢牢掌握学习的主动权。谢谢大家！]]></content>
      <categories>
        <category>数学</category>
        <category>学习指导</category>
      </categories>
      <tags>
        <tag>Attention</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数学的流派与学派]]></title>
    <url>%2F2021%2F06%2F19%2F%E6%95%B0%E5%AD%A6%E7%9A%84%E6%B5%81%E6%B4%BE%E4%B8%8E%E5%AD%A6%E6%B4%BE%2F</url>
    <content type="text"><![CDATA[1. 流派1.1 形式主义流派1.2 逻辑主义流派1.3 直觉主义流派 2. 学派2.1 哥廷根学派2.1.1 核心思想 坚持数学的统一性； 重视纯粹数学和应用数学； 2.1.2 历史简介自文艺复兴后，如果问18世纪世界的科学中心在哪儿，无疑让人联想到法国！在这短短的100年历史中（ 18 世纪中叶到 19 世纪的前 30 年），法国在数学、物理、化学与生命科学等方面取得了卓越成就，达朗贝尔、拉格朗日、库仑、拉瓦锡、拉马克、蒙日、拉普拉斯、勒让德、傅里叶、居维叶、安培、泊松、柯西、拉梅、卡诺、伽罗瓦等群星闪烁。随后进入了19世纪，在接下来的100年时间里，世界科学中心转移到了德国，尤其在数学领域，德国更是独领风骚，其中又是以哥廷根学派闻名于世界。从高斯，到黎曼，再到希尔伯特，哥廷根学派成了数学领域的加速器，极大促进了数学这门学科的繁荣与发展。再过几百年或者几千年乃至人类灭亡前，历朝历代的国王和领袖可能早已被后人遗忘，但是这些人物仍然会被耳提面命地被讲述，他们的名字仍然继续频繁地出现在各种教材中，指引着后入前行。哥廷根数学学派曾经是众神一般存在，其在短短100多年历史中为数学界的发展贡献了半壁江山。而哥廷根学派的兴衰除了标志着数学中心的转移，也标志着从工业革命开始兴盛，主宰世界 200 年的欧洲开始衰弱，不再是科学的中心，科学家心中的殿堂。 2.1.2.1 创始期故事开端于文艺复兴思潮的传播与蔓延。1734 年（雍正十二年），文艺复兴的思潮已经浸染整个欧洲大地，那时，汉诺威王朝统治德国汉诺威地区以及整个英国土地。身为英国国王及汉诺威大公的乔治二世决定委派其重臣冯·明希豪森在德国哥廷根创办一所大学，旨在弘扬欧洲启蒙时代学术自由的理念，哥廷根大学也因此一开欧洲大学学术自由之风气。 英王乔治二世，哥廷根大学创始人，第一任校长 在此后的200多年间，哥廷根大学为人类的进步培养了一大批杰出数学家，物理学家。在数学领域，哥廷根的辉煌始于数学王子高斯，在此之后，黎曼、狄利克雷、雅可比和克莱因相继涌现，众星璀璨，在数学的众多领域，包括代数、几何和分析领域做出了巨大的贡献，一直到大卫·希尔伯特，哥廷根数学学派进入了全盛时期。在物理学领域，尤其是量子物理学方面，也是人才辈出。著名的物理学家，包括普朗克、赫兹、海德堡、费米、泡利和奥本海默等等。据统计，前后共有46名诺贝尔奖得主，在此读书或教学。这就是一代传奇，哥廷根学派，源自哥廷根大学。 2.1.2.2 发展期哥廷根大学成立61年后，在1795 年，一位 18 岁的少年来到了哥廷根大学求学，那个时候的哥廷根大学或许怎么样也不会想到，自己的命运居然会因为这个少年的到来而发生重大的改变。这个少年就是约翰·卡尔·弗里德里希·高斯（Johann Carl Friedrich Gauss ，1777.4.30－1855.2.23），被誉为数学史最伟大的天才之一，仿佛是“数学之神”的阿基米德的转世一般，被人们尊称为“数学王子”。 高斯也是极少数被印在货币上的数学家，他是德元10马克上的男人。 德元10马克 2.1.2.3 繁盛期高斯是一位多产的数学家，他将哥廷根学派带上了一个高峰，高斯对数论、代数、统计、分析、微分几何、大地测量学、地球物理学、力学、静电学、天文学、矩阵理论和光学皆有贡献。以“高斯”命名的成果达100多个，属数学家中之最，比如说高斯分布（正态分布），高斯模糊，高斯积分，高斯整数，高斯消元，高斯曲率，高斯滤波器，高斯引力常数。可以说，大学物里有高斯，高数里有高斯，几乎在理工科书籍里随便挑一本书，都会遇到他。这还是高斯并没有把自己所有研究成果全部发表出来情况下，因为高斯是一个非常谨慎的人。他对自己的工作态度是精益求精，非常严格地要求自己的研究成果。他自己曾说：宁可发表少，但发表的东西是成熟的成果。许多当代的数学家建议他，不要太认真，把结果写出来发表，这对数学的发展是很有帮助的。贝尔这样评价高斯：在高斯死后，人们才知道他早就预见一些十九世纪的数学，而且在1800年之前已经期待它们的出现。如果他能把他所知道的一些东西泄漏，很可能比当今数学还要先进半个世纪或更多的时间。一个碾压后人的例子快速傅里叶变换，即FFT。 时域频域变换 学通信、信号处理的，学编码的，谁都绕不开它，FFT一般认为是1965年Cooley 和Tukey发明的。FFT算法是数字信号处理中极为重要和基础性的理论。直到现在，仍然是应用最为广泛的DSP算法之一。举例来讲，你的美颜相机，磨皮肯定用这个算法，然而，这个算法，高斯早在1805年需要计算彗星轨道的时候已经顺便搞出来了，只是把没有把这部分的研究成果公开发表。也就是说，后人在150多年后，才辛辛苦苦重新发明了高斯曾经总结出的算法。高斯虽然并不热爱教书，但是他还是为哥廷根学派培养了众多的数学人才，让哥廷根学派在短短几十年的时间里得到迅速的发展，为德国成为世界科学中心和数学中心创造了条件。自此之后，哥廷根在很长时间里一直都是世界学术中心。 2.1.2.4 全盛期1855 年高斯去世，解析数论的创始人，高斯的学生狄利克雷，作为高斯的继任者，从柏林来到了哥廷根大学任教。他对函数论、位势论和三角级数论都有重要贡献，经常参加以傅里叶为首的青年数学家小组的活动，深受傅里叶学术思想的影响，可以说紧密团结和培养了一大批优秀的数学家。 狄利克雷 然而仅仅3年之后，1858年夏他去瑞士蒙特勒开会，作纪念高斯的演讲，在那里突发心脏病。狄利克雷虽平安返回了哥廷根，但在病中遭受妻子中风身亡的打击，病情加重，于1859年春与世长辞，年仅54岁。狄利克雷去世之后，高斯的另一位天才学生黎曼成为了哥廷根学派的领袖。 黎曼 黎曼是一名极具创新精神的数学家，他在十几岁的时候就曾只用6天时间读完了厚达859页的勒让德数学名著《数论》，他擅长对概念的创造与想象，黎曼ζ函数，黎曼积分，黎曼引理，黎曼流形，黎曼空间，黎曼映照定理，黎曼-希尔伯特问题，柯西-黎曼方程，黎曼思路回环矩阵都是他的成果。1854年，黎曼发表了《论关于作为几何学基础的假设》，黎曼几何由此诞生。黎曼几何不但导致了另一种非欧几何——椭圆几何学的诞生；而且，更出乎意料的是，它竟然在半个多世纪后引导爱因斯坦成功地创立了广义相对论。如今，黎曼几何已成为理论物理学必备的数学基础了。1859年，黎曼被选为了柏林科学院的通信院士。作为对这一崇高荣誉的回报，他向柏林科学院提交了一篇题为《论小于已知数的质数个数》的论文。这篇只有短短八页的论文就是黎曼猜想的“诞生地”。然而已过了160年时间，黎曼猜想仍未被后人证明，虽然一些极具野心的人士声称已证明，但至今未得到同行的认可。这一猜想，当今数学文献中已有超过一千条数学命题以它（或其推广形式）的成立为前提。然而，天妒英才，黎曼的学术生涯只有短短16年，1866 年，40岁时黎曼就不幸去世。在狄利克雷和黎曼都过早陨落，缺乏继承人，哥廷根学派一时之间群龙无首，进入了短暂的沉寂。19世纪70年代，普鲁士统一了德意志。德国为了赶英超法，德国政府在国内大力实行鼓励科学发展的政策，大量的人力与财力支援办好哥廷根大学，众多的科学人才都纷纷来到哥廷根，1866 年，哥廷根大学郑重邀请克莱因来到哥廷根，成为哥廷根学派的领袖，由此开始了哥廷根学派的中兴之路。 克莱因 当时克莱因已经是蜚声欧洲的大数学家，他擅长把物理概念用在函数理论上，他提出的将各种几何用它们的基础变换群来分类的爱尔兰根纲领曾一度影响数学界的发展，大家最熟悉克莱因的应该就是克莱因瓶了。为了实现哥廷根学派的中兴，克莱因认为不破不立，哥廷根的数学必须有新的领军人物，才能找回自己昔日的荣耀。克莱因的原则是聘请年轻的新星，而不是那些已经成名的数学家。两者的区别在于年轻的数学家更富有创造性思维，更加具有激情投注于数学事业。克莱因的选才标准日后也成为哥廷根的数学传统，在哥廷根这些老一辈数学教授退休或去世后，他们的继任者都是清一色的数学新星。克莱因的眼光可谓毒辣和精准，他一眼就发现了被誉为”数学之王“的希尔伯特，1895年，克莱因提议并说服了德意志教育文化部和哥廷根教授会，聘请希尔伯特来继任著名物理学家、高斯最要好的伙伴韦伯的职位，当时希尔伯特只有 33 岁。 大卫.希尔伯特 而在克莱因的手里，哥廷根学派发展出来了三大派别，以普朗克、索末菲为首的哥廷根物理学派，特别是索末菲，他一生获得 81 个诺奖提名，却终生未得诺奖，他直接教导的学生就有 9 位获得诺奖。由此19世纪末到20世纪初，这一时期，哥廷根大学在全欧乃至世界上的学术地位达到了顶峰。在这半个世纪从这里走出的诺贝尔奖得主人数位居世界大学第八位，创造了“哥廷根诺贝尔奇迹”，成为了世界物理的研究中心。然后就是以普朗特为首的哥廷根流体力学学派，哥廷根流体力学学派由冯·卡门在美国发扬光大，高晓松的外婆、中国第一个空气动力学专业奠基者陆士嘉；两弹一星元勋钱学森、郭永怀；中国力学之父钱伟长；中国近代力学奠基人周培源都是出自哥廷根流体力学学派。 普朗特、冯·卡门、钱学森三代师徒 再有就是哥廷根数学学派，哥廷根数学学派在希尔伯特的手里甚至超越了高斯时期，达到了前所未有的巅峰，希尔伯特在哥廷根任教授期间，他先后在几何学公理化、变分法、积分方程和数学基础方面做出了巨大的贡献，引领着数学的发展。很多大牛都曾来到哥廷根进行交流研究，像爱因斯坦，也曾来到哥廷根，为了寻找相对论的数学基础来跟希尔伯特学习。可以这么说，他几乎与爱因斯坦同时（甚至是早十几天）得到广义相对论的场方程，但是他见了爱因斯坦之后，还是把优先权让给了爱因斯坦，他还说爱因斯坦才是把引力和弯曲失控联系起来的第一人。希尔伯特一个伟大的成就是提出了“希尔伯特问题”。1900年，这是19世纪的结束也是一个新的世纪的到来。在这次巴黎国际数学家代表大会上，希尔伯特发表了题为《数学问题》的著名讲演，表示这将领导新世纪的数学新潮流。他根据19世纪数学研究的成果与发展趋势而提出了23个问题，这23个问题统称希尔伯特23问。希尔伯特问题可以说成为了20世纪数学发展的一盏明灯，为数学的未来探索指引了一条方向。直至今日，希尔伯特问题依然是成为许多数学家力图攻克的难关，对现代数学的研究和发展产生了深刻的影响，并起了积极的推动作用。如今希尔伯特问题中有些已得到圆满解决，有些至今仍未得到解决。他在讲演中所阐发的每个数学问题的解决，都是对数学工作者是一种巨大的鼓舞，也激励着数学家们前赴后继去探索数学未知的领域。而希尔伯特在领导哥廷根数学学派上，凭借着自己无与伦比的魅力吸引着世界各地的年轻人像朝圣般地奔向哥廷根，光他指导的博士就有七八十人。大批青年学者涌向哥廷根，不仅从德国、欧洲，而且来自亚洲，特别是美国。据统计，1862—1934年间获外国学位的美国数学家114人，其中34人是在哥廷根获博士学位的，那个时候很多有影响的论文都是用德语写的。廷根学派成为了世界数学家的摇篮和圣地，是国际数学中心。当时全世界学数学的学生中，最响亮的口号就是“打起你的背包，到哥廷根去”。那个时候的数学界富有盛名的数学家近一半都是出自哥廷根数学学派，哥闵可夫斯基为狭义相对论提供了数学框架——闵可夫斯基四维几何；外尔最早提出规范场理论，并为广义相对论提供理论依据；冯·诺依曼对刚刚降生的量子力学提供了严格的数学基础，发展了泛函分析；“现代数学之母”诺特以一般理想论奠定了抽象代数的基础，并在此基础上刺激了代数拓扑学的发展；柯朗是应用数学大家，他在偏微分方程求解方面的工作为空气动力学等一系列实际课题扫清了道路。这个时候的哥廷根群星璀璨，熠熠生辉，大家都自由徜徉在数学的殿堂之中，任凭思想的火花碰撞。 2.1.2.5 迟暮期1933年，突然的浩劫降临，毁灭了哥廷根学派，那一年，希特勒上台了，颁布了一系列针对犹太人的法令。由于不少哥廷根大学的教授都是犹太人，导致不少犹太裔的教授出走。绝大多数哥廷根派的教授逃亡美国。如诺特、柯朗、冯·诺依曼等。哥廷根数学学派遭受了重大的打击，仅剩希尔伯特苦苦支撑，1943年希尔伯特在孤独中逝世。 大卫.希尔伯特之墓 哥廷根学派彻底凋零，诺特的得意门生范德瓦尔登竖起了哥廷根数学学派的大旗，也算是培育了一批数学家，然而仍然无法挽回哥廷根学派的命运。1996 年，范德瓦尔登去世，哥廷根学派彻底消寂。而诺特、柯朗、冯·诺依曼等人远走美国，之前在哥廷根留学的众多美国学子也因为二战纷纷返回美国，再加上菲尔兹的努力，1924年在多伦多召开的国际数学家大会促进了北美的数学发展和数学家之间的国际交流，再加上希特勒的暴政，北美的数学得到了快速的发展。后来，外尔和冯·诺依曼在美国的普林斯顿高等研究所任教授，柯朗在纽约大学任教，共同创办了举世闻名的应用数学研究所。普林斯顿取代哥廷根成为世界数学的中心，美国由此彻底取代了欧洲的学术中心地位，成为了国际数学中心，一直至今。冯·诺依曼等人后来更是带领人类进入了核武器以及计算机时代，掌握了大批人才的美国拥有着众多的专利技术，由此掌握了全球经济、军事的话语权。哥廷根数学学派200年的兴衰史也是欧洲 200 年来的兴衰史。哥廷根学派的辉煌得益于重视学术交流，拥有自由、平等的讨论和相互紧密合作的学术气氛，而大胆启用众多普遍年轻、思想活跃、富有创造性的数学新星，这是哥廷根学派充满活力的一个重要原因。哥廷根数学的衰弱也可以看出欧洲已不再是世界的中心，人才纷纷外流到更自由、民主、经济更有活力的美国。所以，如果想要学术发展，唯有创造一个言论自由、开放包容的环境，这样人才自然会被吸引而来。 2.1.3 发展成就对20世纪数学的开创和发展起着核心作用的是德国哥廷根数学学派．20世纪哥廷根学派的全盛时期是从克莱因、希尔伯特开始的． 克莱因以其著名的《埃尔朗根纲领》闻名于世，他从变换群的观点出发，把当时已有的各种几何学加以分类，他是哥廷根学派的组织者和领导者． 希尔伯特在代数、几何、分析乃至元数学上的一连串无与伦比的数学成就，使他成为无可争辩的哥廷根数学学派的领袖人物。1900年，他在巴黎的- 国际数学家会议上发表演说，提出了著名的23个问题，表示他将领导新世纪的数学新潮流。 从1900年到1933年，德国的哥廷根大学成为世界数学的中心．在哥廷根， 闵可夫斯基为狭义相对论提供了数学框架——闵可夫斯基四维几何； 外尔最早提出规范场理论，并为广义相对论提供理论依据； 冯·诺依曼对刚刚降生的量子力学提供了严格的数学基础，发展了泛函分析； 女数学家诺特以一般理想论奠定了抽象代数的基础，并在此基础上刺激了代数拓扑学的发展； 柯朗是应用数学大家，他在偏微分方程求解方面的工作为空气动力学等一系列实际课题扫清了道路． …… 2.1.4 主要成员 高斯（1777-1855，数学王子） 狄利克雷（1805-1859，创立了现代函数的正式定义） 黎曼（1826-1866，黎曼几何学创始人，复变函数论创始人之一） 希尔伯特（1862-1943，伟大的数学家） 爱因斯坦（1879-1955，伟大的物理学家） 弗兰克（J. Franck，1882-1964，1925年获诺贝尔物理学奖） 冯·诺依曼（1903-1957，杰出数学家之一） 柯朗（1888-1972，哥廷根数学研究所负责人） 哥德尔（1906-1976，数理逻辑学家） 诺特（1882-1935，抽象代数奠基人之一） 费勒（W. Feller，1906-1970，随机过程论的创始人之一） 阿廷（1896-1962，抽象代数奠基人之一） 费里德里希（K. Friedrichs，1901-1983，应用数学家） 外尔（1885-1955，杰出的数学家之一） 德恩（1878-1952，希尔伯特第3问题解决者） 此外还有波利亚、舍荀（Szeg）、海林格（Hellinger）、爱华德（Ewald）、诺尔德海姆（Nordheim）、德拜（Debye）、威格纳（Wigner） 2.2 布尔巴基学派2.3 苏联数学学派（圣彼得堡学派和莫斯科学派）2.3.1 历史简介17、18世纪由于数学教育的发展，数学迅速地在英国、法国、德国、苏联等国发展起来，其中以哥廷根大学为中心的德国数学学派，发展成为一个广阔的分析领域，并得到广泛的应用，其中克莱因、希尔伯特的出现，让哥廷根数学学派走向了一个巅峰。在彼得大帝一世(1672~1739)之前,俄罗斯是基础科学方面,几乎比中国好不到哪里去.彼得一世有远见,着眼于科学在俄罗斯的发展,做了一系列的事情,例如1725年正式成立（彼得堡）科学院,在筹建科学院的时候，彼得一世充分与巴黎科学院看齐，在制定章程时，采纳德国哲学家莱布尼茨的意见，彼得堡科学院成立之后，彼得一世向全世界网罗人才，当时一流的科学家都收到了彼得一世的邀请函，并陆续为科学院聘任了一些当时的科学大家,例如欧拉\哥德巴赫\伯努利等等.当然,这些人也就是在俄国有吃有喝住一段时间而已,但肯定给俄罗斯科学教育界带来了影响,尽管是很缓慢的影响.19世纪的苏联，出现了创立非欧几何蜚声全球的数学家罗巴切夫斯基，非欧几何是人类认识史上一个富有创造性的伟大成果，它的创立，不仅带来了近百年来数学的巨大进步，而且对现代物理学、天文学以及人类时空观念的变革都产生了深远的影响，在1893年，在喀山大学树立起了世界上第一个为数学家雕塑的塑像，那个人就是罗巴切夫斯基。19世纪下半叶，以切比雪夫为首的一个学派在彼得堡大学“横空出世”，称为彼得堡学派，也称为切比雪夫学派。切比雪夫是彼得堡数学学派的奠基人和当之无愧的领袖。这个学派主要包括 马尔可夫 李亚普诺夫 伯恩斯坦 克雷洛夫 维诺格拉多夫 … 主要围绕解析数论\概率论和数学分析,应该说,还是处于经典分析的范畴,相比同时代的法德科学中心,还处于比较弱的状态.而切比雪夫的学生也是彼得堡学派的代表人物李亚普诺夫，他在概率论中得到中心极限定理的简洁证明，被广泛采用。他的最大贡献是奠定常微分方程稳定性理论的基础，提出许多新方法。这一方向的发展成为以后俄罗斯数学的一大特点。进入20世纪之后，虽然与圣彼得堡学派争霸的莫斯科学派还处于襁褓之中，但是由于学术交流的溢出效应以及数学的传承，导致莫斯科在此时也逐渐涌现出一些新星，其中的代表人物便是叶戈罗夫，叶戈罗夫在莫斯科大学开办数学讨论班作为种子,莫斯科数学学派开始崛起,并成为促使数学从经典数学转入现代数学的一支重要力量.叶戈罗夫和姆罗德舍夫斯基一起开的讨论班,最初以由经典分析衍生出来的微分几何为主题,而几何问题的分析学应用,促使人们需要进一步澄清实分析的基本概念, 所以当时开始了实分析的初步研究,叶戈罗夫本人积极参与了这个动向,并及时引入了莫斯科讨论班,该班的学生鲁金,因此而成为实分析的大师,而恰好,鲁金也是一个具有非凡教学与引导才能的人,并由此而令莫斯科学派成型.鲁金的主要学生: 门索夫 辛钦 亚历山大洛夫 乌里松\苏世林 柯尔莫哥洛夫 诺维科夫 刘斯铁尔尼克 … 都是从扎实而雄厚的实分析核心出发,各自为函数论做出了成就,更进一步延伸,奠定并发展了现代数学的一系列新领域.该学派常被划分为两个专业方向不同的学派，即函数论学派和拓扑学派。前者由叶戈洛夫和卢津创始，科尔莫哥洛夫等人发扬光大。后者以Π.C．亚历山德罗夫、乌雷松、庞特里亚金等人为代表。 叶戈罗夫 莫斯科学派的鼎盛离不开著名数学家、数学教育家柯尔莫哥洛夫的努力，科尔莫哥洛夫师承鲁金，他接过鲁金的衣钵，1931年起他担任莫斯科大学教授。1933年担任莫斯科大学数学力学研究所所长。 可以说是莫斯科学派的领袖与灵魂人物。1941年希特勒上台了，疯狂的排斥犹太人政策，导致哥廷根学派一夜之间毁于一旦。1928年的苏联，基本上还是一个农业国,至从斯大林上台以后，苏联经济就像开挂一样，仅仅十年，苏联铁和钢的产量就增长3倍，煤增长了2倍半多，那时候的苏联所有人对于劳动就只有一个想法，我爱劳动，劳动让我快乐。可是这一切被一个人给破坏了，就是小数君上面提到的希特勒，1941年纳粹德国开始进攻苏联。仅仅三周，苏联的空军力量就被彻底毁坏，斯大林急的就像热锅上蚂蚁，刚开始他想试着将民航机改造为轰炸机来重建空军，可是民航机速度太慢，以及无法预测和控制打击目标所需要的时间，让斯大林头疼不已。这时候救星出现了，安德雷-柯尔莫哥洛夫等苏联数学家，为苏联军重新制定了所有轰炸计算系统，一下子消除了斯大林的烦恼，斯大林呆了，所有将领也都呆了，他们一致认为，必须得和这些数学家搞好关系，所以斯大林开始向数学家提供稳定的工作、收入、住房、汽车、等无比丰厚的待遇，并且在全国正式开启了数学精英教育。柯尔莫哥洛夫这位数学天才的出现，使得苏联以及莫斯科大学的名字响彻了整个世界，在概率论，随机过程论和数理统计方面的划时代贡献，让他成为了20世纪苏联最杰出的数学家，也是20世纪世界上为数极少的几个最有影响的数学家之一，而他的研究几乎遍及数学的所有领域。这个家伙，在1925年大学毕业的时候，一年时间发表了8篇论文！而且每一篇论文都有新概念，新思路，新方法！1930年代，他在概率论、射影几何、数理统计、实变函数论、拓扑学、逼近论、微分方程、数理逻辑、生物数学、哲学、数学史与数学方法论等方面发表论文80余篇。平均每年8篇，而且不同领域！1940年代，这个家伙又去搞湍流理论了。1941年，这家伙一口气发了三篇文章，一举奠定了流体力学界一代宗师的地位。江湖人称K41理论。这个理论是空气动力学（飞行器设计），潜艇设计的基础。 科尔戈莫诺夫 科尔戈莫诺夫生平 俄罗斯数学学派的发展因为当时社会性质的不一样，所以与欧美主流数学界之间其实存在隔离，但是这并没有影响俄罗斯数学学派的发展。到了 20 世纪四五十年代，尽管面临着西方的封锁，可是莫斯科学派却并没有遭受重创，反而走向了巅峰，在概率论、随机过程、复变函数、数理逻辑、泛函、数论、微分方程、拓扑学等诸多前沿分支中突飞猛进，大量涌现一批著名的数学家和更多的数学教育工作者，比如说辛钦、门索夫、施密特、乌里松等等。1963年，在第比利斯召开的概率统计会议上，美国统计学家沃尔夫维茨（J。Wolfowitz，1910—1981）说：“我来苏联的一个特别的目的是确定柯尔莫哥洛夫到底是一个人呢，还是一个研究机构”。之后，邦德里雅金、康脱洛维奇、阿诺德、诺维科夫、曼宁等数学家一个一个地出现，让苏联一举成为当时世界数学第一霸主，而莫斯科大学所涌现的优秀数学家其数量之多，质量之高，恐怕除了19世纪末20世纪初的哥廷根大学，在20世纪就再也没有那个大学敢与之相比了，即使是赫赫有名的普林斯顿大学也没有出过这么多的优秀数学家，世界第一数学强校在当时可谓是实至名归。1966年，国际数学家会议在莫斯科举行，人们普遍认为，苏联数学学派已经领先于世界数坛，成为世界数学中心之一，过去只见德、法语数学着作译成英文，那时则是大量俄文数学着作译为英文的时代，甚至许多俄文数学期刊，美国都有全文译文，研读数学的大学生，也把俄语作为必读的外国语。美苏进入冷战后，苏联深知科技的竞争首先是基础科学的竞争。所以苏联把教育提到国家安全战略的高度，投入了大量的人力物力打造了一套非常高效的人才培养体制。而且在文化上，杰出的科学家，比如物理学家和数学家，就是跟欧美的摇滚明星一样受到全民的崇拜。青少年成长的过程中被灌输了这样的文化观念，许多人都梦想成为科学家的。教育上的国家战略，具体来讲，就是以前的苏联投入很大比例的政府资金到学校的STEM科目（也就是科学，技术，工程和数学）。对于数学精英苏联是这样定义的，首先，他应该在约22岁时解决一个众多着名数学家都不能解决的大问题（即证明大定理），并将成果公开发表出来。这个问题/定理有多大，也多少决定了他未来的成就有多大。在30-35岁时，在前面解决各种实际问题的基础上建立自己的理论，并为同行接受。在40-45岁，在国际学术界建立自己的学派，有相当数量的跟随者。那时候苏联开启以数学为主的数学中学（学校），在这里，学生们将接受普通的中学教育（包括相当多的文化、艺术以及其它的基本科学知识课程）以完成其人生必备的基本知识.在过去的半个世纪中，俄国的顶尖大学（如莫斯科大学、圣彼得堡大学、新西伯利亚大学等），产生了全世界近25%的菲尔兹奖得主，每个大学都有多名诺贝尔奖得主，可能有人会问了，苏联既然那么强，莫斯科大学还称霸世界第一，为什么现在的俄罗斯数学和莫斯科大学我都不了解。因为在90年代，冷战以苏联解体告终，大量的苏联科学家流失到了美国和欧洲。少量的科学家流落到中国。在我比较熟悉的领域中，SVM支撑矢量机之父，统计学习理论的提出者Vapnik就是从前苏联流落出来的科学家。他一个人推动了一个领域往前走了很多年。而他的理论据说在60年代就已经成熟了，只是躺在了前苏联的保险箱里。以至于在俄罗斯有一个笑话，“什么叫美国的大学？就是美国的大楼、俄国的教授、中国的学生。” 2.3.2 主要成就 从实分析开始向下向基础挖，做出一个更宽厚的基础，就是拓扑学。乌里松的点集拓扑学,亚历山大洛夫的代数拓扑学,其弟子庞特里亚金是最重要的拓扑学家之一,而柯尔莫哥洛夫也参与其中; 辛钦运用实分析工具开始了概率论的深入理解之路,随后柯尔莫哥洛夫则整个地在测度论基础上重建了概率论,使得概率论成为现代数学的一部分.进一步马尔可夫加入他们,为随机过程理论奠定了基础. 基于实分析和拓扑学的既有成就,莫斯科学派为泛函分析贡献了重要基础.首先是刘斯铁尔尼克和史尼莱利曼从拓扑学角度解决变分学问题的讨论班,然后是柯尔莫哥洛夫对泛函空间的基础性研究,和函数逼近论的基础研究,最后,由柯尔莫哥洛夫的学生盖尔芳特为泛函分析贡献了最重要的构架性成就,并通过这些工作,使得泛函分析与代数学和拓扑学的综合运用达到新的境界. 分析学当然要用到常微分方程上面来,分析学的现代化也就当然地导致了常微分方程理论的进步.斯捷潘诺夫\彼得罗夫斯基\庞特里亚金等,都为常微分方程这个古老的领域,取得了现代化的成就. 更进一步,经过现代化的分析学还得要用到更复杂的数学物理方程包括偏微分方程上去,特别是物理学与技术科学产生的需求,也需要现代分析学对此作出贡献.彼得罗夫斯基\刘斯铁尔尼克\吉洪诺夫\索伯列夫等,都参与了这一事业,特别是索伯列夫为广义函数理论奠定了基础. 复分析的开拓者戈鲁别夫和普列瓦洛夫,都是叶果洛夫的学生,都有很好的实分析底子,后来鲁金\辛钦\门索夫都参与进来过,后来出现的拉普伦捷夫\盖尔冯德\凯尔迪什\马库舍维奇等,都是重要的复分析家. 数论当然严重地依赖分析的工具,辛钦就没有放过数论,并组织了相应的讨论班.史尼莱利曼和盖尔冯德都因此而做了很好的数论工作,特别是哥德巴赫问题. 2.4 剑桥分析学派2.5 普林斯顿学派2.6 毕达哥拉斯学派 3. 参考资料 数学的“学派”知多少？？？ 近代数学13个学派 三大数学流派（]]></content>
      <categories>
        <category>数学</category>
        <category>学科理解</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[二十世纪的数学 —— Michael Atiyah]]></title>
    <url>%2F2021%2F06%2F15%2F%E4%BA%8C%E5%8D%81%E4%B8%96%E7%BA%AA%E7%9A%84%E6%95%B0%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[谢谢邀请我来这里参加这个活动．当然，如果有人想谈论一个世纪的终结以及下一个世纪的开始，那么他有两个具有相当难度的选择：一个是回顾过去百年的数学；另一个是对未来百年数学发展的预测，我选择了前面这个比较困难的任务，任何人都可以预测未来而且我们并不能判定是对还是错．然而对过去的任何评述，每个人都可以提出异议．我在这里所讲的是我个人的观点．这个报告不可能包含所有内容，特别是，有一些重要的内容我不准备涉及，一部分是因为我不是那些方面的专家，一部分也是出于它们已经在其他地方被评述过了.例如，我不会去谈论那些发生在逻辑与计算领域内的著名事件，这些事件往往是与像Hilbert，Gödel，Turing这些伟大的名字相关的，除了数学在基础物理中的应用之外，我也不会谈论太多数学的其他应用，这是因为数学的应用太广泛了，而且这需要专门的论述．每一个方面都需要一个专门的报告．也许大家在这次会议的其他报告中会听到很多关于这些内容的演讲．另外，试着罗列一些定理，甚至是列出在过去一百年的著名数学家的名字也是毫无意义的，那简直是在做枯燥的练习．所以，代替它们的是，我试着选择一些我认为在很多方面都是很重要的主题来讨论并且强调围绕这些主题所发生的事情．首先我有一个一般性的说明．世纪是一个大约的数字概念．我们不会真地认为在过整整一百年的时候，有些事情会突然停下来，再重新开始，所以当我描述二十世纪的数学时，有些内容实际上可能是跨世纪的，如果某件事件发生在十九世纪九十年代，并持续到二十世纪初，我将不去计较这种时间方面的细节．我所做的就象一个天文学家，工作在一个近似的数字环境中．实际上，许多东西始于十九世纪，只不过在二十世纪才硕果累累．这个报告的难点之一是很难把我们自己放回到1900年时作为一位数学家的位置上，这是因为上个世纪的数学有非常多的内容已经被我们的文化和我们自己吸收掉了．难以想象人们不用我们的术语来思考的那个时代是什么样子的．实际上，如果现在有人在数学上有一个真正重要的发现，其后他也一定会与之一起被忽略掉了！他会完全地被融入到背景之中，于是为了能够回顾过去，我们必须努力去想象在不同时代，人们用不同方式思考问题时的情景． 历史的发展从局部到整体作为开始，我准备列一些主题并且围绕它们来讨论．我谈论的第一个主题概括地讲，就是被大家称为从局部到整体的转变．在古典时期，人们大体上已经研究了在小范围内，使用局部坐标等等来研究事物．在这个世纪，重点已经转移到试图了解事物整体和大范围的性质．由于整体性质更加难以研究，所以大多只能有定性的结果，这时拓扑的思想就变得非常重要了．正是Poincaré，他不仅为拓扑学发展作出先驱性的贡献，而且也预言拓扑学将成为二十世纪数学的一个重要的组成部分，顺便让我提一下，给出一系列著名问题的Hilbert并没有意识到这一点．拓扑学很难在他的那些问题中找到具体体现．但是对Poincaré而言，他相当清楚地看出拓扑学将成为一个重要的内容．让我试着列一些领域，然后大家就能知道我在想什么了．例如，考虑一下复分析（也被称为“函数论”），这在十九世纪是数学的中心，也是象Weierstrass这样伟大人物工作的中心．对于他们而言，一个函数就是一个复变量的函数;对于Weierstrass而言，一个函数就是一个幂级数．它们是一些可以用于写下来，并且可以明确描绘的东西或者是一些公式．函数是一些公式:它们是明确可以用显式写下来的．然而接下来Abe1，Riemann和其后许多人的工作使我们远离了这些，以至于函数变得可以不用明确的公式来定义，而更多地是通过它们的整体性质来定义：通过它们的奇异点的分布，通过它们的定义域位置，通过它们取值范围．这些整体性质正是一个特定函数与众不同的特性．局部展开只是看待它们的一种方式．一个类似的事情发生在微分方程中，最初，解一个微分方程，人们需要寻找一个明确的局部解！是一些可以写下来的东西．随着事物的发展，解不必是一个显函数，人们不一定必须用好的公式来描述它们．解的奇异性是真正决定其整体性质的东西．与发生在复分析中的一切相比，这种精神是多么的类似，只不过在细节上有些不同罢了．在微分几何中，Gauss和其他人的经典工作描述了小片的空间，小块的曲率以及用来描述局部几何的局部方程．只要人们想要了解曲面的整体图象以及伴随它们的拓扑时，从这些经典结果到大范围的转变就是很自然的了．当人们从小范围到大范围时，最有意义的性质就是拓扑的性质．数论也有一个类似的发展，尽管它并不是很明显地适用于这一框架．数论学家们是这样来区分他们称之为“局部理论”和“整体理论”的：前者是当他们讨论一个单个的素数，一次一个素数，以及有限个素数时；后者是当他们同时讨论全部素数时．这种素数和点之间，局部和整体之间的类似性在数论发展过程中起了很重要的作用，并且那些在拓扑学发展中产生的思想深深地影响了数论．当然这种情况也发生在物理学中，经典物理涉及局部理论，这时我们写下可以完全描述小范围性质的微分方程，接下来我们就必须研究一个物理系统的大范围性质．物理学涉及的全部内容就是当我们从小范围出发时，我们可以知道在大范围内正在发生什么，可以预计将要发生什么，并且沿着这些结论前进． 维数的增加我的第二个主题有些不同，我称之为维数的增加．我们再次从经典的复变函数理论开始：经典复变函数论主要是详细讨论一个复变量理论并加以精炼．推广到两个或者更多个变量基本上发生在本世纪，并且是发生在有新现象出现的领域内．不是所有的现象都与一个变量的情形相同，这里有完全新的特性出现，并且n个变量的理论的研究越来越占有统治地位，这也是本世纪主要成就之一．另一方面，过去的微分几何学家主要研究曲线和曲面，我们现在研究n维流形的几何,大家仔细想一想，就能意识到这是一个重要的转变．在早期，曲线和曲面是那些人们能真正在空间里看到的东西．而高维则有一点点虚构的成分，在其中人们可以通过数学思维来想象,但当时人们也许没有认真对待它们．认真对待它们并且用同样重视程度来研究它们的这种思想实际上是二十世纪的产物．同样地，也没有明显的证据表明我们十九世纪的先驱者们思考过函数个数的增加，研究不单单一个而是几个函数，或者是向量值函数(vector-valued function)．所以我们看到这里有一个独立和非独立变量个数增加的问题．线性代数总是涉及多个变量，但它的维数的增加更具有戏剧性，它的增加是从有限维到无穷维，从线性空间到有无穷个变量的Hilbert空间．当然这就涉及到了分析,在多个变量的函数之后，我们就有函数的函数，即泛函．它们是函数空间上的函数．它们本质上有无穷多个变量，这就是我们称为变分学的理论．一个类似的事情发生在一般（非线性）函数理论的发展中．这是一个古老的课题，但真正取得卓越的成果是在二十世纪．这就是我谈的第二个主题． 从交换到非交换第三个主题是从交换到非交换的转变．这可能是二十世纪数学，特别是代数学的最主要的特征之一．代数的非交换方面已经极其重要，当然，它源自于十九世纪．它有几个不同的起源．Hamilton在四元数方面的工作可能是最令人惊叹的，并且有巨大的影响，实际上这是受处理物理问题时所采用的思想所启发．还有Grassmann在外代数方面的工作，这是另一个代数体系，现在已经被融入我们的微分形式理论中．当然，还有Cayley以线性代数为基础的矩阵方面的工作和Galois在群论方面的工作等．所有这些都是以不同的方式形成了把非交换乘法引入代数理论的基石，我形象地把它们说成是二十世纪代数机器赖以生存的“面包和黄油”．我们现在可以不去思考这些，但在十九世纪，以上所有例子都以各自不同的方式取得了重大的突破，当然，这些思想在不同的领域内得到了惊人的发展．矩阵和非交换乘法在物理中的应用产生了量子理论．Heisenberg对易关系是非交换代数在物理中的一个最重要的应用例子，以至后来被von Neumann推广到他的算子代数理论中．群论也是在二十世纪占重要位量的理论，我稍后再回来谈它． 从线性到非线性我的下一个主题是从线性到非线性的转变．古典数学的大部分或者基本上是线性的，或者即使不是很精确的线性，也是那种可以通过某些扰动展开来研究的近似线性，真正的非线性现象的处理是非常困难的，并且只是在本世纪，才在很大的范围内对其进行了真正的研究．我们从几何开始谈起：Euclid几何，平面的几何，空间的几何，直线的几何，所有这一切都是线性的．而从非欧几何的各个不同阶段到Riemann的更一般的几何，所讨论的基本上是非线性的．在微分方程中，真正关于非线性现象的研究已经处理了众多我们通过经典方法所看不到的新现象．在这里我只举两个例子，孤立子和混沌，这是微分方程理论两个非常不同的方面，在本世纪已经成为极度重要和非常著名的研究课题了．它们代表不同的极端．孤立子代表非线性微分方程的无法预料的有组织的行为，而混沌代表的是无法预料的无组织的行为(disorganized behavior)．这两者出现在不同领域，都是非常有趣和重要的，但它们基本土都是非线性现象．我们同样可以将关于孤立子的某些工作的早期历史追溯到十九世纪下叶，但那只是很少的一部分．当然，在物理学，Maxwell方程（电磁学的基本方程）是线性偏微分方程．与之对应的是著名的Yang-Mills方程，它们是非线性方程并被假定用来调控与物质结构有关的力．这些方程之所以是非线性的，是因为Yang-Mills方程本质上是Maxwell方程的矩阵体现，并且由矩阵不可交换这一事实导致方程中出现非线性项．于是在这里我们看到了一个非线性性与非交换性之间的有趣的联系．非交换性产生一类特殊的非线性性，这的确是很有意思和很重要的． 几何与代数至此我谈的是一些一般性的主题，现在我想谈论一下数学中的一个二分叉现象，它来回摇摆却始终伴随着我们，这就给了我一个机会来做一些哲学上的思索和说明．我指的是几何和代数之间的二分法，几何和代数是数学的两个形式支柱，并且都有悠久的历史．几何学可以追溯到古希腊甚至更早的时期；代数学则源于古阿拉伯人和古印度人．所以，它们都已经成为数学的基础，但它们之间有一种令人感到不太自然的关系．让我首先由这个问题的历史开始．Euc1id几何是数学理论中最早的一个例子，直到Descartes在我们现在称为的笛卡儿平面中引入代数坐标之前，它一直是纯几何的．Descartes的做法是一种将几何思考化为代数运算的尝试．从代数学家们的角度来讲，这当然是对几何学的一个重大突破或者说一次重大的冲击，如果我们来比较Newton和Leibniz在分析方面的工作，我们会发现他们属于不同的传统，Newton基本上是一个几何学家而Le1bniz基本土是一个代数学家，这其中有着很深刻的道理．对于Newton而言，几何学，或者是由他发展起来的微积分学，都是用来描述自然规律的数学尝试．他关心的是在很广泛意义下的物理，以及几何世界中的物理．在他看来，如果有人想了解事物，他就得用物理世界的观点来思考它，用几何图象的观点来看待它．当他发展微积分的时候，他想要发展的是微积分的一种能尽可能贴近隐藏在其后的物理内蕴的表现形式．所以他用的是几何论证，因为这样可以与实际意义保持密切关系，另一方面，Leibniz有一个目标，一个雄心勃勃的目标，那就是形式化整个数学，将之变成一个庞大的代数机器．这与Newton的途径截然不同，并且二者有很多不同的记号．正如我们所知道的，在Newton和Leibniz之间的这场大争论中，Leibniz的记号最后得胜．我们现在还沿用他的记号来写偏导数．Newton的精神尚在，但被人们埋葬了很长时间．在十九世纪末期，也就是一百年前，Poincaré和Hilbert是两个主要人物．我在前面已经提到过他们了，并且可以粗略地讲，他们分别是Newton和Leibniz的传人．Poincaré的思想更多的是几何和拓扑的精神，他用这些思想作为他的基本洞察工具．Hilbert更多的是一个形式主义者，他要的是公理化，形式化，并且要给出严格的，形式的描述．虽然任何一个伟大的数学家都不能轻易地被归到哪一类中去，但是，很清楚地，他们属于不同的传统．当准备这个报告的时候，我想我应该写下我们目前这一代中能够继承这些传统的具有代表性的人的名字．谈论还健在的人是十分困难的——谁该放在这张名单上呢？接着我又暗自思忖：有谁会介意被放在这么一张著名的名单的哪一边呢？于是我选择了两个名字Arnold Bourbaki，前者是Poincaré-Newton传统的继承人，而后者，我认为，是Hilbert最著名的接班人．Arnold毫不含糊地认为：他的力学和物理的观点基本上是几何的，是源自于Newton的；以为存在处于二者之间的东西，除了象Riemann（他确实跟两者都有偏离）等少数人之外，都是一种误解．Bourbaki努力继续Hilbert的形式化的研究，将数学公理化和形式化推向了一个令人瞩目的范围并取得了一些成功．每一种观点都有它的优点，但是它们之间很难调和．让我来解释一下我自己是如何看待几何和代数之间的不同．几何学当然讲的是空间，这是毫无疑问的．如果我面对这间房间里的听众，我可以在一秒中内或者是一微秒内看到很多，接收到大量的信息，当然这不是一件偶然的事件．我们大脑的构造与视觉有着极其重要的关系．我从一些从事神经生理学的朋友那里了解到，视觉占用了大脑皮层的百分之八十或九十．在大脑中大约有十七个中枢，每一个中枢专门用来负责视觉活动的不同部分：有些部分涉及的是垂直方向的，有些部分与水平方向有关，有些部分是关于色彩和透视的，最后有些部分涉及的是所见事物的具体含义和解说．理解并感知我们所看到的这个世界是我们人类发展进化的一个非常重要的部分．因此空间直觉(spatial intuition)或者空间知觉(spatial perception)是一种非常强有力的工具，也是几何学在数学上占有如此重要位置的原因，它不仅仅对那些明显具有几何性质的事物可以使用，甚至对那些没有明显几何性质的事物也可以使用．我们努力将它们归结为几何形式，因为这样可以让我们使用我们的直觉．我们的直觉是我们最有力的武器．特别是在向学生或是同事讲解一种数学时可以看得很清楚．当你讲解一个很长而且很有难度的论证，最后使学生明白了．学生这时会说些什么呢？他会说“我看到了（我懂了）！”在这里看见与理解是同义词，而且我们还可以用“知觉”这个词来同时形容它们，至少这在英语里是对的，把这个现象与其他语言作对比同样有趣．我认为有一点是很基本的：人类通过这种巨大的能力和视觉的瞬间活动获取大量的信息，从而得以发展，而教学参与其中并使之完善．在另一方面（也许有些人不这样认为），代数本质上涉及的是时间．无论现在做的是哪一类代数，都是一连串的运算被一个接着一个罗列出来，这里“一个接着一个”的意思是我们必须有时间的概念．在一个静态的宇宙中，我们无法想象代数，但几何的本质是静态的：我可以坐在这里观察，没有什么变化，但我仍可以继续观察．然而,代数与时间有关，这是因为我们有一连串的运算，这里当我谈到“代数”时，我并不单单指现代代数．任何算法，任何计算过程，都是一个接着一个地给出一连串步骤,现代计算机的发展使这一切看得很清楚．现代计算机用一系列0和1来反映其信息并由此给出问题的答案．代数涉及的是时间的操作，而几何涉及的是空间．它们是世界互相垂直的两个方面，并且它们代表数学中两种不同的观念．因此在过去数学家们之间关于代数和几何相对重要性的争论或者对话代表了某些非常非常基本的事情．当然只是为了论证是哪一边输了，哪一边胜利了，这并不值得．当我考虑这个问题时，有一个形象的类比：“你愿意成为一个代数学家还是一个几何学家？”这个问题就象问：“你愿意是聋子还是瞎子？”一样．如果人的眼睛盲了，就看不见空间；如果人的耳朵聋了，就无法听见，听觉是发生在时间之中的，总的来说，我们还是宁愿二者都要．在物理学，也有一个类似的、大致平行的关于物理概念和物理实验之间的划分．物理学有两个部分：理论——概念，想法，单词，定律——和实验仪器．我认为概念在某种广义的意义下是几何的，这是因为它们涉及的是发生在真实世界的事物．另一方面，实验更象一个代数计算．人们做事情总要花时间，测定一些数，将它们代入到公式中去．但是在实验背后的基本概念却是几何传统的一部分．将上述二分叉现象用更哲学或者更文学的语言来说，那就是对几何学家而言，代数就是所谓的“浮士德的奉献”．正如大家所知道的，在歌德的故事里，浮士德通过魔鬼可以得到他所想要的（就是一个漂亮女人的爱），其代价是出卖他的灵魂，代数就是由魔鬼提供给数学家的供品．魔鬼会说：“我将给你这个有力的机器，它可以回答你的任何问题．你需要做的就是把你的灵魂给我：放弃几何，你就会拥有这个威力无穷的机器”(现在可以把它想象成为一台计算机!)．当然我们希望同时拥有它们，我们也许可以欺骗魔鬼，假装我们出卖灵魂，但不真地给它．不过对我们灵魂的威胁依然存在，这是因为当我们转入代数计算时，本质上我们会停止思考，停止用几何的观念来考虑问题，不再思考其含义．在这里我谈论代数学家的话重了一些，但是基本土，代数的目标总是想建立一个公式，把它放到一个机器中去，转动一下把手就可以得到答案．也就是拿来一个有意义的东西，把它化成一个公式，然后得到答案．在这样的一个过程中，人们不再需要思考代数的这些不同阶段对应的几何是什么．就这样，洞察力丢掉了，而这在那些不同的阶段都是非常重要的．我们绝不能放弃这些洞察力！最终我们还是要回到这上面来的，这就是我所谈到的浮士德的奉献．我肯定这种讲法尖锐了一点．几何和代数的这种选择导致能融合二者的一些交叉课题的产生，并且代数和几何之间的区别也不象我讲的那样直截了当和朴实无华．例如，代数学家们经常使用图式(diagram)．而除了几何直觉，图式又能是什么呢？ 通用的技术现在我不想再谈论太多就内容来划分的主题，而想谈谈那些依照已经使用的技术和常见方法所确定的主题，也就是我想描述一些已经广泛应用于众多领域的常见方法．第一个就是： 同调论历史上同调论是作为拓扑学的一个分支而发展起来的．它涉及到以下情形．现有一个复杂的拓扑空间，我们想从中得到它的一些简单信息如计算它的洞或者类似事物的个数,得到某些与之联系的可加的线性不变量等．这是一种在非线性条件下关干线性不变量的构造．从几何的角度来看，闭链可加可减，这样就得到了所谓的一个空间的同调群．同调论，作为一种从拓扑空间获取某些信息的基本代数工具，是在本世纪上半叶发现的．这是一种从几何中获益匪浅的代数．同调概念也出现在其他一些方面．其另一个源头可以追溯到Hilbert及其关于多项式的研究中，多项式是非线性的函数，它们相乘可以得到更高次数的多项式．正是Hilbert那伟大的洞察力促使他来讨论“理想”，具有公共零点的多项式的线性组合．他要寻找这些理想的生成元．生成元可能有很多．他审视它们之间的关系以及关系之间的关系．于是他得到这些关系的一个分层谱系，这就是所谓的“Hilbert合系”．Hilbert的这个理论是一种非常复杂的方法，他试图将一个非线性的情形（多项式的研究）化为线性情形．本质上来讲，Hilbert构造了一个线性关系的复杂体系．能够把象多项式这样的非线性事物的某些信息纳入其中．这个代数理论实际上是与上述拓扑理论平行的，而且现在它们已融合在一起构成了所谓的“同调代数”．在代数几何学中，本世纪五十年代最伟大的成就之一是层的上同调理论的发展及在解析几何学中的扩展，这是由Leray，Cartan，Serre和Grothendieck等人组成的法国学派取得的．从中我们可以感受到一种既有Riemann-Poincaré的拓扑思想，又有Hilbert的代数思想，再加上某些分析手段的融合，这表明同调论在代数的其它分支也有着广泛的应用．我们可以引入同调群的概念，它通常是与非线性事物相关的线性事物．我们可以将之应用于群论，例如，有限群，以及李代数：它们都有相应的同调群．在数论方面，同调群通过Galois群产生了非常重要的应用．因此在相当广泛的情形下同调论都是强有力的工具之一，它也是二十世纪数学的一个典型的特征． K-理论我要谈的另外一个技术就是所谓的“K-理论”．它在很多方面都与同调论相似，它的历史并不很长（直到二十世纪中叶才出现，尽管其起源的某些方面也许可以追溯到更早一些），但它却有着很广泛的应用，已经渗透进了数学的许多部分．K-理论实际上与表示理论紧密相联，有限群的表示理论，可以讲，起源于十九世纪．但是其现代形式——K-理论却只有一个相对较短的历史．K-理论可以用下面的方式来理解：它可以被想成是应用矩阵论的一种尝试．我们知道矩阵的乘法是不可交换的，于是我们想构造矩阵可换的或是线性的不变量．迹，维数和行列式都是矩阵论中可换的不变量，而K-理论即是试图处理它们的一种系统的方法，它有时也被称为“稳定线性代数”．其思想就是，如果我们有很多矩阵，那么把两个不可换的矩阵A和矩阵B放在不同块的正交位置上，它们就可换了，因为在一个大的空间里，我们可以随意移动物体．于是在某些近似情况下，这样做是很有好处的，足以让我们得到一些信息，这就是作为一个技术的K-理论的基石．这完全类似于同调论，二者都是从复杂的非线性情形获取线性的信息．在代数几何中，K-理论是由Grothendieck首先引入的，并且取得了巨大的成功，这些与我们刚刚谈到的层理论密切相关，而且也和他在Riemann-Roch定理方面的工作有紧密联系．在拓扑学方面，Hirzebruch和我照搬了这些思想并且将它们应用到一个纯粹的拓扑范畴内．从某种意义下来说，如果Grothendieck的工作与Hilbert在合系方面的工作有关，那么我们的工作更接近于Riemann-Poincaré在同调方面的工作，我们用的是连续函数，而他用的是多项式．K-理论也在椭圆算子的指标理论和线性分析的研究中起了重要作用．从另外一个不同的角度，Milnor，Quillen和其他人发展了K-理论的代数方面，这在数论的研究中有着潜力巨大的应用．沿着这个方向的发展导致了许多有趣问题的产生．在泛函分析方面，包括象Kasparov在内的许多人的工作将连续的K-理论推广到非交换的C*-代数情形．一个空间上的连续函数在函数乘积意义下形成一个交换代数．但是在其他情形下，自然地产生了类似的关于非交换情形的讨论，这时，泛函分析也就自然而然地成为了这些问题的温床．因此，K-理论是另外一个能够将相当广泛的数学的许多不同方面都能用这种比较简单的公式来处理的领域，尽管在每一个情形下，都有很多特定于该方面且能够连接其他部分的非常困难的，技巧性很强的问题．K-理论不是一个统一的工具，它更象是一个统一的框架，在不同部分之间具有类比和相似．这个工作的许多内容已经被Alain Connes推广到“非交换微分几何”．非常有趣的是，也就是在最近，Witten通过他在弦理论方面（基础物理学的最新思想）的工作发现许多很有趣的方法都与K-理论有关，并且K-理论看起来为那些所谓的“守恒量”提供了一个很自然的“家”．虽然在过去同调论被认为是这些理论的自然框架，但是现在看起来K一理论能提供更好的答案． 李群另一个不单单是一项技术、而且是具有统一性的概念是李群．现在说起李群，我们基本上就是指正交群，酉群，辛群以及一些例外群，它们在二十世纪数学历史中起了非常重要的作用．它们同样起源于十九世纪．SophusLie是一位十九世纪的挪威数学家．正如很多人所讲的那样，他和Fleix Klein，还有其他人一起推动了“连续群理论”的发展．对Klein而言，一开始，这是一种试图统一处理Euclid几何和非欧几何这两种不同类型几何的方法．虽然这个课题源于十九世纪，但真正起步却是在二十世纪，作为一种能够将许多不同问题归并于其中来研究的统一性框架，李群理论深深地影响了二十世纪．我现在来谈谈Klein思想在几何方面的重要性．对于Klein而言，几何就是齐性空间，在那里，物体可以随意移动而保持形状不变，因此，它们是由一个相关的对称群来控制的．Euclid群给出Euclid几何而双曲几何源于另一个李群．于是每一个齐性几何对应一个不同的李群．但是到了后来，随着对Riemann的几何学工作的进一步发展，人们更关心那些不是齐性的几何，此时曲率随着位置的变化而变化，并且空间不再有整体对称性，然而，李群仍然起着重要的作用，这是因为在切空间中我们有Euclid坐标，以至于李群可以出现在一种无穷小的层面上．于是在切空间中，从无穷小的角度来看，李群又出现了，只不过由于要区分不同位置的不同点，我们需要用某种可以处理不同李群的方式来移动物体．这个理论是被Eile Cartan真正发展起来的，成为现代微分几何的基石，该理论框架对于Einstein的相对论也起着基本的作用．当然Einstein的理论极大地推动了微分几何的全面发展．进入二十世纪，我前面提到的整体性质涉及到了在整体层面上的李群和微分几何．一个主要的发展是给出所谓的“示性类”的信息，这方面标志性的工作是由Borel和Hirzebruch给出的，示性类是拓扑不变量并且融合三个关键部分：李群，微分几何和拓扑，当然也包含与群本身有关的代数．在更带分析味的方向上，我们得到了现在被称为非交换调和分析的理论．这是Fourier理论的推广，对于后者，Fourier级数或者是Fourier积分本质上对应于圆周和直线的交换李群，当我们用更为复杂的李群代替它们时，我们就可以得到一个非常漂亮、非常精巧并且将李群表示理论和分析融为一体的理论．这本质上是Harish-Chandra一生的工作．在数论方面，整个“Lang1ands纲领”,现在许多人都这样称呼它，紧密联系于Harish-Chandra理论，产生于李群理论之中．对于每一个李群，我们都可以给出相应的数论和在某种程度实施Langlands纲领．在本世纪后半叶，代数数论的一大批工作深受其影响．模形式的研究就是其中一个很好的例证，这还包括Andrew Wiles在Fermat大定理方面的工作．也许有人认为李群只不过在几何范畴内特别重要而已，因为这是出于连续变量的需要．然而事实并非如此，有限域上的李群的类似讨论可以给出有限群，并且大多数有限群都是通过这种方式产生的．因此李群理论的一些技巧甚至可以被应用到有限域或者是局部域等一些离散情形中．这方面有许多纯代数的工作，例如与George Lusztig名字联系在一起的工作．在这些工作中，有限群的表示理论被加以讨论，并且我已经提到的许多技术在这里也可以找到它们的用武之地． 有限群上述讨论已把我们带到有限群的话题，这也提醒了我：有限单群的分类是我必须承认的一项工作．许多年以前，也就是在有限单群分类恰要完成之时,我接受了一次采访，并且我还被问道我对有限单群分类的看法,我当时很轻率地说我并不认为它有那么重要．我的理由是有限单群分类的结果告诉我们，大多数单群都是我们已知的，还有就是一张有关若干例外情形的表．在某种意义下，这只不过是结束了一个领域．而并没有开创什么新东西，当事物用结束代替开始时，我不会感到很兴奋．但是我的许多在这一领域工作的朋友听到我这么讲，理所当然地会感到非常非常不高兴，我从那时起就不得不穿起“防弹衣”了．在这项研究中，有一个可以弥补缺点的优点．我在这里实际上指的是在所有的所谓“散在群”(sporadic groups)中，最大的被赋予了“魔群”名字的那一个．我认为魔群的发现这件事本身就是有限单群分类中最叫人兴奋的结果了．可以看出魔群是一个极其有意思的动物而且现在还处于被了解之中．它与数学的许多分支的很大一部分有着意想不到的联系，如与椭圆模函数的联系，甚至与理论物理和量子场论都有联系．这是分类工作的一个有趣的副产品．正如我所说的，有限单群分类本身关上了大门，但是魔群又开启了一扇大门． 物理的影响现在让我把话题转到一个不同的主题，即谈谈物理的影响．在整个历史中，物理与数学有着非常悠久的联系，并且大部分数学，例如微积分，就是为了解决物理中出现的问题而发展起来的．在二十世纪中叶，随着大多数纯数学在独立于物理学时仍取得了很好的发展，这种影响或联系也许变得不太明显．但是在本世纪最后四分之一的时间里，事情发生了戏剧性的变化,让我试着简单地评述一下物理学和数学，尤其是和几何的相互影响．在十九世纪，Hamilton发展了经典力学，引入了现在称为Hamilton量的形式化．经典力学导出现在所谓的“辛几何”．这是几何的一个分支，虽然很早已经有人研究了，但是实际上直到最近二十年，这个课题才得到真正的研究．这已经是几何学非常丰富的一部分．几何学，我在这里使用这个词的意思是指，它有三个分支：Riemann几何，复几何和辛几何，并且分别对应三个不同类型的李群．辛几何是它们之中最新发展起来的，并且在某种意义下也许是最有趣的，当然也是与物理有极其紧密联系的一个，这主要因为它的历史起源与Hamilton力学有关以及近些年来它与量子力学的联系．现在，我前面提到过的、作为电磁学基本线性方程的Maxwell方程，是Hodge在调和形式方面工作和在代数几何中应用方面工作的源动力．这是一个非常富有成果的理论，并且自从本世纪三十年代以来已经成为几何学中的许多工作的基础．我已经提到过广义相对论和Einstein的工作．量子力学当然更是提供了一个重要的实例．这不仅仅体现在对易关系上，而且更显著地体现在对Hilbert空间和谱理论的强调上．以一种更具体和明显的方式，结晶学的古典形式是与晶体结构的对称性有关的．第一个被研究的实例是发生在点周围的有限对称群，这是鉴于它们在结晶学中的应用．在本世纪中，群论更深刻的应用已经转向与物理的关系，被假设用来构成物质的基本粒子看起来在最小的层面上有隐藏的对称性，在这个层面上，有某些李群在此出没，对此我们看不见，但是当我们研究粒子的实际行为时，它们的对称性就显现无遗了．所以我们假定了一个模型，在这个模型当中，对称性是一个本质性的要素，而且目前那些很普遍的不同理论都有一些象SU(2)和SU(3)那样的基本李群融入其中并构成基础的对称群，因此这些李群看起来象是建设物质大厦的砖石．并不是只有紧李群才出现在物理中,一些非紧李群也出现在物理中，例如Lorentz群．正是由物理学家第一个开始研究非紧李群的表示理论的．它们是那些能够发生在Hilbert空间的表示，这是因为，对于紧群而言，所有不可约表示都是有限维的，而非紧群需要的是无穷维表示，这也是首先由物理学家意识到的．在二十世纪的最后25年里，正如我刚刚完成阐述的，有一种巨大的从物理学的新思想到数学的渗透，这也许是整个世纪最引人注目的事件之一，就这个问题本身，也许就需要一个完整的报告，但是，基本上来讲，量子场论和弦理论已经以引人注目的方式影响了数学的许多分支，得到了众多的新结果、新思想和新技术．这里，我的意思是指物理学家通过对物理理论的理解已经能够预言某些在数学上是对的事情了．当然，这不是一个精确的证明，但是确有非常强有力的直觉、一些特例和类比所支持．数学家们经常来检验这些由物理学家预言的结果，并且发现它们基本上是正确的，尽管给出证明是很困难的而且它们中的许多还没有被完全证明．所以说沿着这个方向，在过去的25年里取得了巨大的成果．这些结果是极其细致的．这并不象物理学家所讲的“这是一种应该是对的东西”．他们说：“这里有明确的公式，还有头十个实例（涉及超过12位的数字）”．他们会给出关于复杂问题的准确答案，这些决不是那种靠猜测就能得到的，而是需要用机器计算的东西，量子场论提供了一个重要的工具，虽然从数学上来理解很困难，但是站在应用的角度，它有意想不到的回报．这是最近25年中真正令人兴奋的事件．在这里我列一些重要的成果：SimonDona1dson在四维流形方面的工作；Vaughan-Jones在扭结不变量方面的工作；镜面对称，量子群；再加上我刚才提到的“魔群”这个主题到底讲的是什么呢？正如我在前面提到过的一样，二十世纪见证了维数的一种转换并且以转换为无穷维而告终，物理学家超越了这些，在量子场论方面，他们真正试图对广泛的无穷维空间进行细致的研究，他们处理的无穷维空间是各类典型的函数空间，它们非常复杂，不仅是因为它们是无穷维的，而且它们有复杂的代数、几何以及拓扑，还有围绕其中的很大的李群，即无穷维的李群，因此正如二十世纪数学的大部分涉及的是几何、拓扑、代数以及有限维李群和流形上分析的发展，这部分物理涉及了在无穷维情形下的类似处理．当然，这是一件非常不同的事情，但确有巨大的成功．让我更详尽地解释一下，量子场论存在于空间和时间中．空间的真正的意义是三维的，但是有简化的模型使我们将空间取成一维．在一维空间和一维时间里，物理学家遇到的典型事物，用数学语言来讲，就是由圆周的微分同胚构成的群或者是由从圆周到一个紧李群的微分映射构成的群．它们是出现在这些维数里的量子场论中的两个非常基本的无穷维李群的例子，它们也是理所当然的数学事物并且已经被数学家们研究了一段时间．在这样一个1＋1维理论中，我们将时空取成一个Riemann曲面并且由此可以得到很多新的结果．例如，研究一个给定亏格数的Riemann曲面的模空间是个可以追溯到上个世纪的古典课题．而由量子场论已经得到了很多关于这些模空间的上同调的新结果．另一个非常类似的模空间是一个具有亏格数g的Riemann曲面上的平坦G-丛的模空间．这些空间都是非常有趣的并且量子场论给出关于它们的一些精确结果．特别地，可以得到一些关于体积的很漂亮的公式，这其中涉及到Zeta函数的取值．另一个应用与计数曲线(counting curve)有关．如果我们来看给定次数和类型的平面代数曲线，我们想要知道的是，例如，经过那么多点究竟有多少曲线，这样我们就要面临代数几何的计数问题，这些问题在上个世纪一直是很经典的．而且也是非常困难的．现在它们已经通过被称为“量子上同调”的现代技术解决了，这完全是从量子场论中得到的．或者我们也可以接触那些关于不在平面上而在弯曲族上的曲线的更加困难的问题，这样我们得到了另一个具有明确结果的被称为镜面对称的美妙理论，所有这些都产生于1＋1维量子场论．如果我们升高一个维数，也就是2-维空间和1-维时间，就可以得到Vaughan-Jones的扭结不变量理论．这个理论已经用量子场论的术语给予了很美妙的解释和分析．量子场论另一个结果是所谓的“量子群”．现在关于量子群的最好的东西是它们的名字．明确地讲它们不是群！如果有人要问我一个量子群的定义，我也许需要用半个小时来解释，它们是复杂的事物，但毫无疑问它们与量子理论有着很深的联系它们源于物理，而且现在的应用者是那些脚踏实地的代数学家们，他们实际上用它们进行确定的计算．如果我们将维数升得更高一些，到一个全四维理论（三加一维），这就是Donaldson的四维流形理论，在这里量子场论产生了重大影响．特别地，这还导致Seiberg和Witten建立了他们相应的理论，该理论建立在物理直觉之上并且也给出许多非同寻常的数学结果．所有这些都是些突出的例子．其实还有更多的例子．接下来是弦理论并且这已经是过时的了！我们现在所谈论的是M一理论，这是一个内容丰富的理论，其中同样有大量的数学，从关于它的研究中得到的结果仍有待于进一步消化并且足可以让数学家们忙上相当长的时间． 历史的总结我现在作一个简短的总结．让我概括地谈谈历史：数学究竟发生了什么？我相当随意地把十八世纪和十九世纪放在了一起，把它们当做我们称为古典数学的时代，这个时代是与Euler和Gauss这样的人联系在一起的，所有伟大的古典数学结果也都是在这个时代被发现和发展的．有人也许认为那几乎就是数学的终结了，但是相反地，二十世纪实际上非常富有成果，这也是我一直在谈论的．二十世纪大致可以一分为二地分成两部分．我认为二十世纪前半叶是被我称为“专门化的时代”，这是一个Hilbert的处理办法大行其道的时代，即努力进行形式化，仔细地定义各种事物，并在每一个领域中贯彻始终．正如我说到过的，Bourbaki的名字是与这种趋势联系在一起的．在这种趋势下，人们把注意力都集中于在特定的时期从特定的代数系统或者其它系统能获得什么．二十世纪后半叶更多地被我称为“统一的时代”，在这个时代，各个领域的界限被打破了，各种技术可以从一个领域应用到另外一个领域，并且事物在很大程度上变得越来越有交叉性．我想这是一种过于简单的说法，但是我认为这简单总结了我们所看到的二十世纪数学的一些方面．二十一世纪会是什么呢？我已经说过，二十一世纪是量子数学的时代，或者，如果大家喜欢，可称为是无穷维数学的时代．这意味着什么呢？量子数学的含义是指我们能够恰当地理解分析、几何、拓扑和各式各样的非线性函数空间的代数，在这里，“恰当地理解”，我是指能够以某种方式对那些物理学家们已经推断出来的美妙事物给出较精确的证明．有人要说，如果用天真幼稚的方式(naive way)来研究无穷维并问一些天真幼稚的问题，通常来讲，只能得到错误的答案或者答案是无意义的，物理的应用、洞察力和动机使得物理学家能够问一些关于无穷维的明智的问题，并且可以在有合乎情理的答案时作一些非常细致的工作，因此用这种方式分析无穷维决不是一件轻而易举的事情．我们必须沿着这条正确的道路走下去．我们已经得到了许多线索，地图已经摊开了：我们的目标已经有了，只不过还有很长的路要走．还有什么会发生在二十一世纪？我想强调一下Connes的非交换微分几何．Alain Connes拥有这个相当宏伟的统一理论．同样，它融合了一切．它融合了分析、代数、几何、拓扑、物理、数论，所有这一切都是它的一部分．这是一个框架性理论，它能够让我们在非交换分析的范畴里从事微分几何学家通常所做的工作，这当中包括与拓扑的关系．要求这样做是有很好的理由的，因为它在数论、几何、离散群等等以及在物理中都有（潜力巨大的或者特别的）应用．一个与物理有趣的联系也刚刚被发现．这个理论能够走多远，能够得到什么结果，还有待进一步观察．它理所当然地是我所期望的至少在下个世纪头十年能够得到显著发展的课题，而且找到它与尚不成熟的（精确）量子场论之间的联系是完全有可能的．我们转到另一个方面，也就是所谓的“算术几何”或者是Arakelov几何，其试图尽可能多地将代数几何和数论的部分内容统一起来．这是一个非常成功的理论．它已经有了一个美好的开端，但仍有很长的路要走．这又有谁知道呢？当然，所有这些都有一些共同点．我期待物理学能够将它的影响遍及所有地方，甚至是数论：Andrew Wiles不同意我这样说，只有时间会说明一切．这些是我所能看到的在下个十年里出现的几个方面，但也有一些难以捉摸的东西：返回至低维几何．与所有无穷维的富有想象的事物在一起，低维几何的处境有些尴尬．从很多方面来看，我们开始时讨论的维数，或我们祖先开始时的维数，仍留下某些未解之谜．维数为2，3和4的对象被我们称为“低”维的．例如Thurston在三维几何的工作，目标就是能够给出一个三维流形上的几何分类，这比二维理论要深刻得多．Thurston纲领还远远没有完成，完成这个纲领当然将是一个重要的挑战．在三维中另外一个引人注目的事件是Vaughan-Jones那些思想本质上来源于物理的工作．这给了我们更多的关于三维的信息，并且它们几乎完全不在Thurston纲领包含的信息之内．如何将这两个方面联系起来仍然是一个巨大的挑战，但是最近得到的结果暗示两者之间可能有一座桥，因此，整个低维的领域都与物理有关，但是其中实在有太多让人琢磨不透的东西．最后，我要提一下的是在物理学中出现的非常重要的“对偶”．这些对偶，泛泛地来讲，产生于一个量子理论被看成一个经典理论时有两种不同的实现．一个简单的例子是经典力学中的位置和动量的对偶．这样由对偶空间代替了原空间，并且在线性理论中，对偶就是Fourier变换．但是在非线性理论中，如何来代替Fourier变换是巨大的挑战之一．数学的大部分都与如何在非线性情形下推广对偶有关．物理学家看起来能够在他们的弦理论和M一理论中以一种非同寻常的方式做到了这一点．他们构造了一个又一个令人叹为观止的对偶实例，在某种广义的意义下，它们是Fourier变换的无穷维非线性体现，并且看起来它们能解决问题，然而理解这些非线性对偶性看起来也是下个世纪的巨大挑战之一．我想我就谈到这里．这里还有大量的工作，并且我觉得象我这样的一个老人可以和你们这么多的年轻人谈谈是一件非常好的事情；而且我也可以对你们说：在下个世纪，有大量的工作在等着你们去完成．]]></content>
      <categories>
        <category>数学</category>
        <category>学科理解</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数学各个研究方向简介]]></title>
    <url>%2F2021%2F06%2F15%2F%E6%95%B0%E5%AD%A6%E5%90%84%E4%B8%AA%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[1. 数论人类从学会计数开始就一直和自然数打交道了，后来由于实践的需要，数的概念进一步扩充，自然数被叫做正整数，而把它们的相反数叫做负整数，介于正整数和负整数中间的中性数叫做0。它们和起来叫做整数。对于整数可以施行加、减、乘、除四种运算，叫做四则运算。其中加法、减法和乘法这三种运算，在整数范围内可以毫无阻碍地进行。也就是说，任意两个或两个以上的整数相加、相减、相乘的时候，它们的和、差、积仍然是一个整数。但整数之间的除法在整数范围内并不一定能够无阻碍地进行。人们在对整数进行运算的应用和研究中，逐步熟悉了整数的特性。比如，整数可分为两大类—奇数和偶数（通常被称为单数、双数）等。利用整数的一些基本性质，可以进一步探索许多有趣和复杂的数学规律，正是这些特性的魅力，吸引了古往今来许多的数学家不断地研究和探索。数论这门学科最初是从研究整数开始的，所以叫做整数论。后来整数论又进一步发展，就叫做数论了。确切的说，数论就是一门研究整数性质的学科。 1.1 数论的发展简况自古以来，数学家对于整数性质的研究一直十分重视，但是直到十九世纪，这些研究成果还只是孤立地记载在各个时期的算术著作中，也就是说还没有形成完整统一的学科。自我国古代，许多著名的数学著作中都关于数论内容的论述，比如求最大公约数、勾股数组、某些不定方程整数解的问题等等。在国外，古希腊时代的数学家对于数论中一个最基本的问题——整除性问题就有系统的研究，关于质数、和数、约数、倍数等一系列概念也已经被提出来应用了。后来的各个时代的数学家也都对整数性质的研究做出过重大的贡献，使数论的基本理论逐步得到完善。在整数性质的研究中，人们发现质数是构成正整数的基本“材料”，要深入研究整数的性质就必须研究质数的性质。因此关于质数性质的有关问题，一直受到数学家的关注。到了十八世纪末，历代数学家积累的关于整数性质零散的知识已经十分丰富了，把它们整理加工成为一门系统的学科的条件已经完全成熟了。德国数学家高斯集中前人的大成，写了一本书叫做《算术探讨》，1800年寄给了法国科学院，但是法国科学院拒绝了高斯的这部杰作，高斯只好在1801年自己发表了这部著作。这部书开始了现代数论的新纪元。在《算术探讨》中，高斯把过去研究整数性质所用的符号标准化了，把当时现存的定理系统化并进行了推广，把要研究的问题和意志的方法进行了分类，还引进了新的方法。 1.2 数论的基本内容数论形成了一门独立的学科后，随着数学其他分支的发展，研究数论的方法也在不断发展。如果按照研究方法来说，可以分成初等数论、解析数论、代数数论和几何数论四个部分。初等数论是数论中不求助于其他数学学科的帮助，只依靠初等的方法来研究整数性质的分支。比如中国古代有名的“中国剩余定理”，就是初等数论中很重要的内容。解析数论是使用数学分析作为工具来解决数论问题的分支。数学分析是以函数作为研究对象的、在极限概念的基础上建立起来的数学学科。用数学分析来解决数论问题是由欧拉奠基的，俄国数学家车比雪夫等也对它的发展做出过贡献。解析数论是解决数论中艰深问题的强有力的工具。比如，对于“质数有无限多个”这个命题，欧拉给出了解析方法的证明，其中利用了数学分析中有关无穷级数的若干知识。二十世纪三十年代，苏联数学家维诺格拉多夫创造性的提出了“三角和方法”，这个方法对于解决某些数论难题有着重要的作用。我国数学家陈景润在解决“哥德巴赫猜想”问题中也使用的是解析数论的方法。代数数论是把整数的概念推广到代数整数的一个分支。数学家把整数概念推广到一般代数数域上去，相应地也建立了素整数、可除性等概念。几何数论是由德国数学家、物理学家闵可夫斯基等人开创和奠基的。几何数论研究的基本对象是“空间格网”。什么是空间格网呢？在给定的直角坐标系上，坐标全是整数的点，叫做整点；全部整点构成的组就叫做空间格网。空间格网对几何学和结晶学有着重大的意义。由于几何数论涉及的问题比较复杂，必须具有相当的数学基础才能深入研究。数论是一门高度抽象的数学学科，长期以来，它的发展处于纯理论的研究状态，它对数学理论的发展起到了积极的作用。但对于大多数人来讲并不清楚它的实际意义。由于近代计算机科学和应用数学的发展，数论得到了广泛的应用。比如在计算方法、代数编码、组合论等方面都广泛使用了初等数论范围内的许多研究成果；又文献报道，现在有些国家应用“孙子定理”来进行测距，用原根和指数来计算离散傅立叶变换等。此外，数论的许多比较深刻的研究成果也在近似分析、差集合、快速变换等方面得到了应用。特别是现在由于计算机的发展，用离散量的计算去逼近连续量而达到所要求的精度已成为可能。数论在数学中的地位是独特的，高斯曾经说过“数学是科学的皇后，数论是数学中的皇冠”。因此，数学家都喜欢把数论中一些悬而未决的疑难问题，叫做“皇冠上的明珠”，以鼓励人们去“摘取”。下面简要列出几颗“明珠”：费尔马大定理、孪生素数问题、歌德巴赫猜想、圆内整点问题、完全数问题……在我国近代，数论也是发展最早的数学分支之一。从二十世纪三十年代开始，在解析数论、刁藩都方程、一致分布等方面都有过重要的贡献，出现了华罗庚、闵嗣鹤、柯召等第一流的数论专家。其中华罗庚教授在三角和估值、堆砌素数论方面的研究是享有盛名的。1949年以后，数论的研究的得到了更大的发展。特别是在“筛法”和“歌德巴赫猜想”方面的研究，已取得世界领先的优秀成绩。特别是陈景润在1966年证明“歌德巴赫猜想”的“一个大偶数可以表示为一个素数和一个不超过两个素数的乘积之和”以后，在国际数学引起了强烈的反响，盛赞陈景润的论文是解析数学的名作，是筛法的光辉顶点。至今，这仍是“歌德巴赫猜想”的最好结果。 2. 拓扑学2.1 拓扑学的由来几何拓扑学是十九世纪形成的一门数学分支，它属于几何学的范畴。有关拓扑学的一些内容早在十八世纪就出现了。那时候发现一些孤立的问题，后来在拓扑学的形成中占着重要的地位。在数学上，关于哥尼斯堡七桥问题、多面体的欧拉定理、四色问题等都是拓扑学发展史的重要问题。哥尼斯堡（今俄罗斯加里宁格勒）是东普鲁士的首都，[推荐]数学各个研究方向简介普莱格尔河横贯其中。十八世纪在这条河上建有七座桥，将河中间的两个岛和河岸联结起来。人们闲暇时经常在这上边散步，一天有人提出：能不能每座桥都只走一遍，最后又回到原来的位置。这个问题看起来很简单有很有趣的问题吸引了大家，很多人在尝试各种各样的走法，但谁也没有做到。看来要得到一个明确、理想的答案还不那么容易。1736年，有人带着这个问题找到了当时的大数学家欧拉，欧拉经过一番思考，很快就用一种独特的方法给出了解答。欧拉把这个问题首先简化，他把两座小岛和河的两岸分别看作四个点，而把七座桥看作这四个点之间的连线。那么这个问题就简化成，能不能用一笔就把这个图形画出来。经过进一步的分析，欧拉得出结论——不可能每座桥都走一遍，最后回到原来的位置。并且给出了所有能够一笔画出来的图形所应具有的条件。这是拓扑学的“先声”。在拓扑学的发展历史中，还有一个著名而且重要的关于多面体的定理也和欧拉有关。这个定理内容是：如果一个凸多面体的顶点数是v、棱数是e、面数是f，那么它们总有这样的关系：f+v-e=2。根据多面体的欧拉定理，可以得出这样一个有趣的事实：只存在五种正多面体。它们是正四面体、正六面体、正八面体、正十二面体、正二十面体。著名的“四色问题”也是与拓扑学发展有关的问题。四色问题又称四色猜想，是世界近代三大数学难题之一。四色猜想的提出来自英国。1852年，毕业于伦敦大学的弗南西斯.格思里来到一家科研单位搞地图着色工作时，发现了一种有趣的现象：“看来，每幅地图都可以用四种颜色着色，使得有共同边界的国家都被着上不同的颜色。”1872年，英国当时最著名的数学家凯利正式向伦敦数学学会提出了这个问题，于是四色猜想成了世界数学界关注的问题。世界上许多一流的数学家都纷纷参加了四色猜想的大会战。1878～1880年两年间，著名律师兼数学家肯普和泰勒两人分别提交了证明四色猜想的论文，宣布证明了四色定理。但后来数学家赫伍德以自己的精确计算指出肯普的证明是错误的。不久，泰勒的证明也被人们否定了。于是，人们开始认识到，这个貌似容易的题目，其实是一个可与费马猜想相媲美的难题。进入20世纪以来，科学家们对四色猜想的证明基本上是按照肯普的想法在进行。电子计算机问世以后，由于演算速度迅速提高，加之人机对话的出现，大大加快了对四色猜想证明的进程。1976年，美国数学家阿佩尔与哈肯在美国伊利诺斯大学的两台不同的电子计算机上，用了1200个小时，作了100亿判断，终于完成了四色定理的证明。不过不少数学家并不满足于计算机取得的成就，他们认为应该有一种简捷明快的书面证明方法。上面的几个例子所讲的都是一些和几何图形有关的问题，但这些问题又与传统的几何学不同，而是一些新的几何概念。这些就是“拓扑学”的先声。 2.2 什么是拓扑学拓扑学的英文名是Topology，直译是地志学，也就是和研究地形、地貌相类似的有关学科。我国早期曾经翻译成“形势几何学”、“连续几何学”、“一对一的连续变换群下的几何学”，但是，这几种译名都不大好理解，1956年统一的《数学名词》把它确定为拓扑学，这是按音译过来的。拓扑学是几何学的一个分支，但是这种几何学又和通常的平面几何、立体几何不同。通常的平面几何或立体几何研究的对象是点、线、面之间的位置关系以及它们的度量性质。拓扑学对于研究对象的长短、大小、面积、体积等度量性质和数量关系都无关。举例来说，在通常的平面几何里，把平面上的一个图形搬到另一个图形上，如果完全重合，那么这两个图形叫做全等形。但是，在拓扑学里所研究的图形，在运动中无论它的大小或者形状都发生变化。在拓扑学里没有不能弯曲的元素，每一个图形的大小、形状都可以改变。例如，前面讲的欧拉在解决哥尼斯堡七桥问题的时候，他画的图形就不考虑它的大小、形状，仅考虑点和线的个数。这些就是拓扑学思考问题的出发点。拓扑性质有那些呢？首先我们介绍拓扑等价，这是比较容易理解的一个拓扑性质。在拓扑学里不讨论两个图形全等的概念，但是讨论拓扑等价的概念。比如，尽管圆和方形、三角形的形状、大小不同，在拓扑变换下，它们都是等价图形。左图的三样东西就是拓扑等价的，换句话讲，就是从拓扑学的角度看，它们是完全一样的。在一个球面上任选一些点用不相交的线把它们连接起来，这样球面就被这些线分成许多块。在拓扑变换下，点、线、块的数目仍和原来的数目一样，这就是拓扑等价。一般地说，对于任意形状的闭曲面，只要不把曲面撕裂或割破，他的变换就是拓扑变幻，就存在拓扑等价。应该指出，环面不具有这个性质。比如像左图那样，把环面切开，它不至于分成许多块，只是变成一个弯曲的圆桶形，对于这种情况，我们就说球面不能拓扑的变成环面。所以球面和环面在拓扑学中是不同的曲面。直线上的点和线的结合关系、顺序关系，在拓扑变换下不变，这是拓扑性质。在拓扑学中曲线和曲面的闭合性质也是拓扑性质。[推荐]数学各个研究方向简介我们通常讲的平面、曲面通常有两个面，就像一张纸有两个面一样。但德国数学家莫比乌斯(1790～1868)在1858年发现了莫比乌斯曲面。这种曲面就不能用不同的颜色来涂满两个侧面。拓扑变换的不变性、不变量还有很多，这里不在介绍。拓扑学建立后，由于其它数学学科的发展需要，它也得到了迅速的发展。特别是黎曼创立黎曼几何以后，他把拓扑学概念作为分析函数论的基础，更加促进了拓扑学的进展。二十世纪以来，集合论被引进了拓扑学，为拓扑学开拓了新的面貌。拓扑学的研究就变成了关于任意点集的对应的概念。拓扑学中一些需要精确化描述的问题都可以应用集合来论述。因为大量自然现象具有连续性，所以拓扑学具有广泛联系各种实际事物的可能性。通过拓扑学的研究，可以阐明空间的集合结构，从而掌握空间之间的函数关系。本世纪三十年代以后，数学家对拓扑学的研究更加深入，提出了许多全新的概念。比如，一致性结构概念、抽象距概念和近似空间概念等等。有一门数学分支叫做微分几何，是用微分工具来研究取线、曲面等在一点附近的弯曲情况，而拓扑学是研究曲面的全局联系的情况，因此，这两门学科应该存在某种本质的联系。1945年，美籍中国数学家陈省身建立了代数拓扑和微分几何的联系，并推进了整体几何学的发展。拓扑学发展到今天，在理论上已经十分明显分成了两个分支。一个分支是偏重于用分析的方法来研究的，叫做点集拓扑学，或者叫做分析拓扑学。另一个分支是偏重于用代数方法来研究的，叫做代数拓扑。现在，这两个分支又有统一的趋势。 3. 射影几何射影几何是研究图形的射影性质，即它们经过射影变换后，依然保持不变的图形性质的几何学分支学科。一度也叫做投影几何学，在经典几何学中，射影几何处于一种特殊的地位，通过它可以把其他一些几何学联系起来。 3.1 射影几何的发展简况十七世纪，当笛卡儿和费尔马创立的解析几何问世的时候，还有一门几何学同时出现在人们的面前。这门几何学和画图有很密切的关系，它的某些概念早在古希腊时期就曾经引起一些学者的注意，欧洲文艺复兴时期透视学的兴起，给这门几何学的产生和成长准备了充分的条件。这门几何学就是射影几何学。基于绘图学和建筑学的需要，古希腊几何学家就开始研究透视法，也就是投影和截影。早在公元前200年左右，阿波罗尼奥斯就曾把二次曲线作为正圆锥面的截线来研究。在4世纪帕普斯的著作中，出现了帕普斯定理。在文艺复兴时期，人们在绘画和建筑艺术方面非常注意和大力研究如何在平面上表现实物的图形。那时候，人们发现，一个画家要把一个事物画在一块画布上就好比是用自己的眼睛当作投影中心，把实物的影子影射到画布上去，然后再描绘出来。在这个过程中，被描绘下来的像中的各个元素的相对大小和位置关系，有的变化了，有的却保持不变。这样就促使了数学家对图形在中心投影下的性质进行研究，因而就逐渐产生了许多过去没有的新的概念和理论，形成了射影几何这门学科。射影几何真正成为独立的学科、成为几何学的一个重要分支，主要是在十七世纪。在17世纪初期，开普勒最早引进了无穷远点概念。稍后，为这门学科建立而做出了重要贡献的是两位法国数学家——笛沙格和帕斯卡。笛沙格是一个自学成才的数学家，他年轻的时候当过陆军军官，后来钻研工程技术，成了一名工程师和建筑师，他很不赞成为理论而搞理论，决心用新的方法来证明圆锥曲线的定理。1639年，他出版了主要著作《试论圆锥曲线和平面的相交所得结果的初稿》，书中他引入了许多几何学的新概念。他的朋友笛卡尔、帕斯卡、费尔马都很推崇他的著作，费尔马甚至认为他是圆锥曲线理论的真正奠基人。迪沙格在他的著作中，把直线看作是具有无穷大半径的圆，而曲线的切线被看作是割线的极限，这些概念都是射影几何学的基础。用他的名字命名的迪沙格定理：“如果两个三角形对应顶点连线共点，那么对应边的交点共线，反之也成立”，就是射影几何的基本定理。帕斯卡也为射影几何学的早期工作做出了重要的贡献，1641年，他发现了一条定理：“内接于二次曲线的六边形的三双对边的交点共线。”这条定理叫做帕斯卡六边形定理，也是射影几何学中的一条重要定理。1658年，他写了《圆锥曲线论》一书，书中很多定理都是射影几何方面的内容。迪沙格和他是朋友，曾经敦促他搞透视学方面的研究，并且建议他要把圆锥曲线的许多性质简化成少数几个基本命题作为目标。帕斯卡接受了这些建议。后来他写了许多有关射影几何方面的小册子。不过迪沙格和帕斯卡的这些定理，只涉及关联性质而不涉及度量性质(长度、角度、面积)。但他们在证明中却用到了长度概念，而不是用严格的射影方法，他们也没有意识到，自己的研究方向会导致产生一个新的几何体系射影几何。他们所用的是综合法，随着解析几何和微积分的创立，综合法让位于解析法，射影几何的探讨也中断了。射影几何的主要奠基人是19世纪的彭赛列。他是画法几何的创始人蒙日的学生。蒙日带动了他的许多学生用综合法研究几何。由于迪沙格和帕斯卡等的工作被长期忽视了，前人的许多工作他们不了解，不得不重新再做。1822年，彭赛列发表了射影几何的第一部系统著作。他是认识到射影几何是一个新的数学分支的第一个数学家。他通过几何方法引进无穷远虚圆点，研究了配极对应并用它来确立对偶原理。稍后，施泰纳研究了利用简单图形产生较复杂图形的方法，线素二次曲线概念也是他引进的。为了摆脱坐标系对度量概念的依赖，施陶特通过几何作图来建立直线上的点坐标系，进而使交比也不依赖于长度概念。由于忽视了连续公理的必要性，他建立坐标系的做法还不完善，但却迈出了决定性的一步。另—方面，运用解析法来研究射影几何也有长足进展。首先是莫比乌斯创建一种齐次坐标系，把变换分为全等，相似，仿射，直射等类型，给出线束中四条线交比的度量公式等。接着，普吕克引进丁另一种齐次坐标系，得到了平面上无穷远线的方程，无穷远圆点的坐标。他还引进了线坐标概念，于是从代数观点就自然得到了对偶原理，并得到了关于一般线素曲线的一些概念。在19世纪前半叶的几何研究中，综合法和解析法的争论异常激烈；有些数学家完全否定综合法，认为它没有前途，而一些几何学家，如沙勒，施图迪和施泰纳等，则坚持用综合法而排斥解析法。还有一些人，如彭赛列，虽然承认综合法有其局限性，在研究过程中也难免借助于代数，但在著作中总是用综合法来论证。他们的努力使综合射影几何形成一个优美的体系，而且用综合法也确实形象鲜明，有些问题论证直接而简洁。1882年帕施建成第一个严格的射影几何演绎体系。射影几何学的发展和其他数学分支的发展有密切的关系，特别是“群”的概念产生以后，也被引进了射影几何学，对这门几何学的研究起了促进作用。把各种几何和变换群相联系的是克莱因，他在埃尔朗根纲领中提出了这个观点，并把几种经典几何看作射影几何的子几何，使这些几何之间的关系变得十分明朗。这个纲领产生了巨大影响。但有些几何，如黎曼几何，不能纳入这个分类法。后来嘉当等在拓广几何分类的方法中作出了新的贡献。 3.2 射影几何学的内容概括的说，射影几何学是几何学的一个重要分支学科，它是专门研究图形的位置关系的，也是专门用来讨论在把点投影到直线或者平面上的时候，图形的不变性质的科学。在射影几何学中，把无穷远点看作是“理想点”。通常的直线再加上一个无穷点就是无穷远直线，如果一个平面内两条直线平行，那么这两条直线就交于这两条直线共有的无穷远点。通过同一无穷远点的所有直线平行。在引入无穷远点和无穷远直线后，原来普通点和普通直线的结合关系依然成立，而过去只有两条直线不平行的时候才能求交点的限制就消失了。由于经过同一个无穷远点的直线都平行，因此中心射影和平行射影两者就可以统一了。平行射影可以看作是经过无穷远点的中心投影了。这样凡是利用中心投影或者平行投影把一个图形映成另一个图形的映射，就都可以叫做射影变换了。射影变换有两个重要的性质：首先，射影变换使点列变点列，直线变直线，线束变线束，点和直线的结合性是射影变换的不变性；其次，射影变换下，交比不变。交比是射影几何中重要的概念，用它可以说明两个平面点之间的射影对应。在射影几何里，把点和直线叫做对偶元素，把“过一点作一直线”和“在一直线上取一点”叫做对偶运算。在两个图形中，它们如果都是由点和直线组成，把其中一图形里的各元素改为它的对偶元素，各运算改为它的对偶运算，结果就得到另一个图形。这两个图形叫做对偶图形。在一个命题中叙述的内容只是关于点、直线和平面的位置，可把各元素改为它的对偶元素，各运算改为它的对偶运算的时候，结果就得到另一个命题。这两个命题叫做对偶命题。这就是射影几何学所特有的对偶原则。在射影平面上，如果一个命题成立，那么它的对偶命题也成立，这叫做平面对偶原则。同样，在射影空间里，如果一个命题成立，那么它的对偶命题也成立，叫做空间对偶原则。研究在射影变换下二次曲线的不变性质，也是射影几何学的一项重要内容。如果就几何学内容的多少来说，射影几何学&lt; 仿射几何学&lt; 欧氏几何学，这就是说欧氏几何学的内容最丰富，而射影几何学的内容最贫乏。比如在欧氏几何学里可以讨论仿射几何学的对象(如简比、平行性等)和射影几何学的对象(如四点的交比等)，反过来，在射影几何学里不能讨论图形的仿射性质，而在仿射几何学里也不能讨论图形的度量性质。1872年，德国数学家克莱因在爱尔朗根大学提出著名的《爱尔朗根计划书》中提出用变换群对几何学进行分类，就是凡是一种变换，它的全体能组成“群”，就有相应的几何学，而在每一种几何学里，主要研究在相应的变换下的不变量和不变性。 4. 常微分方程4.1 微分方程的概念方程对于学过中学数学的人来说是比较熟悉的；在初等数学中就有各种各样的方程，比如线性方程、二次方程、高次方程、指数方程、对数方程、三角方程和方程组等等。这些方程都是要把研究的问题中的已知数和未知数之间的关系找出来，列出包含一个未知数或几个未知数的一个或者多个方程式，然后取求方程的解。但是在实际工作中，常常出现一些特点和以上方程完全不同的问题。比如：物质在一定条件下的运动变化，要寻求它的运动、变化的规律；某个物体在重力作用下自由下落，要寻求下落距离随时间变化的规律；火箭在发动机推动下在空间飞行，要寻求它飞行的轨道，等等。物质运动和它的变化规律在数学上是用函数关系来描述的，因此，这类问题就是要去寻求满足某些条件的一个或者几个未知函数。也就是说，凡是这类问题都不是简单地去求一个或者几个固定不变的数值，而是要求一个或者几个未知的函数。 解这类问题的基本思想和初等数学解方程的基本思想很相似，也是要把研究的问题中已知函数和未知函数之间的关系找出来，从列出的包含未知函数的一个或几个方程中去求得未知函数的表达式。但是无论在方程的形式、求解的具体方法、求出解的性质等方面，都和初等数学中的解方程有许多不同的地方。 在数学上，解这类方程，要用到微分和导数的知识。因此，凡是表示未知函数的导数以及自变量之间的关系的方程，就叫做微分方程。 微分方程差不多是和微积分同时先后产生的，苏格兰数学家耐普尔创立对数的时候，就讨论过微分方程的近似解。牛顿在建立微积分的同时，对简单的微分方程用级数来求解。后来瑞士数学家雅各布·贝努利、欧拉、法国数学家克雷洛、达朗贝尔、拉格朗日等人又不断地研究和丰富了微分方程的理论。 常微分方程的形成与发展是和力学、天文学、物理学，以及其他科学技术的发展密切相关的。数学的其他分支的新发展，如复变函数、李群、组合拓扑学等，都对常微分方程的发展产生了深刻的影响，当前计算机的发展更是为常微分方程的应用及理论研究提供了非常有力的工具。牛顿研究天体力学和机械力学的时候，利用了微分方程这个工具，从理论上得到了行星运动规律。后来，法国天文学家勒维烈和英国天文学家亚当斯使用微分方程各自计算出那时尚未发现的海王星的位置。这些都使数学家更加深信微分方程在认识自然、改造自然方面的巨大力量。微分方程的理论逐步完善的时候，利用它就可以精确地表述事物变化所遵循的基本规律，只要列出相应的微分方程，有了解方程的方法。微分方程也就成了最有生命力的数学分支。 4.2 常微分方程的内容如果在一个微分方程中出现的未知函数只含一个自变量，这个方程就叫做常微分方程，也可以简单地叫做微分方程。 一般地说，n 阶微分方程的解含有 n个任意常数。也就是说，微分方程的解中含有任意常数的个数和方程的解数相同，这种解叫做微分方程的通解。通解构成一个函数族。 如果根据实际问题要求出其中满足某种指定条件的解来，那么求这种解的问题叫做定解问题，对于一个常微分方程的满足定解条件的解叫做特解。对于高阶微分方程可以引入新的未知函数，把它化为多个一阶微分方程组。 4.2 常微分方程的特点常微分方程的概念、解法、和其它理论很多，比如，方程和方程组的种类及解法、解的存在性和唯一性、奇解、定性理论等等。下面就方程解的有关几点简述一下，以了解常微分方程的特点。 求通解在历史上曾作为微分方程的主要目标，一旦求出通解的表达式，就容易从中得到问题所需要的特解。也可以由通解的表达式，了解对某些参数的依赖情况，便于参数取值适宜，使它对应的解具有所需要的性能，还有助于进行关于解的其他研究。 后来的发展表明，能够求出通解的情况不多，在实际应用中所需要的多是求满足某种指定条件的特解。当然，通解是有助于研究解的属性的，但是人们已把研究重点转移到定解问题上来。一个常微分方程是不是有特解呢？如果有，又有几个呢？这是微分方程论中一个基本的问题，数学家把它归纳成基本定理，叫做存在和唯一性定理。因为如果没有解，而我们要去求解，那是没有意义的；如果有解而又不是唯一的，那又不好确定。因此，存在和唯一性定理对于微分方程的求解是十分重要的。 大部分的常微分方程求不出十分精确的解，而只能得到近似解。当然，这个近似解的精确程度是比较高的。另外还应该指出，用来描述物理过程的微分方程，以及由试验测定的初始条件也是近似的，这种近似之间的影响和变化还必须在理论上加以解决。 现在，常微分方程在很多学科领域内有着重要的应用，自动控制、各种电子学装置的设计、弹道的计算、飞机和导弹飞行的稳定性的研究、化学反应过程稳定性的研究等。这些问题都可以化为求常微分方程的解，或者化为研究解的性质的问题。应该说，应用常微分方程理论已经取得了很大的成就，但是，它的现有理论也还远远不能满足需要，还有待于进一步的发展，使这门学科的理论更加完善。 5. 非欧几何5.1 非欧几何的来源非欧几何学是一门大的数学分支，一般来讲 ，他有广义、狭义、通常意义这三个方面的不同含义。所谓广义式泛指一切和欧几里的几何学不同的几何学，狭义的非欧几何只是指罗式几何来说的，至于通常意义的非欧几何，就是指罗式几何和黎曼几何这两种几何。欧几里得的《几何原本》提出了五条公设，长期以来，数学家们发现第五公设和前四个公设比较起来，显得文字叙述冗长，而且也不那么显而易见。有些数学家还注意到欧几里得在《几何原本》一书中直到第二十九个命题中才用到，而且以后再也没有使用。也就是说，在《几何原本》中可以不依靠第五公设而推出前二十八个命题。因此，一些数学家提出，第五公设能不能不作为公设，而作为定理？能不能依靠前四个公设来证明第五公设？这就是几何发展史上最著名的，争论了长达两千多年的关于“平行线理论”的讨论。由于证明第五公设的问题始终得不到解决，人们逐渐怀疑证明的路子走的对不对？第五公设到底能不能证明？[推荐]数学各个研究方向简介到了十九世纪二十年代，俄国喀山大学教授罗巴切夫斯基在证明第五公设的过程中，他走了另一条路子。他提出了一个和欧式平行公理相矛盾的命题,用它来代替第五公设，然后与欧式几何的前四个公设结合成一个公理系统，展开一系列的推理。他认为如果这个系统为基础的推理中出现矛盾，就等于证明了第五公设。我们知道，这其实就是数学中的反证法。但是，在他极为细致深入的推理过程中，得出了一个又一个在直觉上匪夷所思，但在逻辑上毫无矛盾的命题。最后，罗巴切夫斯基得出两个重要的结论： 第一，第五公设不能被证明。第二，在新的公理体系中展开的一连串推理，得到了一系列在逻辑上无矛盾的新的定理，并形成了新的理论。这个理论像欧式几何一样是完善的、严密的几何学。 这种几何学被称为罗巴切夫斯基几何，简称罗氏几何。这是第一个被提出的非欧几何学。从罗巴切夫斯基创立的非欧几何学中，可以得出一个极为重要的、具有普遍意义的结论：逻辑上互不矛盾的一组假设都有可能提供一种几何学。几乎在罗巴切夫斯基创立非欧几何学的同时，匈牙利数学家鲍耶·雅诺什也发现了第五公设不可证明和非欧几何学的存在。鲍耶在研究非欧几何学的过程中也遭到了家庭、社会的冷漠对待。他的父亲——数学家鲍耶·法尔卡什认为研究第五公设是耗费精力劳而无功的蠢事，劝他放弃这种研究。但鲍耶·雅诺什坚持为发展新的几何学而辛勤工作。终于在1832年，在他的父亲的一本著作里，以附录的形式发表了研究结果。那个时代被誉为“数学王子”的高斯也发现第五公设不能证明，并且研究了非欧几何。但是高斯害怕这种理论会遭到当时教会力量的打击和迫害，不敢公开发表自己的研究成果，只是在书信中向自己的朋友表示了自己的看法，也不敢站出来公开支持罗巴切夫斯基、鲍耶他们的新理论。 5.2 罗氏几何（双曲几何）罗式几何学的公理系统和欧式几何学不同的地方仅仅是把欧式几何平行公理用“从直线外一点，至少可以做两条直线和这条直线平行”来代替，其他公理基本相同。由于平行公理不同，经过演绎推理却引出了一连串和欧式几何内容不同的新的几何命题。我们知道，罗式几何除了一个平行公理之外采用了欧式几何的一切公理。因此，凡是不涉及到平行公理的几何命题，在欧式几何中如果是正确的，在罗式几何中也同样是正确的。在欧式几何中，凡涉及到平行公理的命题，再罗式几何中都不成立，他们都相应地含有新的意义。下面举几个例子加以说明： 欧式几何 同一直线的垂线和斜线相交。垂直于同一直线的两条直线或向平行。 存在相似的多边形。过不在同一直线上的三点可以做且仅能做一个圆 罗氏几何 同一直线的垂线和斜线不一定相交。垂直于同一直线的两条直线，当两端延长的时候，离散到无穷。不存在相似的多边形。过不在同一直线上的三点，不一定能做一个圆。 从上面所列举得罗式几何的一些命题可以看到，这些命题和我们所习惯的直观形象有矛盾。所以罗式几何中的一些几何事实没有象欧式几何那样容易被接受。但是，数学家们经过研究，提出可以用我们习惯的欧式几何中的事实作一个直观“模型”来解释罗式几何是正确的。1868年，意大利数学家贝特拉米发表了一篇著名论文《非欧几何解释的尝试》，证明非欧几何可以在欧几里得空间的曲面（例如拟球曲面）上实现。这就是说，非欧几何命题可以“翻译”成相应的欧几里得几何命题，如果欧几里得几何没有矛盾，非欧几何也就自然没有矛盾。人们既然承认欧几里是没有矛盾的，所以也就自然承认非欧几何没有矛盾了。直到这时，长期无人问津的非欧几何才开始获得学术界的普遍注意和深入研究，罗巴切夫斯基的独创性研究也就由此得到学术界的高度评价和一致赞美，他本人则被人们赞誉为“几何学中的哥白尼”。 5.3 黎曼几何（椭圆几何）欧氏几何与罗氏几何中关于结合公理、顺序公理、连续公理及合同公理都是相同的，只是平行公理不一样。欧式几何讲“过直线外一点有且只有一条直线与已知直线平行”。罗氏几何讲“过直线外一点至少存在两条直线和已知直线平行”。那么是否存在这样的几何“过直线外一点，不能做直线和已知直线平行”？黎曼几何就回答了这个问题。黎曼几何是德国数学家黎曼创立的。他在1851年所作的一篇论文《论几何学作为基础的假设》中明确的提出另一种几何学的存在，开创了几何学的一片新的广阔领域。黎曼几何中的一条基本规定是：在同一平面内任何两条直线都有公共点(交点)。在黎曼几何学中不承认平行线的存在，它的另一条公设讲：直线可以无限演唱，但总的长度是有限的。黎曼几何的模型是一个经过适当“改进”的球面。近代黎曼几何在广义相对论里得到了重要的应用。在物理学家爱因斯坦的广义相对论中的空间几何就是黎曼几何。在广义相对论里，爱因斯坦放弃了关于时空均匀性的观念，他认为时空只是在充分小的空间里以一种近似性而均匀的，但是整个时空却是不均匀的。在物理学中的这种解释，恰恰是和黎曼几何的观念是相似的。此外，黎曼几何在数学中也是一个重要的工具。它不仅是微分几何的基础，也应用在微分方程、变分法和复变函数论等方面。 5.4 三种几何的关系欧氏几何、罗氏几何、黎曼几何是三种各有区别的几何。这三中几何各自所有的命题都构成了一个严密的公理体系，各公理之间满足和谐性、完备性和独立性。因此这三种几何都是正确的。在我们这个不大不小、不远不近的空间里，也就是在我们的日常生活中，欧式几何是适用的；在宇宙空间中或原子核世界，罗氏几何更符合客观实际；在地球表面研究航海、航空等实际问题中，黎曼几何更准确一些。 6. 计算数学6.1 什么是计算数学现代的科学技术发展十分迅速，他们有一个共同的特点，就是都有大量的数据问题。比如，发射一颗探测宇宙奥秘的卫星，从卫星世纪开始到发射、回收为止，科学家和工程技术人员、工人就要对卫星的总体、部件进行全面的设计和生产，要对选用的火箭进行设计和生产，这里面就有许许多多的数据要进行准确的计算。发射和回收的时候，又有关于发射角度、轨道、遥控、回收下落角度等等需要进行精确的计算。有如，在高能加速器里进行高能物理试验，研究具有很高能量的基本粒子的性质、它们之间的相互作用和转化规律，这里面也有大量的数据计算问题。计算问题可以数是现代社会各个领域普遍存在的共同问题，工业、农业、交通运输、医疗卫生、文化教育等等，那一行那一业都有许多数据需要计算，通过数据分析，以便掌握事物发展的规律。研究计算问题的解决方法和有关数学理论问题的一门学科就叫做计算数学。计算数学属于应用数学的范畴，它主要研究有关的数学和逻辑问题怎样由计算机加以有效解决。 6.2 计算数学的内容计算数学也叫做数值计算方法或数值分析。主要内容包括代数方程、线性代数方程组、微分方程的数值解法，函数的数值逼近问题，矩阵特征值的求法，最优化计算问题，概率统计计算问题等等，还包括解的存在性、唯一性、收敛性和误差分析等理论问题。我们知道五次及五次以上的代数方程不存在求根公式，因此，要求出五次以上的高次代数方程的解，一般只能求它的近似解，求近似解的方法就是数值分析的方法。对于一般的超越方程，如对数方程、三角方程等等也只能采用数值分析的办法。怎样找出比较简洁、误差比较小、花费时间比较少的计算方法是数值分析的主要课题。在求解方程的办法中，常用的办法之一是迭代法，也叫做逐次逼近法。迭代法的计算是比较简单的，是比较容易进行的。迭代法还可以用来求解线性方程组的解。求方程组的近似解也要选择适当的迭代公式，使得收敛速度快，近似误差小。在线性代数方程组的解法中，常用的有塞德尔迭代法、共轭斜量法、超松弛迭代法等等。此外，一些比较古老的普通消去法，如高斯法、追赶法等等，在利用计算机的条件下也可以得到广泛的应用。在计算方法中，数值逼近也是常用的基本方法。数值逼近也叫近似代替，就是用简单的函数去代替比较复杂的函数，或者代替不能用解析表达式表示的函数。数值逼近的基本方法是插值法。初等数学里的三角函数表，对数表中的修正值，就是根据插值法制成的。 在遇到求微分和积分的时候，如何利用简单的函数去近似代替所给的函数，以便容易求到和求积分，也是计算方法的一个主要内容。微分方程的数值解法也是近似解法。常微分方程的数值解法由欧拉法、预测校正法等。偏微分方程的初值问题或边值问题，目前常用的是有限差分法、有限元素法等。有限差分法的基本思想是用离散的、只含有限个未知数的差分方程去代替连续变量的微分方程和定解条件。求出差分方程的解法作为求偏微分方程的近似解。 有限元素法是近代才发展起来的，它是以变分原理和剖分差值作为基础的方法。在解决椭圆形方程边值问题上得到了广泛的应用。穆恰，有许多人正在研究用有限元素法来解双曲形和抛物形的方程。 计算数学的内容十分丰富，它在科学技术中正发挥着越来越大的作用。 7. 运筹学在中国战国时期，曾经有过一次流传后世的赛马比赛，相信大家都知道，这就是田忌赛马。田忌赛马的故事说明在已有的条件下，经过筹划、安排，选择一个最好的方案，就会取得最好的效果。可见，筹划安排是十分重要的。 现在普遍认为，运筹学是近代应用数学的一个分支，主要是将生产、管理等事件中出现的一些带有普遍性的运筹问题加以提炼，然后利用数学方法进行解决。前者提供模型，后者提供理论和方法。 运筹学的思想在古代就已经产生了。敌我双方交战，要克敌制胜就要在了解双方情况的基础上，做出最优的对付敌人的方法，这就是“运筹帷幄之中，决胜千里之外”的说法。但是作为一门数学学科，用纯数学的方法来解决最优方法的选择安排，却是晚多了。也可以说，运筹学是在二十世纪四十年代才开始兴起的一门分支。 运筹学主要研究经济活动和军事活动中能用数量来表达的有关策划、管理方面的问题。当然，随着客观实际的发展，运筹学的许多内容不但研究经济和军事活动，有些已经深入到日常生活当中去了。运筹学可以根据问题的要求，通过数学上的分析、运算，得出各种各样的结果，最后提出综合性的合理安排，已达到最好的效果。 运筹学作为一门用来解决实际问题的学科，在处理千差万别的各种问题时，一般有以下几个步骤：确定目标、制定方案、建立模型、制定解法。 虽然不大可能存在能处理及其广泛对象的运筹学，但是在运筹学的发展过程中还是形成了某些抽象模型，并能应用解决较广泛的实际问题。 随着科学技术和生产的发展，运筹学已渗入很多领域里，发挥了越来越重要的作用。运筹学本身也在不断发展，现在已经是一个包括好几个分支的数学部门了。比如：数学规划（又包含线性规划；非线性规划；整数规划；组合规划等）、图论、网络流、决策分析、排队论、可靠性数学理论、库存论、对策论、搜索论、模拟等等。 7.1 各分支简介数学规划的研究对象是计划管理工作中有关安排和估值的问题，解决的主要问题是在给定条件下，按某一衡量指标来寻找安排的最优方案。它可以表示成求函数在满足约束条件下的极大极小值问题。 数学规划和古典的求极值的问题有本质上的不同，古典方法只能处理具有简单表达式，和简单约束条件的情况。而现代的数学规划中的问题目标函数和约束条件都很复杂，而且要求给出某种精确度的数字解答，因此算法的研究特别受到重视。 这里最简单的一种问题就是线性规划。如果约束条件和目标函数都是呈线性关系的就叫线性规划。要解决线性规划问题，从理论上讲都要解线性方程组，因此解线性方程组的方法，以及关于行列式、矩阵的知识，就是线性规划中非常必要的工具。 线性规划及其解法—单纯形法的出现，对运筹学的发展起了重大的推动作用。许多实际问题都可以化成线性规划来解决，而单纯形法有是一个行之有效的算法，加上计算机的出现，使一些大型复杂的实际问题的解决成为现实。 非线性规划是线性规划的进一步发展和继续。许多实际问题如设计问题、经济平衡问题都属于非线性规划的范畴。非线性规划扩大了数学规划的应用范围，同时也给数学工作者提出了许多基本理论问题，使数学中的如凸分析、数值分析等也得到了发展。还有一种规划问题和时间有关，叫做“动态规划”。近年来在工程控制、技术物理和通讯中的最佳控制问题中，已经成为经常使用的重要工具。 排队论是运筹学的又一个分支，它有叫做随机服务系统理论。它的研究目的是要回答如何改进服务机构或组织被服务的对象，使得某种指标达到最优的问题。比如一个港口应该有多少个码头，一个工厂应该有多少维修人员等。 排队论最初是在二十世纪初由丹麦工程师艾尔郎关于电话交换机的效率研究开始的，在第二次世界大战中为了对飞机场跑道的容纳量进行估算，它得到了进一步的发展，其相应的学科更新论、可靠性理论等也都发展起来。 因为排队现象是一个随机现象，因此在研究排队现象的时候，主要采用的是研究随机现象的概率论作为主要工具。此外，还有微分和微分方程。排队论把它所要研究的对象形象的描述为顾客来到服务台前要求接待。如果服务台以被其它顾客占用，那么就要排队。另一方面，服务台也时而空闲、时而忙碌。就需要通过数学方法求得顾客的等待时间、排队长度等的概率分布。排队论在日常生活中的应用是相当广泛的，比如水库水量的调节、生产流水线的安排，铁路分成场的调度、电网的设计等等。 对策论也叫博弈论，前面讲的田忌赛马就是典型的博弈论问题。作为运筹学的一个分支，博弈论的发展也只有几十年的历史。系统地创建这门学科的数学家，现在一般公认为是美籍匈牙利数学家、计算机之父——冯·诺依曼。 最初用数学方法研究博弈论是在国际象棋中开始的——如何确定取胜的着法。由于是研究双方冲突、制胜对策的问题，所以这门学科在军事方面有着十分重要的应用。近年来，数学家还对水雷和舰艇、歼击机和轰炸机之间的作战、追踪等问题进行了研究，提出了追逃双方都能自主决策的数学理论。近年来，随着人工智能研究的进一步发展，对博弈论提出了更多新的要求。搜索论是由于第二次世界大战中战争的需要而出现的运筹学分支。主要研究在资源和探测手段受到限制的情况下，如何设计寻找某种目标的最优方案，并加以实施的理论和方法。在第二次世界大战中，同盟国的空军和海军在研究如何针对轴心国的潜艇活动、舰队运输和兵力部署等进行甄别的过程中产生的。搜索论在实际应用中也取得了不少成效，例如二十世纪六十年代，美国寻找在大西洋失踪的核潜艇“打谷者号”和“蝎子号”，以及在地中海寻找丢失的氢弹，都是依据搜索论获得成功的。运筹学有广阔的应用领域，它已渗透到诸如服务、库存、搜索、人口、对抗、控制、时间表、资源分配、厂址定位、能源、设计、生产、可靠性、等各个方面。 8. 分形几何8.1 分形几何的产生客观自然界中许多事物，具有自相似的“层次”结构，在理想情况下，甚至具有无穷层次。适当的放大或缩小几何尺寸，整个结构并不改变。不少复杂的物理现象，背后就是反映着这类层次结构的分形几何学。 客观事物有它自己的特征长度，要用恰当的尺度去测量。用尺来测量万里长城，嫌太短；用尺来测量大肠杆菌，又嫌太长。从而产生了特征长度。还有的事物没有特征尺度，就必须同时考虑从小到大的许许多多尺度（或者叫标度），这叫做“无标度性”的问题。 如物理学中的湍流，湍流是自然界中普遍现象，小至静室中缭绕的轻烟，巨至木星大气中的涡流，都是十分紊乱的流体运动。流体宏观运动的能量，经过大、中、小、微等许许多度尺度上的漩涡，最后转化成分子尺度上的热运动，同时涉及大量不同尺度上的运动状态，就要借助“无标度性”解决问题，湍流中高漩涡区域，就需要用分形几何学。 在二十世纪七十年代，法国数学家曼德尔勃罗特在他的著作中探讨了英国的海岸线有多长？这个问题这依赖于测量时所使用的尺度。 如果用公里作测量单位，从几米到几十米的一些曲折会被忽略；改用米来做单位，测得的总长度会增加，但是一些厘米量级以下的就不能反映出来。由于涨潮落潮使海岸线的水陆分界线具有各种层次的不规则性。海岸线在大小两个方向都有自然的限制，取不列颠岛外缘上几个突出的点，用直线把它们连起来，得到海岸线长度的一种下界。使用比这更长的尺度是没有意义的。还有海沙石的最小尺度是原子和分子，使用更小的尺度也是没有意义的。在这两个自然限度之间，存在着可以变化许多个数量级的“无标度”区，长度不是海岸线的定量特征，就要用分维。 数学家寇赫从一个正方形的“岛”出发，始终保持面积不变，把它的“海岸线”变成无限曲线，其长度也不断增加，并趋向于无穷大。以后可以看到，分维才是“寇赫岛”海岸线的确切特征量，即海岸线的分维均介于1到2之间。 这些自然现象，特别是物理现象和分形有着密切的关系，银河系中的若断若续的星体分布，就具有分维的吸引子。多孔介质中的流体运动和它产生的渗流模型，都是分形的研究对象。这些促使数学家进一步的研究，从而产生了分形几何学。 电子计算机图形显示协助了人们推开分形几何的大门。这座具有无穷层次结构的宏伟建筑，每一个角落里都存在无限嵌套的迷宫和回廊，促使数学家和科学家深入研究。法国数学家曼德尔勃罗特这位计算机和数学兼通的人物，对分形几何产生了重大的推动作用。他在1975、1977和1982年先后用法文和英文出版了三本书，特别是《分形——形、机遇和维数》以及《自然界中的分形几何学》，开创了新的数学分支——分形几何学。 8.2 分形几何的内容分形几何学的基本思想是：客观事物具有自相似的层次结构，局部与整体在形态、功能、信息、时间、空间等方面具有统计意义上的相似性，成为自相似性。例如，一块磁铁中的每一部分都像整体一样具有南北两极，不断分割下去，每一部分都具有和整体磁铁相同的磁场。这种自相似的层次结构，适当的放大或缩小几何尺寸，整个结构不变。 维数是几何对象的一个重要特征量，它是几何对象中一个点的位置所需的独立坐标数目。在欧氏空间中，人们习惯把空间看成三维的，平面或球面看成二维，而把直线或曲线看成一维。也可以稍加推广，认为点是零维的，还可以引入高维空间，对于更抽象或更复杂的对象，只要每个局部可以和欧氏空间对应，也容易确定维数。但通常人们习惯于整数的维数。 分形理论认为维数也可以是分数，这类维数是物理学家在研究混沌吸引子等理论时需要引入的重要概念。为了定量地描述客观事物的“非规则”程度，1919年，数学家从测度的角度引入了维数概念，将维数从整数扩大到分数，从而突破了一般拓扑集维数为整数的界限。 维数和测量有着密切的关系，下面我们举例说明一下分维的概念。当我们画一根直线，如果我们用 0维的点来量它，其结果为无穷大，因为直线中包含无穷多个点；如果我们用一块平面来量它，其结果是 0，因为直线中不包含平面。那么，用怎样的尺度来量它才会得到有限值哪？看来只有用与其同维数的小线段来量它才会得到有限值，而这里直线的维数为 1(大于0、小于2)。 对于我们上面提到的“寇赫岛”曲线，其整体是一条无限长的线折叠而成，显然，用小直线段量，其结果是无穷大，而用平面量，其结果是 0(此曲线中不包含平面)，那么只有找一个与“寇赫岛”曲线维数相同的尺子量它才会得到有限值，而这个维数显然大于 1、小于 2，那么只能是小数了，所以存在分维。经过计算“寇赫岛”曲线的维数是1.2618……。 8.3 分形几何学的应用分形几何学已在自然界与物理学中得到了应用。如在显微镜下观察落入溶液中的一粒花粉，会看见它不间断地作无规则运动(布朗运动)，这是花粉在大量液体分子的无规则碰撞(每秒钟多达十亿亿次)下表现的平均行为。布朗粒子的轨迹，由各种尺寸的折线连成。只要有足够的分辨率，就可以发现原以为是直线段的部分，其实由大量更小尺度的折线连成。这是一种处处连续，但又处处无导数的曲线。这种布朗粒子轨迹的分维是 2，大大高于它的拓扑维数 1。在某些电化学反应中，电极附近成绩的固态物质，以不规则的树枝形状向外增长。受到污染的一些流水中，粘在藻类植物上的颗粒和胶状物，不断因新的沉积而生长，成为带有许多须须毛毛的枝条状，就可以用分维。 自然界中更大的尺度上也存在分形对象。一枝粗干可以分出不规则的枝杈，每个枝杈继续分为细杈……，至少有十几次分支的层次，可以用分形几何学去测量。 有人研究了某些云彩边界的几何性质，发现存在从 1公里到1000公里的无标度区。小于 1公里的云朵，更受地形概貌影响，大于1000公里时，地球曲率开始起作用。大小两端都受到一定特征尺度的限制，中间有三个数量级的无标度区，这已经足够了。分形存在于这中间区域。 近几年在流体力学不稳定性、光学双稳定器件、化学震荡反映等试验中，都实际测得了混沌吸引子，并从实验数据中计算出它们的分维。学会从实验数据测算分维是最近的一大进展。分形几何学在物理学、生物学上的应用也正在成为有充实内容的研究领域。 9. 突变理论突变理论是20世纪70年代发展起来的一个新的数学分支。 9.1 突变理论的产生许多年来，自然界许多事物的连续的、渐变的、平滑的运动变化过程，都可以用微积分的方法给以圆满解决。例如，地球绕着太阳旋转，有规律地周而复始地连续不断进行，使人能及其精确地预测未来的运动状态，这就需要运用经典的微积分来描述。但是，自然界和社会现象中，还有许多突变和飞跃的过程，飞越造成的不连续性把系统的行为空间变成不可微的，微积分就无法解决。例如，水突然沸腾，冰突然融化，火山爆发，某地突然地震，房屋突然倒塌，病人突然死亡……。这种由渐变、量变发展为突变、质变的过程，就是突变现象，微积分是不能描述的。以前科学家在研究这类突变现象时遇到了各式各样的困难，其中主要困难就是缺乏恰当的数学工具来提供描述它们的数学模型。那么，有没有可能建立一种关于突变现象的一般性数学理论来描述各种飞跃和不连续过程呢？这迫使数学家进一步研究描述突变理论的飞跃过程，研究不连续性现象的数学理论。1972年法国数学家雷内·托姆在《结构稳定性和形态发生学》一书中，明确地阐明了突变理论，宣告了突变理论的诞生。 9.2 突变理论的内容突变理论主要以拓扑学为工具，以结构稳定性理论为基础，提出了一条新的判别突变、飞跃的原则：在严格控制条件下，如果质变中经历的中间过渡态是稳定的，那么它就是一个渐变过程。 比如拆一堵墙，如果从上面开始一块块地把砖头拆下来，整个过程就是结构稳定的渐变过程。如果从底脚开始拆墙，拆到一定程度，就会破坏墙的结构稳定性，墙就会哗啦一声，倒塌下来。这种结构不稳定性就是突变、飞跃过程。又如社会变革，从封建社会过渡到资本主义社会，法国大革命采用暴力来实现，而日本的明治维新就是采用一系列改革，以渐变方式来实现。 对于这种结构的稳定与不稳定现象，突变理论用势函数的洼存在表示稳定，用洼取消表示不稳定，并有自己的一套运算方法。例如，一个小球在洼底部时是稳定的，如果把它放在突起顶端时是不稳定的，小球就会从顶端处，不稳定滚下去，往新洼地过渡，事物就发生突变；当小球在新洼地底处，又开始新的稳定，所以势函数的洼存在与消失是判断事物的稳定性与不稳定性、渐变与突变过程的根据。 托姆的突变理论，就是用数学工具描述系统状态的飞跃，给出系统处于稳定态的参数区域，参数变化时，系统状态也随着变化，当参数通过某些特定位置时，状态就会发生突变。 突变理论提出一系列数学模型，用以解是自然界和社会现象中所发生的不连续的变化过程，描述各种现象为何从形态的一种形式突然地飞跃到根本不同的另一种形式。如岩石的破裂，桥梁的断裂，细胞的分裂，胚胎的变异，市场的破坏以及社会结构的激变……。 按照突变理论，自然界和社会现象中的大量的不连续事件，可以由某些特定的几何形状来表示。托姆指出，发生在三维空间和一维空间的四个因子控制下的突变，有七种突变类型：折迭突变、尖顶突变、燕尾突变、蝴蝶突变、双曲脐突变、椭圆脐形突变以及抛物脐形突变。例如，用大拇指和中指夹持一段有弹性的钢丝，使其向上弯曲，然后再用力压钢丝使其变形，当达到一定程度时，钢丝会突然向下弯曲，并失去弹性。这就是生活中常见的一种突变现象，它有两个稳定状态：上弯和下弯，状态由两个参数决定，一个是手指夹持的力(水平方向)，一个是钢丝的压力(垂直方向)，可用尖顶突变来描述。 尖顶突变和蝴蝶突变是几种质态之间能够进行可逆转的模型。自然界还有些过程是不可逆的，比如死亡是一种突变，活人可以变成死人，反过来却不行。这一类过程可以用折迭突变、燕尾突变等时函数最高奇次的模型来描述。所以，突变理论是用形象而精确的得数学模型来描述质量互变过程。 英国数学家奇曼教授称突变理论是“数学界的一项智力革命——微积分后最重要的发现”。他还组成一个研究团体，悉心研究，扩展应用。短短几年，论文已有四百多篇，可成为盛极一时，托姆为此成就而荣获当前国际数学界的最高奖——菲尔兹奖。 9.3 突变理论的应用突变理论在在自然科学的应用是相当广泛的。在物理学研究了相变、分叉、混沌与突变的关系，提出了动态系统、非线性力学系统的突变模型，解释了物理过程的可重复性是结构稳定性的表现。在化学中，用蝴蝶突变描述氢氧化物的水溶液，用尖顶突变描述水的液、气、固的变化等。在生态学中研究了物群的消长与生灭过程，提出了根治蝗虫的模型与方法。在工程技术中，研究了弹性结构的稳定性，通过桥梁过载导致毁坏的实际过程，提出最优结构设计……。 突变理论在社会现象的一个用归纳为某种量的突变问题，人们施加控制因素影响社会状态是有一定条件的，只有在控制因素达到临界点之前，状态才是可以控制的。一旦发生根本性的质变，它就表现为控制因素所无法控制的突变过程。还可以用突变理论对社会进行高层次的有效控制，为此就需要研究事物状态与控制因素之间的相互关系，以及稳定区域、非稳定区域、临界曲线的分布特点，还要研究突变的方向与幅度。 10. 模糊数学二十世纪六十年代，产生了模糊数学这门新兴学科。 10.1 模糊数学的产生现代数学是建立在集合论的基础上。集合论的重要意义就一个侧面看，在与它把数学的抽象能力延伸到人类认识过程的深处。一组对象确定一组属性，人们可以通过说明属性来说明概念（内涵），也可以通过指明对象来说明它。符合概念的那些对象的全体叫做这个概念的外延，外延其实就是集合。从这个意义上讲，集合可以表现概念，而集合论中的关系和运算又可以表现判断和推理，一切现实的理论系统都一可能纳入集合描述的数学框架。 但是，数学的发展也是阶段性的。经典集合论只能把自己的表现力限制在那些有明确外延的概念和事物上，它明确地限定：每个集合都必须由明确的元素构成，元素对集合的隶属关系必须是明确的，决不能模棱两可。对于那些外延不分明的概念和事物，经典集合论是暂时不去反映的，属于待发展的范畴。 在较长时间里，精确数学及随机数学在描述自然界多种事物的运动规律中，获得显著效果。但是，在客观世界中还普遍存在着大量的模糊现象。以前人们回避它，但是，由于现代科技所面对的系统日益复杂，模糊性总是伴随着复杂性出现。 各门学科，尤其是人文、社会学科及其它“软科学”的数学化、定量化趋向把模糊性的数学处理问题推向中心地位。更重要的是，随着电子计算机、控制论、系统科学的迅速发展，要使计算机能像人脑那样对复杂事物具有识别能力，就必须研究和处理模糊性。 我们研究人类系统的行为，或者处理可与人类系统行为相比拟的复杂系统，如航天系统、人脑系统、社会系统等，参数和变量甚多，各种因素相互交错，系统很复杂，它的模糊性也很明显。从认识方面说，模糊性是指概念外延的不确定性，从而造成判断的不确定性。 在日常生活中，经常遇到许多模糊事物，没有分明的数量界限，要使用一些模糊的词句来形容、描述。比如，比较年轻、高个、大胖子、好、漂亮、善、热、远……。在人们的工作经验中，往往也有许多模糊的东西。例如，要确定一炉钢水是否已经炼好，除了要知道钢水的温度、成分比例和冶炼时间等精确信息外，还需要参考钢水颜色、沸腾情况等模糊信息。因此，除了很早就有涉及误差的计算数学之外，还需要模糊数学。 人与计算机相比，一般来说，人脑具有处理模糊信息的能力，善于判断和处理模糊现象。但计算机对模糊现象识别能力较差，为了提高计算机识别模糊现象的能力，就需要把人们常用的模糊语言设计成机器能接受的指令和程序，以便机器能像人脑那样简洁灵活的做出相应的判断，从而提高自动识别和控制模糊现象的效率。这样，就需要寻找一种描述和加工模糊信息的数学工具，这就推动数学家深入研究模糊数学。所以，模糊数学的产生是有其科学技术与数学发展的必然性。 模糊数学的研究内容1965年，美国控制论专家、数学家查德发表了论文《模糊集合》，标志着模糊数学这门学科的诞生。模糊数学的研究内容主要有以下三个方面： 第一，研究模糊数学的理论，以及它和精确数学、随机数学的关系。察德以精确数学集合论为基础，并考虑到对数学的集合概念进行修改和推广。他提出用“模糊集合”作为表现模糊事物的数学模型。并在“模糊集合”上逐步建立运算、变换规律，开展有关的理论研究，就有可能构造出研究现实世界中的大量模糊的数学基础，能够对看来相当复杂的模糊系统进行定量的描述和处理的数学方法。在模糊集合中，给定范围内元素对它的隶属关系不一定只有“是”或“否”两种情况，而是用介于0和1之间的实数来表示隶属程度，还存在中间过渡状态。比如“老人”是个模糊概念，70岁的肯定属于老人，它的从属程度是 1，40岁的人肯定不算老人，它的从属程度为 0，按照查德给出的公式，55岁属于“老”的程度为0.5，即“半老”，60岁属于“老”的程度0.8。查德认为，指明各个元素的隶属集合，就等于指定了一个集合。当隶属于0和1之间值时，就是模糊集合。 第二，研究模糊语言学和模糊逻辑。人类自然语言具有模糊性，人们经常接受模糊语言与模糊信息，并能做出正确的识别和判断。为了实现用自然语言跟计算机进行直接对话，就必须把人类的语言和思维过程提炼成数学模型，才能给计算机输入指令，建立和是的模糊数学模型，这是运用数学方法的关键。查德采用模糊集合理论来建立模糊语言的数学模型，使人类语言数量化、形式化。如果我们把合乎语法的标准句子的从属函数值定为1，那么，其他文法稍有错误，但尚能表达相仿的思想的句子，就可以用以0到1之间的连续数来表征它从属于“正确句子”的隶属程度。这样，就把模糊语言进行定量描述，并定出一套运算、变换规则。目前，模糊语言还很不成熟，语言学家正在深入研究。人们的思维活动常常要求概念的确定性和精确性，采用形式逻辑的排中律，既非真既假，然后进行判断和推理，得出结论。现有的计算机都是建立在二值逻辑基础上的，它在处理客观事物的确定性方面，发挥了巨大的作用，但是却不具备处理事物和概念的不确定性或模糊性的能力。为了使计算机能够模拟人脑高级智能的特点，就必须把计算机转到多值逻辑基础上，研究模糊逻辑。目前，模糊罗基还很不成熟，尚需继续研究。 第三，研究模糊数学的应用。模糊数学是以不确定性的事物为其研究对象的。模糊集合的出现是数学适应描述复杂事物的需要，查德的功绩在于用模糊集合的理论找到解决模糊性对象加以确切化，从而使研究确定性对象的数学与不确定性对象的数学沟通起来，过去精确数学、随机数学描述感到不足之处，就能得到弥补。在模糊数学中，目前已有模糊拓扑学、模糊群论、模糊图论、模糊概率、模糊语言学、模糊逻辑学等分支。 10.2 模糊数学的应用模糊数学是一门新兴学科，它已初步应用于模糊控制、模糊识别、模糊聚类分析、模糊决策、模糊评判、系统理论、信息检索、医学、生物学等各个方面。在气象、结构力学、控制、心理学等方面已有具体的研究成果。然而模糊数学最重要的应用领域是计算机职能，不少人认为它与新一代计算机的研制有密切的联系。目前，世界上发达国家正积极研究、试制具有智能化的模糊计算机，1986年日本山川烈博士首次试制成功模糊推理机，它的推理速度是1000万次/秒。1988年，我国汪培庄教授指导的几位博士也研制成功一台模糊推理机——分立元件样机，它的推理速度为1500万次/秒。这表明我国在突破模糊信息处理难关方面迈出了重要的一步。模糊数学还远没有成熟，对它也还存在着不同的意见和看法，有待实践去检验。 11. 偏微分方程偏微分方程的起源 如果一个微分方程中出现的未知函数只含一个自变量，这个方程叫做常微分方程，也简称 微分方程；如果一个微分方程中出现多元函数的偏导数，或者说如果未知函数和几个变量 有关，而且方程中出现未知函数对几个变量的导数，那么这种微分方程就是偏微分方程。 在科学技术日新月异的发展过程中，人们研究的许多问题用一个自变量的函数来描述已经 显得不够了，不少问题有多个变量的函数来描述。比如，从物理角度来说，物理量有不同 的性质，温度、密度等是用数值来描述的叫做纯量；速度、电场的引力等，不仅在数值上 有不同，而且还具有方向，这些量叫做向量；物体在一点上的张力状态的描述出的量叫做 张量，等等。这些量不仅和时间有关系，而且和空间坐标也有联系，这就要用多个变量的 函数来表示。应该指出，对于所有可能的物理现象用某些多个变量的函数表示，只能是理想化的，如介 质的密度，实际上“在一点”的密度是不存在的。而我们把在一点的密度看作是物质的质量 和体积的比当体积无限缩小的时候的极限，这就是理想化的。介质的温度也是这样。这样 就产生了研究某些物理现象的理想了的多个变量的函数方程，这种方程就是偏微分方程。微积分方程这门学科产生于十八世纪，欧拉在他的著作中最早提出了弦振动的二阶方程， 随后不久，法国数学家达朗贝尔也在他的著作《论动力学》中提出了特殊的偏微分方程。 这些著作当时没有引起多大注意。1746年，达朗贝尔在他的论文《张紧的弦振动时形成的 曲线的研究》中，提议证明无穷多种和正弦曲线不同的曲线是振动的模式。这样就由对弦 振动的研究开创了偏微分方程这门学科。和欧拉同时代的瑞士数学家丹尼尔·贝努利也研究了数学物理方面的问题， 提出了解弹性系 振动问题的一般方法，对偏微分方程的发展起了比较大的影响。拉格朗日也讨论了一阶偏 微分方程，丰富了这门学科的内容。偏微分方程得到迅速发展是在十九世纪，那时候，数学物理问题的研究繁荣起来了，许多 数学家都对数学物理问题的解决做出了贡献。这里应该提一提法国数学家傅立叶，他年轻 的时候就是一个出色的数学学者。在从事热流动的研究中，写出了《热的解析理论》 ，在 文章中他提出了三维空间的热方程，也就是一种偏微分方程。他的研究对偏微分方程的发 展的影响是很大的。 11.1 偏微分方程的内容偏微分方程是什么样的？它包括哪些内容？这里我们可从一个例子的研究加以介绍。弦振动是一种机械运动，当然机械运动的基本定律是质点力学的 F=ma，但是弦并不是质 点，所以质点力学的定律并不适用在弦振动的研究上。然而，如果我们把弦细细地分成若 干个极小极小的小段，每一小段抽象地看作是一个质点，这样我们就可以应用质点力学的 基本定律了。弦是指又细又长的弹性物质，比如弦乐器所用的弦就是细长的、柔软的、带有弹性的。演 奏的时候，弦总是绷紧着具有一种张力，这种张力大于弦的重量几万倍。当演奏的人用薄 片拨动或者用弓在弦上拉动，虽然只因其所接触的一段弦振动，但是由于张力的作用，传 播到使整个弦振动起来。用微分的方法分析可得到弦上一点的位移是这一点所在的位置和时间为自变量的偏微分 方程。偏方程又很多种类型，一般包括椭圆型偏微分方程、抛物型偏微分方程、双曲型偏 微分方程。上述的例子是弦振动方程，它属于数学物理方程中的波动方程，也就是双曲型 偏微分方程。偏微分方程的解一般有无穷多个，但是解决具体的物理问题的时候，必须从中选取所需要 的解，因此，还必须知道附加条件。因为偏微分方程是同一类现象的共同规律的表示式， 仅仅知道这种共同规律还不足以掌握和了解具体问题的特殊性，所以就物理现象来说，各 个具体问题的特殊性就在于研究对象所处的特定条件，就是初始条件和边界条件。拿上面所举的弦振动的例子来说，对于同样的弦的弦乐器，如果一种是以薄片拨动弦，另 一种是以弓在弦上拉动， 那么它们发出的声音是不同的。 原因就是由于“拨动”或“拉动”的那 个“初始”时刻的振动情况不同，因此产生后来的振动情况也就不同。 天文学中也有类似情况，如果要通过计算预言天体的运动，必须要知道这些天体的质量， 同时除了牛顿定律的一般公式外，还必须知道我们所研究的天体系统的初始状态，就是在 某个起始时间，这些天体的分布以及它们的速度。在解决任何数学物理方程的时候，总会 有类似的附加条件。 就弦振动来说，弦振动方程只表示弦的内点的力学规律，对弦的端点就不成立，所以在弦 的两端必须给出边界条件，也就是考虑研究对象所处的边界上的物理状况。边界条件也叫 做边值问题。 当然，客观实际中也还是有“没有初始条件的问题” 如定场问题（静电场、稳定浓度分布、 ， 稳定温度分布等） ，也有“没有边界条件的问题” 如着重研究不靠近两端的那段弦，就抽象 ， 的成为无边界的弦了。 在数学上，初始条件和边界条件叫做定解条件。偏微分方程本身是表达同一类物理现象的 共性，是作为解决问题的依据；定解条件却反映出具体问题的个性，它提出了问题的具体 情况。方程和定解条件合而为一体，就叫做定解问题。 求偏微分方程的定解问题可以先求出它的通解，然后再用定解条件确定出函数。但是一般 来说，在实际中通解是不容易求出的，用定解条件确定函数更是比较困难的。 偏微分方程的解法还可以用分离系数法，也叫做傅立叶级数；还可以用分离变数法，也叫 做傅立叶变换或傅立叶积分。分离系数法可以求解有界空间中的定解问题，分离变数法可 以求解无界空间的定解问题；也可以用拉普拉斯变换法去求解一维空间的数学物理方程的 定解。对方程实行拉普拉斯变换可以转化成常微分方程，而且初始条件也一并考虑到，解 出常微分方程后进行反演就可以了。应该指出，偏微分方程的定解虽然有以上各种解法，但是我们不能忽视由于某些原因有许 多定解问题是不能严格解出的，只可以用近似方法求出满足实际需要的近似程度的近似 解。 常用的方法有变分法和有限差分法。变分法是把定解问题转化成变分问题，再求变分问题 的近似解；有限差分法是把定解问题转化成代数方程，然后用计算机进行计算；还有一种 更有意义的模拟法，它用另一个物理的问题实验研究来代替所研究某个物理问题的定解。 虽然物理现象本质不同，但是抽象地表示在数学上是同一个定解问题，如研究某个不规则 形状的物体里的稳定温度分布问题，在数学上是拉普拉斯方程的边值问题，由于求解比较 困难，可作相应的静电场或稳恒电流场实验研究，测定场中各处的电势，从而也解决了所 研究的稳定温度场中的温度分布问题。 随着物理科学所研究的现象在广度和深度两方面的扩展，偏微分方程的应用范围更广泛。 从数学自身的角度看，偏微分方程的求解促使数学在函数论、变分法、级数展开、常微分 方程、代数、微分几何等各方面进行发展。从这个角度说，偏微分方程变成了数学的中心。篇幅有限，还有一些大的数学分支尚未介绍，比如 分析学（实分析，复分析，调和分析），随机数学等，具体到应用数学的二级分支，均未涉及到。]]></content>
      <categories>
        <category>数学</category>
        <category>学科理解</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Arnold 论数学教育]]></title>
    <url>%2F2021%2F06%2F10%2FOn%20teaching%20mathematics%2F</url>
    <content type="text"><![CDATA[时间：1997年3月7日地点：Palais de Découverte in Paris 数学是物理的一部分。物理学是一门实验科学，它是自然科学的一部分。而数学是物理学中只需要花费较少的代价进行实验的那一部分。例如 Jacobi 恒等式（保证三角形三条高交于一点）就是一个实验事实，正如同地球是圆的（即同胚于球体）这样的事实一样。但是发现前者却要比发现后者需要较少的代价。在20世纪中叶，人们试图严格地区分物理与数学。其造成地后果是灾难性的。整整一代的数学家在对他们所从事的科学的另一半及其无知的情况下成长，当然，对其他的科学就更无知了。这些人又开始把他们的丑陋的学院式的伪数学教给他们的学生，接着这些丑陋的伪数学又被交给中小学校里的孩子们（他们完全忘记了Hardy的警告：丑陋的数学在阳光下不可能总有藏身之处）。既然那些从物理学中人为挖出来的学院式的数学既无益于教学，又对其他的科学毫无用处，结果可以想见，全世界的人都讨厌数学家（甚至包括那些被他们教出来的可怜的学校里的孩子们以及那些运用这些丑陋数学的人）。这些先天不足的数学家被他们所患的低能症候群折腾的筋疲力尽，他们无能对物理学有个起码的了解。令人们记忆犹新的由他们建造的一个丑陋建筑物就是“奇数的严格公理化理论”。很显然，完全可能创造这样一种理论，使得幼稚的小学生们敬畏它的完美及其内部构造的和谐（例如，这种理论定义了奇数个项的和以及任意个因子的乘积）。从这种偏执狭隘的观点来看，偶数或者被认为是一类“异端”，或者随着时间流逝，被用来作为该理论中几个“理想”对象的补充（为了遵从物理与真实世界的需要）。很不幸的是，这种理论只是数学中一个丑陋而变态的构造，但却统治了我们的数学教育数十年。它首先源自于法国，这股歪风很快传播到对数学基础的教学里，先是毒害大学生，接着中小学生也难免此灾（而灾区最先是法国，接着是其他国家，包括俄罗斯）。如果你问一个法国的小学生：“2＋3等于几？”，他（她）会这样回答：“等于3＋2，因为加法运算是可交换的”。他（她）根本不知道这个和等于几，甚至根本不能理解你在问他（她）什么！还有的法国小学生会这样定义数学（至少我认为很有可能）：“存在一个正方形，但还没有被证明”。据我在法国教学的经验，大学里的学生对数学的认识与这些小学生也差不多（甚至包括那些在’高等师范学校’（ENS）里学习数学的学生－－我为这些显然很聪明但却被毒害颇深的孩子们感到极度的惋惜）。例如，这些学生从未见过一个抛物面，而且一个这样的问题：描述由方程 $xy=z^2$ 所给出的曲面的形状，就能使那些在ENS中研究的数学家们发呆半天；而如下问题：画出平面上由参数方程（例如$x = t^3 - 3t, y = t^4 - 2t^2）$给出的曲线，对学生来说是不可能完成的（甚至对大多数法国的数学教授也一样）。从微积分的入门教科书直到Goursat写的课本，解这些问题的能力都被认为是每个数学家应具备的基本技能。那些喜欢挑战大脑的所谓“抽象数学”的狂热者们，把所有在数学中能与物理和现实经常发生联系的几何统统排除在教学之外。由Goursat, Hermite, Picard等人写的微积分教程被认为是有害的，最近差点被巴黎第6和第7大学的图书馆当垃圾丢掉，只是在我的干预下才得以保存。ENS的听完所有微分几何与代数几何课程的学生（分别被不同的数学家教的），却既不熟悉由椭圆曲线 $y^2 = x^3 + ax + b$ 决定的黎曼曲面，也不知道曲面的拓扑分类（更别提第一类椭圆积分和椭圆曲线的群性质了，即 Euler-Abel 加法定理）。他们仅仅学到了Hodge 构造以及 Jacobi 簇！这样的现象竟然会在法国出现！这个国家可是为整个世界贡献了诸如 Lagrange ，Laplace, Cauchy 以及 Poincaré, Leray 还有 Thom 这些顶级的伟大人物啊！对我而言，一个合理的解释来自 I.G. Petrovskii, 他在1966年曾教导过我: 真正的数学家决不会拉帮结派，只有弱者为了生存才会加入帮派。他们可以联结很多的方面（可能会是超级的抽象，反犹太主义或者“应用的和工业上的”问题），但其本质总是为了解决社会生存问题。 我在此向大家顺便提一下 L. Pasteur 的忠告：从来没有也决不会有任何所谓的“应用科学”，而仅仅有的是科学的应用（十分有用的东东啊！）长久以来我一直对 Petrovskii 的话心存疑虑，但是现今我越来越肯定他说的一点没错。那些超级抽象活动的相当大的部分正在堕落到以工业化的模式无耻的掠夺那些发现者的成果，然后再加以系统地组织设计使自己成为万能的推广者。就彷佛美丽坚所在的新大陆不以哥伦布命名一样，数学结果也几乎从未以它们真正的发现者来命名。为避免被认为我在胡说八道，我不得不在此声明我自己的一些成果由于莫名其妙的原因就被以上述方式无偿征用，其实这样的事情经常在我的老师（Kolmogorov, Petrovskii, Pontryagin, Rokhlin）和学生身上发生。M. Berry 教授曾经提出过如下两个原理： Arnold 原理：如果某个理念中出现了某个人名，则这个人名必非发现此理念者的名字。Berry 原理：Arnold 原理适用于自身。 不过，我们还是说回法国的数学教育上来。当我还是莫斯科大学数力系的一年级新生时，集合论的拓扑学家 L.A. Tumarkin 教我们微积分，他在课堂上很谨慎地一遍又一遍地讲述古老而经典的Goursat 版的法语微积分教程。他告诉我们有理函数沿着一条代数曲线的积分可以求出来如果该代数曲线对应的黎曼面时一个球面。而一般来说，如果该曲面的亏格更高这样的积分将不可求，不过对球面而言，只要在一个给定度数的曲线上有充分多的double points 就足够了（即要求该曲线是unicursal ：即可以将其实点在射影平面上一笔画出来）。这些事实给我们造成多么深刻的印象啊（即使没有给出证明），它们给了我们非常优美而正确的现代数学的思想，比那些长篇累牍的Bourbaki学派的论著不知道好到哪里去了。说真的，我们在这里看到了那些表面上完全不同的事物之间存在着令人惊奇的联系：一方面，对于相应的黎曼面上的积分与拓扑存在着显式的表达式，而另一方面，在 doublepoints 的个数与相应的黎曼面的亏格之间也有重要的联系。这样的例子并不鲜见，作为数学中最迷人的性质之一，Jacobi曾指出：用同一个函数就既可以理解能表示为4个数平方和的整数的性质，又可以描述一个单摆的运动。这些不同种类的数学对象之间联系的发现，就好比在物理学中电与磁之间联系的发现，也类同于地质学上对美洲大陆的东海岸与非洲大陆的西海岸之间相似性的发现。这些发现对于教学所具有的令人激动的非凡意义是无法估量的。正是它们指引着我们去研究和发现宇宙中和谐而精彩的现象。然而，数学教育的非几何化以及与物理学的分离却割断了这种联系。例如，不仅仅学习数学的学生而且绝大部分的代数几何学家都对以下提及的Jacobi 事实一无所知：一个第一类型的椭圆积分表示了相应的哈密顿系统中沿某个椭圆相曲线的运动所走的时间。我们知道一个 hypocycloid 就如同多项式环中的理想一样是无穷无尽的。但是如果要把理想这个概念教给一个从未见过任何 hypocycloid 的学生，就好比把分数的加法教给一个从来没有把蛋糕或苹果等分切割过（至少在脑子里切过）的学生。毫无疑问孩子们将会倾向于同时分子加分子分母加分母。从我的法国朋友那里我听说这种超级抽象的一般化正是他们国家的传统特色。如果说这可能是一个世袭的缺陷，我倒不会不赞成，不过我还是愿意强调那个从Poincaré那儿借来的“蛋糕与苹果”的事实。构造数学理论的方式与其它的自然科学并没有什么不同。首先，我们要考虑一些对象并对一些特殊的事例进行观察。接着我们试图要找到一些我们所观察到的结果在应用上的限制，即寻找那些防止我们不正确地把我们所观察的结果扩展到更广泛领域的反例。作为一个结果我们尽可能地明确提出那由经验得来的发现（如费马猜想和庞加莱猜想）。这之后将是检验我们的结论到底有多可靠的困难的阶段。就这一点来说，数学界已经发展出了一套特别的技术。这种技术，当被运用于现实世界时，有时候很有用，但有时候也会导致自欺欺人。这样的技术被称为“建模”。当构造一个模型时，要进行如下的理想化：某些只能以一定概率或一定的精确性了解的事实，往往被认为是“绝对”正确的并被当作“公理”来接受。这种“绝对性”的意义恰恰是，在把所有我们可以借助这些事实得出的结论称为定理的过程中，我们允许自己依据形式逻辑的规则来运用这些“事实”。显然在任何现实的日常生活中，我们的活动要完全依赖于这样的化减是不可能的。原因至少在于所研究的现象的参数决不可能被绝对准确的知晓，并且参数的微小变化（例如一个过程初始条件的微小改变）就会完全地改变结果。由于这个原因我们可以说任何长期的天气预报都是不可能的，无论我们把计算机造的有多高级或是记录初始条件地仪器有多灵敏，这永远也办不到。与此完全一样的是，公理（那些我们不能完全确定的）的一个小小的改变虽是容许的，一般来说，由那些被接受的公理推出的定理却将导出完全不同的结论。推导的链（即所谓的“证明”）越长越复杂，最后得到的结论可靠性越低。复杂的模型几乎毫无用处（除了对那些无聊的专写论文的人）。数学建模的技术对这种麻烦一无所知，并且还不断地吹嘘他们得到的模型，似乎它们真的就与现实世界吻合。事实上，从自然科学的观点看, 这种途径是显然不正确的，但却经常导致很多物理上有用的被称为“有不可思议的有效性的数学”结果（或叫做“Wigner原理”）。我在此再提一下盖尔方德先生的一句话：还有另一类现象与以上Wigner所指的物理中的数学具有相仿的不可思议的有效性，即生物学中用到的数学也是同样令人难以置信的有效。对一个物理学家而言，“数学教育所致的不易察觉的毒害作用”（F.Klein 原话）恰恰体现在由现实世界抽离出的被绝对化了的模型，并且它与现实已不再相符。这儿是一个简单的例子：数学知识告诉我们 Malthus 方程 dx/dt = x 的解是由初始条件唯一决定的（也即相应的位于（t-x）－平面上积分曲线彼此不交）。这个数学模型的结论显得与现实世界毫不相关。而计算机模拟却显示所有这些积分曲线在t的负半轴上有公共点。事实上，具有初始条件 x(0) = 0 和 x(0) = 1的曲线在t=-100 相交，其实在t=-100 时，你压根就不可能在两条曲线之间再插入一个原子。欧式几何对这种空间在微小距离下的性质没有任何的描述。在这种情况下来应用唯一性定理显然已经超出了模型所能容许的精确程度。在对模型的实际运用中，这种情形必须要加以注意，否则可能会导致严重的麻烦。我还想说的是，相同的唯一性定理也可解释为何在船只停泊码头前的靠岸阶段必须得依靠人工操作：否则的话，如果行进的速度是距离的光滑（线性）函数，则整个靠岸的过程将会耗费无穷长的时间。而另外可行的方法则是与码头相撞（当然船与码头之间要有非理想弹性物体以造成缓冲）。顺便说一下，我们必须非常重视这类问题，例如，登陆月球和火星以及空间站的对接－此时唯一性问题都会让我们头痛。不幸的是，在现代数学的教科书里，即使是较好的一类课本里，对这种令人崇拜的定理所隐藏的危险的事例或探讨都只字没有。我甚至已经形成了这样的印象，那些学院派的数学家（对物理知识都一窍不通）都对公理化形式的数学与建模的主要差异习以为常，而且他们觉得在自然科学中这是很普遍的，只是需要用后期的实验来控制理论推演。我想用不着去提什么初始公理的相对特征，人们也都不会忘记在冗长的论述里犯逻辑错误是在所难免的（彷佛宇宙射线或量子振动所引发的计算崩溃）。每一个还在工作的数学家都知道，如果不对自己有所控制（最好是用事例），那么在10页论述之后所有公式中的记号有半数都会出问题。这样的谬误相抗的技术也同样存在于任何实验科学里，而且应该教给每一个大学低年级的学生。试图创造所谓的纯粹推导式的公理化数学的做法，使得我们不再运用物理学中的研究方法（观察-建模－模型的研究－得出结论－用更多的观察检验模型）取而代之的是这样的方法：定义－定理－证明。人们根本不可能理解一个毫无动机的定义，但我们却无法阻止这些有罪的“代数－公理学家”。例如，他们总是想用长乘规则的手段来定义自然数的乘积。但用这种方法乘法的交换性却难以证明，不过从一堆的公理中仍有可能推导出这样的定理。而且完全可能逼着那些可怜的学生们来学习这个定理以及它的证明（其目的不外乎是提升这门学科以及教授它的人的社会地位）。显然，这种定义和这样的证明对教学和实际工作有百害而无一益。理解乘法交换性的唯一可能的方式，打个比方就是分别按行序和列序来数一个方阵里士兵的人数，或者说用两种方式来计算长方形的面积。任何试图只做不与物理和现实世界打交道的数学都属于宗派主义和孤立主义，这必将损毁在所有敏感的人们眼中把数学创造视为一项有用的人类活动的美好印象。我将再揭示几个这样的秘密（可怜的学生们对此很有兴趣）。一个矩阵的行列式就是一个平行多面体的（定向的）体积，这个多面体的每条边就对应矩阵的列。如果学生们得知了这个秘密（在纯粹的代数式的教育中，这个秘密被仔细地隐藏了起来），那么行列式的整个理论都将成为多线性形式理论的一部分。如果用别的方式来定义行列式，则任何敏感的人都将会永远恨死了诸如行列式，Jacobi式，以及隐函数定理这些鬼东西。一个群又是什么东东呢？代数学家们会这样来教学：这是一个假设的集合，具有两种运算，它们满足一组容易让人忘记的公理。这个定义很容易激起一个自然的抗议：任何一个敏感的人为何会需要这一对运算？“哦，这种数学去死吧”－－这就是学生的反应（他很可能将来就成为了科学强人）。如果我们的出发点不是群而是变换的概念（一个集合到自身的1－1映射），则我们绝对将得到不同的局面，这也才更像历史的发展。所有变换的集合被称为一个群，其中任何两个变换的复合仍在此集合内并且每个变换的逆变换也如此。这就是定义的关键所在。那所谓的“公理”事实上不过是变换群所具有的显然的性质。公理化的倡导者所称的“抽象群”不过是在允许相差同构（保持运算的1－1映射）意义下的不同集合的变换群。正如 Cayley证明的，在这个世界上根本就没有“更抽象的”群。那么为什么那些代数学家仍要用抽象的定义来折磨这些饱受痛苦的学生们呢？顺便提一句，在上世纪60年代我曾给莫斯科的中小学生们讲授群论。我回避了任何的公理，尽可能的让内容贴近物理，在半年内我就教给了他们关于一般的五次方程不可解性的Abel 定理（以同样的方式，我还教给了小学生们复数，黎曼曲面，基本群以及代数函数的monodromy 群）。这门课程的内容后来由我的一个听众 V. Alekseev 组织出版了，名为The Abel theorem in problems.一个光滑流形又是什么东东呢？最近我从一本美国人的书中得知庞加莱对此概念并不精通（尽管是由他引入的），而所谓“现代的”定义直到上世纪20年代才由Veblen给出：一个流形是一个拓扑空间满足一长串的公理。学生们到底犯了什么罪过必须经受这些扭曲和变形的公理的折磨来理解这个概念？事实上，在庞加莱的原著《位置分析》（Analysis Situs）中，有一个光滑流形的绝对清晰的定义，它要比这种抽象的玩意儿有用的多。一个欧式空间$R^N$ 中的k-维光滑子流形是一个这样的子集，其每一点的一个邻域是一个从$R^k$到$R^{N - k}$的光滑映射的图象（其中$R^k$ 和 $R^{N - k}$ 是坐标子空间 ）。这样的定义是对平面上大多数通常的光滑曲线（如 圆环 $x^2 + y^2 = 1$）或三维空间中曲线和曲面的直接的推广。光滑流形之间的光滑映射则是自然定义的。所谓微分同胚则是光滑的映射且其逆也光滑。而所谓“抽象的”光滑流形就是欧式空间的允许相差一个微分同胚意义下的光滑子流形。世界上根本不存在所谓“更抽象的”有限维的光滑流形（Whitney 定理）。为什么我们总是要用抽象的定义来折磨学生们呢？把闭二维流形（曲面）的分类定理证给学生们看不是更好吗？恰恰是这样的精彩定理（即任何紧的连通的可定向的曲面都是一个球面外加若干个环柄似的把手）使我们对现代数学是什么有了一个正确的印象，相反的是，那些对欧式空间的简单的子流形所做的超级抽象的推广，事实上压根没有给出任何新的东东，不过是用来展示一下那些公理化学者们成就的蹩脚货。对曲面的分类定理是顶级的数学成就，堪与美洲大陆或X 射线的发现媲美。这是数学科学里一个真正的发现，我们甚至难以说清到底所发现的这个事实本身对物理学和数学哪一个的贡献更大。它对应用以及对发展正确的世界观的非凡意义目前已超越了数学中的其他的“成就”，诸如对费马大定理的证明，以及对任何充分大的整数都能表示成三个素数和这类事实的证明。为了出风头，当代的数学家有时候总要展示一些“运动会式的”成就，并声称那就是他们的学科里最后的难题。可想而知，这样的做法不仅无助于社会对数学的欣赏，而且恰恰相反，会使人们产生怀疑：对于这样的毫无用处的跳脱衣舞般的问题，有必要耗费能量来做这些（彷佛攀岩似的）练习吗？曲面的分类定理应该被包含在高中数学的课程里（可以不用证明），但不知为什么就连大学数学的课程里也找不到（顺便一下，在法国近几十年来说有的几何课程都被禁止）。在各个层次上，数学教育由学院的特征转回到表述自然科学的重要性的特征，对法国而言是一个及其热点的问题。使我感到很震惊的是那些最好的也是最重要的条理清晰的数学书，在这儿几乎都不为学生们所知（而依我看它们还没有被译成法语）。这些书中有: Rademacher 和 Tö写的 《Numbers and figures》； Hilbert 和 Cohn-Vossen写的《Geometry and the imagination》； Courant 和 Robbins 写的《What is mathematics ?》； Polya 写的《How to solve it》、《Mathematics and plausible reasoning 》； F. Klein 写的《Development of mathematics in the 19th century》。 我清晰地记得在学校时，Hermite 写的微积分教程（有俄语译本）给我留下了多么强烈的印象。我记得在其最开始的一篇讲义中就出现了黎曼曲面（当然所有分析的内容都是针对复变量的，也本该如此）。而积分渐进的内容是通过黎曼曲面上道路形变的方法来研究（如今，我们称此方法为Picard-Lefschetz 理论;顺便提一下，Picard是Hermite的女婿－－数学能力往往是由女婿来传承：Hadamard - P. Levy - L. Schwarz - U. Frisch 这个王朝就是巴黎科学院中另一个这样的范例）。由Hermite 一百多年前所写的所谓的“过时的”教程（也许早就被法国大学的学生图书馆当垃圾扔掉了）实际上要比那些如今折磨学生们的最令人厌烦的微积分课本现代化的多。如果数学家们再不睡醒，那么那些对现代的（最正面意义上的）数学理论仍有需要，同时又对那些毫无用处的公理化特征具有免疫力（这是任何敏锐的人所具有的特征）的消费者们会毫不犹豫的将这些学校里的受教育不足的学究们扫地出门。一个数学教师，如果至今还没有掌握至少几卷Landau 和 Lifshitz 著的物理学教程，他（她）必将成为一个数学界的希罕的残存者，就好似如今一个仍不知道开集与闭集差别的人。]]></content>
      <categories>
        <category>数学</category>
        <category>学科理解</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数学学习的一些参考意见]]></title>
    <url>%2F2021%2F04%2F15%2F%E6%95%B0%E5%AD%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E5%8F%82%E8%80%83%E6%84%8F%E8%A7%81%2F</url>
    <content type="text"><![CDATA[CSDN —— 数学学习路径原文 大学数学基础课是数学分析，高等代数，概率三门。 数学分析（或叫做高等数学，微积分）经典名著太多了，比如菲赫金哥尔茨的《微积分学教程》，柯朗的《微积分和数学分析引论》，卓里奇的《数学分析》，还有美国教材《托马斯微积分》，都是好书，不过这些都是惶惶巨著，需要下大功夫研读，如果想从很浅的基础开始看，可以看《普林斯顿微积分读本》（网上有48课时视频）。所有这些都比国内教材（比如同济的）好很多很多。如果英语基础好的话直接看英文版的，否则看中文的也行。 高等代数（或者叫做线性代数），可以看David C.Lay的《线性代数及其应用》，这本书入门级别，但是质量很高，掌握之后可以看《线性代数应该这样学》，看完线性代数后还觉得不过瘾，可以看高等代数，或者矩阵分析，矩阵理论等等教材，有了线性代数的基础，就有了免疫力，不至于被国内的枯燥教材弄恶心了。 概率论，看国外的最好 这三门学完后，就可以进阶了，首先是在这三门的基础上进阶，数学分析进阶可以看实变函数方面的书，比如《陶哲轩实分析》，不过这本书偏重数学分析的内容，算是对数学分析的深化理解。高等代数进阶刚才说过了，可以看矩阵分析方面的书。多个方向同时进阶可以看咱们华罗庚的《高等数学引论》。 数学的主要几个分支大概是：代数，几何，分析，概率，离散，计算，当然分类不是唯一的。进阶结束之后就可以向着这些方向进发了： 代数方面的，可以看Artin的《代数》，算是入门书，看完之后就可以看代数里的各个方向的著作，比如数论，群论，环，域，拓扑等等。这些方面也是经典著作云集，以国外的为主。 几何方面的，其实几何与代数到了最后好像要统一了。可以先看解析几何入门，然后进入微分几何，黎曼几何，流形，射影几何，画法几何，双曲几何等等。几何与代数统一叙述的著作，可以看代数拓扑，代数几何，代数曲线，同调论方面的书。 数学中最大的一个分支应该是分析吧，它主要包括：实分析，复分析，泛函分析，调和分析，向量分析，张量分析，场论，函数论，常微分方程，偏微分方程，积分方程，积分变换，变分法，特殊函数等等。分析这方面相比代数之类的方向来说，更加偏应用一些。这些方面好书实在太多了，首先就是stein的四部曲：《傅里叶分析》，《实分析》，《复分析》，《泛函分析》。这四部书不厚，但是内容多，不过只要懂微积分和线性代数就可以学习了。复分析还可以看拉夫连季耶夫的《复变函数论方法》，以及一本超级好书：《复分析：可视化方法》，前者讲复分析的方法（主要是共形映射）在各个物理，经济等学科里的应用方法，后者主要是把复变函数的抽象思想用非常美的图形表现出来，而且很深刻。函数论方面可以看法兰西数学系列（蓝色封皮的）一些书，以及国内的两本：路见可的《解析函数边值问题教程》，闻国椿的《共形映射与边值问题》，函数论常常和奇异积分方程相联系，这方面有经典巨著：穆斯海里什维利的《奇异积分方程》实分析常常和泛函分析相联系，可以看国内夏道行的《实变函数与泛函分析》，以及俄罗斯柯尔莫戈洛夫的《函数论与泛函分析初步》，美国Rudin的《泛函分析》等等。学完实分析与复分析之后就可以看调和分析方面的书了，先推荐一本，stein的超级名著：《调和分析》，很厚，牛人stein的专业就是搞调和分析方面的，细细品味吧。向量分析，张量分析，场论，其实这三个学科说是分析也是分析，说是几何也是几何，他们和微分几何有着很多联系，可以先看点入门的，比如国内的两本，一本工程数学类的绿色封皮的《矢量分析与场论》，一本白色封皮的《向量分析与场论》，都很薄，不过可以同时看美国Matthews的《向量微积分》，这本书也不厚，但是它后面的内容会过渡到指标和张量，便于进入张量的学习。张量分析方面可以看国内黄克智的《张量分析》，绝对是好书，作者留学俄罗斯，数学推导功底深不可测，所以学习该书也需要亲自动手推导，不过讲的还是比较清楚的。如果还觉得不够，可以看国外的《张量几何》，谁写的名字我忘了。张量本来就是和微分几何一道由黎曼一手发展的，所以到了最后会偏向几何了。方程类的（常微分，偏微分，积分），前面两者好书太多了，常微分的可以入门可以看俄罗斯庞特里亚金的《常微分方程》，以及钱伟长的《微分方程的解法及其应用》，国内的在这方面写得还行。然后进阶的可以看美国人写的教材，一般都会过度到微分流形。偏微分方程，美国人写的好书很多，就不说了。物理里面的《数学物理方法》，《数学物理方程》之类的书也会涉及偏微分方程的内容。微分方程的求解常常引出特殊函数，这方面可以看一本我们伟大的先进的文明的中华人民共和国在国际上唯一拿得出手的一本数学书：王竹溪的《特殊函数概论》，不过这本书虽说是概论，但内容很多，而且习题超难，据说王竹溪说过“我从来不查积分表”，不知道真的假的。如果觉得该书太难，那么可以看刘适式，刘适达两人合著的《特殊函数》。积分方程与泛函分析联系紧密，主要分为两类，奇异积分方程与非奇异的，前者在函数论方面已经说过，后者入门的可以看沈以淡的《积分方程》，李星的《积分方程》，魏培君的《积分方程及其数值方法》，进阶的可以看陈传璋的《积分方程论及其应用》。路见可的《积分方程论》，不过积分方程搞得好的还是前苏联的，所以可以看看维库阿等人的书。积分变换属于比较小的分支，但是应用却及其广泛，可以看复变函数，积分方程方面的书，里面一般会介绍傅里叶变换，拉普拉斯变换，Z变换，汉克尔变换，梅林变换，离散傅里叶变换，快速傅里叶变换，小波变换等等。小波变换一般在小波分析方面的书里有详细介绍，小波分析主要是法国数学家发展起来的，很复杂啊。三大分支介绍完了，再介绍一点别的分支。概率论的书看完之后，可以看随机过程，统计学等等后续的书。离散数学主要在计算机相关专业应用较多，主要包括集合论，数理逻辑，关系代数，逻辑代数，图论等等，每一门都是一个方向，有很多书。计算数学又叫做数值分析，主要是讲插值，逼近，拟合，矩阵计算，线性方程组求解，非线性方程求根，数值积分，数值微分，广义最小二乘等等，随便看哪本书都可以，重在编程计算。我也是初学数学，希望可以帮到你 CSDN —— 数学学习目录原文 这是作者翻了很多书后的感受。由于作者读书并不仔细，所以对很多书的评价会很片面。希望同学们可以批评指正。当然，介绍远不全面，同时希望有兴趣的同学给予补充。一般来讲后面介绍的书都可以在新浪爱问共享资料中找到，有兴趣的同学可以下载参考.提醒同学们注意，英文版的数学教材可能是(从语法的复杂程度和词汇量角度来讲)最容易读的英文教材(与物理，化学，生物，地理，计算机等学科相比) 还有，一般来讲，苏联书有的原著比翻译好，有的翻译比原著强(因为有的书粗制滥造)，并且一般英译版比中译版更忠实于原著.并且苏联书一般不适合初学者，但有时例外.法兰西经典译丛中有不少好书，书是极好的书，但有些翻译的并不令人满意，所以，有时找来英文版参考是有必要的.但英文版并不一定能在爱问中找到，不过同学们可以试试图书馆，说不定里面有. 美国的书比较多，有些比较经典，当然有些是很难的。一般来讲，有剑桥的标志的书都相对来讲是人民群众喜闻乐见的书。大多数适合初学者。丘成桐先生曾找出一套书组织人进行翻译。有些书翻译的并不理想，但更重要的是选者的眼光，丘老先生选的书一般都是极经典极值得一读的，并且原著一般在爱问上能下载到. 从日本引进的教材，一般讲法比较古典，但是很多是写得极精彩极细致的书，很是值得一看.一般来讲，凡是科大的书写的都比较晦涩难懂，初学者读起来很是困难。有时会有一些问题用高超的技巧掩饰了更本质的东西。所以看到科大的书，初学时要谨慎选择。不过在学完相关内容之后可以参考科大的书，这可以看做对所学内容的极好的考查.北大常有经典教材出现.同学们有时间可以读一读A.Connes：“Advice to the beginner”M.Atiyah：“给年轻数学工作者的建议”Dieudonne：《Mathematics - The Music of Reason》（中文译名：当代数学）为了人类心智的荣耀都是很好的东西，前者是两篇文章，后者是极好的科普书. 最后，抄些丘成桐的话共勉“古人讲’开卷有益’，其实是很对的求学方法。我常看一些难懂的书，当时虽然不懂，有时也忘了书中的内容。后来过了几年，回想起来，都觉得很有帮助.”“各位都看到我数学念得很好，事实上我的求学过程中数学成绩是有高有低的，考试有时好，有时不好。因为当你每次考得很好时，就容易被一定的方法固定住。考试事实上并不能真正测出你对问题懂了没有，重要的是你自己真懂了吗?……以后我教过20多个研究生。有些研究生，他们在高中，大学是考试都考得很好，但是就是因为从前考得很好，以至于后来做研究做不好时就颓丧，灰心，站都站不起来。这些可能跟家长的观念有关.尤其是中国的学生都将考试看得很重.这不是重要的，却看得很重要。” “中国人通常不太会找问题，我觉得解决问题的能力固然很重要，但是训练寻找问题的能力似乎更重要。你可以一辈子做研究，解决你所得到的第二流问题。但是你却不能捡到第一流的问题。会主动寻找问题的人，才是第一流人物。训练寻找问题的能力必须从小培养起.在这个方面，外国学生找问题的能力似乎就比中国人强. 另外，有关忍受挫折的能力，中国人也是较差的。我们做数学研究，常常是屡败屡战，往往错的时候比对的时候多得多。即使是错十次对一次，也是很好的。因为尝试错误越多的地方，你就越能从错的地方找到继续前进的方向.如此一来，牛就学习到更深思熟虑的能力.这跟下棋不能修改错误，或一次考试决定你是否成功是不一样的.” “一个好的数学家至少要掌握两门以上的基本功夫。基本功夫不是一朝一夕学来的…….你做基本功夫一定要做到你看一个题目，明明是未解决的问题，你还是可以坐下来，然后花功夫去解决它。即是你不能够解决它，可是你至少晓得怎样去想办法。同时不会恐慌，放弃.我想这是最重要的。往往我们因为基本功夫没做好，当一个深的题目或看法出现的时候我们就拒绝去接受，认为这些题目不重要，这是去解释自己问什么不能够去做某一个问题的时候最自然的想法. 训练基本功夫要在研究生，大学生或中学生的时候。基本功夫怎样学好呢? 有时一本书看完了就放在一边，看了两三本书后就以为懂了。其实看书是不够的.重要的是做习题，因为只有在做习题的时候，你才晓得什么命题你不懂，也理解到前人遇到的困难在哪里。”同学们有时间可以多看看科普文章，丘成桐很多文章很多话是很振聋发聩的.最后的最后，提示同学们注意各种书后的参考文献。因为即使是比较一般的书，后面往往会引用比较牛逼的参考文献. 数学分析分析可以说是本科阶段最难的课程。难并不是内容的难以理解，因为数学课一般来讲只要写得清楚，并且了解发现的历史，只要有充足的时间是可以读懂的。并且可以说数学是相对简单的科目。分析也是如此。那为什么说分析难呢? 答曰:课时少。这是一个相当要命的问题。多到令人发指的内容要压缩在三个学期内讲完……难的不是内容难以读懂，而是不给你消化和适应的时间。我们分析课程的任务是很重的。因为我们的数学分析分析，不只是数学分析，还包括微积分。美国的处理方法一般是先修一个基础的微积分课程，类似我们的高等数学，然后再修高等微积分，或者数学分析。俄罗斯的处理方式和我们类似(实际上是我们效仿苏联)分析从头讲到尾，不先修微积分。但不论是哪类方式，一般总课时是四个学期。但是我们的总课时只有三个学期。所以留给我们思考和消化的时间就很少。所以一般来讲，往往在学完分析后我们要花时间看完一本高等微积分，做一定的习题(不论你考试考多少)，才能说学得差不多. 有兴趣的同学可以更早的接触一些点集拓扑的内容，因为这些东西会给我们带来意想不到的直观。Rudin的基础拓扑或陈天权的第七章都值得一读。但后者更难一些。可以参考熊金城或芒克里斯的书。不过熊金城的书可能相对来讲好读一些. 测度与积分学起来可能会感觉有些困难，但是实际上可能还不如隐函数定理难。因为在Lebesgue意义下的可积函数空间有意想不到的好性质。收敛定理是相当强有力的工具。并且有了积分理论作为工具，三角级数相关的内容就更容易理解. W.Dunham 《The Calculus Gallery-Masterpieces from Newton to Lebesgue》(微积分的历程—从牛顿到勒贝格)这是一本相当不错的科普。但初看并不容易一口气看完，其中还是有很多要思考的地方的。但学分析时看看，大有裨益.当然国内也有不少比较不错的科普，如张景中写得的一套书，张远楠写的一套书。对加深理解是很有好处的。如果在学分析时感觉很多东西不习惯的话，可以看看数学史。很多问题了解了提出的背景，接受起来就比较舒服。相关的历史在齐民友的’重温微积分’中有，如果想要更详细的了解，就需要查一些专门的数学史的书了.关于数学分析的内容，同学们可以参考陈天权数学分析讲义的前言与后记，还有他写的关于教学感受的论文’数学分析教学中学到的和想到的’ 张筑生 《数学分析新讲》这本书可以说是初学分析的首选参考书。关于作者的伟大事迹可以在网上查到。有网友评论说张的书:”文笔清晰详细，证明深入浅出，通俗易懂”可以说是很恰当的。这套书的特点就是起点不高。但是内容并不浅，可以算是比较深刻的。但更可贵的是书中的证明写得及其细致”自然”，或者更确切的说是让读者读起来感觉每一步都自然得令人发指，没有一点故弄玄虚的感觉。可以说作者最大程度考虑了读者的感受，选择了最合适的切入点，一步步直达问题的本质。有兴趣的同学可以将本书的内容与其它书比较，一般来讲会得出”我擦泪，张筑生好牛逼啊，真的好牛逼啊，竟然能把问题讲的那样明白!”之类的感觉。但本书有两个小缺点，一是没有习题，二是文风比较平淡(当然这跟个人喜好有关)，不像Dieudonné的书那样激情四射。但总的来说，内容相对偏古典(微分不谈流形，积分不讲测度，收敛不涉及函数空间)的数学分析教本中最好的一本。最后，这本书相当实用。后续课程中很多重要定理这本书中都有证明.比如常微分方程的存在唯一性定理，积分因子的存在性等。并且关于曲线，曲面的几何性质的介绍中，很多地方处理的比很多(古典)微分几何教本简明生动，直观易学. 陈天权 《数学分析讲义》重口味的分析学参考书。 可以说是内容相对现代的数学分析教材中最好的一套。对数学感兴趣的同学可以参考一下书的前言和目录。很多讲解是极清楚的，证明也写得很漂亮。由于是教学改革的书，其中加入了应该加入的很多相对近代的内容。所以很多问题讲起来就更加清晰，更加本质。内容虽然抽象近代，作者的写作风格相对比较激情，读起来很有意思，但想完全读懂却要花不小的力气(虽然作者已经讲得相当明白)但是这些花费是异常值得的.最后个人感觉有兴趣致力于做吉米多维奇习题的同学不妨改为做这套书的书后习题，如果能在大四毕业前大概看一遍，是相当有好处的. 陶哲轩 《陶哲轩实分析》不要误解”实分析”的书名，大多同学看到这一书名的第一反应应该是这是一本讲实变函数的书。其实满不是。书名译成实数学分析更合适。虽然书中也讲一些Lebesgue积分的内容，但更类似于”数学分析”的程度。书的内容不如陈天权现代，有些地方比张筑生现代。文风相对活泼，口语化，讲解得严谨透彻，很多地方比陈天权讲得详细，值得参考. 高木贞治 《高等微积分(解析概论)》传说影响了一代日本数学家的分析教材。内容相对古典，证明处理干净利落，讲解到位，读起来很舒服。其中解析函数的引入相当漂亮，可以说是数学分析中引入复函数相关内容的一大典范. 辛钦 《数学分析八讲》刚接触分析时，如果觉得难以入门，ε-语言难以掌握，或者不明白它到底有什么作用。辛钦先生这本小册子可以很漂亮的解决这一问题。读完这本书，读者对分析就会有不少感性的认识. 小平邦彦 《微积分入门》按作者的说法，本书受到高木贞治先生解析概论的影响随处可见。对三角函数的处理比较有特色。内容相对古典，但对于很多重要细节处理相当到位。我们在后续课程中遇到证明中的细节问题时，本书是非常不错的参考. 盖尔鲍姆(B.R.Gelbaum)，奥姆斯特德(J.M.H.Olmsted) 《分析中的反例》书中蕴含了各种各样数学分析和实变函数中的奇奇怪怪的反例，薄薄的一本，但是很有用处. T.M.Apostol 《数学分析》和Rudin齐名的传说中的分析书，内容丰富，实变，复变，泛函都带一些。有界变差函数和斯蒂尔切斯积分讲得相当漂亮，傅里叶级数部分很有意思。但是本书的一大缺点就是Lebesgue积分的定义想要避开测度理论。相关内容处理的比较别扭。再有，就是很多证明不像Rudin那样漂亮(如隐函数定理)。但总体上读起来感觉还是相当不错的. W.Rudin 《数学分析原理》传说中的神书，内容丰富，处理精炼，简洁。只不过”与其说这是一部教科书，不如说这是一部字典”。证明一般漂亮得让人惊讶。但读起来相对来讲要花一些力气。主要是很多地方需要读得很仔细(包括习题，因为很多重要定理和例子被作者放在习题里)。不过作为讨论的材料或讲课的教本却很是合适。因为讲的时候可以展开或者加入一些例子什么的. 齐民友 《重温微积分》内容及其丰富的”文学作品”，。每一章都强调有关理论的基本问题、基本理论和基本方法的历史的背景，其与物理科学的内在联系，其现代的发展与陈述方式特别是它与其他数学分支的关系。同时对一些数学和物理学中重要的而学生常常不了解的问题作了阐述。很是值得一读，缺点是细节处理很不到位，很多地方会出现各种各样的错误。但是作为上面所有书的参考书是很不错的。因为作者更强调历史背景与发展过程，所以对加深理解很有帮助。现代化程度与陈天权的书类似，但证明等各方面不如陈，不过讲解和历史故事很多，为别的书所没有. J.Dieudonné 《Treatise on Analysis(现代分析基础)》法国书一般比较重口味，这本也不例外。每章前言说得激情四射，内容简洁明了，观点相当 高，是学完分析后值得一读的一本书。习题相对比较难，但值得做。可以作为阅读陈天权的数学分析讲义时的参考书目. G.Choquet 《拓扑学教程》虽然叫拓扑学，但本书更注重的是点集拓扑中与分析有关的内容。所以早年间的版本叫做分析与拓扑。这本书翻译的不错。是分析基础部分相当好的参考书。放在这里主要是因为郇中丹书中很多没写明白的东西(如滤子，上半连续等)在这本书中都交代的清清楚楚. P.Bamberg&amp;S.Sternberg 《Analysis-A Course in Mathematics for Students of Physics》引用陈天权老大爷的评价:”本书对线性代数和多元微积分，包括微分形式，做了初等而详细的介绍。它的特色是详细介绍了多元微积分在物理和几何上的应用。用微分形式的语言介绍了电磁理论和热力学，并直观的介绍了拓扑学: 包括上同调，同调及de Rham 定理。虽然本书是为Harvard大学学物理的学生写的讲义，但对于学数学的学生也有很大的参考价值.” L.H。Loomis&amp;S.Sternberg 《Advanced Calculus(高等微积分)》Harvard大学高等微积分的荣誉课。丘成桐选译之一，翻译质量一般，书却绝对是好书。内容丰富，讲解到位，但是看一下需要不少时间，因为要看这本书必做习题，否则难以往后看。所以有时间的同学们可以参考. 夏道行 《实变函数论与泛函分析(上册)》起点不高，并且讲解清晰，适合初学，与周民强相比，强调抽象测度，习题要简单一些，内容相对容易接受。在学习数学分析的有关积分理论时可以作为不错的参考. 卓里奇 《数学分析》非常不错的书，但可能并不适合初学者。第二册相比第一册要牛逼得多。有兴趣的同学可以读一下。不知为何不讲Lebesgue积分，而泛函的内容却出奇的多。感觉翻译后的书不如陈天权好读. 菲赫金哥尔茨 《微积分学教程》传统分析教材中比较传奇的一本。感觉上作为字典更合适。本人不太喜欢这本教材。因为内容实在太多，并且讲法太古典…… R.Courant&amp;F.John 《Introduction to Calculus and Analysis(微积分和数学分析引论)》篇幅感觉上与上一本教材类似，但内容相对浅一些但取材更广泛更有意思。一般来讲R.Courant的书往往能给人一种新鲜感，总体上感觉比菲赫金哥尔茨要舒服(与个人审美有关). 李成章 黄玉民 《数学分析》刘永平老大爷比较喜欢的一本教材。相对古典，内容比较全，但感觉文风枯燥，不是特别好读。总的来讲很多证明没有张筑生来的自然。习题并不容易，但可以参考. 阿黑波夫 丘巴里阔夫 萨多夫尼奇 《数学分析讲义》据译者王昆扬老大爷反应: “此书原著粗制滥造，错误繁多，翻译的过程是一个不断挑错改错的过程.” 因为是讲义，所以读起来并不舒服。不少地方选材和讲法都有待商榷。优点是内容相对丰富，感觉勉强可做参考书(与个人审美有关). S.G.Krantz&amp;H.R.Parks 《The Implicit Function Theorem，History，Theory and Applications》本书对隐函数定理及其历史做了很详细的介绍。这种书相当难找啊. 陶哲轩 《Differential Forms and Intergration》关于微分形式的积分的文章，篇幅不大，起点不高，但讲的很不错. 华罗庚 《高等数学引论》可以看一下，能感觉到华的算功很牛逼。读起来感觉算啊算就算出来了。本书中有很多平时分析里不讲的内容，很有意思，可以一读。但在有些地方(比如曲线积分)的推导感觉不是特别舒服。因为算得比较多(这与个人审美有关). 徐森林 《数学分析》徐森林的书一大特点就是符号特多，读起来不是很容易。内容相对丰富，不如陈天权现代，也不如陈天权好读. 龚昇 《微积分五讲》可以看一看，但要想仔细读一下外微分，陈维桓的微分几何(2006版)，P.Bamberg&amp;S.Sternberg Analysis-A Course in Mathematics for Students of Physics，L.H。Loomis&amp;S.Sternberg Advanced Calculus(高等微积分)都是很好的选择。P.Bamberg&amp;S.Sternberg Analysis-A Course in Mathematics for Students of Physics，读起来更舒服。当然有兴趣的同学还可以参考H.Cartan 微分学. H.Cartan 《微分学》感觉好像什么内容都有，而且都是上课讲的不是特别到位但又特别重要的。这本书可能学完分析之后看会更舒服一些。翻译得比较一般. 邹应 《数学分析》重口味数学分析，比陈天权可能要稍微清新一点，但感觉依然很重. 谢惠民等 《数学分析习题课讲义》神级习题讲义，极好的传统课外补充教材。内容相对古典，讲解非常棒。一元部分要比多元部分强很多。当然不少题目都是很难的。但大多数经过思考后还是能做出来，只是要思考比较长的时间。所以感觉有时间做吉米多维奇的同学不妨试试这本题. 裴礼文 《数学分析中的典型问题与方法》考研专用 波利亚 舍贵 《数学分析中的问题和定理》传说中的习题，不是很容易，有时间可以做一做 代数“代数是慷慨的，它提供给人们的常常比人们要求的还要多.”—-达朗贝尔一般来讲代数课程的课时也不是特别够用。但是比分析稍强。总体上讲，代数一般分为两部分，高等代数和近世代数。其实放在一起处理可能会更好一些。现在高等代数教材中群环域初步内容越来越前置。当然，这是好现象。可以增加同学们对代数的理解。刚接触时可能感觉有些抽象，但一般来讲，成功的抽象往往能将问题变得更加简单纯粹，所以适应之后同学们就会感到抽象的好处。高等代数中的很重要的内容之一是矩阵。对矩阵运算要做到熟练掌握。张贤科和屠伯埙的书中相关内容介绍的比较多，值得参考。但是高等代数中的很多问题往往有可以用两种语言解释，一是矩阵，二是线性变换。希望同学们注意后一种语言。因为很多同学在熟悉矩阵运算之后往往会沉浸在矩阵运算的技巧中，忽略线性变换的语言(本人也曾经这样)。但实际上后者也是相当重要的。因为我们以后接触的空间(比如大多数函数空间)往往不是有限维的。所以就很难使用矩阵处理。所以在这里提示同学们注意后一种语言.另外，有兴趣的同学可以参考一下线性代数的历史，大家会发现矩阵很晚才出现，线性代数比分析要晚的多。最早的线性代数教材好像是库洛什的高等代数教程和Halmos的线性代数.推荐一本相当不错的代数科普书:J.Derbyshire 《代数的历史—-人类对未知量的不舍追踪》 本书对历史介绍相当到位，并且其中也有很多代数相关知识，读起来很有意思.最后提醒大家注意高等代数中的另一个难点Jordan标准型。一般处理方法分成两类，一类用空间分解，另一类是λ-矩阵(实际上是把线性空间V(带着V上的线性变换)视为F[λ]模，再用主理想环上有限生成模的分解定理得到)。前者可能给人的感觉要相对难一些。但是花时间学会前者是值得的。因为前者在李群与李代数相关课程中还是难点。而后者在模论课程中会变得异常的简单. 高等代数丘维声 《高等代数》书的厚度好像再创历史新高，作者讲解的清晰细致，很是到位，所以初学者看懂不成问题，并且内容极其丰富，多得都让人闹不住。有兴趣的同学可以拿来参考. 屠伯埙 《高等代数》书中强调矩阵，有网友评论说:”全书用了80%的篇幅讲矩阵论相关内容”，我看差不多。总的来说内容不如丘维声和张贤科丰富，但矩阵讲的及其到位。习题不是很容易，书写的很平易近人，不难读懂。书里面有各种各样的矩阵处理方法。看完此书后可能对矩阵运算会更加熟练。适合初学者，但是希望同学们不要忽略线性变换的语言. 张贤科 《高等代数》内容和丘维声的书差不多丰富，但是各有侧重。不过全书比丘维声要薄上许多，所以可以看出作者的讲法很是干净简洁。有些地方不容易读懂，很多地方处理的很漂亮。但总的来讲不太适合初学者，但当做参考书却很是不错。并且学完高等代数和线性代数后再看还是会有很大的收获。书后题目不简单，但好在有辅导书。如果实在想不出的话可以看一下。个人感觉内容比所谓亚洲第一难书(李尚志，查建国 线性代数)要丰富，很多处理要比李尚志更加简洁漂亮，并且容易接受。当然习题可能没有李尚志那样难。总的来讲是很好的书. M.Artin 《Algebra(代数学)》绝世神书 当然把这本书列在很多高等代数书目的后面是因为这本书与J.J.Rotman和G.Birkhoff&amp;S.Mac Lane都是将线性代数与近世代数揉在一起讲的书。所以可能在学习高等代数时参考价值就没有那么大。但是在学完第一学期的高等代数后，基本就可以阅读此书。此书选材很有特点(相对来讲没有柯斯特里金的书那么深，并且重线性代数的内容没有讲，并且没有过度抽象的与泛性质相关的内容。重线性代数部分柯斯特里金讲的很全面，而有关泛性质的部分可以在G.Birkhoff&amp;S.Mac Lane中找到。以上所有内容基本上可以在大Rotman上找到)，并且基本上是学数学的本科生同学都应该注意并且应该知道的内容，而且内容相当有意思。可能有些地方没有柯斯特里金丰富(如重线性代数和射影空间)但是可读性和翻译水平要比柯斯特里金的后两本强一些(当然在对每章前后引用的名言部分的翻译还是有很多值得商榷的地方)。当然习题有难有易，有兴趣的同学可以做一做(总共大概有一千五百道)。当然可能对考试没有太大帮助，但对于提高对代数的认识，和审美却又极大的好处。传说Artin在MIT讲课的时候连窗户上都坐满了听课者.另外，作者与芒福德和广中平佑都是扎拉司机在哈佛时的学生。按广中的说法，芒福德和阿廷更偏向几何，而他更偏向代数。传说格罗滕迪克和阿廷家关系不错。传说有一段时间广中，格罗滕迪克等人常到阿廷家聚会，传说直到到半夜十二点才结束. J.J.Rotman 《抽象代数基础教程》可读性可能比M.Artin强一些，作者叙述比较平易近人，并且穿插了不少名词来历和小故事.读起来让人情趣盎然，但内容没有Artin丰富。对于初学者是极合适的书. S.Axler 《Liner Algebra Done Right》书相对来讲不难，但是更强调用线性变换的语言. G.Birkhoff&amp;S.Mac Lane 《A survey of modern algebra》引用J.Derbyshire在’代数的历史’一书中的评论:”20世纪后期，最受数学本科生欢迎的教科书是G.Birkhoff和S.Mac Lane的A survey of modern algebra。这本书第一次出版于1941年，它把20世纪中期代数的所有关键概念都非常清晰的整理到了一起，同时还为学生准备了数以百计的练习题磨练他们的智慧。数，多项式，群，环，域，向量空间，矩阵以及行列式在这本书里都有介绍。我自己就是从G.Birkhoff和S.Mac Lane那里学习的代数学，我承认我的书收到了他们的影响。(不止如此，我还借用了他们书中的一些习题来帮助我解释.)” A.I.Kostrikin&amp;Y.I.Manin 《Linear Algebra and Geometry》相当重口味，在讲授线性代数的内容是果断的使用了范畴的语言，对代数有兴趣的同学可以参考。实际上是柯斯特里金第二册的加强版. 北大版 《高等代数》传说中流传异常广泛的高等代数教本. 许以超 《线性代数与矩阵论》不适合初学，但是可以作为学完高代后再复习的参考书。总共一年半的内容。习题比较难. 柯斯特利金 《代数学引论》比较不错的一套教科书，但是同卓里奇类似，并不适合初学者使用。当然如果有兴趣花时间也是可以读下来的。但是第一册翻译的还成，第二册翻译的就非常的不怎么地，有兴趣阅读的同学可以在张凝川手里找到他的勘误，张很细致的读了全书并且做了习题(了不起啊，我本人佩服之至)然后没事闲的就找我抱怨此书的翻译质量…… 李炯生 查建国等 《线性代数》传说中的亚洲第一难书。习题确实够难的。讲法也很有科大的风范(就是基本选取最晦涩难懂的方式写书)总体感觉不如张贤科，在很多地方感觉讲的不够透彻。可能并不适合初学者. 近世代数刘绍学 章璞 《近世代数导引》应该是由章璞先生主笔，内容不多，但讲解深刻透彻，比丘维声的抽象代数清楚，比杨子胥的深刻，比张禾瑞老先生文风活泼，极适合初学者，作为近世代数的参考书是很合适的. N.Lauritzen 《Concrete Abstract Algebra—-From Numbers to Gröbner Bases》属于讲解清晰，适合初学者的书。老刘(刘玉明)呕血推荐，可以说是老刘课上必引文献之一(剩下的就是M.Artin和聂灵沼 丁石孙了)感谢在外网上找到了电子版的同学，所以现在在新浪爱问可以下载到. 张禾瑞 《近世代数基础》传说中国内最早的近世代数教材之一。群论部分稍微有点少，但是环，域部分精彩无比，绝对经典。放在现在依然是本非常不错的代数教材。值得参考. 范德瓦尔登 《代数学》最早的近世代数教本。当然现在来讲并不古典。前面比较基础的部分在学完高等代数课程后还是不难看懂的。后面的部分内容丰富。全书写作风格比较干脆利落，读起来与Rudin感觉类似. 柯斯特利金 《代数学引论》比较不错的一套教科书，但是同卓里奇类似，并不适合初学者使用。当然如果有兴趣花时间也是可以读下来的。但是第一册翻译的还成，第二册翻译的就非常的不怎么地，有兴趣阅读的同学可以在张凝川手里找到他的勘误，张很细致的读了全书并且做了习题(了不起啊，我本人佩服之至)然后没事闲的就找我抱怨此书的翻译质量…… I.R.Shafarevich 《Basic Notions of Algebra》又是一本神书。书中有各式各样不同代数领域中比较神奇例子和生动深刻的论述。对象是低年级本科生，初学时阅读可能稍微有些困难(主要体现在陌生词汇比较多)。对于提高对代数的认识和审美有极大的好处. 聂灵沼 丁石孙 《代数学引论》一般来讲近世代数课程中的很多稍微深一些的内容都可以在这本书上查到，讲解一般，更适合作为字典使用. 冯克勤 《近世代数引论》又是一本很有科大范儿的书。不推荐初学者阅读。习题相对来讲比较难，但是有习题解。在学完近世代数后可以尝试做一做. 以下是一些对代数有兴趣的同学可以参考的后续阅读的书，其中Miles Reid的书比Atiyah和麦当劳的书要好读一些。按照老刘(刘玉明)的说法K.Erdmann&amp;M.Wildon的李代数是比较适合初学者读的书.并且第一作者是表示论方向的大牛。最后，一般来讲更深的内容可以在大Rotman中找到. T.S.Blyth 《Module Theory—An Approach to Linear Algebra》C.G.Gibson 《Elementary Geometry of Algebraic Curves: an Undergraduate Introduction》F.Kirwan 《Complex Algebraic Curves》Miles Reid 《Undergraduate Commutative Algebra》Miles Reid 《undergraduated algebraic geometry》M.F.Atiyah&amp;I.G.Macdonald 《An introduction to Commutative Algebra》K.Erdmann&amp;M.Wildon 《Introduction to Lie Algebras》J.J.Rotman 《Advanced Modern Algebra》 复变数学分析中，我们更多关注的是底域为实数的函数的分析性质。这样，一个很自然的想法是把实数域变成复数域，研究以复数域为底域的(单变量)函数。这时，我们会发现一个神奇的现象。在实函数中，一般来讲，一个函数的变上限积分函数要比原来的函数有更好的光滑性质，而导函数的光滑性会变弱。但是在复域中，由于复函数的可微和可积(积分与路径无关)要比实函数严格得多(二者竟然等价)，所以就导致对可微(也就是可积)函数求导和求变上限积分函数后不影响函数的光滑性。或者说，一个在某一区域内复可微的函数必定有任意阶连续导数，同时还可以展开为泰勒级数，并且收敛半径不变。可以说，进入复域后，我们研究的函数的光滑性变得非常之好。这便是复变函数与实变函数的一个本质区别.当然，全纯函数(复解析函数)族和亚纯函数族也有着更神奇更深刻的分析性质.最后不得不提的是研究复函数就会很自然的引出多值函数的问题。为了解决这一问题，Riemann天才的通过重叠定义域的方式，恢复了多值函数的单值性，引入了Riemann面的概念。也就是复流形的现代起源. 小平邦彦 《Complex Analysis》作者牛到可以，有兴趣的同学可以查一下，小平先生是传说中的得到沃尔夫奖和菲尔兹奖为数不多的几个人之一，实力可见一斑。同时这本复分析写得也是相当精彩。读起来跟张筑生的数学分析新讲是同一种感觉:”文笔清晰详细，证明深入浅出，通俗易懂”。内容比大多数国内复变函数教本内容更深，更丰富。相对来讲比较强调几何的内容.第六章，第七章是关于Riemann面的极好的入门讲义，有兴趣的同学可以参考.更多的相关内容可以参考L.V.Ahlfors&amp;L.Sario的Riemann Surfaces或者F.Gilligan的 Lectures on Riemann Surfaces(Gtm081)当然书中有不少打印错误，英文翻译的也很生硬(可以明显的看出很多话并不符合英语习惯)，但并不影响理解，对于英语不是特别好的同学，反而有助理解，因为只要将英文直译成对应的中文，一般来讲就很容易看懂. H.Cartan 《解析函数论初步》非常经典，讲解方式相当有特色。算是那种比较薄但内容比较丰富的书。写法相当简练，书中很多内容的处理(形式幂级数，微分形式的积分)让人感觉耳目一新。总的来讲还是比较明白的。但是要求读者知道一点儿点集拓扑的知识和一点儿微分形式的知识。中文版翻译质量一般，但是图书馆有英译版. E.M.Stein&amp;R.Shakarchi 《Complex Analysis》Stein是陶哲轩的老师，这本书是Stein在MIT讲复变的讲义，这是这一系列的第二本，第一本是 Fourier Analysis - An Introduction，第三本是Real Analysis–Measure Theory，Integration，and Hilbert Spaces。Stein的复变内容丰富(有老师指出国内大多数复变教材只能覆盖Stein书前三分之一的内容.)，讲解平易近人，但是感觉风格上更强调分析，我不是特别喜欢(与个人审美有关)，但是很多同学比较喜欢。复变的内容有一部分放在Fourier Analysis - An Introduction的习题中。据传武大有大牛做完了这本书的全部习题，在一次很难的复变考试中提前一个多小时交卷，并且基本正确. 沙巴特 《复分析I单复变函数》为数不多的讲解平易近人的俄罗斯教材。相对强调几何直观。并且中间穿插了很多有意思的历史故事和插图，有很强的可读性。是极好的单复变教本，很适合初学者. Ahlfors 《Complex Analysis(复分析)》极经典的复分析教材，内容丰富，也是比较简洁的教材。讲解的还是可以看懂，只不过不少习题都很有难度。Ahlfors也是即得过菲尔兹(好像是第一届)又得过沃尔夫奖的大牛. 下面的一些是将复函数融进数学分析的书高木贞治 《高等微积分(解析概论)》J.Dieudonné 《Treatise on Analysis(现代分析基础)》T.M.Apostol 《数学分析》R.Courant&amp;F.John 《Introduction to Calculus and Analysis(微积分和数学分析引论)》高木的相对古典，但讲的很精彩简明。Dieudonné的就比较现代，相对要难一些. 钟玉泉 《复变函数论》国内用的比较多的复变函数教材。内容相对古典，但是写法相对严谨，内容不深，讲的挺明白的，读起来很舒服。相对来讲算是国内比较好的教材. 龚昇 《简明复分析》观点比较高，内容深刻丰富，只不过写得太薄，如果老师不讲，读起来就很费劲. 余家荣 《复变函数》内容古典，但细节处理的比较糙，讲解也没有钟玉泉透彻，感觉一般啊. C.A.Berenstein&amp;R.Gay 《Complex Variables an Introduction(Gtm125)》重口味的复变，内容同Ahlfors相当，但显然用了相当现代化的处理方式。有兴趣的同学可以参考. W.Rudin 《Real and Complex Analysis》神书之一，Rudian式的叙述风格，读起来还是有一定难度的。可以作为参考. 实变周民强 《实变函数论》应该是国内用得最多的一本实变。微分与积分部分讲解十分到位，总的来讲这本书讲的还算比较明白，最大的特点就是习题多的像天上的星星。而且很大一部分有相当的难度。有兴趣的同学可以在大四预备一年的时间做一下习题。缺点是不讲抽象测度，但是很多处理还是很为读者考虑的。值得一看的好书. 夏道行 《实变函数论与泛函分析(上册)》起点不高，并且讲解清晰，适合初学，与周民强相比，强调抽象测度，习题要简单一些，内容相对容易接受。在学习数学分析的有关积分理论时可以作为不错的参考. R.L.Wheeden&amp;A.Zygmund 《Measure and integral –An introduction to real analysis》师大早年间用的实变讲义。据传讲得还是很不错的. 王昆扬 《实变函数论讲义》很多地方很有新意，但又有不少细节处理得没有周民强好。后半部分相当有意思，值得一读。但以周民强为参考可能读起来会更舒服一些. P.R.Halmos 《Measure Theory(GTM018测度论)》相对来讲是本相当有历史的书。证明一般比较简洁，漂亮。如果想细致的念一念测度与积分理论，这本书是相当不错的选择。同时是夏道行的非常不错的参考书. E.M.Stein&amp;R.Shakarchi 《Real Analysis–Measure Theory，Integration，and Hilbert Spaces》据网友评论，这本书比国内的很多实变函数教本有更高的可读性. E.H.Lieb&amp;M.Loss 《Analysis》丘成桐选译中的一本，陈天权老大爷的评价是:”这本分析教材是作者们给物理学家和从事自然科学研究的工作者介绍近代分析而写的。他们避开了一般泛函分析，而对具体的空间讨论，介绍了为理解近代量子力学所需的最有用的分析工具。”测度论部分讲的相对简练深刻，和一般的实变教材有些不同。按作者的内容可以相对较快的进入比较重要的Lp空间。其中很多论述相当精彩，值得一看. W.Rudin 《Real and Complex Analysis》神书之一，Rudian式的叙述风格，读起来还是有一定难度的。可以作为参考. Kolgomorov 《函数论与泛函分析初步》名著之一，先讲泛函，再讲实变，值得一读。实变部分很多内容可能和国内一些教材处理方式不同. 徐森林 《实变函数论》科大风格，符号奇多无比，讲解相对晦涩，自称是周民强和夏道行的加强版，但不少细节之处处理不及前二者。优点是习题比较多，而且比较难，习题解比周民强习题解的质量要高一些. G.B.Folland 《Real Analysis》袁文老师推荐的书。传说内容比较现代。写得也很不错. 严士健 《测度与概率》如果感觉Halmos读起来有些困难，本书是一个不错的选择。选材和行文可能比Halmos更适合初学者. 严加安 《测度论讲义》如果觉得实变中积分理论没学过瘾，可以读读此书。涉及到测度论的内容，也可查阅此书。起点比Halmos高些，适合当做字典查阅，可能不适合初学. (古典)微分几何一般来讲是一个学期的课程。主要介绍曲线曲面的局部性质及相应不变量系统。整体性质一般会因为课时的原因略去或再开其他课程讲解。算是本科阶段及其重要的基础课。内容可以看做曲面积分的拓展. 张筑生 《数学分析新讲》书的第三册前一部分花了不少篇幅介绍微分几何的基础知识，讲解条理性强，简明扼要，直观生动，重点突出。虽然是数学分析，可是比不少微分几何教材讲得还好。所以同学们学习微分几何时，可以先看一下这部分内容. 陈维桓 《微分几何(06年版)》感觉上可以算是国内本科阶段最好的微分几何教本。最大的特点是讲解细致清晰，适合初学。微分几何的细节写得严格清晰并不容易，这本书不但做到了这一点，而且用了读者更容易接受的方式讲解。同时内容基本上是自足的，书中引用的定理基本会在附录中给出完整的证明。唯一的一点小问题(与个人审美有关)是本书的很多方程如果贯彻偏导用下标表示的方式的话能写得更紧凑一些，但是基本不影响阅读. W.Klingenberg 《A Course in Differential Geometry (Gtm051)》内容比陈维桓要丰富一些(但基本上和do Carmo差不多)，某些细节的处理显得更严格，证明和讲解都比较简明(颇有Rudin的风格)。可以作为参考书. M.P.do Carmo 《Differential Geometry of Curves and Surfaces曲线与曲面的微分几何》书的内容是一年的课程，按丘成桐的说法，本科阶段能念懂do Carmo就已经很不错了。不过感觉内容确实很多，有兴趣和时间的同学可以念一念。写法上与陈维桓感觉差的比较远，但跟W.Klingenberg比较近. 古志鸣 《几何与拓扑的概念导引》数学与非数学专业的几何与拓扑公共基础课，虽然是研究生的基础课，但是因为考虑到听课的非数学专业的同学，所以就略去了不少重要定理的证明，而改用实例说明，感觉上，学完分析和代数课程的数学系本科生就可以阅读。概念的引导读起来感觉不错，读完后对很多几何概念会有一些感性认识。不过对几何感兴趣的同学最好还是阅读相关的教材，这本书可能当做科普更合适一些. B.A.Dubrovin A.T.Fomenko S.P.Novikov《Modern Geometry —- Methods and Applications》俄罗斯教材选译之一，也收在Gtm系列中，一共三本，但是中译版比英译版少一些讲解的内容，不知道是版本的原因，还是因为那部分语法结构比较复杂所以就不翻译。所以看的时候拿英文版对照一下可能有助理解.七十年代在莫大开设的几何课程的教本。内容相当丰富(国内本科阶段的微分几何一般只能覆盖第一本的一部分)，方法相当现代，但可能因为本科生讲义的原因，讲法上并没有用太多(但也不少)更抽象的数学。学完微分几何课以后念起来可能会更舒服一些. M.Berger&amp;B.Gostiaux 《Differential Geometry: Manifolds Curves and Surfaces(GTM115 微分几何—流形，曲线和曲面)》法国书一般比较重口味，按照邓冠铁老师的话说，法国教材给人的感觉就像为了捞一碗水要先翻过一座高山。叙述现代而抽象，读起来要花一些力气。不过因为讲的很严格由比较一般，所以作为参考书却是不错的选择. H.Cartan 《微分学》后半部分简明而严谨的讲了微分形式及其在几何中的一些应用. 梁灿彬 《微分几何入门与广义相对论》老梁是为数不多的懂数学的物理老师，所以编出来的书数学系的同学读起来障碍不大(可能学完微分几何后读会更好接受)。但是这本书排版太过紧凑，所以读起来可能没那么舒服。想读这本书更好的选择是听一听老梁的课。中科院有，网上也有。讲的非常之好，值得一听. 陶哲轩 《Differential Forms and Intergration》关于微分形式的积分的文章，篇幅不大，起点不高，但讲的很不错. M.P.do Carmo 《Differential Forms and Applications》感觉上讲的没有曲线曲面的微分几何那样清楚易懂，读起来没有do Carmo自称的那样轻松. I.Madsen&amp;J.Tornehave 《From calculus to cohomology》陈天权老大爷的评价是:”这是作者们在Arhus大学讲授微分拓扑的讲义基础上写成的书，包括同调理论的初步及其在示性类上的应用。本书只假定读者具有微积分和线性代数的知识，只在最后要求读者有一些曲面理论的知识.” 文风算是比较简洁那种。但是讲的还是比较明白的. S.Morita 《Geometry of Differential Forms》用更容易接受的语言介绍了微分形式的相关内容，值得一看. 拓扑学拓扑学一般来讲可以大致分为三个部分，点集拓扑，代数拓扑和微分拓扑。点集拓扑更多的可能不是一门专业学科，而更像集合论那样很多学科的基础语言。代数拓扑和微分拓扑更偏向几何。本科阶段的拓扑课程内容相对少。更多的是一些点集拓扑，代数拓扑相对来讲篇幅较少，因为课时的原因，微分拓扑相对较难涉及。所以一般来讲本科阶段拓扑学的课程可能分析的感觉要多于几何学。对几何感兴趣的同学可以参考B.A.Dubrovin A.T.Fomenko S.P.Novikov 《Modern Geometry —- Methods and Applications》和[苏]Ю.Г.鲍里索维奇 Н.М.勃利兹尼亚科夫 Я.А.伊兹拉依列维奇 Т.Н.福缅科 著，盛立人 金成桴 吴利生 徐定宥 许依群 罗嵩龄 译，高等教育出版社，1992.9，拓扑学导论，英译名为Introduction to Topology前者由中译版，在斯普林格的Gtm系列中为第93，104，124本，相对比较好找。但是后者就不太好找，一般只能在图书馆中找到。后者是非常不错的拓扑学教材，内容丰富，通论同调都有讲到，讲法更偏向于几何，读起来妙趣横生. 熊金城 《点集拓扑讲义》点集拓扑部分介绍的非常详细，属于相对比较好读的拓扑学教材。只不过代数拓扑的内容相对较少。但国外的教材代数拓扑的内容就要相对多些. J.R.Munkres 《Topology(拓扑学)》也是一本绝世神书。传说作者与Smale和另一位传说中的同学都是R.Bott的学生。据称作者当时是三个家伙中最牛逼的一个(当时Smale的才华并没有显露出来)，传说不但上课记笔记，而且整理的讲义非常不错，广受欢迎。书的翻译质量很不错。原版相当口语话，翻译也在努力尽量做到保持原版口语化的风格。译者指出:”此书全书取材合理，概念引入自然，论证思路清晰，联系广泛自然” 基本可以算得上人民群众喜闻乐见的好书之一，唯一的一点小问题是内容实在太多，感觉怎么读也读不完的样子。有时间的同学一定要好好读一读. Armstrong 《Basic Topology基础拓扑学》也是非常不错的教材，但是翻译质量不如Munkres。新版除了字体外好像什么也没改，词汇显得比较老旧。可读性稍逊于Munkres，但是选材和讲解比Munkres要简明一些. (日)野口宏 《拓扑学的基础和方法》非常不错的拓扑学科普书，内容丰富，写得比较细致. W.G.Chinn&amp;N.E.Steenrod 《拓扑学的首要概念》非常不错的拓扑学科普书，内容不如野口宏丰富，但讲解可能更容易接受。值得一看. 下面两册书风格类似，前者是复旦的拓扑学，后者是北大的拓扑学。可能都为了更多的介绍代数拓扑对点集拓扑的篇幅进行了压缩处理，内容基本不变，只是证明变得更简明，所以初学时读起来会有一定的困难。阅读时以熊金城作为参考是个不错的注意。与后者相比，前者内容更丰富一些。但总的来讲没有Munkres和Ю.Г.鲍里索维奇等丰富.李元熹 张国樑 《拓扑学》尤承业 《基础拓扑学讲义》 Kelley 《一般拓扑学》一般拓扑学与点集拓扑学是同义词。所以作者为了体现幽默指出也可以把此书称为”青年分析学者须知”类似游览手册或字典的著作，相对来讲不是特别好读。传说习题很难. G.Choquet 《拓扑学教程》虽然叫拓扑学，但本书更注重的是点集拓扑中与分析有关的内容。所以早年间的版本叫做分析与拓扑。这本书翻译的不错。是分析基础部分相当好的参考书。作为泛函分析的参考书是很合适的. 常微分方程一般来讲本科阶段介绍常微分方程的常用解法和基本定理。同学们会发现这门课相当耗时间，我们会花大量时间用来练习解方程，虽然大多数方程都是难以求出解析解的(但这样的练习是不能忽略的)。常微分方程理论相对来讲比偏微分方程要更成体系，显得更完整。但是很多细节问题要深究起来都是无底洞(比如说李雅普诺夫函数的构造等)。常微分方程课程更重要的应该是存在唯一性定理，解对参数的依赖性，定性理论等内容。但因为课时有限，上面提及的内容很难做更细致的讲解，所以就需要同学们在学完之后花时间回顾一下. 王高雄 《常微分方程》内容相对适合初学者。定性理论部分讲得相当精彩。求解方法比丁同仁引入自然。总体上讲，内容没有丁同仁丰富，但可读性比丁同仁强很多. 彼得罗夫斯基 《常微分方程论讲义》算是早年间出版的书，但是现在看起来依然是相当不错的书。选材不落俗套，文风平易近人，讲解细致独到(有网友认为作者行文官僚气严重，这可能与个人审美有关。文风虽然不算特别活泼，但相比之下国内很多书比这本书官僚气更严重)，可读性很高的一本书。内容不及丁同仁丰富，但是可读性更高，作为参考书十分合适. 丁同仁 《常微分方程教程》不少网友认为这是极好的一本书，但个人感觉不少重要定理的证明叙述生硬，过程不够自然，要理解需要花费很大力气。优点是内容丰富. Л.C.庞特里亚金 《常微分方程》内容不及丁同仁丰富，但比丁同仁可读性高. Hirsch&amp;Smale 《微分方程、动态系统与线性代数》网友评论说本书虽然内容现代但注重理解，但可读性很高。不过习题很难，有兴趣的同学可以做一做. W.Walter 《Ordinary Differential Equations(Gtm182)》基本上能够查到常微分方程稍微深一些的内容。可以当做字典用. H.Cartan 《微分学》微分方程定性理论部分讲得挺精彩的，只不过翻译得比较一般. V.I.Arnold 《Ordinary Differential Equations》很多网友说这本书是学习常微分方程时的必读书。但其实本书并不适合入门。说是必读是没错的，但在学习常微分方程的基础课时读就有待商榷。可能同学们在学完常微和微分几何的课程后再读，就会感到非常舒服。而且这样能更强烈的感受到这本书的神奇之处.]]></content>
      <categories>
        <category>数学</category>
        <category>学习指导</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[美国大学数学研究生基础课程参考书目]]></title>
    <url>%2F2021%2F04%2F14%2F%E7%BE%8E%E5%9B%BD%E5%A4%A7%E5%AD%A6%E6%95%B0%E5%AD%A6%E7%A0%94%E7%A9%B6%E7%94%9F%E5%9F%BA%E7%A1%80%E8%AF%BE%E7%A8%8B%E5%8F%82%E8%80%83%E4%B9%A6%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[一、本科生假设本科应有的水平 1.1 分析 《Principles of Mathematical Analysis》Walter Rudin 《Mathematical Analysis》Apostol 《Calculus on Manifolds》M.spivak 《Analysis on Manifolds》Munkres 《Introductory Real Analysis》Kolmogorov/fomin 《Ordinary Differential Equations》Arnold 1.2 代数 《Linear Algebra》Stephen H. Friedberg 《Linear Algebra》Hoffman 《Linear Algebra Done Right》Axler 《Advanced Linear Algebra》Roman 《Algebra》Artin 《A First Course in Abstract Algebra》Rotman 1.3 几何 《Ifferential Geometry of Curves And Surfaces》do carmo 《Differential Topology》Pollack 《Foundations of Geometry》Hilbert 《Topology》James R. Munkres 二、研究生2.1 第一学年2.1.1 几何与拓扑 《Topology》James R. Munkres：较新的拓扑学的教材适用于本科高年级或研究生一年级 《Basic Topology》Armstrong：本科生拓扑学教材 《General Topology》Kelley：一般拓扑学的经典教材，不过观点较老 《General Topology》Willard：一般拓扑学新的经典教材 《Topology And Geometry》Glen Bredon：研究生一年级的拓扑、几何教材 《Introduction to Topological Manifolds》John M. Lee：研究生一年级的拓扑、几何教材，是一本新书 《From Calculus to Cohomology》Madsen：很好的本科生代数拓扑、微分流形教材 2.1.2 代数 《Abstract Algebra》 Dummit：最好的本科代数学参考书，标准的研究生一年级代数教材 《Algebra》 Lang：标准的研究生一、二年级代数教材，难度很高，适合作参考书 《Algebra》 Hungerford：标准的研究生一年级代数教材，适合作参考书 《Algebra》 M,Artin：标准的本科生代数教材 《Advanced Modern Algebra》 Rotman：较新的研究生代数教材，很全面 《Algebra：A Graduate Course》 Isaacs：较新的研究生代数教材 《Basic Algebra Vol I&amp;Ii》 Jacobson：经典的代数学全面参考书，适合研究生参考 2.1.3 分析基础 《Principles of Mathematical Analysis》 Walter Rudin ：本科数学分析的标准参考书 《Real And Complex Analysis》 Walter Rudin：标准的研究生一年级分析教材 《Complex Analysis》 Lars V. Ahlfors：本科高年级和研究生一年级经典的复分析教材 《Functions of One Complex Variable I》 J.B.Conway：研究生级别的单变量复分析经典 《Complex Analysis》 Lang：研究生级别的单变量复分析参考书 《Complex Analysis》 Elias M. Stein：较新的研究生级别的单变量复分析教材 《Real And Functional Analysis》 Lang：研究生级别的分析参考书 《Real Analysis》 Royden：标准的研究生一年级实分析教材 《Real Analysis》 Folland：标准的研究生一年级实分析教材 2.2 第二学年2.2.1 代数 交换代数 《Commutative Ring Theory》 H. Matsumura：较新的研究生交换代数标准教材 《Commutative Algebra I&amp;Ii》 Oscar Zariski , Pierre Samuel：经典的交换代数参考书 《An Introduction to Commutative Algebra》 Atiyah：标准的交换代数入门教材 《Commutative Algebra With A View Toward Algebraic Geometry》 Eisenbud：高级的代数几何、交换代数的参考书，最新的交换代数全面参考 同调代数 《An Introduction to Homological Algebra》 weibel：较新的研究生二年级同调代数教材 《A Course in Homological Algebra》 P.J.Hilton,U.Stammbach：经典全面的同调代数参考书 《Homological Algebra》 Cartan：经典的同调代数参考书 《Methods of Homological Algebra》 Sergei I. Gelfand, Yuri I. Manin：高级、经典的同调代数参考书 《Homology》 Saunders Mac Lane：经典的同调代数系统介绍 2.2.2 代数拓扑 《Algebraic Topology》 A. Hatcher：最新的研究生代数拓扑标准教材 《Algebraic Topology》 Spaniers ：经典的代数拓扑参考书 《Differential Forms in Algebraic Topology》 Raoul Bott and Loring W. Tu：研究生代数拓扑标准教材 《A Basic Course in Algebraic Topology》 Massey：经典的研究生代数拓扑教材 《Algebraic Topology：A First Course》 Fulton：很好本科生高年级和研究生一年级的代数拓扑参考书 《Topology And Geometry》 Glen Bredon：标准的研究生代数拓扑教材，有相当篇幅讲述光滑流形 《Algebraic Topology Homology And Homotopy》：高级、经典的代数拓扑参考书 《A Concise Course in Algebraic Topology》 J.P.May：研究生代数拓扑的入门教材，覆盖范围较广 《Elements of Homotopy Theory》 G.W. Whitehead：高级、经典的代数拓扑参考书 2.2.3 实分析、泛函分析 实分析 《Measure Theory》 Halmos：经典的研究生实分析教材，适合作参考书 《Measure Theory》 Donald L. Cohn：经典的测度论参考书 《Real Analysis》 Royden：标准研究生分析教材 《Real And Complex Analysis》 Walter Rudin：标准研究生分析教材 《Real Analysis》 Folland：标准研究生实分析教材 泛函分析 《Functional Analysis》 Walter Rudin：标准的研究生泛函分析教材 《A Course of Functional Analysis》 Conway：标准的研究生泛函分析教材; 《Functional Analysis》 Lax：高级的研究生泛函分析教材 《Functional Analysis》 Yoshida：高级的研究生泛函分析参考书 2.2.4 微分拓扑 李群、李代数 《Differential Topology》 Hirsch：标准的研究生微分拓扑教材，有相当难度 《Differential And Riemannian Manifolds》 Lang：研究生微分流形的参考书，难度较高 《Foundations of Differentiable Manifolds And Lie Groups》 Warner：标准研究生微分流形教材，有相当的篇幅讲述李群 《Representation Theory: A First Course》 W. Fulton and J. Harris：李群及其表示论标准教材 《Lie Groups And Algebraic Groups》 A. L. Onishchik, E. B. Vinberg：李群的参考书 《Lectures on Lie Groups》 W.Y.Hsiang：李群的参考书 《Introduction to Smooth Manifolds》 John M. Lee：较新的关于光滑流形的标准教材 《Lie Groups, Lie Algebras, And Their Representation》 V.S. Varadarajan：最重要的李群、李代数参考书 《Introduction to Lie Algebras And Representation Theory》 Humphreys：标准的李代数入门教材 2.3 第三学年2.3.1 微分几何 《Riemannian Geometry》Peter Petersen：标准的黎曼几何教材 《Riemannian Manifolds: An Introduction to Curvature》 John M. Lee：最新的黎曼几何教材 《Riemannian Geometry》doCarmo：标准的黎曼几何教材 《A Comprehensive Introduction to Differential Geometry I—V》M. Spivak：全面的微分几何经典，适合作参考书 《Differential Geometry,Lie Groups,And Symmetric Spaces》Helgason：标准的微分几何教材 《Fundamentals of Differential Geometry》Lang：最新的微分几何教材，很适合作参考书 《Foundations of Differential Geometry》kobayashi/nomizu：经典的微分几何参考书 《Introduction to Differentiable Manifolds And Riemannian Geometry》Boothby：标准的微分几何入门教材，主要讲述微分流形 《Riemannian Geometry》 I.Chavel：经典的黎曼几何参考书 《Fomenko, Novikov “Modern Geometry-Methods And Applications”Vol 1—3》Dubrovin：经典的现代几何学参考书 2.3.2 代数几何 《Algebraic Geometry: A First Course》 Harris：代数几何的入门教材 《Algebraic Geometry》 Robin Hartshorne ：经典的代数几何教材，难度很高 《Basic Algebraic Geometry 1&amp;2 2Nd Ed》 I.R.Shafarevich.：非常好的代数几何入门教材 《Principles of Algebraic Geometry》 giffiths/harris：全面、经典的代数几何参考书，偏复代数几何 《Commutative Algebra With A View Toward Algebraic Geometry》 Eisenbud：高级的代数几何、交换代数的参考书，最新的交换代数全面参考 《The Geometry of Schemes》 Eisenbud：很好的研究生代数几何入门教材 《The Red Book of Varieties And Schemes》 Mumford：标准的研究生代数几何入门教材 《Algebraic Geometry I : Complex Projective Varieties》 David Mumford：复代数几何的经典 2.3.3 调和分析 偏微分方程 调和分析 《An Introduction to Harmonic Analysis,Third Edition》 Yitzhak Katznelson：调和分析的标准教材，很经典 《Harmonic Analysis》 Elias M. Stein：标准的研究生调和分析教材 《A Course in Abstract Harmonic Analysis》 Folland：高级的研究生调和分析教材 《Abstract Harmonic Analysis》 Ross Hewitt：抽象调和分析的经典参考书 偏微分方程 《Partial Differential Equations》 Evans：偏微分方程的经典教材 《Partial Differential Equations》 Aleksei.A.Dezin：偏微分方程的参考书 《Linear Partial Differential Operators I&amp;Ii》 L. Hormander：偏微分方程的经典参考书 《Elliptic Partial Differential Equations of Second Order》 David Gilbarg：偏微分方程的经典参考书 《Partial Differential Equations》 Jeffrey Rauch：标准的研究生偏微分方程教材 2.3.4 复分析 多复分析导论 《Functions of One Complex Variable Ii》J.B.Conway：单复变的经典教材，第二卷较深入 《Lectures on Riemann Surfaces》 O.Forster：黎曼曲面的参考书 《Compact Riemann Surfaces》 Jost：黎曼曲面的参考书 《Compact Riemann Surfaces》 Narasimhan：黎曼曲面的参考书 《An Introduction to Complex Analysis in Several Variables》 Hormander：多复变的标准入门教材 《Riemann Surfaces》 Lang：黎曼曲面的参考书 《Riemann Surfaces》 Hershel M. Farkas：标准的研究生黎曼曲面教材 《Function Theory of Several Complex Variables》 Steven G. Krantz：高级的研究生多复变参考书 《Complex Analysis: The Geometric Viewpoint》 Steven G. Krantz：高级的研究生复分析参考书 2.4 专业方向选修课 多复分析 复几何 几何分析 抽象调和分析 代数几何 代数数论 微分几何 代数群、李代数与量子群 泛函分析与算子代数 数学物理 概率理论 动力系统与遍历理论 泛代数 2.5 其他数学基础应该在核心课程学习的过程中穿插选修 《Native Set Theory》 Halmos 《Abstract Set Theory》 Fraenkel 《Mathematical Logic》 Ebbinghaus 《A Mathematical Introduction to Logic》 Enderton 《Foundations of Analysis》 Landau 《Categories for Working Mathematican》 Maclane]]></content>
      <categories>
        <category>数学</category>
        <category>学习指导</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[为什么研究代数几何]]></title>
    <url>%2F2021%2F03%2F27%2F%E4%B8%BA%E4%BB%80%E4%B9%88%E7%A0%94%E7%A9%B6%E4%BB%A3%E6%95%B0%E5%87%A0%E4%BD%95%2F</url>
    <content type="text"><![CDATA[由于数学的抽象与艰深，以及与日常社会生活的严重脱节，数学家们的生活一般来说很难进入公众的视野。另一方面，也由于绝大多数数学家的生活的确是枯燥乏味和平淡无奇的，这些都很难成为记实和文学写作的题材，相比起其他学科来说，专门描写数学家生平与学术贡献的传记并不多。即使在仅有的几本这类传记中，也往往会堆砌一些与数学家真正关注的数学思想与学术生涯并无很大关系的材料，以充实相对缺乏趣味的个人与社会生活内容。因此真正写得好的数学家传记其实是非常少见的。由美国科学出版社在1991年出版的传记《The Unreal Life of Oscar Zariski》$^{[1]}$是一本被公认为写得比较成功的数学家传记。这本书的书名本文暂且译为《不真实的人生——数学家扎里斯基传》，该书作者介绍说之所以取Unreal Life这个书名，是因为扎里斯基曾经说过这样一句话：几何是真实的生活（Geometry is the real life）,作为一名大数学家，扎里斯基的生活被真实地记录在了上百篇论文和几部专著中。相比之下，数学以外的日常生活就显得不那么真实或是虚幻的，这是因为在数学中，人们可以更自由充分地表达自己的个性、好奇心、乐观、骄傲、倔强、诉求以及智力上的浪漫。 这本传记是在扎里斯基去世5年后推出的，内容丰富翔实，表述准确到位，生动展示了扎里斯基作为一名数学家的成长过程和研究教学的主要成就。由于颇受好评，著名的Springer出版社于2009年重新再版了这本出色的传记。目前这本书已经成为我们了解20世纪代数几何发展历史的重要参考文献之一。扎里斯基（1899-1986）是20世纪最有影响的代数几何学家中的一个，他通过运用抽象代数的思想方法，和韦伊（Weil）、格罗腾迪克（Grothendieck）等人一起在20世纪的中期重新建立了代数几何的逻辑基础，澄清了经典代数几何中的许多模糊之处，从而为20世纪下半叶代数几何的大发展奠定了坚实的基础，为此他在1981年获得了沃尔夫数学奖$^{[2]}$。在现代数学众多的分支学科中，代数几何是一门非常重要而又特别的基础学科$^{[3]}$，它与数学中其他分支学科有着广泛的联系，并且被深刻地应用到理论物理及其他的科学技术中。在大多数20世纪现代数学重大进步（例如获得菲尔兹奖和沃尔夫奖的工作）的背后，或多或少都有代数几何的背景。扎里斯基的学生、菲尔兹奖获得者芒福德(Mumford)曾经写过如下一段话来表达他对这门奇特学科的看法： “当我开始在代数几何中研究生涯的时候，我认为有两个吸引我的原因，首先是它研究的对象实在是非常形象和具体的射影曲线与曲面；第二是因为这是一个既小又安静的领域，其中大概只有十来个人在研究，几乎不需要新的想法。然而随着时光的推移，这个学科逐渐获得了一个看上去是诡秘、孤傲而又极端抽象的名声，它的信徒们正在秘密打算接管其他所有的数学领域！从某种程度上说，上述最后一句话是对的：代数几何是一门与大量其他数学分支学科有着最密切关系的学科 一一 例如复解析几何（多复变）与微分几何、拓扑学、K–理论、交换代数、代数群和数论…并且既能给所有这些学科以各种定理、方法和例子，同时又能够从它们那里得到同样多的定理、方法和例子。”$^{[4]}$ 确实很难让人相信：从研究一组多元多项式的零点集合（即代数簇）中可以引发出那么多那么重要深刻而又美好的数学理论。虽然在现代数学中也有一些学科与其他学科有比较密切的联系，但这种联系远不及代数几何与其他学科的联系。抽象代数、代数拓扑与微分拓扑、整体微分几何、数论以及分析中许多重要的理论都是因代数几何的需要而提出的，同时代数几何也将分析、拓扑、几何与数论中的许多基本概念和理论抽象提升到了更高的层次，所以说代数几何是20世纪数学统一化的一个主要源动力。往往在别的学科中是一般性的理论，但是到了代数几何中就变成一个特例。由于数学的发展在很大程度上依赖于各分支学科之间的交叉影响和相互作用，因此可以说代数几何对20世纪现代数学的大发展所起的作用最大。代数几何已经成为将现代数学各主要分支学科紧密联系在一起的中心纽带。由此我们就不难理解为什么国际数学界对于和代数几何有关的重要工作总是给予较高的评介。例如获得沃尔夫奖的陈省身与丘成桐两位大师，他们最重要的工作就与代数几何密切相关：陈（省身）示性类被深刻地推广与运用到代数几何中，而卡拉比-丘（成桐）流形则是当前复代数几何中最热门的研究对象之一。代数几何最早起源于在17和18世纪牛顿和贝朱（Bezout）等人关于平面代数曲线的研究工作，例如牛顿曾经仔细研究过平面三次实代数曲线的分类。到了19世纪上半叶的射影几何登场后，才开始出现一些关于复代数曲线与复代数簇的初步的代数几何理论。然后黎曼在研究复变函数的阿贝尔积分理论的过程中提出了内蕴的黎曼面概念和代数函数的理论，也就是从崭新的比较抽象的拓扑与几何视角来重新研究复代数曲线，并且发现了流形的拓扑不变量──亏格（拓扑学就是从这里开始的）。在此之后，以克罗内克、戴德金和韦伯(Weber)为代表的代数学派受代数数论的启发相继引入了理想、赋值和除子等最基本的概念，特别是戴德金和韦伯两位已经有了用纯代数的方法来研究代数曲线的超前想法。与此同时，以M.诺特为代表的几何学派继续从经典射影几何的角度研究复代数曲线和复代数簇，发现了平面曲线奇点解消的基本方法。从19世纪末期开始，代数几何的发展进入了一个新的历史阶段。一些数学家试图将黎曼的复代数曲线理论推广到复代数曲面上。虽然这里的维数仅仅增加了一维，但是与代数曲线完全不同，研究代数曲面需要克服许多困难，难度极大。庞加莱为此提出了代数拓扑的同调理论，莱夫谢茨（Lefchetz）用这个同调理论研究了复代数曲面的拓扑性质。当然最主要的贡献还是来自于著名的意大利学派。这个学派的三个主要代表人物是卡斯泰尔诺沃（Castelnuovo）、恩里奎斯（Enriques）和塞维里（Severi），他们在20世纪初期用天才的几何直觉和高超的几何技巧，综合运用包括分析与拓扑方法在内的各种方法创造了复代数曲面的一个非常深刻的理论。但同时他们的工作也有一个致命的缺陷，就是缺少一个统一的逻辑基础，一些证明依赖于几何直观，缺乏严密性。和数学史上常见的情形类似，这种逻辑基础不稳的状况对于视严格为生命的数学家们来说是一件特别纠结和难受的事，它严重阻碍了代数几何的进一步向前发展。扎里斯基就是在这个历史发展的关键时刻进入到代数几何领域中来的。扎里斯基早年的经历比较曲折。扎里斯基于1899年出生于白俄罗斯的科布林，这是一个靠近波兰边境的小城市。扎里斯基是犹太人后裔，他是7个孩子中的一个，父亲早逝，靠母亲抚养长大。由于家境不错，受到良好的教育，且从小就显露出对数学的爱好。1918年扎里斯基进入乌克兰的基辅大学后开始学习数学，偏向于代数与数论。同时他在大学里还是一名关心社会、积极宣传马克思主义的进步学生，并且在游行中受过伤。当时正处于十月革命后国内战争的动荡时期，为了更好地学习数学，在经过一番周折后，扎里斯基于1921年来到文艺复兴的发源地意大利，当年秋天进入罗马大学求学。这时的罗马大学正是当时世界代数几何的研究中心，意大利学派的所在地。由于在经典代数几何中需要用到许多代数知识，这对喜欢代数的扎里斯基来说，很自然地被吸引到代数几何这个领域中来了。他在听卡斯泰尔诺沃的“代数几何与代数函数”课的时候，还自学了所需要的复变函数论。而在恩里奎斯的课上，他不安地发现“只有几何，只看到各种曲线和图形，非常随意，没有证明。” 至于意大利学派三位大数学家中最年轻、最有影响的塞维里的课，就更随意了，所作的断言常常分不清是定理还是猜想，或是假设。尽管如此，扎里斯基以他的天赋还是从三位老师那里学到了许多东西，以至他心存感激地称罗马大学为他的“几何乐园”。他开始关心怎样完善他的意大利老师们的代数几何成果的严格证明问题，只是此时他和他的老师们都还不了解在德国哥廷根抽象代数（特别是环论）的发展。当时的看法是也许可以用拓扑和分析的方法来改造代数几何旧有的综合证明方法，所以卡斯泰尔诺沃鼓励他学习莱夫谢茨新的拓扑方法。为此扎里斯基在罗马大学获得博士学位后，于1927年来到美国的约翰斯霍普金斯大学工作，以便于和在普林斯顿的莱夫谢茨进行交往。在美国的前几年中，扎里斯基花了很大精力做的一个工作是写作《代数曲面》$^{[5]}$一书。这本于1935年问世的重要著作系统总结了意大利学派关于代数曲面的经典理论，成为了后人了解意大利学派工作的必读书籍。从这本经典著作中，我们可以发现意大利学派在代数曲面方面的工作确实达到了很高的水平：奇点解消、除子与线性系、黎曼-罗赫(Roch)定理、参模、拓扑方法、分析方法等等。不过，扎里斯基更想做的是：为缺乏严密性的经典代数几何打造一个坚实的逻辑基础，所以他在书中尽量简化各定理原来的证明过程，并在其中注入严密性，正如他在《代数曲面》的前言中所说的：“在代数几何这个领域内，（定理证明）所采用的方法的重要性决不亚于定理与结论本身。”今天再读这本书，可以看到，除了大量使用旧的经典代数几何方法之外，虽然已经开始运用在当时来说是新的拓扑与分析方法（例如同调方法），但却找不到抽象代数方法的任何踪迹。 扎里斯基在完成《代数曲面》的写作后并不十分高兴。他曾经回忆说： “我试图尽我最大的努力揭示出意大利几何学家们所采用的天才几何方法背后的深刻思想，并对整个曲面理论中最重要的一些定理给出证明，虽然做得很成功，但是付出了一个代价。这个代价就是失去了我自己的几何乐园，在这里我曾经是那样的幸福。我开始明显地对那些经我整理的原始证明的严密性感到不安和失落（虽然没有失去对弥漫在这些证明中富有想象力的几何精神的敬意）；我逐渐相信所有这些证明都必须用纯代数的方法重新来过。” 例如在《代数曲面》的第一章中，扎里斯基仔细分析了复代数曲面奇点解消定理的四种不同的证明过程，这些证明所用的方法基本都是不严格的经典代数几何方法，即便扎里斯基再怎么努力,也不可能消除其中的模糊之处。而奇点解消问题在代数几何中是一个非常基本的问题，它的大意是为每个有奇点的代数曲面寻找一个和它在同一类的光滑曲面。这个问题与代数曲面的分类问题直接相关，而分类问题又是代数几何的中心研究课题。对于已经熟悉了现今用抽象代数与层论来表述代数簇性质的人们来说，当知道了1939年之前的代数几何基本上不用抽象代数与理想语言的时候，是有些吃惊的。这是因为用抽象代数与环的理想语言来研究代数簇实在是太确切和方便了，我们难以想象没有这种语言时的情形。例如读一下范德瓦尔登在1939年写的《代数几何引论》中文译本$^{[6]}$，就会发现如果不用现代的理想与拓扑语言时，代数簇性质的描述是比较粗放的(这里笔者介绍一本运用理想与拓扑语言写的一本英文初级引论教材$^{[7]}$）。更加让人吃惊的是，作为现代抽象代数几何鼻祖的扎里斯基，在写完《代数曲面》的时候，居然还不懂环的理想理论！他在这时候从读范德瓦尔登的《代数学》和克鲁尔(Krull)的《理想论》入手，开始自学抽象代数和环的理想理论。与我们现在常见的为学习而学习不同，扎里斯基在学习的时候有着非常明确的目的：那就是同时研究怎样用这些抽象代数的理论来重新严格地给出经典代数几何定理的证明。他尤其为克鲁尔所发现的局部环理论所震动，因为这正是研究任意域上的代数几何所需要的。此外戴德金和韦伯的用纯代数方法研究代数函数（即代数曲线）的著名文章也给扎里斯基以深深的启发。但是“扎里斯基不久就意识到，仅仅改写证明是不够的。他必须引入不类似于他的意大利老师的几何构架的新的概念。虽然（用抽象代数重新改造代数几何的）算术化的目的是严格证明意大利学派的代数几何，从而保留其传统，但是只有引进全新的概念与方法，以此来完全取代旧的方法，这个目标才能达到。”$^{[8]}$这也就是说，要想逐字逐句地运用抽象代数已有的概念和理论将经典代数几何的定理“翻译”成抽象代数的语言是远远不够的，有的时候扎里斯基必须自己重新发明新的抽象代数概念和理论才能应付研究代数簇复杂性质的需要。例如在研究改进意大利学派考虑过的代数曲面奇点解消定理证明的时候，扎里斯基就第一次成功地将环论中的整闭包与赋值环的理论运用到代数几何中，并且在戴德金等人工作的启发下还重新创造了一个新的代数概念：正规（normal）的概念（例如坐标环在其商域中整闭的代数簇称为正规簇）。在有了这些强有力的抽象代数武器后，扎里斯基就能够彻底消除原来证明中的模糊之处，于1939年完全严格地证明了这个重要的奇点解消定理。当然代价是重新改变了经典代数几何中原先比较直观简单的几何语言，代之以更加抽象和难以理解的抽象代数语言。这种语言更加精致和准确，足以处理原来比较粗糙的古典语言所不能对付的复杂情形。从此以后，扎里斯基就在代数几何的严格化与代数化这个方向上做了大量的研究工作，其影响可以从现在普遍采用的术语中反映出来：扎里斯基拓扑、扎里斯基切空间、扎里斯基主定理、扎里斯基曲面和扎里斯基空间等。扎里斯基还投入了大量精力来研究代数几何所需要的抽象代数，并且和另一位数学家塞缪尔（Samuel）一起写出了两大卷已经成为了抽象代数经典著作的《交换代数》$^{[9]}$。就这样，扎里斯基引导着整个代数几何学科进入了一个全新的历史阶段。 与扎里斯基同时或稍后，韦依、范德瓦尔登和周炜良等人也和扎里斯基一样，在积极地推进代数几何基础的重建工作。当然对代数几何基础进行最彻底的改造还是来自于塞尔（Serre）和格罗腾迪克在50年代的伟大工作。人们的感觉是他们突然之间彻底重写了代数几何。其实，塞尔的层论与同调代数是整体微分几何、多复变函数、抽象代数、拓扑学得到充分发展后的产物（层论现在已经成为研究代数簇整体性质的重要工具），而格罗腾迪克是一个集大成者，他等于是综合了扎里斯基和塞尔两人的工作，即通过运用前者的交换代数和后者的层论与同调代数、以及更先进的几何与拓扑思想，将经典的代数簇理论推广成了适用面更广的概形(scheme)理论，从而将代数几何打造成了一个在很大程度上将几何、代数、数论与分析完美统一起来的逻辑推理体系。后来的历史发展证明，当经典代数几何的逻辑基础问题被彻底解决后，代数几何便获得了急速的巨大进步$^{[10]}$。这可以从扎里斯基后来在哈佛大学培养出来的一大批优秀代数几何学者的工作中得到印证，其中有两位获得了菲尔兹奖：广中平佑(Hironaka)是因为完全解决了任意维数的代数簇的奇点解消问题而在1970年获奖，芒福德是在1974年因为对参模理论的贡献而得奖。当然，代数几何在20世纪下半叶最辉煌的胜利应该是怀尔斯(Wiles)在90年代用代数几何的工具证明了数论中著名的费马大定理。这一切都充分显示了当初扎里斯基对建立代数几何基础的所作杰出贡献的重要意义和长远影响。扎里斯基创立代数几何逻辑基础的艰难历程对于今天的学生学习代数几何也有重要的启示。如前所述，代数几何与数论、拓扑、抽象代数、多复变函数、代数群以及复微分几何等学科有着极密切的联系，只有对这些相关学科都有所涉足，才能对代数几何有比较深入的了解。实际上，“代数几何不是一门‘原创的’学科，即可以建立在一组简洁的公理或定义上的学科，它毋宁说是一门‘综合的’学科，其研究方法非常多样，不同时代、不同学派的风格千差万别，教科书也有多种模式，甚至没有大体一致的基本内容，这是与其他学科很不相同的。”$^{[11]}$在学习象代数几何这样的超级航母般的学科时，我们尤其需要了解重要经典代数几何问题的解决过程。这是因为代数几何中许多重要的基本概念和方法都是经过了多次反复抽象与推广而得到的，所以旧的经典方法与新的现代方法在本质上是互相联系的。在历史上曾经引起过困惑争议因而出现较晚的理论，一般来说学生在学习的时候也会有较多的困惑与困难。应当让学生在学习较高层次的理论之前先经历较低层次的抽象过程，只有这样学生才能领悟所学知识的真正内涵。目前庞大的代数几何学科大致可以粗略地分为复代数几何（即复几何）与纯代数几何（即抽象代数几何）两大部分：前者主要运用多复变函数论、代数拓扑学和复微分几何等学科来研究代数簇的性质（虽然这些学科已经很抽象了，但相对来讲还直观一些），而后者主要是以抽象代数和函子作为工具来研究，虽然难以理解和想象，但是结论精确，并且由此得到的结果适用面更广。一般的情形是：在历史上总是先有复代数几何的结果，然后在此基础上引入抽象代数的工具再进行严格化，从而可以推广到纯代数几何的高层次。因此初学者在学习代数几何的时候，应当从学习复代数几何与经典代数几何开始（尽量用现代语言），这样才有可能理解高度抽象的纯代数几何。时代早已进入21世纪，与一百年前扎里斯基来到罗马时所处的时代相比，数学的面貌已经天翻地覆大为改观了。现代数学真正成为了人类知识领域中最博大精深的一个，其抽象与艰深的程度登峰造极。在取得巨大进步的同时，现代数学也面临着分支学科种类繁多，研究范围越来越狭窄、概念越来越抽象的严重问题，这不免让人越来越困惑：数学研究的目标究竟是什么？一方面我们要努力使现代数学这一真正完美的人类文化遗产得到传承并发扬光大，但是另一方面应该看到：数学作为主要研究抽象逻辑结构（模式）的独特学科，与其他自然科学与社会科学学科是很不一样的，后者以大自然与人类社会作为唯一的研究对象，而在数学中，可供研究的逻辑上正确的抽象数学模式可以有任意多个，很容易迷失方向。如何避开那些意义不大的研究对象，找到真正有意义有发展前途的研究方向？对于这些难以回答的问题，我们也许可以从20世纪现代数学波澜壮阔的发展历史，以及象扎里斯基这样的一代数学大师的治学经历中找到一些有益的启示。参考文献：[1] C. Parikh , The Unreal Life of Oscar Zariski , San Diego : Academic Press , Inc . , 1991 (Springer-Verlag出版社2009年再版).[2] 李心灿，当代数学大师──沃尔夫数学奖得主及其建树与见解，北京航空航天大学出版社，1999.[3] 陈跃，现代数学主要分支学科的通俗介绍，数学文化，2012，第1期.[4] D. .Mumford , The Red Book of Varieties and Schemes, (second , Expanded Edition), Springer-Verlag , 1999.[5] O. Zariski , Algebraic Surfaces, 2nd ed , Springer-Verlag , 1971 (世界图书出版公司2010年影印) .[6] 范德瓦尔登，代数几何引论，科学出版社，2008.[7] D. Perrin , Algebraic Geometry : An Introduction , Springer-Verlag, 2008.[8] J. J. Gray , K. H. Parshall (editors) , Episodes in the History of Modern Algebra (1800-1950), American Mathematical Society, 2007.[9] O. Zariski , P. Samuel , Commutative Algebra , Vol . I , II , Van Nostrand , Princeton , 1958, 1960. (Springer-Verlag出版社1979年重印，世界图书出版公司2000年影印).[10] J. Dieudonne , History of Algebraic Geometry , Wadsworth , Inc. ,1985.[11] 李克正，代数几何初步，科学出版社，2004.]]></content>
      <categories>
        <category>数学</category>
        <category>学科理解</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Mathematicians]]></title>
    <url>%2F2021%2F03%2F20%2FMathematicians%2F</url>
    <content type="text"><![CDATA[- Poincaré Jules Henri Poincaré (1854-1912) French Research: xxx publications: 《xxx》 Discuss: 法国数学家，物理学家，哲学家，中学时期心算偏微分方程的神童，狭义相对论最早的创立者，整个拓扑学，动力系统的祖师爷，人类历史上非常罕见的数学物理全才。 - Hilbert David Hilbert (1862-1943) German Research: xxx publications: 《xxx》 Discuss: 号称数学之王，无数天才的老师，20世纪最后一位数学全才。 - Gödel Kurt Gödel (1906-1978) German-Austrian Research: xxx publications: 《xxx》 Discuss: - Serre Jean Pierre Serre (1926- ) French Research: algebraic topology algebraic geometry algebraic number theory publications: 《xxx》 Discuss: 法国大数学家，26岁就拿菲尔兹奖的最年轻得主，这个年纪还没有之一，代数几何，代数拓扑，拓扑K理论，算术几何的宗师级人物，90多岁了，现在是在世的最伟大的数学家，没有之一。 - Grothendieck Alexander Grothendieck (1928-2014) German Research: algebraic geometry publications: 《xxx》 Discuss: 现代代数几何学教皇，现代数学界呼风唤雨的人物，用范畴论和交换代数，同调代数的语言重构代数几何学，R，I进上同调理论，格罗滕迪克-黎曼-罗赫定理，G神孩童时期在集中营里，完全独立的研究出了测度积分理论，而实变函数论是另一个法国数学家提出的，所以教皇天赋之高，令人咋舌，和Serre是基友。 - Weil Andrè Weil (1906-1998) French Research: number theory algebraic geometry publications: 《Foundations of Algebraic Geometry》（1946） 《Number Theory: An Approach Through History From Hammurapi to Legendre》（1984） Discuss: 现代数学之王，布尔巴基学派的元老，算术几何，代数几何学仅次于教皇Grothendieck - Milnor John Willard Milnor (1931- ) American Research: differential topology K-theory dynamical systems publications: 《Morse Theory》（1963） 《Lectures on the h-cobordism theorem》（1965） 《Characteristic classes》（1974） 《Topology from the differentiable viewpoint》（1997） 《Singular Points of Complex Hypersurfaces》（1968） 《Introduction to Algebraic K-Theory》（1971） 《Symmetric Bilinear Forms》《1973） 《Dynamics in One Complex Variable》（2000） 《Collected Papers.vol.I. Geometry》（1994） 《Collected Papers.vol.II. The Fundamental Group》（1995） 《Collected Papers.vol.III. Differential Topology》（2007） 《Collected Papers.vol.IV. Homotopy,Homology and Manifolds》（2009） 《Collected Papers.vol.V. Algebra》（2010） 《Collected Papers.vol.VI. Dynamics（1953-2000）》（2012） 《Collected Papers.vol.VII. Dynamics(1984-2012)》（2014） Discuss: The founder of differential topology, one of the greatest modern geometers, his books always have an advanced standpoint。 - Cartan Élie Cartan (1869-1951) French Research: xxx publications: 《xxx》 Discuss: 法国数学家，现代微分几何学真正的祖师爷，大师级人物，陈省身的老师。 - Kolmogorov Andrey Nikolaevich Kolmogorov (1903-1987) Soviet Research: xxx publications: 《xxx》 Discuss: 苏联大数学家，动力系统，算子代数，随机过程，概率论，统计，流体力学，偏微分方程，微扰算子理论，泛函分析可谓全才。 - Wely Hermann Wely (1885-1955) German Research: xxx publications: 《xxx》 Discuss: 德国大数学家，解析数论，广义复变函数论，数学物理，偏微分方程，也是20世纪几个数学全才之一。 - Luzin Research: xxx publications: 《xxx》 Discuss: A.N.Kolmogorov 的博士生导师。 - Eilenberg Research: xxx publications: 《xxx》 Discuss: Eilenberg-MacLane空间。 - Gromov Mikhail Gromov (1943- ) Russian-French 主页 Research: xxx publications: 《xxx》 Discuss: 苏联大神，黎曼几何，辛几何，几何测度论，辛拓扑，度量微分几何，这几个大类的祖师爷，不亚于刚开始提到的前面几个大神，此人牛逼到可怕。 - V.I.Arnold Research: xxx publications: 《xxx》 Discuss: A.N.Kolmogorov最得意的门徒，数学物理，辛几何，几何测度论，苏联时期的数学神童，本科解决了Hilbert第11问题，创立测度熵理论。 - Atiyah Michael Atiyah (1929-2019) British-Lebanese Research: xxx publications: 《xxx》 Discuss: 英国大数学家，代数几何，代数K理论，数学物理。 - Seidel Research: xxx publications: 《xxx》 Discuss: 辛几何的集大成者是开创者，辛几何教皇。 - Lebesgue Henri Léon Lebesgue (1875-1941) French Research: xxx publications: 《xxx》 Discuss: 实分析开山鼻祖，勒贝格。 - A.Connes Research: xxx publications: 《xxx》 Discuss: 法国大数学家，算子代数，非交换几何的创立者。 - Sergei-Novikov Research: xxx publications: 《xxx》 Discuss: 苏联大神，算术代数几何，同调代数谱理论。 - Klein Christian Felix Klein (1849-1925) German Research: group theory complex analysis non-Euclidean geometry associations betwenn geometry and group theory publications: 《xxx》 Discuss: 爱尔兰根纲领，即厄兰根纲领，是个天才。 - Hadamard Research: xxx publications: 《xxx》 Discuss: - Yuri-Manin Research: xxx publications: 《xxx》 Discuss: 苏联大神，代数几何，算术代数几何大神。 - I.Singer Research: xxx publications: 《xxx》 Discuss: - Donaldson Research: xxx publications: 《xxx》 Discuss: 英国大数学家，博士期间证明了微分拓扑的对角化定理，也是神一样的人物。 - W.Thurston Research: xxx publications: 《xxx》 Discuss: 美国数学家，几何拓扑大神，证明了5维庞加莱猜想，就是开头提到的第一个人名的猜想，它给出了高维流形的几何纲领。 - S.Smale Research: xxx publications: 《xxx》 Discuss: 美国数学家，拓扑动力系统的大神。 - Shafarevich Igor Shafarevich (1923-2017) Russian Research: xxx publications: 《xxx》 Discuss: 苏联大神，代数几何、代数数论学家。 - E.Artin Research: xxx publications: 《xxx》 Discuss: 人们对他的一般评价是，大代数学家.Artin互反律，数论中最强的互反率。 - Vladimir.Drinfield Research: xxx publications: 《xxx》 Discuss: 苏联大神。 - M.Kontsevich Research: xxx publications: 《xxx》 Discuss: 苏联大神，复代数几何，数学物理，镜像同调对称几何创始人，微分几何。 - Gelfand I.M.Gelfand (1913-2009) Soviet Research: xxx publications: 《xxx》 Discuss: 苏联大神，泛函分析大师，他解决了Hilbert关于超越数的问题。 - P.Deligne Research: xxx publications: 《xxx》 Discuss: 教皇的高徒，现在的代数几何教皇。 - Hopf Research: xxx publications: 《xxx》 Discuss: 来自瑞士的拓扑学大师，Harvard大学教授。 - G.Faltings Research: xxx publications: 《xxx》 Discuss: - Chern Shiing-Shen Chern (1911-2004) Chinese-American Research: xxx Differential Geometry Topology publications: 《xxx》 Discuss: - Do Carmo Manfredo do Carmo (1928-2018) Brazilian Research: xxx publications: 《Differential Geometry of Curves and Surfaces》1976 《Riemannian Geometry》1992 《Differential Forms and Applications》2012 Discuss: - Stein Elias M. Stein (1931-2018) American Research: xxx publications: 《Singular Integrals and Differentiability Properties of Functions》1970 《Topics in Harmonic Analysis Related to the Littlewood-Paley Theory》1970 《Introduction to Fourier Analysis on Euclidean Spaces》1971 《Analytic Continuation of Group Representations》1971 《Lectures on Pseudo-differential Operators: Regularity Theorems and Applications to Non-elliptic Problems》1979 《Harmonic Analysis: Real-variable Methods, Orthogonality and Oscillatory Integrals》1993 《Fourier Analysis: An Introduction》2003 《Complex Analysis》2003 《Real Analysis: Measure Theory, Integration, and Hilbert Spaces》2005 《Functional Analysis: An Introduction to Further Topics in Analysis》2011 Discuss: - Milne James S. Milne(1942- ) New Zealand Research: xxx publications: 《xxx》 Discuss: 个人网站 他的课程讲义都非常不错； - Tao Terence Tao (1975- ) Australian-American Research: xxx publications: 《Solving mathematical problems》2006 《Nonlinear dispersive equations: Local and global analysis》2006 《Structure and randomness》2008 《Poincaré’s legacies, Part I》2009 《Poincaré’s legacies, Part II》2009 《An epsilon of room, I: real analysis》2010 《An epsilon of room, II》2010 《Additive combinatorics》2010 《An introduction to measure theory》2011 《Topics in random matrix theory》2012 《Higher order Fourier analysis》2012 《Compactness and contradiction》2013 《Analysis. I. Third edition》2014 《Analysis. II. Third edition》2014 《Hilbert’s fifth problem and related topics》2014 《Expansion in finite simple groups of Lie type》2015 Discuss: 个人博客 Kodaira（小平邦彦），Chern（陈省身），Hopf，Zariski，Yakov-Sinai ，Yua（丘成桐），A.Witten，Fefferman，Atle.Selberg，Margulis，Stein，Hirzebruch，J.LurieJ.Thompson，Sobolev，P.Scholze，J.Tate，M. Artin，Bott，Hormander，Andrei-OkounkovPontryagin，Hermite，Von.NeumannG.Perelman，Bourgain，Vladimir.VoevodskyJ.Nash，Villani，De Giorgi ，Kenji.Fukaya(深谷治贤)，Yakov-EliashbergNirenberg，Schoen，P.Erdos，Lennart-CarlesonSato（佐藤干夫），Quillen，AhlorsEfim Zelmanov,Richard .Hamilton，Sternberg，Welis，Lovasz，Shimura（志村五郎），Kashiwara（柏原正树），Siu（萧荫唐），L.Faddeev，Furstenberg，AnnesLittlewood，Hardy，Szemeredi（组合数学）李俊，田刚，朱席平，张寿武，周伟良，袁湘亚，张伟，袁心意，伟之挥，席南华]]></content>
      <categories>
        <category>数学</category>
        <category>数学家</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数学中未解决的大问题]]></title>
    <url>%2F2021%2F03%2F17%2F%E6%95%B0%E5%AD%A6%E4%B8%AD%E6%9C%AA%E8%A7%A3%E5%86%B3%E7%9A%84%E5%A4%A7%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[数学作为现代科学的根基被或深或浅地广泛应用于各行各业，普通人都或多或少地懂得基本的数学方法。然而现代数学却是一个令多数人望而却步的所在，人们对于其基本问题以及基本方法的了解程度远远低于其他科学，听说过“朗兰兹(Langlands)”的人远远少于听过“冷冻电镜”或者“弦论”的人。这篇文章将介绍现代数学，特别是算术几何中的一系列猜想，它们共同构成了一幅极其宏伟壮阔的蓝图，那是一代代学者的梦想所在。现代数学的多数部分层层叠叠地建立在越来越远离日常经验的抽象体系上，仅仅去透过迷雾管中窥豹的一瞥也会受阻于层层门槛，为避免过份浅薄本文不可避免地将使用一系列术语。尽管如此，为了简洁，几乎所有的陈述都具有一定的模糊性，有时甚至故意的错误，精确的表述需要引进更多现代理论以及微妙的修正。故事要从欧拉开始，欧拉考虑了函数： $$\zeta(s)=\sum_{n=1}^{\infty} n^{-s}$$ 并证明了其在 s = 2 点的值： $$1+\frac{1}{2^{2}}+\frac{1}{3^{2}}+\ldots=\frac{\pi^{2}}{6}$$ 之后黎曼在其著名的论文中提出这一函数满足：①其具有表达式： $$\sum_{n=1}^{\infty} \frac{1}{n^{s}}=\prod_{p \text { prime }} \frac{1}{1-p^{-s}}$$ ②其在 1-s 和 s 的值具有对称性，满足一定函数方程；③其非平凡零点分布在直线 Re(s)=1/2 上。① 和 ② 很容易用初等方法证明，③ 则是著名的黎曼假设——作为数学中最具挑战的问题之一。这一函数，现在通常称之为黎曼$\zeta$函数(Riemann zeta function)，其实是某一类函数的特殊情形，我们称之为L函数，我们猜测它们都具有类似 ①、② 和 ③ 的性质，同时它们在特殊点的值有类似欧拉的表达式。这一模糊的表述看似初等，实质上深刻无比，它包含了美国克莱研究所于21世纪初提出的七个千禧年百万问题中的三个——贝赫和斯维讷通-戴尔猜想(BSD)，霍奇猜想(Hodge conjecture)和黎曼猜想(Riemann Hypothesis)，以及许多其他同样著名的猜想。这一表述的背后，隐藏了一系列无比宏伟的数学结构，这些结构帮助我们澄清并理解问题的涵义，同时提供了强有力的解决工具，对很多人来说它们比问题本身更加迷人。大体上来说，我们有两种不同起源的 L 函数，我们称之为 Motivic L 函数和自守 L 函数。我们先解释 Motivic L 函数，它们起源于数论和代数几何。代数数论的一个核心问题是求解整数系数的一元多项式方程，对于每一个素数p我们可以考虑模p的情形并得到有限域上的一元多项式方程，我们原则上可以很容易地求解，模p的解如何联系于整数解是一个数论的重要问题。高斯和欧拉发现的著名二次互反律(Law of Quadratic Reciprocity)即为此问题在一元二次多项式的特殊情形的解。20世纪初的一个重要发现——类域论(Class field theory)，对于更大一类的一元多项式方程解决了这一问题。这一类方程并不是由多项式的次数限定的，而是取决于方程的内蕴对称性，更加精确地说，它的伽罗瓦群(Galois group)。伽罗瓦在19世纪初的革命性工作首次引进了群论，并利用它来精确地度量多项式的对称性，我们第一次能够绕开繁琐的计算，用更深层次的抽象性质去处理表面更加具体的问题，它标志着现代代数的开端。一元多项式的复杂性在于伽罗瓦群的复杂性，而类域论处理了交换伽罗瓦群的情形，非交换的情形要复杂的多，它是现代朗兰兹纲领(Langlands program)的一个重要目标。对于每一个一元多项式我们可以定义L函数，它们通常叫做戴德金$\zeta$函数(Dedekind zeta function)，黎曼$\zeta$函数则是一元一次多项式的特殊情况。它们可以初等地证明满足 ① 和 ②。一个自然的推广是考虑多元多项式的情况，这里我们进入了代数几何的领域。多项式的零点定义了一个几何对象，我们称之为代数簇(Algebraic variety)，对于它们的研究我们通常称为代数几何。代数几何作为一门古老的学科在20世纪经历了蔚为壮观的发展，20世纪初期意大利学派对代数曲面的研究有了长足的进展，然而其不严格的基础促使奥斯卡·扎里斯基(Oscar Zariski)和 安德烈·韦伊(André Weil)重构了整个代数几何的基础，韦伊更是指出了代数几何和数论与拓扑之间的惊人联系，之后亚历山大·格罗滕迪克(Alexander Grothendieck)为了理解韦伊的猜想更进一步用更抽象本质的方法重新构建了代数几何的基础并引进了一系列强大的工具，特别是他的上同调理论(cohomology)，最终导致了皮埃尔·德利涅(Pierre Deligne)完整证明了韦伊猜想并因此得到了菲尔兹奖。我们要重点提格罗滕迪克的上同调理论，其根植于代数拓扑，格罗滕迪克同时构造了一系列上同调理论，它们具有非常类似的性质，但却起源于非常不同的构造，格罗滕迪克试图寻找出它们的共同本质并由此提出了Motive理论。这一理论并不完整，因为它基于一系列猜想，格罗滕迪克称之为标准猜想。如果标准猜想被证明，我们就能得到一套非常漂亮的理论，它导出了所有上同调，同时我们能证明一系列表面无关的问题。著名的百万问题之一霍奇猜想的重要性就在于它能导出标准猜想。每一个Motivic L 函数都是由Motive给出的，对于这些函数，① 很容易验证，但是 ② 我们还无法证明一般情况， 一个已知例子是有理数上椭圆曲线的情形， 安德鲁·怀尔斯(Andrew Wiles)关于费马大定理的证明的一个推论(谷山-志村猜想，完整情形于01年由怀尔斯的几位学生证明)。对于几乎所有 L 函数③ 都是未知的，唯一的例外是Motive在有限域的情形，③ 即是德利涅所证明的韦伊猜想。对于Motivic L 函数的特殊值的问题，我们需要Motive的一个推广，我们称之为mixed motive, 这是一个更加庞大但更加遥远的梦想，我们完全不知道如何构造它。它的存在能够推导出一系列及其漂亮的等式，推广欧拉对于黎曼$\zeta$的公式，著名的贝林森猜想(Beilinson conjecture)， 百万问题之一的BSD等都属此类。虽然我们无法构造mixed motive，却能够构造它的一个弱化变形，我们称之为导出范畴， 弗拉基米尔·沃埃沃德斯基(Vladimir Voevodsky)给出了这样一个构造从而获得了2002年的菲尔兹奖。Motive是比 L 函数更本质的存在，但是我们很难直接计算它，替代的办法是考虑Motive的不同表达。每一个Motive都能给出一系列伽罗瓦群的表示以及复几何中的霍奇结构，它们完全决定了 L 函数，因而考虑它们是更根本的问题。我们已经看到类域论解决了交换伽罗瓦群的情形，一个简单但却根本的想法是群的表示比群本身更加基本，因而我们需要考虑的不是伽罗瓦群本身，而是它的表示，这样所有的交换伽罗瓦群就等价于一维的伽罗瓦表示，而非交换的就等价于高维的表示。为了能够理解它们，我们必须考虑它们的内在对称性，令人惊讶的是，这些对称性很大程度上来源于一类完全不同的数学对象—–自守形式。自守形式的起源可以追溯到19世纪，Klein和昂利·庞加莱(Henri Poincaré)是这一方向的先驱者。然而如果我们再往前看，仔细阅读黎曼关于$\zeta$函数的性质 ②的证明，就会发现他实质上使用了一种非常特殊的自守形式的对称性，我们现在称之为权1/2的模形式。实际上几乎所有的已知的关于性质 ② (整体域上的L函数)的证明都使用了自守形式，我们猜测motivic L 函数都能从某类自守形式构造，这一大胆的猜测起源于志村五郎和谷山丰对于椭圆曲线的特殊情况，之后由朗兰兹推广到一般情况，亦即现代数学中如雷贯耳的朗兰兹纲领。志村五郎的方法很大程度上是来源于代数几何，他从具体计算中看到了一些精致的特殊结构，他的方法太过具体以至于很难直接推广到一般情况。朗兰兹的洞见在于看出了这些结构背后的表示论内核，他系统将代数群的无穷维表示引进到数论中，找到了一个非常一般的全局性纲领，近五十年来它吸引了无数最杰出的学者。通常认为朗兰兹纲领由两部分组成，第一部分称为互反猜想，它描述了数论与表示论的对应关系，最一般的猜测是Motive是等价于相当一部分自守形式的，特别的它指出伽罗瓦表示应该等价于代数群的表示，因而motivic L 函数等价于自守 L 函数。第二部分称之为函子性猜想，它描述了不同群之间的表示的联系。这一纲领意义深远，它可以对最一般的 L 函数证明②，并且导出一系列困难的猜想，如阿廷猜想。 经过几十年的努力，我们对这一纲领的理解有了很大进展，杰出的代表性学者包括菲尔兹奖得主弗拉基米尔·德林费而德(Vladimir Drinfeld)，洛朗·拉福格(Laurent Lafforgue)和吴宝珠，不过距离完整的纲领仍然非常遥远。必须要提的是，朗兰兹纲领的范围还在不断扩展，类比经典的纲领，我们发展出了几何朗兰兹，p-adic朗兰兹，甚至物理上爱德华·威滕(Edward Witten)都提出了类似的朗兰兹对偶，它们牵涉到了非常不同的领域，使用非常不同的方法，但是它们都展现出了极深层次的相似性，从不同的角度丰富了纲领本身。一个最新的值得一提的进展来自彼得·舒尔茨(Peter Scholze)正在进行的工作，他利用由他发展的p-adic几何类比函数域的情形去证明局部数域的情形。我们非常粗糙地回顾了一些现代数学，特别是算术几何领域的重要问题，从现在来看，几乎所有以上提到的猜想都还非常遥远(也许BSD是个例外)，每一个也许都足以耗尽一个人毕生精力，然而正是其困难和深刻吸引了无数人。某种程度上，数学家和探险家是一类人。]]></content>
      <categories>
        <category>数学</category>
        <category>学科理解</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[现代数学各子领域关系的简单介绍和学习建议]]></title>
    <url>%2F2021%2F03%2F16%2F%E7%8E%B0%E4%BB%A3%E6%95%B0%E5%AD%A6%E5%90%84%E5%AD%90%E9%A2%86%E5%9F%9F%E5%85%B3%E7%B3%BB%E7%9A%84%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[原链接 这篇文章是写给对本科以上层次的数学感兴趣但还未入门的初学者的，数学圈的人随便看看就行了，没什么“硬”的东西，闲聊而已。很多人都听说过“现代数学分成代数、分析、几何”三大块这种说法。其实这种说法并不准确。数学并不是像生物学分类那样，按照界门纲目科属种那样能够严格地分出不同层次的分界线。现代数学不同领域的差异当然存在，但是这些领域的边界线则犬牙交错，交叉的地方并不清晰。而且某个领域使用其他领域的方法和定理也是很常见的事情。那么，我们首先简单介绍一下三大方法论大致是个什么“取向”，给对数学有兴趣的初学者一点感觉。代数：以线性代数、抽象代数为基础，研究各种代数结构，比如最常见的群环模域线性空间，李代数，以及不那么常见的高阶同伦代数（homotopy algebra）等等。代数的一个基本特征是对称性。一般来说，某个数学对象（比如说拓扑空间）如果具备某种代数结构（比如拓扑空间上面有同调群），那我们就可以利用这种代数结构的已知结果，来反过来研究、“探测”那个数学对象。这是代数影响其他数学分支的一个基本模式。分析：以广义的微积分（比如实分析复分析调和分析等等）、微分方程理论、泛函分析等为研究工具，对函数、方程等“可以求导”的东西进行精细的分析（比如不等式估计等等），的一种方法论。分析大致可以分为软分析和硬分析。个人的观点是，软分析有点像定性的分析，比如泛函分析里各种结论，比如一个函数空间紧嵌入到另一个函数里，不需要知道到底怎么嵌入的，就可以依据紧性推导出一些结论。而硬分析则有点像定量的分析：每个常数，跟哪些量有关，具体是怎么个相关法（多项式依赖？指数依赖）？这些常数具体是多少，能不能做到最优，最优常数是多少？用一列东西去逼近一个东西，误差项大概有多大？误差项是什么阶数（多项式（几次多项式？）？多项式乘以对数？）？能不能把bound放大或者缩小，直至最优？ etc.几何（与拓扑）：主要关注几何对象与拓扑对象。几何与拓扑的区别在于，拓扑比几何更“软”，更flexible，几何是在拓扑空间上加额外的结构（度量结构、复结构、辛结构，或者这种结构的“组合结构”，比如Kahler结构，等等）。拓扑关注的一个重要对象是拓扑不变量，比如同调上同调、同伦群、K理论等等。几何可极粗略地分为微分几何与代数几何——微分几何主要关心曲率等，代数几何主要关注代数簇、scheme等等的各种“代数性质”（“代数”这个形容词可以粗略理解为只跟多项式有关）以及我不懂的各种东西（这个话题抱歉我没法聊，懂的太少。。）。当然除此以外还有其他一些方法论，比如概率论（其实可以放在广义的分析框架里面，但是研究的方法、看待问题的角度还是有独特的地方）、组合、数理逻辑等等。我一开始说三大方法论不是完全分割的，相互之间互有联系，下面举一些例子来说明。分析里面的代数：有些人可能觉得分析就是搞搞不等式估计、求求导积个分什么的，用不到多少代数。其实也不一定。PDE很多时候都有对称性，这些对称性很多时候能简化问题。（李当初发明李代数的目的可是拿来解微分方程的，他想用李代数来刻画方程内在的infinitesimal symmetry）。调和分析自然地和表示论有联系。另外再说一件事。我在本系听deformation theory seminar的时候，有个人讲到PDE里面蕴含了一些homotopy algebra的结构，然后他做了一些对这种代数结构的研究。目前有价值的PDE基本都来自于“大自然”，比如来自物理或者来自几何。这些被大自然挑选出来的方程，里面可能本身就蕴含了一些内在的结构，使得他们相对于人类随便乱写的一个方程更容易处理。几何里面的代数：代数几何当然和代数有深刻的联系。这方面就举一个例子，Kodaira embedding theorem. Kodaira embedding是从Kodaira vanishing＋指标定理（HRR） 推出来的，Kodaira vanishing是说positive line bundle做某种twist以后的高阶上同调全部为0，算是一个（同调）代数结论。Kodaira embedding是说对紧Kahler流形，positive line bundle和ample line bundle是一回事，而ample line bundle能把这个流形嵌入到某个CP^N里面，算是一个几何结论。这就是一个“同调代数应用于几何学”的例子。微分几何里面也有代数。微分几何里面holonomy group之类的东西和李群、表示论都有着千丝万缕的联系，spin structure，Clifford algebra这些东西都算是代数的方法论应用于几何学（以及拓扑学）。代数里面的几何：纯代数里面很多东西都可以翻译成代数几何的语言。比如Galois theory可以翻译成代数几何里面的etale cover（具体是什么不要问我，我就随便一说）。代数里面的分析：比如p-adic analysis，差不多是模仿复分析的方法，在p-adic field上做分析。另外我们有著名的GAGA原理，复代数几何和复微分几何某种意义上可以看成用不同的方法论研究同一个对象，很多时候能得到相同的结果。OK，说了这么多，该去睡了。。最后再说一句：数学专业的低年级本科生们，如果以后打算做数学研究的话，学专业课的时候不要抱着“我以后做代数所以不需要认真学分析”或者“我以后学分析所以没必要好好学抽代”之类的想法。在力所能及的范围内，尽量多学点东西。本科那些知识，都是各个分支的common knowledge，你现在可能觉得某些知识和你感兴趣的东西毫不相干，但也许以后你学得更深入的时候，它们就突然出现了。]]></content>
      <categories>
        <category>数学</category>
        <category>学科理解</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[一封范畴论的邀请函]]></title>
    <url>%2F2021%2F02%2F23%2F%E4%B8%80%E5%B0%81%E8%8C%83%E7%95%B4%E8%AE%BA%E7%9A%84%E9%82%80%E8%AF%B7%E5%87%BD%2F</url>
    <content type="text"><![CDATA[原文：An invitation to category theory 以前为了描写对称性，群论走进了物理。现在为了描写量子材料中的量子纠缠，范畴论也正在走进物理。可到底什么是范畴论？范畴论是一个关于关系的理论，描述并研究关系的所有可能性质。如果绘制一幅数学地图，地面上会有代数、拓扑、分析等不同领域，而范畴论则像是悬挂在天空中的月亮，它提供整个地图的缩略图，让我们看到在地面看不到的各个领域之间的关系，证明看似不相关的数学领域并非完全不同。当你在某个数学领域的边界处艰难跋涉时，范畴思维可以指引你，它增强你的直觉，让你的洞察力更敏锐。而这一关于关系的全面抽象理论，也正好是描写多体量子纠缠的自然语言。 从最早开始学习数学，我们就知道代数与几何有很强的关联，代数方程可以表示成图形和几何对象，几何特征可以用代数表达式刻画。就好像有一座桥梁连接广阔的数学世界中的这两个领域，桥的两边互为镜像。 代数与几何之间对应关系的3个例子：代数表达式-三角形面积，二次方程-半径为2的圆，线性方程-斜率为1的直线。因此，尽管代数和几何是很不相同的数学领域，但这种联系表明，它们之间存在着内在关联。不仅如此，还有集合论、群论、线性代数、拓扑学、图论、微分几何等等，这些看上去似乎没什么关系的数学分支实际上都存在深层次的关联，代数与几何的关联只不过是其中的冰山一角。令人惊奇的是，这些关联或桥梁不仅仅是浮于表面的印象。它们是数学，而且这种数学有个名字：范畴论。 范畴论是什么？马丁·库佩（Martin Kuppe）曾绘制过一幅精美的数学地图，其中范畴论高高悬挂在天空，提供了整个地图的缩略图。它让我们能够看到在地面看不到的各个领域之间的关系，证明看似不相关的数学领域并不是完全不同。当你想解决某个领域（比如说拓扑）中的问题，但没有合适的工具可以使用时，这就变得非常有用。通过将问题转移到不同领域（比如群论），就能让你换个角度看问题，说不定还能发现新的工具，让问题变得更容易解决。事实上，范畴论就是这样产生的。它诞生于20世纪40年代，背景是人们试图用更简单的代数方法来解决一个困难的拓扑问题。 马丁·库佩的数学地图 回到数学地图，你可以注意到各领域都包含一些对象：集合论有集合，群论有群，拓扑学有拓扑空间…… 这些对象彼此关联：集合通过映射关联，群通过同态关联，拓扑空间通过连续映射关联……这条共同的线索贯穿了整个地图，将各领域统一到一起。范畴论将这种统一形式化了。更具体地说，范畴是一组对象及其关系的集合，这些对象之间的关系（称为态射，morphisms）在组合（composition ）和结合性（associativity）方面表现良好。这样就为数学提供了一个模板，将不同内容输入模板，就能重建一个数学领域：集合范畴由集合和它们之间的关系（映射）组成；群范畴由群和它们之间的关系（群同态）组成；拓扑空间范畴由拓扑空间和它们之间的关系（连续映射）组成；等等。 集合与集合之间的关系（映射）；群与群之间的关系（群同态）；拓扑空间与拓扑空间之间的关系（连续映射）。巴里·马祖尔（Barry Mazur）写了一篇精彩的非专业性文章介绍范畴论，《什么时候一样东西等于另一样东西？》，范畴和模板的类比就是在这篇文章中提出来的。他在文中写道：“范畴的概念是万能的……几乎没有哪种数学对象不适合这个方便并且经常能带来启发的模板。” 事实上，正如范畴论专家尤金妮娅·程（Eugenia Cheng）在她的论文《高维范畴论》中所指出的，“范畴论是数学的数学。” 关系就是一切范畴论的一个主要特点是它剥离了很多细节：它并不具体关心集合中的某个元素，或者某个群是否可解，或者某个拓扑空间是否有可列基。所以你可能会想，“呃，范畴论似乎太抽象了。这样做有什么好处吗? ” 当然，答案是肯定的！剥离细节的一个好处是，我们的注意力从单个对象上转移开，转向它们之间存在的关系——态射。任何一个范畴论专家都会告诉你：关系就是一切。 事实上，范畴论的一个主要信条就是，一个数学对象完全由它与所有其他对象的关系决定。换句话说，当且仅当两个对象以同样方式与范畴中的每个对象相关时，两个对象本质上是不可区分的。这其中的主旨 [这是著名的米田引理（Yoneda lemma）的一个推论] 与我们的日常经验并没有太大区别。你可以通过观察人们的关系来了解他们，比如他们在 Facebook 上的朋友，他们在 Twitter 上关注的人，他们周五晚上和谁出去玩。如果你遇到两个人，他们有完全相同的朋友，他们在社交媒体上的互动也完全相同，他们在周五晚上和相同的人在一起，那么你可能会开玩笑地说，“你甚至分不清他们。”撇开所有玩笑不谈，范畴论告诉我们，这其实是真正的数学！那你可能会想，“嗯，如果数学关系如此重要，那么范畴之间的关系呢？它们存在吗? ”问得好。答案是：当然！事实上，这些特殊的关系有个名字——函子（functor）。但是为什么要就此止步呢？这些关系之间的关系呢？它们也有名字：自然变换（natural transformation）。 范畴之间的关系被称为函子，函子之间的关系被称为自然变换。事实上，我们可以继续：“关系之间的关系之间的关系……?”这样做将使我们进入更高维的范畴论，这正是尤金妮娅·程的主要研究领域。尽管听起来很抽象，但这些构造——范畴、函子和自然变换——组成了一个理论宝库，不仅仅涉及数学，还涵盖许多学科！范畴论自诞生以来，已经在计算机科学、量子物理学、系统生物学、化学、动力系统和自然语言处理等领域找到了自然应用。（“应用范畴论”网站上有一个应用列表，http://appliedcategorytheory.org/workshops ） 因此，虽然范畴论听起来有点抽象，它其实具有很多实际应用。这并不奇怪。范畴论是关于关系的，而关系在我们所处的世界中无处不在！ 结语范畴有点像凤尾鱼：有些人天生喜欢，而对其他人则是一种后天习得的口味。所以是的，范畴论确实不能在求极限时为你的 ε 找到一个 ，或者确定你的520阶的群是否为单群，或者为你的偏微分方程构造一个解。为了做到这些，我们必须脚踏实地。但是，当你在最喜欢的数学领域的角落和缝隙中艰难跋涉时，范畴思维可以指引你——它可以增强你的直觉，让你的洞察力更敏锐。如今，我们尤其难以摆脱范畴论在现代数学中的普遍存在。所以无论你学数学的目标是什么，学习一点关于范畴的知识都是值得的！ 作者介绍个人网站：Math3maTai-Danae Bradley是纽约城市大学数学博士生。感兴趣的领域包括范畴论、拓扑学、机器学习和量子物理，空闲时间爱好涂鸦和写博客。一个与数学相关的网站：chalkdust]]></content>
      <categories>
        <category>数学</category>
        <category>学科理解</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[席南华院士科普讲座《数学的意义》实录]]></title>
    <url>%2F2021%2F02%2F11%2F%E5%B8%AD%E5%8D%97%E5%8D%8E%E9%99%A2%E5%A3%AB%E7%A7%91%E6%99%AE%E8%AE%B2%E5%BA%A7%E3%80%8A%E6%95%B0%E5%AD%A6%E7%9A%84%E6%84%8F%E4%B9%89%E3%80%8B%E5%AE%9E%E5%BD%95%2F</url>
    <content type="text"><![CDATA[演讲视频 1. 演讲环节谢谢主持人的介绍，谢谢大家在周末星期六的下午听这个报告。我今天要说的是“数学的意义”。数学，要说爱你不容易，不管你是天才还是庸人，都是它虐待的对象，差别在于有人在这虐待的过程中得到快乐，但大部分人得到的是痛苦。痛苦的一个根源是其实我们并不认识它，撇开我们在与数学打交道的过程中的不愉快或愉快，今天让我们从另一个角度、一个轻松的带着喝下午茶的心情，带着一个旁观者的心态，来看一看数学的意义。 1.1 数与形导出的数学发展史提起数学，我们会想到什么？从小学到大学都有数学课，它在最重要的课程行列。我们也知道，在日常生活和科学技术中，它很有用。除此之外可能就想的不多了。换句话说，对数学的本质，它为什么有用，甚至更进一步为什么有数学，数学除了实用以外还有什么别的含义，就不大想了，这似乎是和我国文化的实用主义是有关系的。在这样的背景下，可以说我们对数学的认识是很不足的，我们看见的实用只是数学的一个面，是冰山一角。数学理论的源头在古希腊，我们有谁不知道欧几里得几何原本呢？它的数学发展的水平之高，即便在今天看来，都是让人感到非常吃惊的。它为什么会是这个样子，它的产生当然与希腊当时的文化和哲学是分不开的。跨越时空，让我们来到2000多年前的希腊，看他们是怎样认识数学的。他们说，“数学是现实的核心，万物皆数，数统治着宇宙”等观点，都是出自毕达哥拉斯学派，柏拉图学派是深受毕达哥拉斯学派的影响。我们都知道数学研究量与形，但这么说还难以感受数学的重要性，也很难联想到数学是现实的核心。大家想一下，有什么东西没有量与形的属性呢？换句话说，量与形是物质与事物的基本属性，不管是什么东西，它的这两个属性是摆脱不掉的。数学研究就是这些基本的属性，这决定了数学的价值，也使我们明白，数学它是基础而重要的。说它是现实的核心也就不奇怪了。如果我们想要对数学有很好的认识的话，就有必要回顾一下，历史上它是怎么产生的。为什么能够产生数学、人们是怎样一步步建立数学体系的？就是说，在遥远的过去数学是什么样子？其实整个历史过程是非常的漫长，数学有很长的历史，不像有些学科非常的短，可能就是20世纪开始的，但数学不一样，它作为一个独立的、有理论的学科出现，还是2000多年前。应该说公元前600年到公元前300年期间，欧几里得《几何原本》它就是一个光辉的典范，它把古代时候的数学都系统的整理出来，用公里化的方法处理，整个思维体系影响了后面两千多年。他的几何《原本》也在2000多年间是标准的教科书。几乎同时，亚里士多德的学生欧德摩斯就写有数学史的著作，所以数学史人们很早就关注它了。不过，比起人类和人类文明的历史，数学的历史要短暂的多。在一万多年前人类就开始定居于一处，靠农牧业生活，在中国的考古中，包括周口店的头骨，我们都能看出来。不过文字的出现却要晚的多，大约在公元前3200年的时候。文字的出现对整个文明来讲是极其重大的事情，在我国古代认为这一是件泣鬼神的事情，在没有文字的时候，你想要在数学上有重要的发展，那是不可想象的，所以文字出现以前，数学的发展其实是非常缓慢的。我们都有一个深刻的印象，就是数学的抽象特点。即便是一个非常简单的概念，数，就是一个抽象的概念，你在大自然中间看不到一个抽象的数，比如1。抽象的数的发展其实也是非常缓慢的，类似的概念包括线段、直线、三角形、圆等等也是一样。数的概念据人们研究也并不是仅仅只有人独有，据说有些动物也有数的概念。人们提炼数的概念其实经过了一个很漫长的时间，开始的时候人们对数的观念是与具体的物品联系在一起的，比如说一棵树、一块石头、两个人、两条鱼等等，对形也是一样的。逐渐的，人们发现了一棵树、一块石头等具体物体的共同的数字属性，数的抽象概念就这样形成了。数，是自然界若干物体的共同数字属性，这是一个抽象的概念，你在自然界当中不能直接找到。我们今天可能没有意识到，其实这在人类认识自然的过程中间是一个巨大的飞跃。实际生活的需要产生了数字间的计算，比如说要分配食物、交换物品、到指定日期前的天数等等，这都需要对数进行一个计算。我们日常生活中间对数学的认识，说数学有用，很多时候都停留在这个阶段，比如说会算帐、会分配什么东西等等，它其实是对数学的一个误解。还有一件很重要的事情，就是要给数一个名称，并且能够记下来告诉别人，这件事情也并不是一件很简单的事情，所以在文字刚产生之初就引进了数学符号，这在算术的发展上是非常重要的。一般的算术符号和公式、未知数的符号等是很晚才完成的，包括我们现在熟悉的常用的加减乘除的符号、代数符号都是很晚很晚（才完成的）。像现在的代数符号是到了16、17世纪意大利数学家韦达引进的，他对代数学的发展起了一个巨大的作用。算术最早是在巴比伦和埃及那里发展起来的，它由于实际生活的需要，包括税收、丈量土地、贸易、建筑和天文等等。虽然数学发展到今天已经非常抽象，但它的来源还是实际的生活与生产。不过需要说清楚的是，这里所产生的只是一些计算的规则和问题的解答，算术的这种形式并不是数学理论，原因在于它没有关于数的普遍的定义。前些年，也许现在还有，有一个电视台的《最强大脑》里面可以看到有些人算的很快。一个运算能力非常强的人，大家会有一些误解，以为这些人都有很强的数学能力，其实这是一个误会，他有数字的运算能力却不一定有数学的能力。从实际后来发展的情况来看，他们其实并没有数学的能力，原因在于他对于数的普遍规律没有什么深刻的认识，所以不具备数学的天赋。向理论算术的过渡也是逐渐进行的，在古代像中国、巴比伦、埃及就已经知道百万以上的数了。我们看《史记》上的记载，在战国时代，它的战争规模就已经非常庞大了，打起仗来动用士兵经常几十万、上百万等等，虽然我们今天都习以为常。我们现在的孩子数数1、2、3……都会数下去，但是在他的意识里边，是不是会想着这个数能够一直数下去？可能知道，也可能不知道。数是不是会到某个地方截止了？这个也是不清楚的。在古代最伟大的科学家阿基米德专门有一本书叫《数砂法》，里面明确指出了命名大量砂粒的数目的方法，这在当时是一件需要详细解释的事情。其实今天遇到天文数字，我们也很难具体的数一数，我们可能到百万、到亿、到万亿等等，再往大了，一般人也用不到那些数字，也不知道怎么称呼，最后笼统的就会用一个数字——天文数字来表述它。对于很大的数字要给它命名，在古代不容易，在今天其实也没那么容易。在公元前三世纪的时候，希腊人明确意识到两个重要的思想：数列可以无限地延续下去；不但可以运用具体的数，还可以讨论一般的数，从而证明关于数的普遍定理。比方说《几何原本》里面就证明了素数有无穷多个，这是关于数的普遍的定理。这个时候，数学理论就产生了。算术概念其实反映了物体集合量的关系，这些概念是在分析和概括大量实际经验的基础上加以抽象化而产生的，并且是逐渐产生的。刚开始是与具体对象相连的数，然后是抽象的数，再就是一般的数。但有意思的一件事情是，每一个阶段都依赖先前的概念和积累的经验，这是数学概念形成的基本规律之一，其实其他的科学也是一样的，要形成一个概念，都要依赖于前面的积累。算术让人信服的一个根源，在于它的结论和概念是运用逻辑方法得到的，逻辑方法和概念都是以数千年的实践为基础，以世界的客观规律为基础。我们对数学的逻辑都是非常信服的，逻辑也不是凭空产生的，它也经过了一个漫长的过程，以数千年的实践为基础，以世界的客观规律为基础。这种想法以为我们的逻辑能够独立这个世界客观，它是不合适的，这当然也就意味着逻辑也有它的局限，逻辑是非常诡异的，它的诡异性远远超出我们的想象。算术尽管它的概念是抽象的，但有广泛的应用，原因在于它的概念和结论概括了大量实践经验，在抽象的形式里面表现出现实世界那些经常和到处碰到的关系。计算的对象可以是不同的，是动物、农产品、星球等等，它舍弃了所有局部和具体的东西，抽取了某些普遍的性质，这就是数字的共同属性。性质的普遍性其实决定了应用的广泛性，抽象的价值就在这个地方。算术的抽象性保证了广泛应用的可能性，这种抽象并不是空洞的，而是来源于长期实践的经验。对于全部的数学，对于任何抽象概念和理论，它其实都是一样的。理论应用广泛的可能性取决于其中所概括的原始材料的广泛性。要说清楚一点，抽象与空洞不是一回事，我们经常会看到，某个人说的话真空洞，他说的话好像没什么内容等等，不管报纸上还是很多领导的讲话也好，都有这个印象，原因在于它里面并不概括什么实际的内容，而仅仅是形式上给你一些正确的东西，这种形式上正确的东西其实并没有什么价值。而数学上的抽象并不是一个形式的东西，它来源于长期的实践经验。对于任何数学，对于任何其他的科学包括哲学等等都是一样的，需要概括一些非常广泛的东西，并且有实际的丰富的内容。还是这么说，理论应用广泛的可能性取决于概括的原始材料的广泛性，如果概念本身概括的东西很少的话，希望它能够有广泛的应用，那是不现实的。毫无疑问，抽象也会有它的局限性，因为在抽象的过程中间会丢弃掉很多东西，只反映对象部分的属性。常常也是这样，仅有数据是不够的，我们现在生活在一个信息时代，大数据的时代，大家对数据的强调到了非同寻常的地步，认为数据要主宰这个世界的一切一样。但是从过去的经验来看，它可能还做不到这一点。数据只是事物的一部分属性而已，换句话说不能无限制的运用抽象的概念，就像把一只羊和一头狼加在一起，一升水和一升酒混在一起，它都不是算术一加一的应用，虽然可能有些商人会在酒里兑水，我们也有个非常有名的动画片《喜洋洋与灰太郎》等等。真理是具体的，虽然数学是抽象的。把抽象应用到具体是一种艺术和一种技术。有意思的一件事情就是我们的思维常常是会超出实践提出的任务这些要求以外很远，这非常有意思，比如十亿或者百亿这样的大数字概念，它当然是在计算中间产生的，很早很早就有了。但这些概念出现的时候其实没什么用处，直到后来才有用。科学里有很多这样的东西，刚开始出现的时候没有什么用处，我们后面还会举一些例子，这就是说我们实用的一些哲学观点，可能要避免。这种例子在科学上很多，举个简单的例子，大家在高中的数学里面有复数，我们知道求方程的时候都要求根是一个实根等等，但是对于X^2+1=0这样一个方程，我们就没有根了，没有根怎么办？那就不存在了。得出这个结论，但是我们又不满足，最后又引进了一个根，虚数。从这个概念本身就知道，它是一个虚构的，它是想象出来的，不存在。但是到了后来，这个数非常的重要，由于虚数的引进之后我们就有了复数的概念，复数上的数学是非常庞大和深刻的。陈省身先生对复数就非常着迷，他说复数太迷人，你怎么都参不透它，里面有很多的东西是那么神秘，那么深刻。他晚年致力于的一项工作就是证明一个六维的球面上有复结构，但一直都没有做下来。当然这个问题到现在谁也没有做下来，所以他没有做出来也一点不奇怪。类似的，线段、直线、圆和三角形等等抽象概念，也是逐步发展起来的，它是一些物体的共同的空间属性，是形方面的属性。和算术一样，它产生于实践，然后逐步形成数学的理论，现在已经是及其庞大的理论了。形的概念，也从我们熟悉的点、线、面等等变得非常陌生，比方说在三维空间里面，把所有过圆点的实线拉出来，它也是一个非常好的结构，是一个射影空间。几何的抽象当然也是很明显的，因为这里头点没有大小、线没有宽度厚度，面也没有厚度，它只是现实世界物体的一个空间属性的抽象，在现实中间你看不到这样的点、线和面。对这些抽象的空间形式是没有办法做实验的，所以只能用逻辑推理的方法从一些结论导出另一些结论，重要的是我们需要认识到这些结论其实是现实世界的抽象的一个反映。几何和算术一样，它原始概念的明显性、推理的方法、结论的令人信服都如同算术那样，以实践和世界客观规律为基础。既然以实践为基础，也就意味着它会有局限，就会有人想，我们直观提炼出这些概念，是不是很好的反映了现实？很久很久以前人们是很有信心的，但随着科学的发展，或者说随着人们对几何公里深入分析的时候，这个信念就动摇了。大家知道对欧几里得几何第五公式的讨论和思考，最后导致了非欧几何，那非欧几何中的黎曼几何对相对论是非常重要的，更好的描述了我们的宇宙。所以我们来源于实践中的很多东西，到后来又经过不断的修正，通过实践和理性的思考。在数学里面，量与形是事物的基本属性，那毫无疑问，分开讨论量的属性和形的属性都是不够的，他们两者必然会有联系、互相有制约。数学分支之间的联系互相渗透，是有特别重大的意义的，它有力的推动了数学的前进，并揭示了这些分支所反映的现实世界关系的丰富多彩。我们现在非常强调交叉，原因就在于不同的学科其实都是现实中间不同角度的反映而已，只有把它结合起来，才能对这个现实有更全面的认知。这有点类似于盲人摸象，每个学科可能只摸到一个局部、一个侧面而已，把所有的合起来，我们就会对这个“象”有个更完整的认识了。回到算术与几何，它同样有密切的联系，不仅互相作用，而且是产生进一步的一般概念、方法和理论的来源。这一点非常的重要，就像我们现在的交叉，它不断产生新的概念、方法、理论等等。数学和化学结合到一起就会有计算化学；数学和物理的结合一直是非常紧密的，（它们的结合）有数学物理；还有计算生物学等，像现在很多数学家转去做生物，我知道有些美国的数学家转去做生物之后，结果成为美国科学生物方向的院士，这样的例子还有很多。算术和几何是数学成长的两个根源，其密切的联系在刚开始就有了。比方说简单的一个长度测量就已经是算术和几何的结合了。当你测量物体的时候，会把单位长度的东西放在物体上面，然后数一数共放了多少次，其中第一步“放”的时候就是一个几何的性质——全等，第二步“数”当然是算术的做法。在测量时候常常会发现，选用的单位不能在被测的物体上放置整数次，这时候就必须把单位加以分割，以便利用单位的一部分来更准确的表示量，这就已经超出整数的范围了，要用分数来表示这个量，分数就这样产生了。这是几何与算术相互作用的结果，它引起了数的概念从整数到分数的推广，这也是数的概念非常重要的一步，分数就这样产生了。直接在自然界中间还形成不了分数的概念，但是通过几何与算术的联系，它就产生了。不过无理数的发现，还不能通过测量实现，因为在实际测量中间，如果分割和度量达到过于细小的程度时候，这些细小的量就会被直接忽略掉，也做不到无限精确的测量，而且无限精确也没有意义。勾股定理告诉我们，单位边长的正方形对角线的长度就是2的平方根，这样数的概念就进一步发展了。而且逐渐的人们把数理解为某个量与被取做单位量的比值，可以不再把数与具体物体量的属性联系起来，这意味着对数的认识又比前面进了一大步，它是两个量的比，比如3/5，就是3和5的比值，和测量、和数（shǔ）数（shù）都没有任何的关系。这里要特别强调一下无理数的发现。我们可能都知道，在古希腊的时候，人们利用勾股定理，他们叫做毕达哥拉斯定理，发现了单位边长的正方形不能够被有理数度量的时候，希腊人是感到震惊的。他们认为这些事情好像破坏了世界的美一样，不能理解这件事情。但它既然这样自然的产生，当然在数学里面有重大的意义。从哲学上来讲，它的发现也是数学理论在揭示自然规律和现象的威力深刻性上一个典型的例子。可能我们平常没有意识到这一点，就是无理数没有数学理论是发现不了的，其他的手段包括测量、抽象、实验等等，都发现不了，只有数学理论能够告诉你世界存在无理数，而且会有很多很多。后面我们还会谈到一些其他东西，比如说无穷也同样只有数学能做到，别的科学做不到。数的概念进一步的发展就是实数，然后就是复数，到了后来就是代数结构，这个地步已经到了比较高深的数学了。换句话在我们日常生活中间不一定能够直接感受到，可能也不需要感受到，专家会给我们忙这些事情，（把它们）运用到物理、通信、航天等地方。关于数与形的联系，华罗庚先生有一个非常深刻的见解，他说，“数缺形时少直观，形缺数时难入微”。确实是这样，你把这两个统一起来考虑的时候，对这两者的认识都会变得更深刻。如果你孤立的来考虑，不会走的那么远。 1.2 数学的独特贡献：认识无限简单地谈一下历史之后，我们应该说数学了。数学应该是从数（shǔ）数（shù）开始的，我们有谁不会数数呢？在幼儿园里的孩子都会1、2、3……这么数下去。一般孩子数到100，可能他的爸爸妈妈就让他过去了。不过有些望子成龙的家长可能会让他一直数到N，数到一个抽象的N。一般可能想不到用正整数把所有整数都数一数，其实这是可能的，一个数法就是从零开始，然后一个负数一个正数、一个负数一个正数，结果就把整数这么一个个排下去了。这件事情有点意思，也说明数数好像没有那么简单。接下来我们就可能会想着用正整数去数有理数，刚开始看这似乎是不可能的一件事情，但出人意料这也是可能的。有理数是两个整数的比，当然前面还有一个正负号，我们可以要求这个分子分母没有大于1的公因子，把分子分母都加起来，先按这个值大小分成若干部分，这时可以用整数去数。然后对于固定的和，这里的有理数肯定是有限的，那这部分又能数。这样操作下去之后，结果发现有理数也能数，从零开始，然后接下来就是分子分母都是1的数，只有1和负1；那分子分母加起来是3的时候，那就是1/2，2，-1/2，-2；加起来是4的时候就是1/3，3，-1/3，-3等等。这个样子就把有理数全部都数下去了，这应该说数数还是非常有意思的一件事情。那接下来你可能想继续用整数来数实数，但很遗憾，实数确实没办法用整数来数。这显示出实数和有理数、整数之间，从无穷的观点来看，它是有巨大差别的。而且有理数虽然看起来乱糟糟，我们还是能够把它数清楚，但实数我们做不到这一点。证明并不难，我们这里不用去管它了。这里马上就会产生一个问题，在自然数全体和实数全体之间有没有一个数的集合,它一方面没有办法数，或者说我们不能像整数那样数下去;另一方面它和实数全体也不一样多,也就是说你不能和实数集建立一一对应，一一对应通俗的语言说来就是旗鼓相当，数学的语言就是等式，就是势力相等的意思。这个问题看起来很自然，问的就是像在1和2之间有没有整数一样。不过大家可能意识不到的事情是，这个问题在数学里面是特别重要的一个问题，一个很基础的问题。康托是集合论的创始人，他提出这样一个假设——连续统假设，说这样的集合没有。大家可能知道，在1900年国际数学大会上，伟大的数学家希尔伯特提了23个问题，这23个问题中的第一个问题就是连续统假设，可见这个问题在数学中的重要性。数学家们花了很大的力气来研究它，哥德尔，伟大的奥地利数学逻辑学家，他在1940年就证明了连续统假设和我们现在这个逻辑体系是没有矛盾的，没有矛盾还不能说它对。又过了23年到1963年，一位美国数学家科恩，他发明了一种非常有利的办法，叫做力波法，证明这个结论否定的一面和我们现在的逻辑体系也是没有矛盾的。这个事情就变得诡异起来了，换句话说这么简单自然的一个问题，在逻辑上来讲，我们证明不了它是对或者错，就像在我们日常生活中一句话一样，“说你行你就行，说你不行你就不行”，这让我们对逻辑产生了很奇怪的感觉，原来它也有它不能的时候。科恩因为这项工作，在1966年获得了菲尔兹奖，在取得了这项伟大的成就之后，他心气高昂，觉得数学里面没什么问题值得他研究，除了有一个问题叫黎曼猜想，数学里面最著名的一个问题。科恩后来的余生就致力于研究黎曼猜想，他这个心劲有点类似于我们古代唐诗所描述的境界“曾经沧海难为水”。很可惜，科恩已经去世了，黎曼猜想还依然活着，谁也没办法证明它。在这个地方我们可以看出来，逻辑实际上比我们想的诡异的多，很多时候我们对它的认识可能还不那么透彻。关于逻辑我愿意在这里再多说一点点，一般人对于数学的逻辑都非常有信心，不仅数学家相信，物理学家相信，一般老百姓也相信。但随着我们对数学的认识不断的加深的时候，就有很多的悖论，包括罗斯的悖论等等。这些悖论也就意味着数学的逻辑不像我们平时想得那样无所不能、无所不利。我们能做的事就是给它建立一个很坚实的基础，比如这个世界有狼，那我们就圈一块地，把狼赶到外面去，然后在圈里面放羊。把数学就建立在这个领域，这个大厦就非常牢固了。数学家对这个努力的方向是非常乐观的，罗素与怀特海就写过数学原理三大本书，试图来做这件事情。罗素是一位非常杰出的数学家，数学家拿诺贝尔奖的人很多，但是这位数学家是通过文学拿的诺贝尔奖，实际他是通过这三本书——《数学原理》拿的诺贝尔奖。据说当时正好在诺贝尔奖评选委员会里，有一个人对他这项工作很了解，结果就颁给他了。拿诺贝尔奖文学奖的数学家目前只有一个。伟大的数学家希尔伯特对这样一个努力的方向也非常的乐观，认为我们一定能够做到这一点，我们必须做到，也将会做到。但他这种乐观的话说出来之后，朗朗的笑声没有多久，在1931年，哥德尔，还是这个哥德尔，他就证明了两个不完备性定理。第一个定理说，如果你的公里体系包含算术公里体系，就是我们最常用的体系，因为我们总要处理整数、算术这些东西，如果包含这个体系了，必然会有一个命题是没法判断它的正确与否的。就像我们刚才（提到的）一样。歌德这个构造还要简单一些，那是更早完成的。另一个不完备定理说，如果有一个公里体系包含了这个算术公里体系，那么它的不完备性是不能够由自身证明。就像在法庭上你不能自证清白。这对希尔伯特的形式化纲领是一个致命的打击，也宣告他的形式化纲领是不可能实现的。希尔伯特得知这个消息后当然非常的沮丧，更遭的是那个冬天，他还把腿给摔断了，这显然是一个不祥之兆。从数数引发出来的问题，我们可以看到逻辑的诡异性，也揭示了我们认知上的局限性。数理逻辑还和计算机科学是密切相关的，计算机科学能做到哪一步，哪些地方不能做，这个界限有时候还不是特别的清楚。但是我们通过数理逻辑知道有些东西做不了，还有很多东西能做不能做我们并不知道，比如P和NP问题等等，它反应了一些诡异的东西。哥德尔这项工作不仅在数学界里面，而且在哲学界里面都产生了巨大的影响，他实质上和我们的常识或者是一般所想的差的太远了。在上个世纪70年代有一本书，是获得美国普利策奖的，书名就是《G.E.B》——一条永恒的金带。这个G就是哥德尔；E就是埃舍尔，一位荷兰的画家；B就是音乐家巴赫。他把哥德尔的不完备性定理和埃舍尔的绘画以及巴赫的音乐给联系起来。你在看埃舍尔绘画的时候也是很有意思的，它在整个局部上都是非常合理的：水不断地往高处流，结果最后整体上看它流到原来地方，或者甚至比原来更低的地方。巴赫的音乐也是，有时候听了你会感觉到它不断的深厚，结果回到原来的地方。那本书就揭示了这中间的一些联系，是一本很有影响的书。我们国内也有翻译。埃舍尔的画科学家也很感兴趣，因为它揭示了一些非常奇怪的矛盾现象。印象中间像杨振宁写的《基本历史简史》里面就有一幅插图，是用了埃舍尔的绘画。 埃舍尔绘画作品《瀑布》 在我们有限的生命里面，要认识无限，似乎是一件困难的事情，甚至可能是一件让人不安的事情。在古诗里面就说了“生年不满百，常怀千岁忧”，这就表明我们并不甘心局限于自己有限的时空。但无限是令人敬畏的，帕斯卡说到，“当我想到我生命的短暂停留，被前后的永恒所吞噬，我所占据的小小空间，被我也一无所知的无限广阔的空间所淹没，我感到恐惧，这些无边无际的空间的永恒的寂静使我害怕”。在数数的游戏中间，我们就感受到了整数的无穷和实数的无穷的差别。数学非常重要的一个作用是能够认识无限，这是别的学科做不到的。你没有看到任何其他的学科能够做这件事情，哲学讨论无限，讨论不出个所以然，只有数学能够研究无限，这是它神奇的地方。我们利用无限还可以研究有限，例子包括极限、级数、无限集合等等。在无限里面也有差别，我们刚才已经看到了整数的无限和实数的无限的差别，在数学里面专门有个分支研究这种差别，那就是集合论。对于无限，希尔伯特的认识是非常深刻的，他说，“没有其他的问题能够如此深刻的触动人的精神；也没有其他的思想能如此富有成果地激发人的思想逻辑领悟力；然而也没有其他的概念比无限的概念更需要澄清”。我们常常有个朴素的想法，希望长生不老，其实是跟无穷联系在一起的。 1.3 数学是什么我们现在转过来看一些观点，数学是那么的有魅力，伟人们从不吝啬他们对数学的敬畏和赞美之词，说出了一些非常深刻的观点。像古希腊，毕达哥拉斯学派、柏拉图学派，他们认为数学是现实的核心。我们常常听到的观点“万物皆数”源自毕达哥拉斯，他的学派还有类似的表述，“数统治着宇宙，数是万物的本质”。柏拉图学派深受毕达哥拉斯学派的影响，把数学摆在至高的位置，“纯粹思想的最高形式是数学。”在柏拉图学院的大门上写着“无几何学识者勿入此门”。在柏拉图的名著《理想国》里面，第七篇有很长的对话讨论算术与几何的重要性，结论就是 “算术迫使灵魂使用纯粹理性通向真理，几何是认识永恒事物的，并把算术和几何作为青年人必须学习的第一门和第二门功课。”古希腊认为“数学是自然界最真实的一个本质”，有这样的认识，古希腊在数学上能够取得开天辟地的成就，似乎也就不奇怪了。这句话在我们今天的时代应该会有更深的体会，在我们今天的社会信息时代里面，什么东西都要数字化、数字地球、数字这个、数字那个等等，其实背后都离不开数学。伽利略认为 “宇宙就是用数学语言写成的，如果你不懂数学，要想认识宇宙是不可能的，这些语言的字母就是三角形、圆以及其他的几何形状等等。”高斯认为“数学是科学的皇后”。也许大家看过徐迟的报告文献《哥德巴赫猜想》里面提到过这句话。高斯是被称为19世纪的数学王子，是19世纪最伟大的数学家，也是杰出的物理学家、天文学家、大地测量学家，他的这句话常被人引用，只是不知道高斯把皇帝弄哪儿去了。不过也许大家可以想一下。维格纳是一位获诺贝尔奖的物理学家，他提到 “在自然科学中，数学是不可思议地有效，已经达到了不合理的程度。”他的这个观点问世以后，引起了长久的讨论和引申。狄拉克也是一位杰出的物理学家，他认为“上帝是一位非常高等级的数学家，他用非常先进的数学来构造这个宇宙，我们只要在数学里面有进一步的认识的话，都会有助于我们认识这个宇宙。”我只是有点奇怪，他为什么不认为上帝是一个最高等级的数学家，他是不是认为最高等级数学家还有什么别的人？在欧洲甚至一些文人对数学也是赞叹不已，这和我们国家的文人不太一样，我们国家的文人好像赞美数学的很少。我只是看到很多文人写的作品里面，对数学是表现极其的厌恶之情，以不懂数学而自豪等等。伏尔泰认为“数学必须驾驭我们理智的奔驰，他是盲人的拐杖，没有它寸步难行。一切确凿无疑的事实都应该归公于数学和经验。”这是一种认识，也是一种信念。法国数学的强大，不仅是法国数学界的功绩，也有深刻的文化因素。甚至他们的皇帝对数学也是赞叹有佳，把它和国家的繁荣富强联系起来。拿坡仑是19世纪法国伟大的军事家、政治家、法兰西第一帝国的提倡者。人们一般都关注他的军政成就，其实他在科教方面的成就对法国以后的发展也同样是至关重要的。在法兰西第一帝国期间，法国制定了保留至今的国民教育制度，成立了公立中学和法兰西学院来培养人才，鼓励科学研究与技术研究事业的兴起。拿坡仑本人对科学文化事业是极为关注的，掌权以后他定期出席法兰西科学院的会议，邀请院士们报告科学进展，把许多奖赏授予科学家，包括外国的科学家。拿坡仑的关注，促进了法国科学的繁荣，出现了像拉普拉斯、拉格朗日、蒙日、卡诺、傅里叶、吕萨克、拉马克、居维叶等一大批耀眼的科学明星。我们国家的领导人现在对数学也是非常重视的。西方国家强调数学的还有哲学家，康德是18世纪德国的哲学家，被认为是所有时代最伟大的哲学家之一，他拥有渊博的自然科学知识，对道德有着深刻的理解。他的哲学对德国古典哲学和西方哲学都有深远的影响，对马克思主义哲学的诞生也有深刻的影响。《纯粹理性批判》是其最有名的著作，他认为“数学科学呈现出一个最辉煌的例子，不借助实验，纯粹的推理就能够成功的大大扩大人们的认知领域。”关于这点，我们前面提到的无理数就是一个典型的例子，当然虚数也是个典型的例子，我们后面还会有更多的例子来说明这一点。我们常常会听到，“飞行的马赫数”，很多人觉得数学很难或者什么之类等等，但是马赫的观点完全不一样，他说，“也许听起来奇怪，数学的力量在于它躲避了一切不必要的思考和它令人愉快的节省了脑力劳动”。其实做数学节省了很多的脑力劳动，你不用辛苦的考虑很多东西，因为很多东西的数量关系就决定了它们的主要性质。如果像这位雷尼的话就更有意思了，他说，“如果我感到忧伤，我会做数学变得快乐；如果我正快乐，我会做数学保持快乐。”我是完全同意他的观点，做数学多好。黑格尔是德国18至19世纪的科学家，德国古典维新主义的集大成者，创立了欧洲哲学史上最庞大的客观维新主义体系，并且极大的发展了维新辩证法。他的上述观点（“数学是上帝描述自然的符号。”）和伽利略的观点是一脉相承的。现在数学在社会科学里面应用也变得越来越广泛，在经济里面是一个典型的例子，你要是不懂数学的话，只做经济学，它的出路并不是很好。爱因斯坦无疑是上个世纪最伟大的科学家，他的观点更让人深思，他说，“纯数学能使我们发现概念和联系这些概念的规律，给了我们理解自然现象的钥匙。”他进一步说到，“数学之所以比一切其它科学受到尊重，”虽然他自己是一个物理学家，“一个理由是因为它的命题是绝对可靠的，无可争辩的，而其它的科学经常处于被新发现的事实推翻的危险。数学之所以有高的声誉，另一个理由就是数学使得自然科学实现定理化，给予自然科学某种程度的可靠性。”你看到其他的学科一篇论文半衰期非常短，我们常听说某些学科五年前的论文到现在已经没什么价值了，但你看欧几里得《几何原本》用了两千多年，勾股定理到现在我们还是一直不停的在用，所以数学的生命是永恒的，不像其他的学科。即便是伟大的牛顿定理，后来也发现只是低速世界的定理，在更大的空间里面、更小的空间里面它其实都不适用。小的空间里有量子力学，大的空间有相对论。 1.4 数学的纯粹和无处不用对数学在现实中的用处，华罗庚先生的观点是非常透彻的，“从宇宙之大、粒子之微，火箭之速，化工之巧，地球之变，生物之谜，日用之繁，无处不用数学。”你可能会注意到这一点，它其实还是迎合了我们国家一种实用主义的思维。从华罗庚先生这些话里面，每一句都能引申出很多的东西。比如第一句话中对于无垠的宇宙，离开了相对论要认识宇宙其实是很困难的，前两年发现了引力波，其实来源于相对论；在粒子之微这里，有量子力学，包括薛定谔方程；火箭之速也会用到数学，必须要计算好，不然坐火箭出去旅行，很有可能就回不来；化工里面也是一样的，它有很多的化学反应，微小的实验尺度里面就会用到微分，大的实验尺度里面会用到积分；地球之变不用说，现在的天气预报能够预报的比以前更准确，毫无疑问数学起了很重要的作用，包括建模之类的；生物之谜也是一样的，人为什么演变到今天，它的基因怎么演变的，这里概率和统计就起了很重要的作用。这里还可以说一个故事，本拉登前几年被击毙了，当时美国的情报人员花了很大的力气弄清楚他的落脚点。那科学家怎么来看这件事情呢？科学家用了一个模型来推测本拉登的落脚点，他认为本拉登这个时候的行为跟濒危动物的行为差不多，所以利用濒危动物的行为来预测本拉登的落脚点，最后推测出来他可能在两个地方落脚，其中一个就是白沙瓦，这就是本拉登最后被击毙的地方。你可以看一下，运用科学所得到的结论，是常常出人意料的。美国的情报人员其实花了很大的力量，同时很多时候是冒着生命危险的，所以现在情报机关里面雇佣了很多科学家一点儿都不奇怪。在华罗庚先生的话里面，日用之繁，不用说，我们一个最切身的感受就是深受堵车之害，这里数学可以帮助解决很多的问题，运筹优化之类的。还有一件事情也可能有悖于大家的常识，很多时候，路多的时候交通不一定更顺畅，封掉几条路，交通反而更顺畅了，这是经过实际证明的。在二次大战期间，交通因素变得非常的重要，因为要保证物资有效的调度到前线去。苏联数学家为此建立了线性规划的理论来解决这个问题，当时发挥了很重要的作用。有意思的事情是，美国经济学家后来把这个理论用到了经济学里，也取得了巨大的成功，结果在上个世纪70年代这位苏联科学家康托诺维奇，就和美国的经济学家一起拿了诺贝尔奖。数学家拿经济奖的人还挺多，包括纳什，《美丽心灵》的主角，大家都看过这个故事。纳什拿诺贝尔经济奖的论文很短，只有两页纸的样子，不像经济学家，写起论文来都是长篇大论，说起来也头头是道，不把你说糊涂一般是不罢休的。为什么这么说呢？也有个笑话说，就某个经济现象发表看法的话，五个经济学家会有五个观点，如果这中间还有一个是哈佛毕业的话，五个经济学家就会有六个观点，要把他们的观点统一起来基本是没有希望的。我们回到数学这里来，数学的抽象当然来源于长期的实践。它并不是凭空起来的，它的结论是从概念中运用逻辑方法得出来的，而逻辑方法和概念同样是以数千年的实践为基础，没有这些实践的基础也不会有今天的逻辑，它同样以世界的客观规律为基础。数学的规律实际上是自然规律的一部分，只是以抽象的形式反映出来，不过抽象的面目基本上是人见人不爱。现在数学的发展既有外部问题的驱动，也有内在问题的驱动，内在问题的驱动其实也是现实世界的一个曲折的反映而已，只不过是以抽象的形式表达出来而已，那抽象推导出来的数学在现实中间有用就一点儿也不奇怪了，数学的理论还是自然规律的一部分。我们看一下两千多年前希腊人关于圆锥曲线的研究，在17世纪被用于描写天体的运动，过了将近两千年，它才变得有用。黎曼几何是广义相对论的框架。欧几里得出来，后来人们对于第五公式进行了一些反思，因为有些地方跟我们的直觉是不太一样的。比如过直线外一点做这条直线的平行线只有一条，但是从我们视觉上来讲，比如两条平行线的接轨，一直往远方看最后交于一点，这个直观对于绘画非常重要。对于绘画的讨论包括光线的投影等等，最后产生了摄影几何，它其实是一种非欧几何。对于欧几里得第五公式的讨论形成两个几何，一个是双曲几何，一个是球面几何。另一种就是黎曼几何，黎曼几何是完全从数学内部产生的。但是到后来相对论出来之后，人们发现欧式几何是不适用的，相对论的数学框架用黎曼几何正合适，它对引力的解释也和原来完全不一样，并不是说两个物体的质量之间轻，而是说物体质量非常大的时候空间是有弯曲的。另外比方说纤维丛理论在规范场理论中的应用也是一样的，当时杨振宁对这个事情感到非常的惊讶，就跟陈省身先生交流说，“你们数学里面凭空做出来的东西怎么会在物理里面非常重要？”陈省身就说，“我们的几何本来就是现实中的一部分，所以不能说它是凭空产生的。”当然还有很多的例子，包括矩阵和无限维空间在量子力学中的作用，海森堡刚开始把他的量子力学叫做矩阵力学，因为矩阵的乘法具有非交换性。概率论在统计力学、生物和金融中也有广泛的应用，概率论的来源其实是赌博，很多的数学在很久很久以前是人们完全凭兴趣研究的，后来在自然科学或者其他地方都有想不到的大用处。怀特海德就感叹到，“对那些只把知识和研究局限于明显有用的那些人，不会有比如下示例给出更深印象的告诫了：圆锥曲线只是作为抽象科学（的内容），被研究了一千八百年，除了满足数学家的求知欲外，没有任何实用的考虑，然而在这漫长的抽象研究的最后，它们被发现是获得最重要的自然规律之一的知识所必不可少的钥匙。”我觉得怀特海德的话对我们国家来讲，不管是政府也好，还是一般的百姓也好，都是有它的意义的。我们一般都非常关注“有用”，我们学过很多东西，包括学经管，它就是为了挣钱、有用。只是为了兴趣去探索未知的东西，这种精神在我们国家应该是比较少的。我自己在教学的过程中间也遇到一些这个现象，甚至一年级的大学生就问，“线性代数有什么用呢？”线性代数这么技术的东西当然非常有用，包括在通信里面。这个学生提的问题让我感到非常惊讶，换句话说他这个时候没有体会到学习的乐趣，而只是关心有什么用，这其实很难走远，不应该这样问。我觉得他是问错了，他应该问有没有意思，有意思驱动的话做下去就会走的更远，因为一直觉得它有意思。你想你在生活中间不就追求一个有意思吗？这个“有用”，当一个人成为“有用”的时候，我是怀疑这个“有用”有什么含义呢？你是被别人利用，还是你要利用别人？所以“有用”这个东西推敲下去，结果好像不太好。知识通过感性的感觉而产生，逐渐成为考察的对象，最后变成理性的财产。所以我们现在都说知识是人类的财富等等，它确实是一个财富。在我们古代所说的“书中自有黄金屋”，它有一定正确的成分，但还不完全正确，因为它太现实了，包括“颜如玉”等等。我不知道女孩子看到这样的句子会有什么感受，是不是还希望加一句“还有帅哥在里头”。 1.5 数学的思维之美数学的思维方式当然也是一种智慧，这一点尤其重要。在学习数学的过程中间，掌握了数学的思维方式，怎么考虑问题等等，这比知识有价值得多。知识可以上网去搜，可以看书、翻书等都没问题，但怎么考虑问题是能力中一个重要组成部分。我们用两个例子看一下数学的智慧。第一个例子是哥尼斯堡七桥问题。（如下图）这是一个城市，河流是这个样子，有七座桥，问题就是能否设计一条路线通过每一个桥，正好过一次。据说当时市民周末一个很受欢迎的消遣就是能否设计一条路线通过每座桥正好一次。但这个问题当时市民都没有解决，最后大概是一个城市的市长把这个问题交给了欧拉，一个著名的数学家，欧拉把这个问题解决了。我们看一下欧拉是怎样解决这个问题的，这个过程体现了抽象的价值和数学的思维。 首先这条河流把城市分成四部分，每一部分大小其实都不重要，重要的是过桥的路径设计，从而可以把陆地抽象为一个点，大小反正无所谓，干脆没有大小就得了。而桥就抽象成点与点之间的连线，这个图就画成这个样子。简化成这样之后，这个问题的本质就全部展示出来了，除了起点和终点，走过中间那些点，走到这个点的次数和走出那个点的次数加起来必然是一个偶数，就是说连接那个点的桥数必然是偶数。可是上图连接四个点的线路，也就是桥数分别是5、3、3、3，所以不可能设计一条路线通过每座桥正好一次。欧拉解决这个问题的方式，显出了抽象的价值和数学的智慧，这是图论的开始，也是拓扑学的一个先声。图论在信息科学中间，包括网络和芯片设计，都非常有用说到数学思维我们还举一个例子，二战期间很多数学家参与了战争，包括图灵等人破译密码，也包括很多统计学家分析数据等等。其中有一件事情就是很多战机出去空战的时候，很多被击落了，也有很多又回来了，回来的很多战机上面就布满了弹痕、弹眼之类的，这就需要分析在哪些地方需要加固。空军提的建议是，应该在弹孔最多的地方加固，但数学家提出的意见是，应该在弹孔最少的地方加固。为什么？弹孔最多的都能飞回来，意味着这个地方多打几个弹孔也没关系，这就是个缺失数据的问题。弹孔少的地方，比如说发动机，因为被击中后基本就是栽下去，回来的不多。数学家提出的观点和军方是完全相反的，后来事实证明数学家是对的，他挽救了很多飞机和飞行员的生命另外再举个例子，就是晶体的分类。我们都很喜欢钻石，非常的漂亮，还有雪花也很美，他们都是晶体。晶体有多少种？这是很实际的问题。晶体的主要特点是对称，由外部的对称和内部的对称结构来决定，晶体的对称性对晶体的种类带来了很强的约束。数学中间研究对称的分支是群论。外部的对称是很容易确定的，关于内部的对称，舍去了晶体的所有物理性质。仅从几何对称性的角度考虑晶体，在1885年到1890年期间，俄国的晶体学家费德洛夫就确定了晶体的微观的对称形式230种。他的这项工作后来是晶体实验工作数学理论的基础，对晶体的内部结构的确定发挥了巨大的作用。包括1912年德国人劳尔，以及包括后来英国人布拉格父子，他们对晶体内部结构的确定等等，这些数学理论都起了非常重要的作用。劳尔和布拉格父子先后于1914年和1915年获得了诺贝尔奖。群论是研究对称的一个基本工具，在物理中间非常重要，不过它的来源非常有意思，它是解方程产生的。 1.6 数学的逻辑之美很多人都感到数学有一种特殊的美感，他们也曾经做过生理上的分析，发现这个美感和看到漂亮风景、帅哥靓女之类，神经的反应好像差不多的。事实上还有一些物理学家，对数学之美的感受是很强烈的，对数学的美的追求也是无尽的。外尔对数学美的态度就是这样，“我的工作总是设法把真与美统一起来，但如果只能选择这个或另一个时，我常常选择美。”。一般我们追求真善美，但好像从道德上来讲，这样做是不对的，但数学里面的美很可能是更高层次的真实。就像在我们所认识的世界里面，你的认识是有一定局限的，但美是一个原则，让你发现更高层次的真实。外尔写的《群论量子力学》1928年首次出版，非常的有名，据说当时的理论物理学家都会把这本书放在书架上，但都不看，因为里面的数学太难了。物理学家对数学家写的书好像好感并不多，他们的评价大概是这样的，认为数学家写的书有两种：第一种是看了一页就看不下去了，第二种是看了一行就看不下去了哈代是20世纪杰出的分析学家，也是他所在的时代英国最杰出的数学家，他的一个数学家的独白表达了他对数学的看法，影响颇广。他也是一个唯美主义者，他认为“美是（数学的）第一道检验：难看的数学在这个世界上没有长驻之地。狄拉克认为，“物理定律必须有数学的美，上帝用美丽的数学创造了这个世界。”狄拉克方程就是一个典型的例子，它是个很有名的方程，杨振宁对它也是非常赞叹的，专门有文章提到这件事情，就是利用这个方程，人们发现了正电子。当初根据已有的实验结果来讲，它的方程不是这样的。但他认为根据实验结果得出的方程不美，所以就给修改了，修改之后很多东西又解释不了，他就大胆地预言应该还有一个例子没有发现，后来果然通过实验发现了。他对这个公式当然也是非常的喜欢。也有一个很牛的物理学家费曼，课讲的非常好，有次大概因为开会，这两个人（费曼和狄拉克）碰在一起了，长时间的沉默之后，狄拉克就冒了一句话，“我有一个方程，你有吗？”估计费曼当时非常的郁闷。物理学家也好，数学家也好，独特的人是非常多的，英文有个词叫eccentric（中文译为怪人），在我们国家对eccentric好像没那么宽容，西方文化对他们要宽容一些罗素说，“数学，如果正确地看，不但拥有真理，而且也有至高的美。”罗素是数学家，也是哲学家，获得过诺贝尔奖文学奖。他所写的《西方哲学史》从一个哲学家的角度，而非哲学史家的角度看待西方的哲学史，那独特的视角、脉络清晰，文笔也非常的流畅，但又不乏幽默，所以他对美的认知自然有非常广阔的背景如果你觉得数学不美的话，从某种意义上讲我不太建议你去学数学，或者你至少培养了美感之后再去学数学。数学美的含义到底是什么？这个问题提得多了之后，我觉得就要想一想它到底什么内容？后来我发现它大概有以下的内容：形式上要清晰、简洁，还有就是要简单、原创、新颖，不新颖的话，老生常谈，不会有美的感觉；还有就是很优美，以及一个很重要的就是不同对象之间的联系，这一点大家以前可能没有意识到其实是非常重要的。它的内涵必须要非常深刻、重要，还有基本和蕴意丰富，从这个基本的对象出发，能解释很多其他的东西。它的证明要清晰、干净利落、巧妙。 我们用一些例子来说明一下这些观点。第一个就是勾股定理，勾三股四弦五，我们常常理解起来就是3^2+4^2=5^2这样一个等式而已。但实际上它揭示了3、4、5这三个数的联系，这是非常重要的。勾股定理我们知道，三角形的直角边的平方和等于斜边的平方，以前我们理解起来，就是这两个边能够求出第三边，其实这只是它价值很小的一部分，更重要的是这三个边之间的联系。我国古代赵爽给了一个很漂亮的证明，他把四个直角三角形拼起来得到一个大的正方形，里面包含一个小的正方形，比较一下面积就能够得到勾股定理的证明。这里你能感受到这个证明的清晰、干净、利落和巧妙，和一种美感。定义的本身也是非常简洁优美的，它的内涵是非常丰富的。 比方说我们应用这个定理，我们就知道，平面上以原点为圆心、半径为r的方程，它就是一个很漂亮的方程，x^2+y^2=r^2。关于它的蕴意的丰富，我们其实可以从这里提出很多的问题来，这些问题在中学就可以让老师告诉学生，但是一般老师好像并没有这样启发学生。比方说什么样的正整数能够成为直角三角形的边长？这样的问题有趣，但还不算太难。另一个问题，如果边长都是整数，它的直角三角形面积是不是也是整数？这也比较简单。到了第三个问题，你就会发现它是惊人的难，如果直角三角形的边长都是有理数，什么情况下它的面积是整数？我们可以举一个例子，3/2、20/3、41/6，它是一个直角三角形的三个边长，它的面积是5。看起来这个问题好像不太简单，这个问题其实已经有一千年的历史，是古埃及人提出来的。157就是这样一个整数，以157为面积的最简单的有理直角三角形的三个边长，大家可以看一下，分子分母都会有40多位。大家可能想不到这里面会有这么复杂的数据在这里头，你更想不到这个问题它会和BSD猜想联系在一起。BSD猜想到目前为止谁也没能够证明它，已有的结果离完全解决遥远得很，因为它是关于椭圆曲线的一个问题，也是克雷数学研究所几个千禧年的问题之一。换句话说如果你能够证明它，能拿到100万美元，也有着享誉全世界的学术声誉。 我们前面提到过，欧几里得的一个证明说素数有无穷多个。素数是一个数学的基本对象，里面神秘的东西非常的多。欧几里得证明同样干净利落，富有美感。假设这个结论不对，只有有限个素数，那我把这有限个素数乘起来再加1，那这个新的数M，前面N个素数都不会是它的因子。所以M的素因子就会和前面那n个素因子不一样，这是一个矛盾，所以素数有无穷多个，这个定理就非常完美的被证明，好像就没什么事情可以做了。但数学家他从来都不会这样考虑问题，就像庞加莱所说，“我们从来没有完全理解过一个问题，我们只是对这个问题理解的更深了一点、更多了一点。”素数看起来很容易明白，但可能是数学里面最神秘、最难以琢磨的一个对象。你会有很多问题接二连三的产生，比方说素数在自然数中间占有多大的比例？这个问题很难回答，你可以把它变得更容易琢磨一点，就1到N之间有多少个素数？这个问题到现在为止没有一个人能够回答。关于素数有无穷多个，后来欧拉有个更好的证明，欧拉的证明对数学产生了一个巨大的影响，包括产生了欧拉函数（Euler’ totient function）等等，今天我们不会有时间谈这些还有一个看上去非常简单的问题——哥德巴赫猜想，每个大于2的偶数都是两个素数的和，比方说6可以写成3+3，20可以写成13+7等等，但是谁也没有能够证明这个结果。到目前为止最好的结果还是四、五十年前我国数学家陈景润做的，他证明了“1+2”，它的含义就是充分大的偶数都能够写成一个数字加上另一个数，另一个数的素因子不超过两个。陈景润的这项工作随着徐迟的报告文献传遍我国大江南北，敬仰、爱慕的信件如雪片般的飞过来，这个盛况后来再也没有出现过。徐迟报告文献的副产品就是，大家都知道数学家连1+1都弄不清楚，原来1+1还是这么高深的数学曾有人和我说起陈景润的工作，他是完全从字面上来理解“1+2”的。我试图给他解释陈景润工作中“1+2”的含义，他听后斜看了我一眼，说我不懂。我当时无语，觉得做科普还是很不容易的，同时也发现人们是多么的执着于自己不合事实的理解，可能这和他的自尊心、心智安全感也是分不开的另一个看起来简单的问题就是卵生素数猜想，比如3和5，41和43，他们都是相差2的素数对。它的问题是，这样的素数对有没有无限多个？2013年华裔数学家张益唐在这个问题上取得巨大的突破，他证明了存在无穷多对素数，每一对素数的差都不超过7000万。张益唐结果哄动一时，他本人在逆境中也保持对理想追求的故事也是非常立志的，他感动了世界讲到数学美的时候我们还可以提一个例子，前面提到过根号2不是有理数，我们可以给一个很严格的证明。假设这个结论不正确，它是两个整数的比，x=a/b，我们可以要求分子分母没有公因子，那么去分母之后得到xb=a。然后做平方得到x^2b^2=a^2，从而就是2b^2=a^2，所以a肯定是偶数。然后再把2b^2=a^2代进去之后，会得到b也是偶数，这样就会有一个矛盾了，所以这个假设是错的，所以它必然是一个无理数。 我们在小学的时候都学过圆，也知道圆周率（π），大家都计算过圆周求面积等等，不过好像没有想过圆周率这个数是不是有理数或者无理数，这里反应一个问题就是我们提问题的能力是比较弱的。不知道大家注意到没有，很多的问题都是外国人提出来的，我们自己提的问题或者我们自己开创的理论是比较少的，这其实反应出来我们思维上的一个局限，愿意跟随而不愿意开创π这个数不仅是一个无理数，而且还是个非常无理的数，它是一个超越数。这个事情到1882年才由林德曼证明，他也证明了古希腊的画圆为方的问题是不可能的。 1.7 数学的形美我们前面谈的美基本上都是思维和逻辑的美，其实数学里面当然也不缺少形美，毕竟形是数学研究的对象，形里面充满了更为感知的美。这两个图像来自于极小曲面与分形几何，分形几何是研究海岸线发现的，后来成为一个很漂亮的应用数学分子，在细胞分裂的研究中也有应用。极小曲面很漂亮，也很有用。就如同他们证明正质量猜想的时候，极小曲面就是很关键的工具。 还有动力系统，动力系统大家知道跟浑沌是有关的，两个天体之间的运动轨迹通过万有引力就可以确定，但三体运动这个事情就变得比较复杂了，当时瑞典皇家科学院提出这个问题，要求把这个问题搞清楚。对这个问题庞加莱做了创新性的工作，他刚开始的论文获奖但有严重的错误，后来更正了。数学动力系统就从那里产生，他发现这个问题非常的不简单，存在多种情况。动力系统过去几年在数学里面是非常活跃的，好几位数学家因为动力系统的工作拿了菲尔兹奖，包括C.T.Mcmullen，包括两年前去世的一位女数学家米尔扎哈尼（Maryam Mirzakhani），这是目前唯一一位拿菲尔兹奖的女数学家，她也是C.T.Mcmullen的学生，是个伊朗人，很可惜。去世的还有一位数学家，就是弗拉基米德·福沃特斯基。动力系统在直观上来讲是非常简单的，一个微小的初始变幻，可以带来巨大的结果上的差别。在气象学里面有一个很形象的说法，在巴西雨林里面的一个蝴蝶抖一下翅膀，纽约可能就会下一场大雨。 右边这个图形是一个卡拉比丘流行，这应该是丘成桐最有名的工作，他证明了卡拉比猜想。卡拉比当时猜想有一类流行，丘成桐试图去证明这个猜想，后来他发现这个猜想可能是错的，就去证明这个猜想是错的，然后就在一个会上做报告。做完报告后，台下的听众觉得他讲的很有道理，所以也就对这个猜想不再关心了。卡拉比也正好在台下，听完报告回去后觉得哪个地方不太明白，就让丘成桐再解释一下。丘成桐当然要试图解释这个疑问，但是一个星期过去之后，好像没办法解释，两个星期过去了也没解释了，后来意识到他做错了。换句话说，丘成桐先生也有窘迫的时候。这其实告诉我们，每个人都有可能出错，包括伟大的数学家。很多老师可能在上课的时候都有卡住的情况，但“牛人”的做法一般人可能未必做得到，比方说大数学家希尔伯特在讲课的时候也会突然卡住愣在台上，他愣一下后会转过身来对学生说“啊！这显然的，你们自己去证吧！丘成桐意识到自己最初对卡拉比猜想工作有错误之后，他就朝另一个方向努力，再次证明这个猜想，过了三年终于把这个猜想证明了。因为这个工作和正质量猜想的工作，后来他拿了菲尔兹奖。他的这个工作的影响在数学里面是非常大的，丘成桐先生是几何分析这个方向一位非常重要的创始人。不但如此，这类流形在物理中间也非常重要，人们发现在弦的里面，正好需要这样一个空间，所以他在物理界里面也是名动江湖。 1.8 那些有个性的数学家数学家对美是非常有热情的，很多东西不美的话他不会追求。当然数学家也是一群有特殊天赋的人，他的个性也是多种多样的维纳，控制论的创始人，也是一位杰出的数学家，他在上世纪30年代访问过中国，对华罗庚非常欣赏。有一天他要搬家了，到一个新地方，可他对于这种事情不上心。（他的家人）老早就告诉他，当天还给了他一张新地址的纸条，让他这一天一定回到新的家里。但他回家的时候把纸条弄丢了，习惯地回到老地方，却发现家不见了。他看见一个女孩就问，“对不起，也许你认识我，我是诺伯特.韦纳，我们刚搬家，你知道我们搬到哪儿去了吗？”那女孩非常愉快的回答说“是的，爸爸，妈妈就知道你会忘记的”德林才气过人，因为证明了韦伊猜想获得了菲尔兹奖。他说，“能否做数学难题只是心理问题。”这颇有点“说我行，我就行；说我不行，我就不行”的味道。这个说法也呼应了一个广为流传的真假莫辩的故事。说某个很牛的大学里面，有一天也许因为天气不好，班上一位非常杰出的学生就迟到了。他到了一看课已经结束了，黑板上只留了一些题目，这位学生是非常优秀的学生，就当作课后作业拿回去做了。（做的过程中）他发现这些题挺难的，花了一个星期时间只做出来其中的六道，然后他就有点狼狈的拿给教授说“真是抱歉，这题目有点难，我只做出六道”。教授毫无疑问的感到震惊，“什么？你把这些给解决掉了？这些都是我们这个领域里面大家正在努力解决的难题！”这个学生感到非常吃惊。所以做数学有时候是个心理问题，你觉得它是个作业的话大概就能把它做出来，如果觉得它是个难题很可能就做不出来。有点糟糕的是这个学生后来再也没有做出更好的工作，他当了系主任之后这样说，“我们是这样选系主任的，谁不能做研究的话我们就选他当系主任。匈牙利数学家厄尔迪斯是有传奇色彩的，他无固定的居所，总在旅行，到一处就与那儿的数学家合作，所以合作的数量惊人。他认为“数学家就是把咖啡变成定理的装置。西格尔是第一届沃尔夫奖的得主，非常聪明，也很努力小平邦彦，杰出的日本数学家，他在上个世纪50年代就拿了菲尔兹奖，他常说自己天资不好，做事一丝不苟，全身心的投入，第一次学范德瓦尔登的《代数学》时什么也没看明白，看不明白怎么办？他就抄，一直抄到明白为止。我想有他这样的劲头的话，没有什么学不明白数学家经常犯错，我们刚才提到邱成桐先生也会犯错误。对这个犯错来讲，有些错误是好的，有些不太好。邱成桐犯的错误就是个好的错误，最后导致了问题的解决。一位数学家这样评价他的一位同事，“他犯了很多错误，但都是朝着好的方向犯的。我试着这样做，但发现犯好的错误是很困难的。开尔文，大家知道开氏温度，他是这样评价数学家的，他说，“数学家就是这样的人，他觉得下面这个公式是很显然的。”如果你也觉得这个公式显然的话呢，你们就会是数学家。他说刘维尔就是一个数学家。刘维尔还办了一个非常高水平的杂志，刘维尔杂志。 笛卡儿是数学家，也是哲学家。数学上他创立了《解析几何》，哲学上他提出“我思故我在”，引起人们对意识与存在的关系的一个审视。有一个传言，说他与瑞典公主克里斯蒂娜恋爱，文字传情会被皇室审查受阻，于是他就用了一个极坐标方程表达他的爱情。幸好那个女孩也是对数学非常明白的一个人，她把这个方程转化成一个心型，从而明白了笛卡儿的心意。这么说来数学不仅是描写大自然的语言，也是描写爱情的语言。 我说完了我的报告，谢谢大家！ 2. Q &amp; A 环节 问：学数学的出路何在、以后可以干什么、要是不转行一直留在数学专业的话有什么经验之谈？ 答：我想有迷茫是非常正常的，但其实在报告里面也讲到了，数学是现实的一个核心，把这个核心都掌握了的话，我想将来的出路是非常宽广的。你（现在）最重要的事情就是把数学学好，如果不转行一直留在数学这个专业里，根据自己的兴趣，如果愿意做研究就做研究，如果愿意做应用可以做应用，它的整个的就业前景是非常广泛的。其实过去很多年来，在美国，学数学的职业前景一直都是排在前十的，很多年都是排在第一位，数学的就业是不用担心的。更重要的是第一把自己的功课学好，第二找到自己的兴趣所在，是愿意做学术、还是愿意解决实际的问题等等。可以通过自己不断地探索，同时也可以跟老师探索、跟同学探索到底哪个地方自己真正有兴趣，探索清楚这样一件事情，我想方向也就明确了。 问：能否讲讲群环域这些代数结构的发展背景，并给一些学习上的建议？ 答：抽象代数的发展应是20世纪初，有一本比较好的数学史的书能够帮助你了解它的历史，就是克莱因写的《古今数学思想》。在学习中你要重视了解的是抽象与具体的联系，要知道群的产生跟解方程是密不可分的，它实际上是产生于一些很具体的对象。在数论里面也有很多群的概念，包括交换群，同于能够产生有限环等等。所以你一定要理解抽象与具体的联系，对每一个抽象的概念，包括重要的定理，应该尽可能的用很多具体的例子，来帮助你理解。一旦把抽象和具体的联系关系处理好，近世代数里面所有的抽象就变得内容丰富了，而通过具体的例子，也能够帮你了解、思考、提出问题以及把握中间的真正实质。 问：请问应该如何结合数学的意义，在数学教学中去发展学生对数学的学习兴趣呢？或者对数学教学进行优化？ 答：这应该是一个非常普遍的问题，不仅中国存在这个问题，世界上其他地方也存在这个问题。我想这并没有一般的灵丹妙药，数学里面有很多有趣的东西，必须针对具体学生的领悟程度等，通过适当的方式把它们展现出来。数学的一个特点是抽象，但它的抽象包含了很多实际的内容，用这些实际的内容来展示数学，比方说之前提到的数学的形美，可以通过画一个漂亮的椭圆来展示，就直观上让学生感受到很多有趣的东西，通过慢慢给他们这些直观的感受，使他们能感到有趣。我想经过努力，他们会感到数学是非常有意思的，并且愿意学下去，但是到底能学到哪一步还是因人而异的。 问：如何看待数学天赋，基本功与数学成果的关系？ 答：从这个（网友的）名字来看，他对Andrew wiles是非常敬仰的。那么其实Andrew wiles的故事就能够给他很多启发，首先Andrew wiles当然很有天赋，他在很小的时候，在童年的时候，对费马大定理就非常的有兴趣，所以兴趣和天赋对于数学来讲是需要的。但是Andrew wiles是非常努力的一个人，当他感到他能做出（某项研究）来的时候，就有几年的时间，其中就没有做过（其他）事情，其他的活动尽可能少的参与。没有一个很好的基本功要做很好的数学是不可能的一件事情。但是怎么样把基本功打好，这也并不是一件很容易的事情。除了自己努力学以外，很多东西必须要很好的老师给你指点，让你明白这个枯燥的东西背后的本质是什么。所以既要有天赋也要努力，再加上优秀的老师指点的话，最后取得优秀的数学成果是顺理成章的一件事情，水到渠成。 问：现在在上研究生，但感觉一直游离在数学的边缘，就像接触了一个物体，只知道这个物体重要，现实也很多地方用到它，却不知道内部是怎样的。如何才能真正进入到数学的领域？怎么样的状态才算是真正进入数学领域？ 答：我想这位同学这个感觉非常的好，他至少知道自己没有弄明白东西，这就给他一个提升的空间。如果他觉得弄明白的话，这可能是更糟糕的事情。既然觉得没弄明白，就表明他还可以继续努力。他需要把这个问题具体化，比方说觉得看书看不懂，哪里不懂必须要弄明白，必须要跟老师、跟别人来交谈。对于哪一本具体的书，哪个具体的问题不懂，如果仅仅是空泛谈不懂的话，是解决不了问题的。必须把这个问题落实到某个具体，一旦他在某个地方突破了这个障碍之后，我想他可能对整个数学的感受就完全不一样了。把一个让他最最苦恼不明白的一本书拿出来，这本书里面到底是哪个地方不明白，不明白在什么地方，（通过）仔细跟人讨论，把这个不明白的问题给明确下来。很多时候这就是个探索的过程，就像庞加莱说的：“其实我们从来就没弄明白过一件事情，只是我们不断的加深理解。”所以没有弄明白这个事情很正常，需要不断地探索，可以自己探索、看书、跟别人讨论，但一定要把自己在哪个地方不明白弄清楚，如果自己在哪个地方都不明白的话，那就说明你还要在搞清楚不明白哪个问题这件事情上花更多的时间。 问：学高等代数的时候是很久以前了，没有机会读“基础代数”，不过听说还没有第三卷，什么时候出版呀？高等代数没学好，所有东西用起来感觉都是镜里观花，很机械。怎样能把代数学好用好？ 答：第一个问题比较简单，第三卷已经送到出版社去了，应该在9月份左右(出版），我希望它9月份能够出来。那高等代数没有学好呢，有几个原因，第一个可能用的教材不够好，第二个可能老师教的不够好。他需要理解高等代数里面最本质的东西是什么，其实高等代数里面最重要的一点，它是从解方程这里发展起来的，表面上看起来通过消元法可以解出所有的方程，但事实上你发现变量的个数一大之后，这个办法肯定是不管用的。那在这个时候，对这个方程来讲它就有很多内在的结构，包括系数矩阵的秩，增广矩阵的秩等等，这个秩就反应这个方程可解不可解。还有你做消元法的时候，你发现是对它们系数作些运算，这里面产生向量空间，方程的关系实际就是向量之间的线性组合、线性关系、相关无关等等。还有就是矩阵，你抓住了线性方程以及相关的概念之后呢，你发现很多东西应该都是比较容易理解的，它的目的还是解方程。那么你发展的很多东西，反过来一方面是数学理论，拓展了这个空间，一方面它也对这个线性方程达到一个更深的理解。这个也是不断深入、不断交替的过程，已经有了线性空间之后，包括欧式空间里面，包括各种各样变换产生的群，就会变得更为丰富，应用更为广泛。这个欧式空间里面，这个距离，最后的话对无解的方程可以有最小二乘法等等，给出一个近似解。你发现通过解方程这样一个脉络下去理解高等代数的话，很多东西都会变得比较容易理解，不管是对方程也好，对理论也好，这个在我书里你多读几遍能够看得出来。]]></content>
      <categories>
        <category>数学</category>
        <category>学科理解</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[给基础数学本科新生的选课建议]]></title>
    <url>%2F2021%2F01%2F27%2F%E7%BB%99%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E6%9C%AC%E7%A7%91%E6%96%B0%E7%94%9F%E7%9A%84%E9%80%89%E8%AF%BE%E5%BB%BA%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[大家好，我是来自清华大学数学系的准大四学生。学了三年现代数学，我想把自己的一些感悟记录下来。回头看这三年，觉得走了很多弯路、做了很多意义不大的事情，想来是跟学长、老师们的深层次沟通少了，所以想用剖析自己的经历、优缺点的方式，向大家展示一个天分普通的学生的本科学习历程，希望后来人能够更好地利用这三年时间。 一、指导思想：广度优先为什么我是大三结束的时候来写这篇建议呢，因为到了大四大家已经要开始准备自己那一个小方向的毕业论文了，前三年才是基础数学的基础性学习阶段。老师们都说，在本科时候要多学点东西；丘成桐先生也经常说，数学家至少要精通两个方向，才有可能发现不同方向的联系，才能做出大成就。“发现不同学科的联系”是我逐渐领悟到的努力目标，其本质是更好地理解数学，同时也是把冗余的东西缩并起来，化归到自己原有的知识体系中。所以这篇建议的（来源于我的）局限性在于“广度优先”的指导思想，我还不能理解很多同学（他们往往都是天赋异禀的）很早就瞄着代数几何或者代数拓扑或者分析一直往深处学的这种行为，我也尝试过拿起一本书从头学到尾，但是往往会被突然出现的新概念所挫败，非常不理解研究它的动机，从而再往深学就成了某种机械性地强迫性行为（但我想，他们肯定是看破了这种动机）。另一个局限性就是，我分析学得不好。我大一至大三，三年时间共修了31门数学课： 分析类：数学分析(1)、数学分析(2)、数学分析(3)、实分析、复分析(1)、复分析(2)、泛函分析、常微分方程、偏微分方程(1)、偏微分方程(2)、分析力学、概率论 几何类：微分流形、拓扑学、微分拓扑、代数拓扑、微分几何、黎曼几何、黎曼曲面、复几何 代数类：线性代数(1)、线性代数(2)、代数学前沿基础、抽象代数(1)、抽象代数(2)、代数数论(1)、代数数论(2)、代数几何(1)、代数几何(2)、李群李代数、群表示论 修习的时间顺序为： 大一上：数学分析(1)，线性代数(1) 大一下：数学分析(2)，线性代数(2)，复分析(1)，代数学前沿基础 大二上：数学分析(3)，常微分方程，拓扑学，抽象代数(1) 大二下：实分析，分析力学，概率论，微分拓扑，代数数论(1)，黎曼曲面 大三上：泛函分析，偏微分方程(2)，微分流形，代数数论(2)，微分几何，代数几何(1)，李群李代数，抽象代数(2)，复分析(2) 大三下：偏微分方程(1)，黎曼几何，复几何，代数拓扑，群表示论，代数几何(2) （估计不少人会惊讶于我选课之多，这其实是一把双刃剑）（非本校的同学欲知课程大纲可以参看附录） 二、最基本的语言：数分、线代、抽代、拓扑、流形我们一入学就会听老师说数分和线代是你学其他一切数学的基础，我想这句话中的“一切数学”必定包括了概率、统计与应用，但如果局限在基础数学上的话，必定要加上抽代和拓扑。大一的时候，老师叫我们不要选更多课了，专心学好数分和线代，作为刚入学的新生怀着对未知事物的敬畏，我也就只选了数分和线代。现在看来，老师的话对于大部分同学来说是对的，因为很多同学不适应这种与高考数学截然不同的思维方式，很多人甚至没能在期中考试中及格；但很幸运的是我上手很快，可能是因为我高中的时候就已经看了半本卓里奇。由于只选了两门课，课后的时间就拿来做卓里奇的习题。现在看来，尽管卓里奇的习题很多都是今后可能会学的数值分析、大学物理里面的内容，但是所产生的作用也就只有习题的作用。我花费了大量的时间在上面，经常花整个半天在一道题目上，不是说这样不好，而是有更好的替代方案，可以用这些时间去学抽代和拓扑。我后来知道，王志涵学长还有七字班的三位学弟都是在大一一入学就修习了拓扑。学了抽象代数，相当于打开了代数类的大门；学了拓扑学和微分流形，相当于打开了几何类的大门。抽象代数：我是寒假自学了姚慕生的《抽象代数学》和Artin的《代数》(Algebra)，学一遍是学不懂的而且会容易忘，于是我在大一之后的暑假花了两个星期看了Rotman的《群论导论》(An Introduction to the Theory of Groups)的前几章，并把习题都做了（基础性的课程就是得认认真真地从头啃到尾）。那时我感觉我的抽代中的群论部分已经没有问题了，于是大二上开设的抽象代数课我一节都没有去听过，考试只花了一半的时间就拿了满分。但学得好不好跟考试成绩的关系不大。尽管我把姚慕生《抽象代数学》（这是我们的教材）看了三遍以上，自认为群论和环论掌握得不错，但是Galois理论却没学懂。徐凯学长也说，他当初学Galois理论的时候也碰到了困难，他推荐给我Hungerford的《代数》(Algebra)。Hungerford事无巨细，把建立Galois理论的过程写得清清楚楚。但这容易使我们陷入一个误区，就是只知道证明Galois理论，而不会使用它。学一遍是学不会的，所有的东西都还要再去学成人版。三年以来，我把Hungerford的域论一章看了至少三遍，Galois理论前前后后也学了至少三遍，关键在于，我不只是重新再看Hungerford这一本书，而是在学习抽象代数2、代数数论的时候，有了应用Galois理论的地方，等到要用Galois理论的地方，再回头来学第二遍、第三遍，才能学得更好。今年在丘赛讨论班上，基于对各种概念的熟悉，我用一张A4纸大小的笔记就建立起了Galois理论，这就是所谓的成人版，也是华罗庚先生说的，把书读厚了，再把书读薄。拓扑学：我大二上才学的拓扑。老师讲课风格很飘逸，许多东西不给严谨的证明，而我课后也学得不认真，经常是一节课没听懂，课后又不去复习，一拖好几周，就会觉得这门课程越来越难，而最后期末复习的时候，梳理完所有知识，又觉得这门课没讲多少东西。但这样的学习习惯终究是不好的，把自己不懂的东西拖得太久，想来我有很多门课程都是以这种学习态度对待的，尽管靠着期末复习能够拿到很高的分数，但是事实上学过的东西过了一个学期就基本忘光了。跟于品教授聊天的时候，他说：你把东西忘光了，就是没有学会。于品老师是做偏微分方程的，但是他本科学的代数几何都还没忘，做起题目来游刃有余。所以我想，每周把新学的东西复习一下，就会大大增加学会的可能。微分流形：数学分析的时候也讲流形，讲欧式空间里的曲面，但是欧式空间里的坐标所能成为的角色太多了，我学的时候经常混淆概念。如果这个时候去学一般性的微分流形理论，就会把这些概念理的特别清楚。我是用Tu的《流形导论》(An Introduction to Manifolds)入门的。只用看前几章，学会流形等相关概念就行。流形是把几何对象抽象出来的概念，是最最基本的研究对象，几乎所有的几何课都要拿几节课的时间来科普流形的定义，我记得我大二下上黎曼几何、黎曼曲面、微分拓扑的时候，三门课同时讲微分流形，听得都腻了。 三、启发性的直观：黎曼曲面、微分拓扑、微分几何我们经常会看到书上极其突兀地引入新概念，找寻定义这种新概念的缘由，就得用历史的观点去看它的形成历史。我总相信，数学家的大脑不是神的大脑，是可以被理解的，所有想法必定有根源，是从当时的环境中孕育出来的。周坚教授说：复分析联系着所有的现代数学，所有的现代数学都是从复分析里诞生的。黎曼曲面：学了复分析之后，就可以学黎曼曲面。黎曼曲面就是复分析解析延拓而来的——解析延拓，就孕育出了“层”的概念，以及它跟基本群的联系，比如沿着两条路径做函数的解析延拓，延拓出来的值是否相同呢？如果着两条路径可以连续地变化到对方，那么延拓的值就是一样的。研究黎曼曲面上的亚纯函数，可以建立黎曼曲面与函数域的一一对应，这是把几何与代数联系起来。代数数论中的概念，比如素理想的分解，就可以用几何的眼光来看待。我们也可以把它们推广到代数几何里。所以当你学代数几何里的finite morphism时，知道它的几何来源，会对你接受代数几何的理论有很大的帮助。研究黎曼曲面上的微积分，来证明Riemann-Roch定理，这是对偏微分方程的应用，也是Hodge理论的伊始。微分拓扑：除了三角剖分所引出的单纯同调之外，de Rham上同调应该是同调理论最直观的例子了。同调群有太多太多看法了，站在微分形式的角度就是在看这个方程（当然这个说法不太妙，因为类似地也可以说复分析就是在研究Cauchy-Riemann方程组）。de Rham上同调里，积分这个操作带来了Poincare对偶。而有些同学是先在代数拓扑里，用奇异上同调学的Poincare对偶，虽然在代数上做法很自然，但是如果先有了de Rham上同调的背景，理解一般系数的同调的操作，就会好很多。要想构造定义在整个流形上的东西，Cech上同调又会自然地出现，与之相伴的，还有谱序列。总之，几何是自然给我们人类的直观体验，在几何里发现好的数学，再做推广，要比闷头闷脑地把一般理论硬学下来舒服得多。微分几何：李海中教授说：微分几何的口诀就是，用微积分的办法研究曲线曲面论。我看微分几何就只有一条：研究流形的弯曲。微分几何是一门比较古典的课程，但只有学了微分几何之后，才不会觉得黎曼几何里定义曲率张量很人为。Cartan和陈省身在微分几何里发展了活动标架法，复几何里同样有关于向量丛上联络的计算，要理解它们，或者说理解“张量”这个概念是一个难点。尽管线代里讲了张量，微分流形里也讲了张量，但是一旦在微分几何或者复几何里用起来，尤其是在物理学家那里用起来的时候，你会发现很难理解他们在干的是同一件事情（用坐标分量、用张量的语言、用活动标架法），所以可以死皮赖脸的要学长给你讲清楚，如果他讲不清楚，那你就知道他也没学会这个东西。 四、大一统的理论：代数拓扑、代数几何我觉得很多人会觉得我把代数拓扑和代数几何这两门课写成“大一统的理论”像是一个民科干出来的事情，我这里“大一统”是站在前面几何的角度上说的。代数拓扑把几何里的一些代数操作抽象出来，把 系数变成 系数，所有的事情都往universal的方向上走。代数几何也是一样，尽管我们经常说他是研究多项式的零点，这听起来像是高中解析几何，但实际上，上世纪五六十年代发展出来的概形的概念是把复几何里的代数操作抽象出来。代数几何里遇到的层的上同调可以统一很多常见的上同调理论，在拓扑里学的常系数的上同调、或者群的上同调，这些都可以用层的语言来表述。范畴论的观点是对数学的一次革命。六字班学弟吴雨宸就特别喜欢将一切东西范畴化。这样一来，几百年来数学各领域的诸多概念就可以被结构性的观点缩并起来。私以为“范畴化”这件事有改写数学史的可能。但对于我这种普通天赋的人来说，代数几何和代数拓扑是不好学的。大二的时候，我尝试过自己去看Hartshorne的《代数几何》(Algebraic Geometry)，但是无法掌握整体的框架，也对那些省去很多细节的证明望而却步。徐凯学长推荐我看扶磊教授的《代数几何》(Algebraic Geometry)，但是一个接一个的命题堆蹙在一起，我一点儿也不知道代数几何是想干嘛。不过现在看来，这些书都是在建立代数几何的最最基本的语言，所以显得像字典一样。但我代数几何学的还太少了，不敢再多说其他话了。（如果想获取更多关于代数几何的建议，建议还是问其他的学长吧！）这学期上了孙晟昊老师的代数几何2这门课，孙晟昊老师将Hartshorne第二三章中的细节完全补上，像对待代数小白一样教我们，甚至比扶磊老师的书还要耐心，那时我才知道原来那些半页纸不到的证明省去了多少不便写在书本上的细节。一学期学下来，也仅仅是知道了概形、层的上同调的概念，老师说，这虽然是代数几何课的结束，却仅仅是代数几何的开始，我也不知道接下来该往哪儿走。代数拓扑也很类似，我同很多人一样，先学奇异同调。但除了会用长正合列之外，同调理论的证明、架构对于我而言都是一片模糊的，换句话说，也是被字典一样的书给看蒙了。最开始，我用长正合列，是不看每个箭头的映射到底是怎么给出来的，后来才发现如果讲同构而不去讲同构是怎么给出来的话，很多几何信息就被抛弃了。从Whitehead定理和Hurewicz定理中就可见一斑，如果有单连通CW复形之间的连续映射f诱导了整系数同调之间的同构，那么f是同伦等价，而这个同构f就是至关重要的，因为有很多同调群一样但两个空间不同伦等价的例子。这个学期周坚教授要我去看Bott-Tu的《代数拓扑中的微分形式》(Differential Forms in Algebraic Topology)，虽然这本书王志涵学长从我大一开始就一直推荐我去读，但是由于我大一大二时候数学成熟度不高，同调理论不熟悉，也没有人来点拨，导致我连一本写得这么平易近人的教材都读不下去。但这学期经过一年多的同调理论的熏陶之后，总算能把这本书读下去了。前几天在准备丘赛的时候，于品教授就教我们用成人的眼光，或者说用真正的理解，来看de Rham上同调。虽然此前我那些Poincare对偶相关的定理都背的很熟了，因为我看出来了它就是一个积分操作诱导的对偶，而积分这个运算可以做，就需要那些冗长的条件，但是却不知道Poincare对偶有什么用。于品老师带着我们做题，他教我们用Poincare对偶来计算上同调环，微分形式的外积就对应着子流形的相交。我顿时豁然开朗！虽然此前这些结论我都知道而且会证，但就是还有那一层窗户纸没被点破。我也回想起来，这学期周坚教授开的复几何课上，周坚老师用Lefshchetz超平面相交理论来讲复几何，那时因为学习态度不认真还没理解为什么周坚说这才叫几何，现在看来就都是Poincare对偶啊！ 五、辅助性的工具：同调代数、交换代数经过大一上只选了两门课的空闲之后，我大一下选了代数学前沿基础这门课，它是讲模论、范畴论和同调代数的。对那时只是自学过抽象代数的我来说，在后半学期跟上这门课非常困难，倒不是说内容很困难——都是最基本的范畴论、同调代数，而是缺乏学习的动机，老师有的时候说的pull-back方格是fiber bundle之类的话，我就完全不知道。最后一学期下来，就感觉像在地图上一片黑暗中亮起了一个孤零零的小块，随着时间的推移，我就忘得一干二净。交换代数也是一样，因为学长们说学代数几何要先知道交换代数，而我进入大二之后，抽象代数又学了很多，所以就又开始自己看Atiyah和Macdonald的《交换代数导引》(Introduction to Commutative Algebra)。可以说是看一遍忘一遍，就跟我的实分析、复分析还有概率论一样，没有去使用它们，笨笨的脑子就记不住它们。所以我现在对于这种工具类的科目，倾向于有目的性的学习，而不是一鼓作气看一整本书的系统性学习。要用到的时候，就去看对应的章节；等到掌握得都差不多的时候，再可以考虑从头看一遍，梳理整体的知识。而且大家都说看代数几何要先看交换代数，但实际上在我们学校两门代数几何课上，老师会帮忙补一点交换代数的知识，并且课上只是偶尔会用到交换代数，所以我觉得我校的同学完全可以先学代数几何，边学边补对应的交换代数。毕竟数学得学得开心，逼自己去看字典，如果不顺心的话，就别看了。 六、数学的皇后：代数数论我最开始接触数论是大二下学期上扶磊老师的代数数论1，但扶磊老师第一次在清华教本科生数论课，所以只讲了素数定理的证明以及赋值理论，关于代数整数环、素理想涉及甚少。所以为了丘赛，我又去自学了冯克勤的《代数数论》的第一部分，这一部分比扶磊老师讲得古典很多，但是丘赛特别喜欢考，其实也是非常重要，因为代数数论发展之初就是在看素数在更大的数域里是如何分解的。徐凯学长推荐我看Neukirch的《代数数论》(Algebraic Number Theory) 的前两章，但我根本无法理解Neukirch的证明中的代数细节，觉得高深莫测，现在看来确实是交换代数的成熟度不够高，有些代数操作不能理解，应该要找学长或者老师好好扣扣细节，就会进步很大的。大三上学期我学了陈宗彬老师的代数数论2，陈宗彬老师北大出身，思维极快，一学期的代数数论涵盖局部域、高阶分歧群、类域论、Tate thesis的完整理论。我上课完全跟不上，只能抄笔记，陈老师省略的细节也特别多，最后班上只剩下五个人。最遗憾的就是我课后没有去及时补上来，我那学期选了十门数学课，很多课都是课后没有管，也就导致没有学懂。我还是觉得一学期最多选四门数学课，这样课后才有钻研的时间。上课没能掌握，寒假就自己看了一遍Serre的《局部域》(Local Fields) 和Serge Lang的《代数数论》 (Algebraic Number Theory) ，才总算有点感觉。后来于品老师说：你不懂就去问他，我说：感觉自己的问题会太简单了，或者说到处都是问题，于品说：那你就叫他重新讲一遍！确实，感觉自己问问题的能力差了好多，很多问题自己想不清楚，可是也不想去问老师知道答案。这种不求甚解的风格可能来源于我们高中数学竞赛只做题而不公布题目的答案的做法，还是不太好的。我大三上还跟着陈宗彬老师、张志宇学长等人参加了 上的local Langlands对应讨论班，但除了我最开始讲的 的表示之外，其他的我全都没能听懂。越是难的东西就越应该多花时间，我不该在选了九门数学课的情况下还参加这个讨论班的。在我大三这年，清华数学系开始了一项新计划：数学学堂班基础科研训练计划(Junior Thesis)。我选的是陈宗彬老师的“带复乘椭圆曲线的算术”(Arithmetic of Elliptic Curves with Complex Multiplication）。我利用寒假时间把Silverman的《椭圆曲线上的算术》(The Arithmetic of Elliptic Curves)给抄了一遍，Silverman的讲法不需要知道代数几何，对于我来说非常友好。进入大三下学期后，我开始看Silverman的第二本书《椭圆曲线算术的高等论题》(Advanced Topics in the Arithmetic of Elliptic Curves)的第二章：复乘理论。但是我发现第二本书对椭圆曲线的熟悉高了很多，我不得不重新把第一本书从头再看一遍，边看边敲latex，这样就逼着我搞明白证明的每一步，虽然是个傻办法，但总比一目十行地看书却吸收不了好多了，因为学东西是需要时间的。等我敲了70页latex后，我就已经体会到复乘理论的深刻之处了。但是我想，如果我到时候junior thesis答辩的时候只讲这个复乘理论会不会太简单了，毕竟什么论文都没看，气势上输给学弟可不好啊！所以我开始看Coates和Wiles在1977年证明带复乘椭圆曲线上的弱BSD猜想的特殊情况。确实原始论文太难读了，我找到Karl Rubin在1995年写的一篇note，于是开始啃，开始同时结合十几篇论文一起啃。这些论文对椭圆曲线的掌握要求得太高了，非常难读。一度想过只想讲复乘理论，但是最后陈宗彬给我规划答辩内容的时候，叫我验证一条特殊的椭圆曲线上的BSD猜想。我就在想，如果我连这条特殊的椭圆曲线上的BSD猜想都验证不完的话，那我可真没东西可讲了。于是我在答辩前三周日以继夜地攻读那些论文，把所有他们推广得以致于表述极其复杂的定理全都限制到我这条特殊的椭圆曲线上。事情慢慢就开朗起来了，很多为了推广而作的技术性操作都变为平凡，而我就能抓住最主要的思想——那就是Birch和Swinnerton-Dyer在五十年代的那篇论文中做的计算——我也总算理解了为什么陈宗彬老师说BSD猜想是算出来的了。反过来，知道最主要的部分后，那些技术性推广也变得可理解了。最后6月10号那天，我做了一个非常满意的报告，介绍了那条特殊的椭圆曲线上BSD猜想该怎么证，尽管在场的人几乎都没能跟着听完全程。 七、准备丘赛近年来全国各大高校越来越重视丘赛，诚然丘赛的结果对于各所学校来说非常重要，但是对于我们学生来说，准备丘赛的过程才是最重要的。正如丘成桐先生在丘赛颁奖典礼上一直说的，之前我们的学生去到美国高校考不过他们的qualify，这个丘赛就是要训练学生们的基本功。我也一直认为，像我们这种天赋一般的同学学一遍东西是学不懂的，要做题、要梳理出成人版的知识脉络，才有可能学懂。刚进入大学那会儿，高中竞赛刚结束，解题思维很活跃，卓里奇上几乎就没有做不出来的题目。但是随着开始习惯于应付大学的数学作业，别人问题目也不想去认真考虑，解题能力大大下降，脑子变迟钝很多。大二丘赛失利后，我开始做丘赛往年的真题，能够切实地感觉到自己的注意力越来越集中、思维越来越快。所以学弟学妹们千万别抗拒这种应试的东西，它不像高考数学，它的题目可活了呢！ 八、修习顺序建议我对倾向于代数或几何的普通同学有如下的建议（这是接近现代数学的最基本的脉络）： 大一：数学分析、线性代数、抽象代数、拓扑+自学流形的相关概念 大二：复分析、黎曼曲面、微分拓扑+Bott Tu的《代数拓扑中的微分形式》 大三：复几何、代数拓扑、代数几何 夸张点说，这应当是每个想学基础数学的同学必须要掌握的东西。 九、附录：课程大纲 分析类： 数学分析(1)：实数理论、极限、单变量微积分 数学分析(2)：多变量微积分、曲面上的积分 数学分析(3)：级数理论、傅立叶分析 实分析：测度论和Lebesgue积分 复分析(1)：最基本的复分析 复分析(2)：每年内容不一定，可能会讲有理函数的迭代问题、双曲度量 泛函分析：最基本的泛函分析 常微分方程：存在性、唯一性、延拓定理 偏微分方程(1)：波方程、热方程、泊松方程的存在唯一性 偏微分方程(2)：椭圆方程、双曲方程、抛物方程的存在唯一正则性 分析力学：Lagrange力学以及一些玄学 概率论：最基本的概率论 几何类： 微分流形：流形的概念以及流形上常见的研究对象 拓扑学：点集拓扑、基本群、复叠空间、同调理论 微分拓扑：流形的横截相交、逼近，Stokes定理，Poincare-Hopf定理 代数拓扑：同伦论、同调论 微分几何：曲线曲面论 黎曼几何：最基本的黎曼几何 黎曼曲面：黎曼曲面的几何与代数部分 复几何：复流形的上同调、Hodge理论 代数类： 线性代数(1)：矩阵与行列式 线性代数(2)：矩阵的对角化 代数学前沿基础：模论、范畴论、同调代数 抽象代数(1)：基本的群环域 抽象代数(2)：Galois理论，可能还会讲有限群的线性表示 代数数论(1)：赋值理论，素数定理 代数数论(2)：每年不一定 代数几何(1)：古典的variety 代数几何(2)：概形与层的上同调 李群李代数：复半单李代数的表示论 群表示论：有限群的复表示、模表示]]></content>
      <categories>
        <category>数学</category>
        <category>学习指导</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MIT牛人对数学在机器学习中的作用给的评述]]></title>
    <url>%2F2020%2F12%2F01%2FMIT%E7%89%9B%E4%BA%BA%E5%AF%B9%E6%95%B0%E5%AD%A6%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8%E7%BB%99%E7%9A%84%E8%AF%84%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[感觉数学似乎总是不够的。这些日子为了解决research中的一些问题，又在图书馆捧起了数学的教科书。从大学到现在，课堂上学的和自学的数学其实不算少了，可是在研究的过程中总是发现需要补充新的数学知识。Learning和Vision都是很多种数学的交汇场。看着不同的理论体系的交汇，对于一个researcher来说，往往是非常exciting的enjoyable的事情。不过，这也代表着要充分了解这个领域并且取得有意义的进展是很艰苦的。记得在两年前的一次blog里面，提到过和learning有关的数学。今天看来，我对于数学在这个领域的作用有了新的思考。 1、线性代数与统计学对于Learning的研究，Linear Algebra（线性代数）和 Statistics（统计学）是最重要和不可缺少的。这代表了Machine Learning中最主流的两大类方法的基础： 一种是以研究函数和变换为重点的代数方法，比如Dimension reduction，feature extraction，Kernel等； 一种是以研究统计模型和样本分布为重点的统计方法，比如Graphical model, Information theoretical models等； 它们侧重虽有不同，但是常常是共同使用的，对于代数方法，往往需要统计上的解释，对于统计模型，其具体计算则需要代数的帮助。以代数和统计为出发点，继续往深处走，我们会发现需要更多的数学。 2、微积分Calculus（微积分），是数学分析体系的基础，其重要性用不言而喻。Learning研究的大部分问题是在连续的度量空间进行的，无论代数还是统计，在研究优化问题的时候，对一个映射的微分或者梯度的分析总是不可避免。而在统计学中，Marginalization和积分更是密不可分——不过，以解析形式把积分导出来的情况则不多见。 3、偏微分方程Partial Differential Equation（偏微分方程），这主要用于描述动态过程，或者仿动态过程。这个学科在Vision中用得比Learning多，主要用于描述连续场的运动或者扩散过程。比如Level set, Optical flow都是这方面的典型例子。 4、泛函分析Functional Analysis（泛函分析），通俗地，可以理解为微积分从有限维空间到无限维空间的拓展——当然了，它实际上远不止于此。在这个地方，函数以及其所作用的对象之间存在的对偶关系扮演了非常重要的角色。Learning发展至今，也在向无限维延伸——从研究有限维向量的问题到以无限维的函数为研究对象。Kernel Learning 和 Gaussian Process 是其中典型的例子——其中的核心概念都是Kernel。很多做Learning的人把Kernel简单理解为Kernel trick的运用，这就把kernel的意义严重弱化了。在泛函里面，Kernel (Inner Product) 是建立整个博大的代数体系的根本，从metric, transform到spectrum都根源于此。 5、测度理论Measure Theory（测度理论），这是和实分析关系非常密切的学科。但是测度理论并不限于此。从某种意义上说，Real Analysis可以从Lebesgue Measure（勒贝格测度）推演，不过其实还有很多别的测度体系——概率本身就是一种测度。测度理论对于Learning的意义是根本的，现代统计学整个就是建立在测度理论的基础之上——虽然初级的概率论教科书一般不这样引入。在看一些统计方面的文章的时候，你可能会发现，它们会把统计的公式改用测度来表达，这样做有两个好处：所有的推导和结论不用分别给连续分布和离散分布各自写一遍了，这两种东西都可以用同一的测度形式表达：连续分布的积分基于 Lebesgue测度，离散分布的求和基于计数测度，而且还能推广到那种既不连续又不离散的分布中去（这种东西不是数学家的游戏，而是已经在实用的东西，在Dirchlet Process或者Pitman-Yor Process里面会经常看到)。而且，即使是连续积分，如果不是在欧氏空间进行，而是在更一般的拓扑空间（比如微分流形或者变换群），那么传统的黎曼积分（就是大学一年级在微积分课学的那种）就不work了，你可能需要它们的一些推广，比如Haar Measure或者Lebesgue-Stieltjes积分。 6、拓扑学Topology（拓扑学），这是学术中很基础的学科。它一般不直接提供方法，但是它的很多概念和定理是其它数学分支的基石。看很多别的数学的时候，你会经常接触这样一些概念：Open set / Closed set，set basis，Hausdauf, continuous function，metric space, Cauchy sequence, neighborhood, compactness, connectivity。很多这些也许在大学一年级就学习过一些，当时是基于极限的概念获得的。如果，看过拓扑学之后，对这些概念的认识会有根本性的拓展。比如，连续函数，当时是由epison法定义的，就是无论取多小的正数epsilon，都存在xxx，使得xxx。这是需要一种metric去度量距离的，在general topology里面，对于连续函数的定义连坐标和距离都不需要——如果一个映射使得开集的原像是开集，它就是连续的——至于开集是基于集合论定义的，不是通常的开区间的意思。这只是最简单的例子。当然，我们研究learning也许不需要深究这些数学概念背后的公理体系，但是，打破原来定义的概念的局限在很多问题上是必须的——尤其是当你研究的东西它不是在欧氏空间里面的时候——正交矩阵，变换群，流形，概率分布的空间，都属于此。 7、微分流形Differential Manifold（微分流形），通俗地说它研究的是平滑的曲面。一个直接的印象是它是不是可以用来fitting一个surface什么的——当然这算是一种应用，但是这是非常初步的。本质上说，微分流形研究的是平滑的拓扑结构。一个空间构成微分流形的基本要素是局部平滑：从拓扑学来理解，就是它的任意局部都同胚于欧氏空间，从解析的角度来看，就是相容的局部坐标系统。当然，在全局上，它不要求和欧氏空间同胚。它除了可以用于刻画集合上的平滑曲面外，更重要的意义在于，它可以用于研究很多重要的集合。一个n-维线性空间的全部k-维子空间(k &lt; n)就构成了一个微分流形——著名的Grassman Manifold。所有的标准正交阵也构成一个流形。一个变换群作用于一个空间形成的轨迹(Orbit) 也是通常会形成流形。在流形上，各种的分析方法，比如映射，微分，积分都被移植过来了。前一两年在Learning里面火了好长时间的Manifold Learning其实只是研究了这个分支的其中一个概念的应用: embedding。其实，它还有很多可以发掘的空间。 8、李群论Lie Group Theory（李群论），一般意义的群论在Learning中被运用的不是很多，群论在Learning中用得较多的是它的一个重要方向Lie group。定义在平滑流行上的群，并且其群运算是平滑的话，那么这就叫李群。因为Learning和编码不同，更多关注的是连续空间，因为Lie group在各种群中对于Learning特别重要。各种子空间，线性变换，非奇异矩阵都基于通常意义的矩阵乘法构成李群。在李群中的映射，变换，度量，划分等等都对于Learning中代数方法的研究有重要指导意义。 9、图论Graph Theory（图论），由于它在表述各种关系的强大能力以及优雅的理论，高效的算法，越来越受到Learning领域的欢迎。经典图论，在 Learning中的一个最重要应用就是graphical models了，它被成功运用于分析统计网络的结构和规划统计推断的流程。Graphical model所取得的成功，图论可谓功不可没。在Vision里面，maxflow (graphcut)算法在图像分割，Stereo还有各种能量优化中也广受应用。另外一个重要的图论分支就是Algebraic graph theory (代数图论)，主要运用于图的谱分析，著名的应用包括Normalized Cut和Spectral Clustering。近年来在semi-supervised learning中受到特别关注。]]></content>
      <categories>
        <category>数学</category>
        <category>学科应用</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[陶哲轩谈什么是好的数学]]></title>
    <url>%2F2020%2F09%2F16%2F%E9%99%B6%E5%93%B2%E8%BD%A9%E8%B0%88%E4%BB%80%E4%B9%88%E6%98%AF%E5%A5%BD%E7%9A%84%E6%95%B0%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[我们都认为数学家应该努力创造好数学。但“好数学”该如何定义？甚至是否该斗胆试图加以定义呢？让我们先考虑前一个问题。我们几乎立刻能够意识到有许多不同种类的数学都可以被称为是“好”的。比方说，“好数学”可以指（不分先后顺序）： 好的数学题解（比如在一个重要数学问题上的重大突破）； 好的数学技巧（比如对现有方法的精湛运用，或开发新的工具）； 好的数学理论（比如系统性地统一或推广一系列现有结果的概念框架或符号选择）； 好的数学洞察（比如一个重要的概念简化，或对一个统一的原理、启示、模拟或主题的实现）； 好的数学发现（比如对一个出人意料、引人入胜的新的数学现象、关联或反例的揭示）； 好的数学应用（比如应用于物理、工程、计算机科学、统计等领域的重要问题，或将一个数学领域的结果应用于另一个数学领域）； 好的数学展示（比如对新近数学课题的详尽而广博的概览，或一个清晰而动机合理的论证）； 好的数学教学（比如能让他人更有效地学习及研究数学的讲义或写作风格，或对数学教育的贡献）； 好的数学远见（比如富有成效的长远计划或猜想）； 好的数学品位（比如自身有趣且对重要课题、主题或问题有影响的研究目标）； 好的数学公关（比如向非数学家或另一个领域的数学家有效地展示数学成就）； 好的元数学（比如数学基础、哲学、历史、学识或实践方面的进展）； 严密的数学（所有细节都正确、细致而完整地给出）； 美丽的数学（比如拉马努金的那些令人惊奇的恒等式；陈述简单漂亮、证明却很困难的结果）； 优美的数学（比如保罗·厄多斯的“来自天书的证明”观念通过最少的努力得到困难的结果）； 创造性的数学（比如本质上新颖的原创技巧、观点或各类结果）； 有用的数学（比如会在某个领域的未来工作中被反复用到的引理或方法）； 强有力的数学（比如与一个已知反例相匹配的敏锐的结果，或从一个看起来很弱的假设推出一个强得出乎意料的结论）； 深刻的数学（比如一个明显非平凡的结果，比如理解一个无法用更初等的方法接近的微妙现象）； 直观的数学（比如一个自然的、容易形象化的论证）； 明确的数学（比如对某一类型的所有客体的分类；对一个数学课题的结论）； 如上所述，数学的质量这一概念是一个高维的概念，并且不存在显而易见的标准排序。我相信这是由于数学本身就是复杂和高维的，并且会以一种自我调整及难以预料的方式而演化；上述每种质量都代表了我们作为一个群体增进对数学的理解及运用的一种不同方式。至于上述质量的相对重要性或权重，看来并无普遍的共识。这部分地是由于技术上的考虑——一个特定时期的某个数学领域的发展也许更易于接纳一种特殊的方法；部分也是由于文化上的考虑——任何一个特定的数学领域或学派都倾向于吸引具有相似思维、喜爱相似方法的数学家。这同时也反映了数学能力的多样性：不同的数学家往往擅长不同的风格，因而适应不同类型的数学挑战。我相信“好数学”的这种多样性和差异性对于整个数学来说是非常健康的，因为这允许我们在追求更多的数学进展及更好的理解数学这一共同目标上采取许多不同的方法，并开发许多不同的数学天赋。虽然上述每种质量都被普遍接受为是数学所需要的质量，但以牺牲其他所有质量为代价来单独追求其中一两种却有可能变成对一个领域的危害。考虑下列假想的（有点夸张的）情形：一个领域变得越来越华丽怪异，在其中各种单独的结果为推广而推广，为精致而精致，而整个领域却在毫无明确目标和前进感地随意漂流。一个领域变得被令人惊骇的猜想所充斥，却毫无希望地在其中任何一个猜想上取得严格意义上的进展。一个领域变得主要通过特殊方法来解决一群互不关联的问题，却没有统一的主题、联系或目的。一个领域变得过于枯燥和理论化，不断地用技术上越来越形式化的框架来重铸和统一以前的结果，后果却是不产生任何令人激动的新突破。一个领域崇尚经典结果，不断给出这些结果的更短、更简单以及更优美的证明，却不产生任何经典著作以外的真正原创的新结果。在上述每种情形下，有关领域会在短期内出现大量的工作和进展，但从长远看却有边缘化和无法吸引更年轻的数学家的危险。幸运的是，当一个领域不断接受挑战，并因其与其他数学领域（或相关学科）的关联而获得新生，或受到并尊重多种“好数学”的文化熏陶时，它不太可能会以这种方式而衰落。这些自我纠错机制有助于使数学保持平衡、统一、多产和活跃。现在让我们转而考虑前面提出的另一个问题，即我们到底该不该试图对“好数学”下定义。下定义有让我们变得傲慢自大的危险，特别是，我们有可能因为一个真正数学进展的奇异个例不满足主流定义而忽视它。另一方面，相反的观点即在任何数学研究领域中所有方法都同样适用并该得到同样资源，或所有数学贡献都同样重要也是有风险的。那样的观点就其理想主义而言也许是令人钦佩的，但它侵蚀了数学的方向感和目的感，并且还可能导致数学资源的不合理分配。真实的情形处于两者之间，对于每个数学领域，现存的结果、传统、直觉和经验（或它们的缺失）预示着哪种方法可能会富有成效，从而应当得到大多数的资源；哪种方法更具试探性，从而或许只要少数有独立头脑的数学家去进行探究以避免遗漏。比方说，在已经发展成熟的领域，比较合理的做法也许是追求系统方案，以严格的方式发展普遍理论，稳妥地沿用卓有成效的方法及业已确立的直觉；而在较新的、不太稳定的领域，更应该强调的也许是提出和解决猜想，尝试不同的方法，以及在一定程度上依赖不严格的启示和模拟。因此，从策略上讲比较合理的做法是，在每个领域内就数学进展中什么质量最应该受到鼓励做一个起码是部分的（但与时俱进的）调查，以便在该领域的每个发展阶段都能最有效地发展和推进该领域。比方说，某个领域也许急需解决一些紧迫的问题；另一个领域也许在翘首以待一个可以理顺大量已有成果的理论框架，或一个宏大的方案或一系列猜想来激发新的结果；其他领域则也许会从对关键定理的新的、更简单及更概念化的证明中获益匪浅；而更多的领域也许需要更大的公开性，以及关于其课题的透彻介绍，以吸引更多的兴趣和参与。因此，对什么是好数学的定义会并且也应当高度依赖一个领域自身的状况。这种定义还应当不断地得到更新与争论，无论是在领域内还是通过旁观者。如前所述，有关一个领域应当如何发展的调查，若不及时检验和更正，很有可能会导致该领域内的不平衡。上面的讨论似乎表明评价数学质量虽然重要，却是一件复杂得毫无希望的事情，特别是由于许多好的数学成就在上述某些质量上或许得分很高，在其他质量上却不然；同时，这些质量中有许多是主观而难以精确度量的（除非是事后诸葛）。然而，一个令人瞩目的现象是：上述一种意义上的好数学往往倾向于导致许多其他意义上的好数学，由此产生了一个试探性的猜测，即有关高质量数学的普遍观念也许毕竟还是存在的，上述所有特定衡量标准都代表了发现新数学的不同途径，或一个数学故事发展过程中的不同阶段或方面。 本节选自《数学和数学家的故事》第4册，李学数编著，上海科学技术出版社]]></content>
      <categories>
        <category>数学</category>
        <category>学科理解</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[丘成桐：漫谈微分几何]]></title>
    <url>%2F2020%2F09%2F14%2F%E4%B8%98%E6%88%90%E6%A1%90%EF%BC%9A%E6%BC%AB%E8%B0%88%E5%BE%AE%E5%88%86%E5%87%A0%E4%BD%95%2F</url>
    <content type="text"><![CDATA[今天很高兴能够在各位面前讲讲我做学问的经验，可以供大家参考一下。我讲「如何学好微分几何」的题目，主要是想跟大家讲讲有关于从前我做学问的态度，因为我是做几何的，所以我就讲做微分几何。很明显的，大部份的同学不会选几何，不过没有关系，其实就是讲讲我做学问的态度。首先，讲讲我从前的一些经验。我从前在香港长大，在香港念中学、大学，然后到美国念研究所，所以至少在前一半跟大家的经验应该差不了太远，不过是时代有点不同。我在多年前念数学，你们现在念数学，看法上已经有许多不相同，事实上我也不太了解你们现在的想法。不过基本上，我们都是中国文化出生的，所以我想仍有一部份共同的地方。基本上我们是要讲怎么作科学研究，也就是纯科学的研究，我们要看的是我们的志向是怎样的。假如我们想做一个好的科学家，当然我讲的是怎么做一个好的数学家。先说我自己的经验，我从前在香港培正中学念中学的时候，就开始对数学有兴趣。当然还有一些其它的课程，我对数学有兴趣，一方面是受到我家庭的影响，我父亲是做哲学的，所以对于念数学一直都相当鼓励，到了中学以后，我父亲去世了。不过也因此对于自然科学有很浓厚的兴趣。另一方面受老师的影响也很大。我想很重要的当我们开始要做一个学问，尤其是你真的要做一个出色的科学家，跟你的兴趣和你一开始所立下的志向有很大的关系。就是说，开始的时候你期望能够做到什么。假如说开始的时候你根本不想做一个好的科学家，那么你就永远也不可能做一个好的科学家。从前有位大学老师跟我讲说：「假如你不买马票，你永远也中不了。」倒不是说我鼓励你们去买马票，是说假如你不准备做好的科学家，就永远也做不了一个好的科学家。不过是不是讲，你想做一个好的科学家，你就可以做个好的科学家呢？当然不是，你还要有很多其它的因素在里面，我想第一点是要你将做人的目标先决定。我在国外二十多年了，也教了不少的学生，有些在世界上算是很出名，但有些不是太行。从这方面来讲，比较好的学生和不好的学生我可以晓得不同的经验。我想好的学生大部份一开始就决定他要做到什么程度的科学家，从很早就可以看得出来，因为有了志向以后，才晓得怎么去用功、怎么去花时间在上面。这看起来倒是老生常谈，因为你从小学、中学到大学，大概很多老师都跟你讲同样的意见，可能你听多了都觉得没有什么意思，但是事实上这是成功的第一个因素。我的一位老师跟我讲，你要决定以后你想做什么，讲明了，不是为名就是为利。当时我很惊讶，老师为什么讲这一句话。我们不能否定大部份的想法不是为名就是为利，同时这个想法也推动了不少科学的研究。不过我们也晓得，单是为名为利不可能将科学达到最高峰的研究，我们一定要对这个科学有浓厚的兴趣。我们应当晓得，做科学，我们有一个很纯正的想法，就是对真理的追寻，在真理的背后有一个很漂亮的境界在里面，我们到了一个境界以后，对我们追求学问的人来讲，是无法抗拒的，就算是没有名没有利，我们也希望能够将这个真理搞清楚。举例来讲，如果你喜欢下棋的话，有时你会晓得下到一半的时候，结局会是怎样，你非为名也非为利，当然可以讲说你是为了好胜，但是有时候你总是想追求，想晓得怎么解决这个问题。在科学上来讲我们要追求的是比这个高的境界。我为什么讲为名为利这个事实呢？举例来讲，我们这几年在哈佛大学里教了几个在大学里念数学念得很好的学生，可是到了毕业的时候，我晓得他们明明对数学有很大的兴趣，但是他们选取了完全不同的途径，他们有些人宁愿选取做生意或是到银行里面做事。我并不反对你们去做生意、赚大钱，我失望的缘故是因为这些学生明明是对做学问兴趣特别大，但是他们没有办法去抗拒赚钱的引诱而放弃了继续做学问的前途，有些人甚至过了几年赚了钱，又想重新再做学问，但问题是无论你资质有多好，一般来讲你将做学问的机会放弃以后，再想重新做起将会遇到许多困难。并不是说不可能，也曾有这种情形发生过，但是真正能够达到的情形，几乎是绝无仅有，做学问是不能中断的。我遇见过很多朋友，有些甚至是很有名的数学家，他们有些人会讲我现在一方面做行政的工作，一方面可以做学问，可是事实上，这是没有办法可以达到两者兼顾的情形。我们晓得做学问几乎是全心全意的工作，当对证明追寻的时候，很难说受到其它外界的打扰，仍能够达到很高的成功的。以我的经验来讲，在想问题的时候，晚上睡觉也在想这个问题，躺在床上也在想，早上起床第一件事就是想这个问题。我并不是讲你们也要这样子，我是希望你们在遇到一个问题要解决的时候，你要全力以赴，不可能在中间慢慢想一点而在其它也可以花点功夫，这样精神不集中的态度是不可能做好学问的。我想对大家做个建议，假如你想做个真正的好科学家的话，就不能够再往回走，假如你想做生意，那干脆一开始就不要想这个问题，并不是你要做个好的教员就要照我刚才讲的，要花这么多功夫，倒是要念好科学这是很重要的，所以这是第一点，立志很重要。第二点我要讲的，我在国外多年，遇见过许多很出名的数学家，甚至许多有名的物理学家我也见过许多。在我认为并没有一个是真正的像一般报纸上所讲的是天才，在我所亲身认识的大科学家，都是经过很大的努力，才能够达到他所达到的成就。我的学生问我：「为什么你做的比我好？」，我说很简单，我比你用功。我在办公室或是在家里边，我天天在想问题，你们在外面玩，而我花了功夫在解决想了很久的问题，我总比你不想、不花时间成就大一点。你可能去听个大科学家或大数学家演讲，你会觉得漂亮得不得了，怎么一个人能够讲得这么好！这个人是个天才！可是你有没有想到，他在后面准备花了多少时间想这个问题？大概你们听过最出名的科学家费因曼，《费因曼物理》漂亮得不得了，所有出名的物理学家都这么讲，去听的人不是学生，都是老师或物理学家。费因曼在准备费因曼物理的时候是什么事都不做，就只有脑子在花功夫，整天在想这个问题，跟许多学生不停的在谈这个问题。费因曼是个有名的天才，可是他准备这个研究也花了许多不同的功夫。我想很多出名的科学家在有所表现出不同的时候，你会觉得他是天才，事实上他用在后面的功夫都是很不少的。有许多很聪明很厉害的人可能是研究生甚至是教授，往往你给他一个问题，他可以很快给你一个答案，同时是很不错的一个答案。可是很多这样出色的学生或是教授，过了很久以后，你总会觉得他没有做出很好的成绩出来。问题是，你解决的问题太容易了；没有再花很多精神去考虑这个问题。尤其在我们中国人最缺乏的，就是在做中学生或是大学生的时候，没有将一个问题从头到尾仔细考虑清楚，并没有真正的全部了解，这是个很重要的问题。从一个很小的问题，我们可以引发很多不同而且有意思的问题。思考要自己训练，不单是在联考或在大学的时候，老师出个题目，你考了一百分就完了，假如这样的话，你很容易就满足你自己，你不觉得问题有什么意思。往往出名的研究是在很平凡的问题里面，不停的思考所找出来的，很多人因为很快将问题解决了，便不愿再想下去，所以不能够再启发新的东西。科学的研究，不是解决人家已经晓得的问题。当一个科学家问一个好的问题的时候，即是成功的一半。因为科学的推动是从不断的找寻新的问题，新的方向出来的，解决从前的问题虽是个重要的推动方向，可是我们还要找出新的方向，而不单是解决从前的问题。我们知道在物理上解决问题的时候，往往大的或出名的公式是将前面固定的理论推翻，而找出新的路子。为什么大数学家或大物理学家能够做到这个地步呢？因为他们不断的问问题。有时候在一般人来讲很明显的问题，在出名的科学家看起来，就不见得很明显。为什么不明显呢？因为我们有不同层次的问题要一路考虑下去。问问题的能力是一个很重要的训练，并不是花很多功夫就可做到，我想在我们中国的小学、中学或大学里都没有很好的做到这一点，我想从小应该做到这一点的。在我们来看数学跟其它物理、化学或生物等实验科学有那些不同？物理或化学等科学是从一般实验、现象界所找的题目，最后再经过实验的证实，才能算是个成功的理论。理论物理学家可以发展很多不同漂亮的理论，但最后假如不能够在实验里做出来的话，对物理学家来讲就是一篇废话。数学家有个好处。就是说，我们做了学问，一方面大部份是从一般的科学里面产生给我们的，一方面可以当作文学作品来欣赏。我们的取材多采多姿，一方面是比较基本的，从自然界或物理上的基本粒子、广义相对论、重力场去拿出很多基本的大自然的问题。这方面对近代几何学上的影响很大，另一方面可从比较没那么基本的理论里发生出来。所谓不基本，并不是说不重要。我们要了解到我们有些问题是从工业界来的，譬如说做飞机、做螺丝，甚至做流体变动的问题，都是可产生许多有趣的几何问题或是数学问题。例如说机械人手怎么去拿东西？这都可以看做是基本的几何问题，物理学家不一定有兴趣，可是数学家却有很大的兴趣。另外我们也可以对与实际问题不相近的问题产生兴趣，我们对一个图画得漂不漂亮，我们也可以在数学上研究。几何在数学上的取材有三个不同方向：第一是从基本自然界里产生的问题。从基本粒子、重力场到电磁波基本上如何产生的种种重要几何问题，从表面上你看不出来为什么它跟几何有关，但事实上近代物理将很多这种基本场论的问题变成几何问题，对微分几何来讲有很大的贡献。第二是刚才所讲，工业界与古典力学出了很多很重要的几何问题。第三就是纯粹从美的观点来找问题。举例来讲，从数论里面找了许多很漂亮的问题，尤其是近十或二十年来，大部份重要的数论问题大多是用几何的方法来解决的，这是几何在数学上三个重要的取材方向。我为什么讲取材的问题呢？因为很多中学生或大学生在念几何或是某些数学课程的时候，认为我们念那个学科就念那个学科就够了，而不要念其它的学问，这是个很错误的观念。因为数学里面每一门的学问都有密切关联的，不单是数学，其实所有的理论科学中间都有很密切的关系。例如我们刚刚所讲的，高能物理与数学的关系，或是化学甚至生物都跟数学有很大的关系，所以我想怎么学几何呢？第一点是当你决定好要做一个好的几何学家时，你一定要广泛的学不同的学问，基础要比较广，如微分方程、代数、物理学以及其它学科，至少在心理上有个准备，就是说这些学科将来是对你有帮助的。你听起来会觉得这是很困难的事情，你不可能学会这么多种不同的学问。这主要的分别就是你要有一个层次，你的专科是那一方面，就要多学一点，但不可忘掉其它的学科。有时在某个意义下，我们可以很惊讶的看到同一个学问、同一个命题，在两个不同的学科里面，可以以不同的方法出现，就是说以不同的方法证明。我想主要的原因是根本上这两个学科的分别并不是很大。在几十年前有个出名的物理学家说数学有不可思议的力量。为什么数学能够在物理上有这么大的影响呢？因为从物理学家的看法，数学家祇是在玩一些简单的符号，纯粹是在家里想一些自己的问题，与自然界的关系好象不大，其实这是个错误的想法。我们数学家研究的问题是很具体的，只是有不同的层次，所以有点不同而已。举例来说我们研究微分几何上一个最简单的图形-圆球，这圆球可以说是一个抽象的观念，我们也可以说它是自然界很具体的一部份。也就是说我们将所研究的圆球视为自然界的一部份，其实跟物理的现象差不了太远的。尤其在现代的高能物理里，我们研究基本粒子，尤其到了量子力学的观念以后，因为能量已经到了很高的地步，所以有很多根本没有办法做实验，所以基本上也是在家里或课堂里或办公室里用纸笔来算，这跟数学家想象的差不了太远。假如物理学家可以这么做，表示数学家也能够坐在家里面而对自然界达到某种程度的了解。为什么我要讲这些呢？这些与微分几何有什么关系呢？我要讲的是你在选题的时候，我们虽然有个自由度对于选题与自然界无关，但是我们也有一个限度在里面，假如我们选的问题与现实相差太远，最后我们的命题会被淘汰掉。在历史上出现很多不同的研究，过了十年、二十年后就完全被淘汰的。你看现在的图书馆里面有许多的文章出现，不过再过个十年八年以后，我想大部份的文章是会被淘汰掉的，根本在整个数学历史上起不了任何作用。这是因为很多的文章实在没有解决问题，其次是对我们研究的对象没有产生任何效果。所以虽然我们数学界不用时间来做证明，可是我们有某种程度的测试。一般来讲，证的很好的数学，二十年或五十年内都可以看到它在现实里出现帮助。我们晓得在这个二十年以来，从前许多不重要的问题，在今日的工程上发生很大的影响。举例来讲，从前在数论里对于质数的搜查这个问题，这完全是一个无聊的命题。就是说一个很大的数，你怎么将它因子分解得很快。近十多年来，在国防科学上这问题变成一个重要的命题，有许多国防科学家在做这方面的研究，所以说数学上的选题很重要。为什么因子分解很重要呢？表面上看来跟真正的用途好象没有什么关联，可是它是一个很自然的问题，一个很大的整数它怎么分解，很快地，表面上并不重要，但可以帮助我们了解质数的分布情形，所以我说选题是一个很重要的问题。我记得从前我们在做大学生的时候，花了很多功夫去念一些文章与参考书，有些对数学来讲是很无意义的，可是反过来说因为花了很多功夫，所以可以了解到有些问题比较重要，有些问题比较不重要，所以花的功夫并没有白费。其次我们讲做一个学生应该是怎么一个看法。对于做数学或做微分几何来讲，我觉得研究的气氛很要紧，尤其在中国的环境里，好象是不太容易培养出这种气氛来。假如你旁边的朋友或同学跟你谈的都是其它的问题，譬如说股票涨了或跌了或其它问题，久而久之，你大概对于做学问也没有很大的兴趣，所以培养做学问的态度与你交的朋友、跟的老师的关系很大。如果你们时常讨论学术上的问题，你就不会觉得自己很孤单，能够激励你对数学上有更大的兴趣。假如你自暴自弃，就是说你认为自己不能够在数学上做研究，不能够在数学上达到贡献的话，你永远也达不到，而且同时也影响到你旁边的朋友，使得大家都不能向前走。我们晓得许多出名的数学家甚至在牢里也可以写一些出名的文章，倒不是你永远关在牢里就能做好的文章，是说人在最困难的时候也可以做研究。除了气氛很重要外，你也需要得到先进的支持，从前我们念中学的时候，念了很多关于做学问的方法，从前觉得很好笑，以后念书念得多了以后就觉得这些很重要，事实上这些是很重要的经验。有句话说「学而不思则罔，思而不学则怠」，你单是学而不想是不行的，你单是想而不学也是不行的，这两句话看起来很简单，其实就是怎么分配你的学习跟思想，这是一个很微妙很重要的问题。一个人无论你多用功多天才，你假如不将前人做过的东西去体验去学习，是不可能做好的。这道理很简单，一个人的智能有限，我们不可能与前面十年、五年所有人做过的加起来的智能相比，我们要靠前人的经验，要靠他们的启发，才能够向前迈进，虽然有人自夸的讲比他们加起来都行，我不相信这种情形，也没见过这种情形。所以出名的贡献如爱因斯坦、牛顿的贡献，也是在前人的成果方面再向前走一大步或一小步。所以学是一定要的，可是如果你学过这个东西以后而不去思考，不去消化，就算你可以考第一，考一百分，但是你不想是绝对没有用的。我们看过很多出名的天才，十二岁就拿到学士学位，甚至拿了很高分，可是往往我们看不出他以后的成就。为什么很多所谓的天才在以后的科学发展里没有任何的贡献？这是因为他们没有思考，没有思考在科学上完全不会引起任何的波澜、任何的贡献，对于整个科学完全没有好处。所以学了以后一定要思考，怎么分配你的学习跟思考就往往要有导师的帮忙或是同学的帮忙。所谓的帮忙并不是说老师跟你讲你应当这么做或应当怎么做，这样往往是没有很大的效果，所以我刚刚讲的气氛很重要。从人家用功的程度或是讲话的态度的启发，或是讲话的时候能够去听，追根出什么东西来，从它而得到很大的帮助。从前我到柏克莱去念研究所时，我花了很多功夫去听很多不同的科目，有些人觉得很奇怪，为什么我会去听那些课？我觉得这些课对我有好处，过了几十年后我还是觉得有好处。有些课在我去听的当时可能不懂，可是听了还是觉得有好处，因为一个人的脑袋的想法并不是那么简单的，有时候某些东西当时可能不懂，可是慢慢的就能领悟很多东西。我举例来讲，我做博士论文的时候，我刚好要用到群论的东西，当时我问过许多专家，但是都不懂，我突然想到从前在某一课上听过一个有关这方面的论文，我忘了当时讲什么课，但我记得大概在那里可以找这方面的文章，所以我花了2天的时间在图书馆，结果给我找到差不多是我所要的文章。假如当初不去听这门课的话，我完全没有这个机会，所以有时候听一门不懂的课，有很多不同的帮助，所以很多研究生我跟他们讲，你们去听课不一定要懂，你坐在那边总比不坐在那边好，你不坐在那边的话，你完全不可能知道有其它的方法。我想最后还是你对整个学问有多大兴趣的问题，假如你对这个学问兴趣不大的话，你没办法长年累月的坐在图书馆，坐在办公厅里，或是坐在一个课堂上听课，所以你一定要先决定你对这学问的兴趣有多大，当然做研究还有许多其它方面比较复杂的原因，以后有机会我们再讲下去。我想现在你们在大学的阶段，最要紧的是决定以后你要做什么东西，其它的可能就容易做到了。]]></content>
      <categories>
        <category>数学</category>
        <category>学科理解</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MIT牛人解说数学体系]]></title>
    <url>%2F2020%2F09%2F08%2FMIT%E7%89%9B%E4%BA%BA%E8%A7%A3%E8%AF%B4%E6%95%B0%E5%AD%A6%E4%BD%93%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[1. 为什么要深入数学的世界作为计算机的学生，我（原作者）没有任何企图要成为一个数学家。我学习数学的目的，是要想爬上巨人的肩膀，希望站在更高的高度，能把我自己研究的东西看得更深广一些。说起来，我在刚来这个学校的时候，并没有预料到我将会有一个深入数学的旅程。我的导师最初希望我去做的题目，是对appearance和motion建立一个统一的模型。这个题目在当今计算机视觉中百花齐放的世界中并没有任何特别的地方。事实上，使用各种图模型把各种东西联合在一起，在近年的论文中并不少见。我不否认现在广泛流行的图模型是对复杂现象建模的有力工具，但是，我认为它不是万能的，并不能取代对于所研究的问题的深入的钻研。如果统计学习包治百病，那么很多“下游”的学科也就没有存在的必要了。事实上，开始的时候，我也是和计算机视觉中很多人一样，想着去做一个图模型——我的导师指出，这样的做法只是重复一些标准的流程，并没有很大的价值。经过很长时间的反复，另外一个路径慢慢被确立下来——我们相信，一个图像是通过大量“原子”的某种空间分布构成的，原子群的运动形成了动态的可视过程。微观意义下的单个原子运动，和宏观意义下的整体分布的变换存在着深刻的联系，这需要我们去发掘。在深入探索这个题目的过程中，遇到了很多很多的问题，如何描述一个一般的运动过程，如何建立一个稳定并且广泛适用的原子表达，如何刻画微观运动和宏观分布变换的联系，还有很多。在这个过程中，我发现了两个事情： 1.我原有的数学基础已经远远不能适应我对这些问题的深入研究。2.在数学中，有很多思想和工具，是非常适合解决这些问题的，只是没有被很多的应用科学的研究者重视。 于是，我决心开始深入数学这个浩瀚大海，希望在我再次走出来的时候，我已经有了更强大的武器去面对这些问题的挑战。我的游历并没有结束，我的视野相比于这个博大精深的世界的依旧显得非常狭窄。在这里，我只是说说，在我的眼中，数学如何一步步从初级向高级发展，更高级别的数学对于具体应用究竟有何好处。 2. 集合论：现代数学的共同基础现代数学有数不清的分支，但是，它们都有一个共同的基础——集合论。因为它，数学这个庞大的家族有个共同的语言。集合论中有一些最基本的概念：集合(set)，关系(relation)，函数(function)，等价 (equivalence)，是在其它数学分支的语言中几乎必然存在的。对于这些简单概念的理解，是进一步学些别的数学的基础。我相信，理工科大学生对于这些都不会陌生。不过，有一个很重要的东西就不见得那么家喻户晓了—— 那就是“选择公理” (Axiom of Choice)。这个公理的意思是“任意的一群非空集合，一定可以从每个集合中各拿出一个元素。”似乎是显然得不能再显然的命题。不过，这个貌似平常的公理却能演绎出一些比较奇怪的结论，比如巴拿赫-塔斯基分球定理 ——“一个球，能分成五个部分，对它们进行一系列刚性变换（平移旋转）后，能组合成两个一样大小的球”。正因为这些完全有悖常识的结论，导致数学界曾经在相当长时间里对于是否接受它有着激烈争论。现在，主流数学家对于它应该是基本接受的，因为很多数学分支的重要定理都依赖于它。在我们后面要回说到的学科里面，下面的定理依赖于选择公理： 拓扑学：Baire Category Theorem实分析（测度理论）：Lebesgue不可测集的存在性泛函分析四个主要定理： i. Hahn-Banach Extension Theorem ii. Banach-Steinhaus Theorem (Uniform boundedness principle) iii. Open Mapping Theorem iv. Closed Graph Theorem 在集合论的基础上，现代数学有两大家族：分析(Analysis)和代数(Algebra)。至于其它的，比如几何和概率论，在古典数学时代，它们是和代数并列的，但是它们的现代版本则基本是建立在分析或者代数的基础上，因此从现代意义说，它们和分析与代数并不是平行的关系。 3. 分析：在极限基础上建立的宏伟大厦3.1 微积分：分析的古典时代——从牛顿到柯西先说说分析(Analysis)吧，它是从微积分(Caculus)发展起来的——这也是有些微积分教材名字叫“数学分析”的原因。不过，分析的范畴远不只是这些，我们在大学一年级学习的微积分只能算是对古典分析的入门。分析研究的对象很多，包括导数(derivatives)，积分(integral)，微分方程(differential equation)，还有级数(infinite series)——这些基本的概念，在初等的微积分里面都有介绍。如果说有一个思想贯穿其中，那就是极限——这是整个分析（不仅仅是微积分）的灵魂。一个很多人都听说过的故事，就是牛顿(Newton)和莱布尼茨 (Leibniz)关于微积分发明权的争论。事实上，在他们的时代，很多微积分的工具开始运用在科学和工程之中，但是，微积分的基础并没有真正建立。那个长时间一直解释不清楚的“无穷小量”的幽灵，困扰了数学界一百多年的时间——这就是“第二次数学危机”。直到柯西用极限的观点重新建立了微积分的基本概念，这门学科才开始有了一个比较坚实的基础。直到今天，整个分析的大厦还是建立在极限的基石之上。柯西(Cauchy)为分析的发展提供了一种严密的语言，但是他并没有解决微积分的全部问题。在19世纪的时候，分析的世界仍然有着一些挥之不去的乌云。而其中最重要的一个没有解决的是“函数是否可积的问题”。我们在现在的微积分课本中学到的那种通过“无限分割区间，取矩阵面积和的极限”的积分，是大约在1850年由黎曼(Riemann)提出的，叫做黎曼积分。但是，什么函数存在黎曼积分呢（黎曼可积）？数学家们很早就证明了，定义在闭区间内的连续函数是黎曼可积的。可是，这样的结果并不令人满意，工程师们需要对分段连续函数的函数积分。 3.2 实分析：在实数理论和测度理论上建立起现代分析在19世纪中后期，不连续函数的可积性问题一直是分析的重要课题。对于定义在闭区间上的黎曼积分的研究发现，可积性的关键在于“不连续的点足够少”。只有有限处不连续的函数是可积的，可是很多有数学家们构造出很多在无限处不连续的可积函数。显然，在衡量点集大小的时候，有限和无限并不是一种合适的标准。在探讨“点集大小”这个问题的过程中，数学家发现实数轴，这个他们曾经以为已经充分理解的东西，有着许多他们没有想到的特性。在极限思想的支持下，实数理论在这个时候被建立起来，它的标志是对实数完备性进行刻画的几条等价的定理（确界定理，区间套定理，柯西收敛定理，Bolzano-Weierstrass Theorem和Heine-Borel Theorem等等）——这些定理明确表达出实数和有理数的根本区别：完备性（很不严格的说，就是对极限运算封闭）。随着对实数认识的深入，如何测量“点集大小”的问题也取得了突破，勒贝格创造性地把关于集合的代数，和Outer content（就是“外测度”的一个雏形）的概念结合起来，建立了测度理论(Measure Theory)，并且进一步建立了以测度为基础的积分——勒贝格积分(Lebesgue Integral)。在这个新的积分概念的支持下，可积性问题变得一目了然。上面说到的实数理论，测度理论和勒贝格积分，构成了我们现在称为实分析 (Real Analysis)的数学分支，有些书也叫实变函数论。对于应用科学来说，实分析似乎没有古典微积分那么“实用”——很难直接基于它得到什么算法。而且， 它要解决的某些“难题”——比如处处不连续的函数，或者处处连续而处处不可微的函数——在工程师的眼中，并不现实。但是，我认为，它并不是一种纯数学概念游戏，它的现实意义在于为许多现代的应用数学分支提供坚实的基础。下面，我仅仅列举几条它的用处： 黎曼可积的函数空间不是完备的，但是勒贝格可积的函数空间是完备的。简单的说，一个黎曼可积的函数列收敛到的那个函数不一定是黎曼可积的，但是勒贝格可积的函数列必定收敛到一个勒贝格可积的函数。在泛函分析，还有逼近理论中，经常需要讨论“函数的极限”，或者“函数的级数”，如果用黎曼积分的概念，这种讨论几乎不可想像。我们有时看一些paper中提到 $L^p$ 函数空间，就是基于勒贝格积分。 勒贝格积分是傅立叶变换（这东西在工程中到处都是）的基础。很多关于信号处理的初等教材，可能绕过了勒贝格积分，直接讲点面对实用的东西而不谈它的数学基础，但是，对于深层次的研究问题——特别是希望在理论中能做一些工作——这并不是总能绕过去。 在下面，我们还会看到，测度理论是现代概率论的基础。 3.3 拓扑学：分析从实数轴推广到一般空间——现代分析的抽象基础随着实数理论的建立，大家开始把极限和连续推广到更一般的地方的分析。事实上，很多基于实数的概念和定理并不是实数特有的。很多特性可以抽象出来，推广到更一般的空间里面。对于实数轴的推广，促成了点集拓扑学(Point- set Topology)的建立。很多原来只存在于实数中的概念，被提取出来，进行一般性的讨论。在拓扑学里面，有4个C构成了它的核心： Closed set（闭集） 在现代的拓扑学的公理化体系中，开集和闭集是最基本的概念。一切从此引申。这两个概念是开区间和闭区间的推广，它们的根本地位，并不是一开始就被认识到的。经过相当长的时间，人们才认识到：开集的概念是连续性的基础，而闭集对极限运算封闭——而极限正是分析的根基。 Continuous function（连续函数） 连续函数在微积分里面有个用 $\epsilon-\delta$ 语言给出的定义，在拓扑学中它的定义是“开集的原像是开集的函数”。第二个定义和第一个是等价的，只是用更抽象的语言进行了改写。我个人认为，它的第三个（等价）定义才从根本上揭示连续函数的本质——“连续函数是保持极限运算的函数” ——比如y是数列x1, x2, x3, … 的极限， 那么如果 f 是连续函数，那么 f(y) 就是 f(x1), f(x2), f(x3), …的极限。连续函数的重要性，可以从别的分支学科中进行类比。比如群论中，基础的运算是“乘法”，对于群，最重要的映射叫“同态映射”——保持“乘法”的映射。在分析中，基础运算是“极限”，因此连续函数在分析中的地位，和同态映射在代数中的地位是相当的。 Connected set（连通集） 比它略为窄一点的概念叫(Path connected)，就是集合中任意两点都存在连续路径相连——可能是一般人理解的概念。一般意义下的连通概念稍微抽象一些。在我看来，连通性有两个重要的用场：一个是用于证明一般的中值定理(Intermediate Value Theorem)，还有就是代数拓扑，拓扑群论和李群论中讨论根本群(Fundamental Group)的阶。 Compact set（紧集） Compactness似乎在初等微积分里面没有专门出现，不过有几条实数上的定理和它其实是有关系的。比如，“有界数列必然存在收敛子列”——用compactness的语言来说就是——“实数空间中有界闭集是紧的”。它在拓扑学中的一般定义是一个听上去比较抽象的东西——“紧集的任意开覆盖存在有限子覆盖”。这个定义在讨论拓扑学的定理时很方便，它在很多时候能帮助实现从无限到有限的转换。对于分析来说，用得更多的是它的另一种形式 ——“紧集中的数列必存在收敛子列”——它体现了分析中最重要的“极限”。Compactness在现代分析中运用极广，无法尽述。微积分中的两个重要定 理：极值定理(Extreme Value Theory)，和一致收敛定理(Uniform Convergence Theorem)就可以借助它推广到一般的形式。 从某种意义上说，点集拓扑学可以看成是关于“极限”的一般理论，它抽象于实数理论，它的概念成为几乎所有现代分析学科的通用语言，也是整个现代分析的根基所在。 3.4 微分几何：流形上的分析——在拓扑空间上引入微分结构拓扑学把极限的概念推广到一般的拓扑空间，但这不是故事的结束，而仅仅是开始。在微积分里面，极限之后我们有微分，求导，积分。这些东西也可以推广到拓扑空间，在拓扑学的基础上建立起来 —— 这就是微分几何。从教学上说，微分几何的教材，有两种不同的类型: 一种是建立在古典微积分的基础上的“古典微分几何”，主要是关于二维和三维空间中的一些几何量的计算，比如曲率； 还有一种是建立在现代拓扑学的基础上，这里姑且称为“现代微分几何” —— 它的核心概念就是“流形”(manifold) （就是在拓扑空间的基础上加了一套可以进行微分运算的结构）。现代微分几何是一门非常丰富的学科。比如一般流形上的微分的定义就比传统的微分丰富，我自己就见过三种从不同角度给出的等价定义——这一方面让事情变得复杂一些，但是另外一个方面它给了同一个概念的不同理解，往往在解决问题时会引出不同的思路。除了推广微积分的概念以外，还引入了很多新概念：tangent space, cotangent space, push forward, pull back, fibre bundle, flow, immersion, submersion 等等。 近些年，流形在machine learning似乎相当时髦。但是，坦率地说，要弄懂一些基本的流形算法， 甚至“创造”一些流形算法，并不需要多少微分几何的基础。对我的研究来说，微分几何最重要的应用就是建立在它之上的另外一个分支：李群和李代数——这是数学中两大家族（即分析和代数）的一个漂亮的联姻。分析和代数的另外一处重要的结合则是泛函分析，以及在其基础上的调和分析。 4. 代数：一个抽象的世界4.1 关于抽象代数回过头来，再说说另一个大家族 —— 代数。如果说古典微积分是分析的入门，那么现代代数的入门点则是两个部分：线性代数(linear algebra)和基础的抽象代数(abstract algebra)——据说国内一些教材称之为近世代数。代数——名称上研究的似乎是数，在我看来，主要研究的是运算规则。一门代数，其实都是从某种具体的运算体系中抽象出一些基本规则，建立一个公理体系，然后在这基础上进行研究。一个集合再加上一套运算规则，就构成一个代数结构。 在主要的代数结构中，最简单的是群(Group)——它只有一种符合结合率的可逆运算，通常叫“乘法”。如果，这种运算也符合交换率，那么就叫阿贝尔群 (Abelian Group)。 如果有两种运算，一种叫加法，满足交换率和结合率，一种叫乘法，满足结合率，它们之间满足分配率，这种丰富一点的结构叫做环(Ring)，如果环上的乘法满足交换率，就叫可交换环(Commutative Ring)。 如果，一个环的加法和乘法具有了所有的良好性质，那么就成为一个域(Field)。基于域，我们可以建立一种新的结构，能进行加法和数乘，就构成了线性代数(Linear algebra)。 代数的好处在于，它只关心运算规则的演绎，而不管参与运算的对象。只要定义恰当，完全可以让一只猫乘一只狗得到一头猪:-)。基于抽象运算规则得到的所有定理完全可以运用于上面说的猫狗乘法。当然，在实际运用中，我们还是希望用它干点有意义的事情。学过抽象代数的都知道，基于几条最简单的规则，比如结合律，就能导出非常多的重要结论——这些结论可以应用到一切满足这些简单规则的地方 —— 这是代数的威力所在，我们不再需要为每一个具体领域重新建立这么多的定理。抽象代数有在一些基础定理的基础上，进一步的研究往往分为两个流派： 研究有限的离散代数结构（比如有限群和有限域），这部分内容通常用于数论，编码，和整数方程这些地方； 另外一个流派是研究连续的代数结构，通常和拓扑与分析联系在 一起（比如拓扑群，李群）。 我在学习中的focus主要是后者。 4.2 线性代数： “线性”的基础地位对于做Learning, vision, optimization或者statistics的人来说，接触最多的莫过于线性代数 —— 这也是我们在大学低年级就开始学习的。线性代数，包括建立在它基础上的各种学科，最核心的两个概念是向量空间和线性变换。线性变换在线性代数中的地位，和连续函数在分析中的地位，或者同态映射在群论中的地位是一样的 —— 它是保持基础运算（加法和数乘）的映射。在learning中有这样的一种倾向——鄙视线性算法，标榜非线性。也许在很多场合下面，我们需要非线性来描述复杂的现实世界，但是无论什么时候，线性都是具有根本地位的。没有线性的基础，就不可能存在所谓的非线性推广。我们常用的非线性化的方法包括流形和kernelization，这两者都需要在某个阶段回归线性。流形需要在每个局部建立和线性空间的映射，通过把许多局部线性空间连接起来形成非线性；而kernerlization则是通过置换内积结构把原线性空间“非线性”地映射到另外一个线性空间，再进行线性空间中所能进行的操作。而在分析领域，线性的运算更是无处不在，微分，积分，傅立叶变换，拉普拉斯变换，还有统计中的均值，通通都是线性的。 4.3 泛函分析： 从有限维向无限维迈进在大学中学习的线性代数，它的简单主要因为它是在有限维空间进行的，因为有限，我们无须借助于太多的分析手段。但是，有限维空间并不能有效地表达我们的世界——最重要的，函数构成了线性空间，可是它是无限维的。对函数进行的最重要的运算都在无限维空间进行，比如傅立叶变换和小波分析。这表明了，为了研究函数（或者说连续信号），我们需要打破有限维空间的束缚，走入无限维的函数空间 —— 这里面的第一步，就是泛函分析。泛函分析(Functional Analysis)是研究的是一般的线性空间，包括有限维和无限维，但是很多东西在有限维下显得很trivial，真正的困难往往在无限维的时候出现。在泛函分析中，空间中的元素还是叫向量，但是线性变换通常会叫作“算子”(operator)。除了加法和数乘，这里进一步加入了一些运算，比如加入范数去表达“向量的长度”或者“元素的距离”，这样的空间叫做“赋范线性空间”(normed space)，再进一步的，可以加入内积运算，这样的空间叫“内积空间”(Inner product space)。大家发现，当进入无限维的时间时，很多老的观念不再适用了，一切都需要重新审视。 所有的有限维空间都是完备的（柯西序列收敛），很多无限维空间却是不完备的（比如闭区间上的连续函数）。在这里，完备的空间有特殊的名称：完备的赋范空间叫巴拿赫空间(Banach space)，完备的内积空间叫希尔伯特空间(Hilbert space)。 在有限维空间中空间和它的对偶空间的是完全同构的，而在无限维空间中，它们存在微妙的差别。 在有限维空间中，所有线性变换（矩阵）都是有界变换，而在无限维，很多算子是无界的(unbounded)，最重要的一个例子是给函数求导。 在有限维空间中，一切有界闭集都是紧的，比如单位球。而在所有的无限维空间中，单位球都不是紧的 —— 也就是说，可以在单位球内撒入无限个点，而不出现一个极限点。 在有限维空间中，线性变换（矩阵）的谱相当于全部的特征值，在无限维空间中，算子的谱的结构比这个复杂得多，除了特征值组成的点谱(point spectrum)，还有approximate point spectrum和residual spectrum。虽然复杂，但是，也更为有趣。由此形成了一个相当丰富的分支 —— 算子谱论(Spectrum theory)。 在有限维空间中，任何一点对任何一个子空间总存在投影，而在无限维空间中， 这就不一定了，具有这种良好特性的子空间有个专门的名称切比雪夫空间(Chebyshev space)。这个概念是现代逼近理论的基础(approximation theory)。函数空间的逼近理论在Learning中应该有着非常重要的作用，但是现在看到的运用现代逼近理论的文章并不多。 4.4 继续往前：巴拿赫代数，调和分析，李代数基本的泛函分析继续往前走，有两个重要的方向。第一个是巴拿赫代数 (Banach Algebra)，它就是在巴拿赫空间（完备的内积空间）的基础上引入乘法（这不同于数乘）。比如矩阵——它除了加法和数乘，还能做乘法——这就构成了一个巴拿赫代数。除此以外，值域完备的有界算子，平方可积函数，都能构成巴拿赫代数。巴拿赫代数是泛函分析的抽象，很多对于有界算子导出的结论，还有算子谱论中的许多定理，它们不仅仅对算子适用，它们其实可以从一般的巴拿赫代数中得到，并且应用在算子以外的地方。巴拿赫代数让你站在更高的高度看待泛函分析中的结论，但是，我对它在实际问题中能比泛函分析能多带来什么东西还有待思考。最能把泛函分析和实际问题在一起的另一个重要方向是调和分析 (Harmonic Analysis)。我在这里列举它的两个个子领域，傅立叶分析和小波分析，我想这已经能说明它的实际价值。它研究的最核心的问题就是怎么用基函数去逼近和构造一个函数。它研究的是函数空间的问题，不可避免的必须以泛函分析为基础。除了傅立叶和小波，调和分析还研究一些很有用的函数空间，比如Hardy space，Sobolev space，这些空间有很多很好的性质，在工程中和物理学中都有很重要的应用。对于vision来说，调和分析在信号的表达，图像的构造，都是非常有用的工具。当分析和线性代数走在一起，产生了泛函分析和调和分析；当分析和群论走在一起，我们就有了李群(Lie Group)和李代数(Lie Algebra)。它们给连续群上的元素赋予了代数结构。我一直认为这是一门非常漂亮的数学：在一个体系中，拓扑，微分和代数走到了一起。在一定条件下，通过李群和李代数的联系，它让几何变换的结合变成了线性运算，让子群化为线性子空间，这样就为Learning中许多重要的模型和算法的引入到对几何运动的建模创造了必要的条件。因此，我们相信李群和李代数对于vision有着重要意义，只不过学习它的道路可能会很艰辛，在它之前需要学习很多别的数学。 5. 现在概率论：在现代分析基础上再生最后，再简单说说很多Learning的研究者特别关心的数学分支：概率论。自从Kolmogorov在上世纪30年代把测度引入概率论以来，测度理论就成为现代概率论的基础。在这里，概率定义为测度，随机变量定义为可测函数，条件随机变量定义为可测函数在某个函数空间的投影，均值则是可测函数对于概率测度的积分。值得注意的是，很多的现代观点，开始以泛函分析的思路看待概率论的基础概念，随机变量构成了一个向量空间，而带符号概率测度则构成了它的对偶空间，其中一方施加于对方就形成均值。角度虽然不一样，不过这两种方式殊途同归，形成的基础是等价的。在现代概率论的基础上，许多传统的分支得到了极大丰富，最有代表性的包括： 鞅论 (Martingale) —— 由研究赌博引发的理论，现在主要用于金融（这里可以看出赌博和金融的理论联系，:-P）； 布朗运动(Brownian Motion) —— 连续随机过程的基础，以及在此基础上建立的随机分析(Stochastic Calculus)，包括随机积分（对随机过程的路径进行积分，其中比较有代表性的叫伊藤积分(Ito Integral)），和随机微分方程。 对于连续几何运用建立概率模型以及对分布的变换的研究离不开这些方面的知识。]]></content>
      <categories>
        <category>数学</category>
        <category>学科理解</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[职业数学家推荐的数学书单]]></title>
    <url>%2F2020%2F09%2F04%2F%E8%81%8C%E4%B8%9A%E6%95%B0%E5%AD%A6%E5%AE%B6%E6%8E%A8%E8%8D%90%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%A6%E5%8D%95%2F</url>
    <content type="text"><![CDATA[原文 1. 说在前面的话这个阅读书单几年前就列好来，如今又加以扩充，重新发在这里，并附上几点说明： 这是《高等数学自学指南书单》的后续。列这个书单的初衷是想鼓励大家自学数学。我历来认为，我们完全可以通过数学书籍和文献来直面数学之神，不需要任何人（比如硕导，博导，合作者等等）做中间代理； 这个书单适合作为数学专业大学生的参考书单，也适合作为中学，大专数学教师（掌握数学分析，高等代数的前提下）进一步学习数学的参考书单； 本人尽量挑选数学各个分支最标准的教材，有志于数学研究的学生应当尽量阅读自己感兴趣的方向的最标准教材（特别是数学大师的著作）。书单上的书都有中英文出版，数学专业的学生如果条件许可，建议尽量阅读英文原版。很遗憾目前国内数学本科教学往往没有采用这些教材，甚至根本没有提及； 这个书单仅由我个人罗列，难免反映我的数学品味和个人喜好，有所偏颇，比如我最喜爱数论，所以推荐了很多数论名著和数论标准教材； 很多人可能认为我的这个书单中不少书并不适合本科生阅读，比如有不少GTM系列教材。这一点我当然知道，但第一流的数学本科生完全可以尝试阅读Weil的《Basic Number Theory》，Karatsuba的《基础解析数论》，Jürgen的《代数数论》，还有Hartshorne的《代数几何》； 列了两本问题集，分别是数论和离散几何领域的，这两个领域的显著特点是问题和猜想的陈述非常简单，但解决起来却非常非常困难。希望这两本问题集会激发学生的兴趣和野心。另外，并不是说这两本书中的所有问题都有经过时间考验，所以对于某些感兴趣的问题还是可以适当钻研，但建议不要太沉迷； 有人可能会觉得很奇怪，所有推荐的书作者都是外国人，其实这不是偶然。国内的许多著名教材比如华罗庚的《数论导引》，二潘的《解析数论》其实并非真正的标准教材，更适合做参考书； 书单上所有的书籍英文版都可以在网站http://b-ok.org下载； 书后面加一个星的表示有点难读，加两个星的表示很难读，加三个星的表示非常非常。。。非常难读； 2. 数学大师的经典 《Elementary Mathematics from an Advanced Standpoint》（《高观点下的初等数学》全3册）- Felix Klein 1849-1925（菲利克斯·克莱因） 这套书是数学教育的圣经，尤其适合师范生和中学数学教师； 《Famous Problems of Elementary Geometry》（《初等几何的著名问题》） 《Development of Mathematics in the 19th Century》（《数学在19世纪的发展》） 这本《数学19世纪》国内高教出版社有翻译出版过，但是翻译质量非常低劣，建议谨慎购买； 《Lectures on the Icosahedron and the Solution of Equations of the Fifth Degree》（《关于正二十面体和五次方程解的讲义》） 难度：★ 《The Foundations of Geometry》（《几何基础》）- David Hilbert 1862–1943 (大卫·希尔伯特) 难度：★ 继《几何原本》之后，最伟大的几何著作，可以看成是《几何原本》的升级版； 《Geometry and the imagination》（《直观几何》 与康福森(S.Cohnvossen)合著） 非常优美亲切的几何书； 《Methods of Mathematical Physics》（《数学物理方法》（共两卷） 与柯朗（Richard Courant）合著） 难度：★★ 不论对于基础数学还是数学物理，都是传世经典巨作； 《The Theory of Algebraic Number Fields》（《代数数域理论》） 难度：★★ 将十九世纪的代数数论做了一个完整的总结，语言有些陈旧，但里面的内容和处理方法今天读来仍然大受启发； 《Classical Group》（《典型群》）- Hermann Weyl 1885 –1955 （赫尔曼·外尔）； 难度：★★ 经典李群及其表示论的传世之作； 《Symmetry》（《对称》）- 非常优美的一本科普小书； 《Basic Number Theory》（《基础数论》）- Andre Weil 1906–1998 （安德烈·韦伊）； 难度：★★★ 严肃做代数数论以及相关领域的人，恐怕都绕不过Weil的这本著作，和希尔伯特的《代数数域理论》一样都是里程碑式的作品； 3. 数学各领域的名著3.1 数学通科名著 《What is Mathematics：an Elementary Approach to Ideas and Methods》（《什么是数学:对思想和方法的基本研究》）- R·柯朗（Richard Courant） H·罗宾（Herbert Robbins）； 这是一本备受学界大家推崇的数学高级科普著作，优秀的中学生可以挑战一下这本书； 《Proofs from THE BOOK》（《数学天书中的证明》）- G.M.齐格勒 (Martin Aigner)； 这本书是数学证明的典范作品，它会告诉你，一段真正的数学证明是一首诗，是一座艺术品； 3.2 数学史的名著（包括优秀的传记） 《Mathematical Thought from Ancient to Modern Times》（《古今数学思想》（共三卷））- 莫里斯·克莱因(Morris Kline)； 《Mathematics: The Loss of Certainty》（《数学：确定性的丧失》）- 莫里斯·克莱因(Morris Kline) 莫里斯·克莱因是伟大的数学教育家和数学史家，在数学教育界和数学历史界有巨大影响力，除了这两套名著外，他的其他作品比如《西方文化中的数学》也是强烈推的； 《Hilbert》（《希尔伯特：数学界的亚历山大》）- 康斯坦西·瑞德 (Reid. Constance) 《Courant》（《柯朗：一位数学家的双城记》）- 康斯坦西·瑞德 (Reid. Constance) 这是康斯坦西继《希尔伯特》之后的又一本史诗级数学传记，国内二十年前有出版过中译文。如果把希尔伯特的传记看成是二战前德国数学圣城哥廷根大学的崛起之路，那么柯朗的这本传记可以看成是二战前后柯朗从德国到美国，在纽约重现哥廷根的辉煌的史诗征程； 《The Mystery of the Aleph》（《神秘的阿尔法》）- D. Aczel 这是开创集合论的一代宗师康托尔的传记。今天已经完全熟悉各种各样的无穷概念的数学师生，完全无法想象康托尔一百多年前刚引入这些概念时，一切都显得有多么的荒诞不经，光怪陆离。真正的才华既是上苍的恩赐，也是命运的诅咒； 《The Man Who Loved Only Numbers》（《数字情种：埃尔德什传》）- 霍夫曼（Hoffman） 从未有哪个人像数学大师埃尔德什一样完全地把自己奉献给数学，没有女人，没有生活，没有固定住所。。。。。。 《The Man Who Knew Infinity》（《知无涯者:拉马努金传》）- 罗伯特·卡尼格尔(Robert Kanigel) 什么样的人才能称得上是数学天才，真正的数学天赋到底是什么样子，看看拉马努金的传记吧； 《Godel: A Life Of Logic, The Mind, And Mathematics》（《逻辑人生》）- John L. Casti，Werner DePauli； 这本传记不但描述哥德尔的学术生涯，也花费大量笔墨介绍著名的哥德尔不完备定理，也可以作为现代数理逻辑的介绍读物； 《Isaac Newton》（《牛顿传》）- 詹姆斯·格莱克 (James Gleick) 十分推荐这本优美传神的传记，有中译文。大家都知道牛顿是有史以来最伟大的物理学家，以至于好多人都忘了他其实和阿基米德，高斯，黎曼并列为有史以来最伟大的几位数学家； 《The Music of the Primes: Why an Unsolved Problem in Mathematics Matters》（《素数的音乐》）- Marcus du Sautoy 讲述素数和黎曼猜想的科普书已经非常多了，但我最推崇这本，国内出版过中译文； 《Fermat’s Last Theorem》（《费马大定理》）- 辛格（Simon Singh） 看过这本书，但目前没有购买，费马大定理从费马写下定理到怀尔斯最终完成证明，整整耗费350年，多少数学天才和数学大师在这里折戟沉沙，扼腕长叹； 3.3 数论的名著 《Elementary Number Theory and its applications》（《初等数论及其应用》）- 罗森(Kenneth H.Rosen) 《A Friendly Introduction to Number Theory》（《数论概论》）- 约瑟夫 H.西尔弗曼（Joseph H.Silverman） 第1，2本数论教材都比较亲切，内容相对简单，尤其是第1本，所以也十分适合需要运用数论知识的其他专业学生老师参考； 《An Introduction to the Theory of Numbers》（《数论导引》）- 哈代与莱特 (G.H. Hardy and E.M. Wright) 难度：★ 数论最经典的教材，没有之一； 《Introduction to Analytic Number Theory》（《解析数论导论》） - 阿波斯托尔 《Unsolved Problem in Number Theory》（《数论中未解决的问题》）- 盖伊 (K. Guy) 《A Classical Introduction to Modern Number Theory》（《现代数论的经典引论》）- 爱尔兰 与 罗森（K. Ireland and M. Rosen） 难度：★ 《A Course in Arithmetic》（《算术教程》）- 赛尔（J.P. Serre） 难度：★ 有一点抽象代数的背景就很可以很顺利地开始阅读5，6两本著名的数论教材了，读到后面要用到一点复分析知识； 《Basic Analytic Number Theory 》（《基础解析数论》）- 卡拉楚巴（Karatsuba） 难度：★★★ 《Algebraic Number Theory 》（《代数数论》）- 诺伊基希(Jürgen N.) 难度：★★★ 《Algebraic Number Theory 》（《代数数论》）- Serge Lang 难度：★★★ 3.4 拓扑学的名著 《Basic Topology》 （《基础拓扑学》）- 阿姆斯特朗(M.A.Armstrong) 《Topology from the Differentiable Viewpoint》（《从微分观点看拓扑》）- 约翰·米尔诺(John W.Milnor) 难度：★ 米尔诺的每本书都非常优美，每本！ 《Topology》 (2nd Edition)（《拓扑学》）- Munkres, James 几十年来一直是点集拓扑学最标准的教材，国内也翻译出版过多次； 《Algebraic Topology》（《代数拓扑》）- Allen Hatcher 难度：★★ 代数拓扑学最标准的教材，国内有影印； 3.5 代数学的名著 《Algebra》（《代数学》（共两卷））- 范德瓦尔登 (B.L.Van der waerden) 难度：★ 范德瓦尔登的《代数学》是我本科时代最美记忆之一； 《Basic Algebra》（ 《基础代数学》（共两卷））- 雅各布森 (N.Jacobson) 难度：★ 《Introduction to Commutative Algebra》（《交换代数导引》）- 迈克尔·阿蒂亚 (Michael Atiyah) 难度：★ 3.6 群论，李群，李代数，表示论的名著 《Linear Representations of Finite Groups》（《有限群的线性表示》）- 赛尔（J.P. Serre） 《Introduction to Lie Algebras and Representation Theory》（《李代数和表示论导论》）- J.E. Humphreys 难度：★ 这两本书都是表示论领域最基础最标准的教材，虽然很薄，但内容非常精炼，应用十分广泛； 《Representation Theory: a first course》（《表示论基本教程》）- W.Fulton,J.Harris 难度：★ 这本表示论教材内容覆盖面非常广，关于李群的部分也是非常适合作为教材，最难能可贵的是，举了许多例子，这些例子都非常非常重要； 3.7 (代数)几何学的名著 《Introduction to geometry》（《几何导论》）- Coxeter 最经典的几何著作之一，写的太优美了，以至于许多图书馆的这本书都被盗。很奇怪国内居然没有影印或翻译； 《Differential Geometry of Curves and Surfaces》（《曲线与曲面的微分几何》）- 杜卡莫 (P.do Carmo) 《Riemannian Geometry》（《黎曼几何》）- 杜卡莫 (P.do Carmo) 难度：★ 杜卡莫的这两本教材我非常喜欢，可以作为黎曼几何的入门阶梯，对于本科生而言，陈省身的《微分几何讲义》比较晦涩难懂； 《Differential geometry in the large》（《整体微分几何》）- H.霍普夫 (H.Hopf) 难度：★★ 非常优美的一本小书； 《Algebraic Geometry》（代数几何》）- R.哈茨霍恩 (R.Hartshorne) 难度：★★★ 本科时代读过的最难的两本书之一，另一本是Weil 的《Basic Number Theory》； 3.8 分析学的名著 《Complex Analysis》（复分析》）- 阿尔福斯 (Lars V.Ahlfors) 难度：★ 《Real and Complex Analysis》（《实分析与复分析》）- 鲁丁 (Walter Rudin) 难度：★ 《Functional Analysis》（《泛函分析》）- 鲁丁 (Walter Rudin) 难度：★★ 《Fourier Analysis》（《傅里叶分析》）- 斯坦 （M.Stein） 《Complex Analysis》（《复分析》）- 斯坦 （M.Stein） 《Real Analysis》（《实分析》）- 斯坦 （M.Stein） 《Functional Analysis》（《泛函分析》）- 斯坦 （M.Stein） 难度：★★ Rudin和Stein的分析教材都是经典和标准教材； 《Functional Analysis》（《泛函分析》）- Peter D.Lax 难度：★★ 《Functional Analysis》 （《泛函分析》）- 吉田耕作 Yosida 难度：★★ 《An Introduction to Harmonic Analysis》（《调和分析导论》 Katznelson 难度：★ 3.9 集合论，数理逻辑的名著 《A Course in Mathematical Logic》（《数理逻辑教程》）- J.贝尔 (John Bell) 难度：★ 数理逻辑最全面最标准的教材，没有之一； 《Naive Set Theory》（《朴素集合论》）- 哈莫斯 (Halmos P.R.) 一本薄薄的小册子，也适合非数学专业阅读了解集合论； 《Introduction to Mathematical Philosophy 》（《数理哲学导论》）- 伯特兰·罗素 (Bertrand Russell) 难度：★ 这是一本面向公众的数理逻辑讲义，也是我最钟爱的一本书，特地购入中英文版。我认为这本书很好地回答了一个数学哲学问题：什么是数？我相信不论是公众还是职业数学家读这本书都会有收获； 《Mathematical Logic》（《数理逻辑》）- Ebbinghaus, Flum, Thomas 这本书风格非常亲切，虽然十分精练，但又不失严格，从零基础开始，最后讲到赫赫有名的哥德尔不完备定理，所以强烈推荐给大家； 3.10 常微分方程，动力系统的名著 《Ordinary Differential Equations》（《常微分方程》）- 阿若尔德 写得非常几何，非常物理，非常直观，非常优美； 《Geometrical Methods in the Theory of Ordinary Differential Equations》（《常微分方程的几何方法》）- 阿若尔德 难度：★ 阿若尔德的这两本书写得非常几何，非常物理，非常直观，非常优美； 《Differential Equations, Dynamical Systems, and an Introduction to Chaos》（第3版）（《微分方程，动力系统&amp; 混沌导引》）- Morris W. Hirsch，Stephen Smale ，Robert L. Devaney 《Introduction to Dynamical Systems 》（《动力系统引论》）- Brin, Michael 难度：★ 半个世纪的迅猛发展，使得动力系统早就成为和代数拓扑，黎曼几何，数论，表示论一样庞大的分支，但是很遗憾国内的本科教学在这块几乎是空白的，Brin, Michael的这本书无疑是最适合本科生阅读的，内容覆盖面非常广，而且能抓住动力系统各个方向的最基础知识点； 《Mathematical Methods in Classical Mechanics》（《经典力学的数学方法》）- 阿若尔德 难度：★ 3.11 概率论和组合数学的名著 《Elementary Probability Theory》（《初等概率论:英文版(第4版) 》）- 钟开莱(Kai Lai Chung) 难度：★★ 钟开莱的这本本科生教材非常通俗易懂，甚至适合高中生。上个世纪七八十年代，国内曾翻译出版过中文版，到现在这套书已经非常稀少了，在二手书网站上，中文版薄薄的一本已经被卖到一两百元了。希望国内出版社能尽快重新翻译出版这本书； 《A Course In Probability Theory》（《概率论教程:英文版(第3版) 》）- 钟开莱(Kai Lai Chung) 难度：★★ 钟开莱的这本教材让我一度认为概率论就是实分析和测度论加上独立性，非常适合基础数学专业学生阅读； 《The Probabilistic Method 》（《概率方法》）- Alon, Noga 难度：★ 概率方法在图论中的应用非常神奇，这本书也写的非常优美，也是我最钟爱的一本书； 《A Walk Through Combinatorics: An Introduction to Enumeration and Graph Theory》（《组合数学导引》）- Bona, Miklos 这也是我最钟爱的一本书，写得非常优美，组合大师Stanley亲自作序，最后一章介绍了大名鼎鼎的关于算法的NP猜想，和4本一样都是最标准的组合教材； 《Introductory Combinatorics Fifth Edition》（《组合数学》）- Richard A.Brualdi 《Research Problems in Discrete Geometry》（《离散几何中的研究问题》）- Brass, Moser, Pach 《Enumerative Combinatorics》（《计数组合学》）- Stanley 4. 哲学,物理学与其它领域的名著加上这些书目也体现我个人喜好，我认为哲学和数学，“行深般若波罗蜜多时”，理应贯通。本科时代，除了数学书籍外，我读得最多的就是哲学书籍： 《The Republic》（《理想国》） - 柏拉图 (Plato) 《The Metaphysics》（《形而上学》）- 亚里士多德 (Aristotle) 《A Treatise of Human Nature》（《人性论》）- 休谟（D. Hume） 《Meditations on First Philosophy》（《第一哲学沉思录》）- 笛卡尔 （Rene Descartes） 《Critique of Pure Reason》（《纯粹理性批判》）- 康德（Immanuel Kant） 《Principles of Economics》（《《经济学原理》》）- 曼昆 (N. Gregory Mankiw) 《The Logic of Hegel》（《小逻辑》）- 黑格尔（Hegel） 《The World as Will and Representation》（《作为意志和表象的世界》）- 叔本华（Schopenhauer） 《Feynman Lectures on Physics》（《费恩曼物理学讲义（共三卷）》）- 费恩曼（Feynman） 《Introductory Lectures on Psycho-Analysis》（《精神分析引论》）- 弗洛伊德 （S.Freud）]]></content>
      <categories>
        <category>数学</category>
        <category>学习指导</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[极端类别不平衡数据下的分类问题]]></title>
    <url>%2F2020%2F08%2F07%2F%E6%9E%81%E7%AB%AF%E7%B1%BB%E5%88%AB%E4%B8%8D%E5%B9%B3%E8%A1%A1%E6%95%B0%E6%8D%AE%E4%B8%8B%E7%9A%84%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[极端类别不平衡数据下的分类问题]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>类别不平衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中文和英文自然语言处理异同点分析]]></title>
    <url>%2F2020%2F05%2F13%2F%E4%B8%AD%E6%96%87%E5%92%8C%E8%8B%B1%E6%96%87%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%BC%82%E5%90%8C%E7%82%B9%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[原文链接]]></content>
  </entry>
  <entry>
    <title><![CDATA[法国巴黎高等师范学校数学教材推荐]]></title>
    <url>%2F2020%2F04%2F20%2F%E6%B3%95%E5%9B%BD%E5%B7%B4%E9%BB%8E%E9%AB%98%E7%AD%89%E5%B8%88%E8%8C%83%E5%AD%A6%E6%A0%A1%E6%95%B0%E5%AD%A6%E6%95%99%E6%9D%90%E6%8E%A8%E8%8D%90%2F</url>
    <content type="text"><![CDATA[原文 数学是最复杂的研究性学科之一，其研究的先修基础要求很高，所以学习过程也非常需要技术性。中国的数学教材多偏向于苏联风格，不易读，无形中提高了门槛。所以一个合适的教学体系和教材推荐对于数学的学习至关重要。这份的书单，是根据法国巴黎高等师范学校（数学最牛校，没有之一）的指定教材及教授推荐给出，在保持了学术难度的情况下降低学习门槛。这套书目是这套教材构成一个完整的数学教材体系，都是教得特别深入浅出的专著，特别适合自学提高。以下是按照学习推荐进度排序的，分本科生和研究生的课程。自学起点是高中毕业。 本科数学如果大家对微积分已经可以定量算了（例如可以计算面积分），就请跳过第一本，否则需要补充一下普通微积分的基础. 《Calculus DeMYSTiFieD》 这是绝对的入门书籍，基础向。如果大家之前学过高数，就可以忽略这一本了。 下面就开始严格的数学训练了： 数学分析（一）（英文版）by Apostol 数学分析（二）（英文版）by Apostol 本书为美国大学标准数分教材。数分是一切的基础，没有数分的底子，实变学十遍也没用。可是很多人在初入数学殿堂就立志不做数学了，就是因为采用了苏联风格的中文教材，实在悲剧。学数学本来就是一件快乐而清晰的事情，所以第一本至关重要。请看这本吧，看完之后你会发现中文数分教材很坑爹。 《Linear Algebra Done Right 》by Axler 好书能让人顺理成章地领悟新概念，烂书能让人放弃理想。这是一本中规中矩但清晰易读的好书。薄薄两百多页，很快就能读完。 《All the Mathematics You Missed But Need to Know for Graduate School》by Garrity 校长建议大家学完数分和线代之后，不要直接开始学复变或者实变，可以先开始感受一下高级数学的美。这本书可以使读者很容易看透其中的数学本质。仿佛度假观光一样，举重若轻地谈了很多深刻的数学领域，例如拓扑和“形式(form)”。数学系的人，先读点轻松的数学入门，日后在读深入的著作将有高屋建瓴之效。有了一定的数学概念以后，再开始读基础向的书籍。 分析类对于实变和复变之争的问题，校长认为应该先学复变。虽然复数域大家比较不熟悉，可是复数域的性质比实数域要规整很多，一阶可导，阶阶可导。这么完美的属性在数学中可不多。学习应该先学简单的在学复杂的。 复变和实变皆推荐Princeton大神Stein的著作 《Complex Analysis 》by Elias M. Stein, Rami Shakarchi 《Real Analysis, Measure Theory, Integration, And Hilbert Spaces》 by Elias M. Stein, Rami Shakarchi 对于数学这种复杂度和抽象程度极高的学科，光看不行，必须有配套的习题作为质量保证。推荐这本 《A Complex Analysis Problem Book》 有了实变复变的分析学基础后，看泛函分析将是如鱼得水。 泛函推荐两本，第一本入门，第二本提高（建议在学完拓扑后再看） 《Functional Analysis》by Peter Lax 《functional analysis》 by.Walter.Rudin Rudin和物理中的Griffith一样，Rudin在数学分析领域所做的杰出工作可能并不广为人知，但他的三本教科书被翻译成多种语言版本，供世界各地的大学生使用。这是他的第三本也是最成功的一本分析学教材，获得1993年美国数学会颁发的Leroy P.Steel奖。大家看完这一本，下一个该做的事情就是把中文版泛函分析教材烧了（当然，中英互译的附录可以留下来背单词用）。 概率类数学系的同学先通过工科概统有一个直观的感受： 《Foundamental of Probability and Statistics for engineers》by Soong 再加强数学严密性训练： 《Foundations of Modern Probability》by Kallenberg 代数类 《First course in abstract algebra with applications》by Rotman 你会惊讶于，为什么对新手而言这么难的一门课能够被他讲得如此生动。你应该知道看完它应该做什么了吧？对的—— 烧中文书。另外说一句，群论的始祖伽罗华就出自巴黎高师。 下面就进入经典的点集拓扑的学习，点集拓扑推荐这本 《Basic Topology》by Armstrong 当然，既然已经学过了分析和拓扑，下一步学习流形就顺理成章了。 《Tensor analysis on Manifolds》 这本流形上的张量分析很好地介绍了广义相对论中数学的应用。作为本科生，了解一下未来各个方向的内容至关重要。 学抽代和拓扑完直接学代数拓扑？其实没必要，高师就是把代数拓扑放在研究生一年级的。你可以先更好地理解一下群论中的Isomor phism和Free Group这个概念。感受一下应用的美妙（当然不是生活层面的应用，而是稍微具象一些的数学理论，虽然knot theory本身也是研究生的一个细分的专业）推荐这本书： 《Introduction to Knot Theory》Crowell Fox 最后你还需要补这两本书就能够本科数学毕业了。 《Differential Equations, Dynamical Systems &amp; A Introduction to Chaos》 很好的微分方程入门，对理解nonlinear有奇效。洛伦兹吸引子的魅力也被充分展示。 《 An Introduction to Modern Mathematical Computing 》by Borwein, Skerritt 研究生数学数学的领域众多，但低年级的研究生入门课程的都必须掌握的。在这些的基础上才有可能谈及后期的研究。 《Algebraic Topology》by A.Hatcher Hatcher的代数拓扑可以说成功地把这门课教得赏心悦目。 学研究生基础课代数几何之前要先学交换代数，推荐这本《交换代数六讲》 《Six Lectures on Commutative Algebra》by Elias 《Lectures On Algebraic Geometry I Sheaves, Cohomology》 《Lectures on Algebraic Geometry II Basic Concepts, Coherent Cohomology, Curves and their Jacobians》 在之前Manifold的张量分析基础上，更好地理解黎曼面，这两本套装不可或缺。 《An Introduction To Lie Groups And Lie Algebras 》by Kirillov 连续群在数学和物理各领域的应用极广，这本李群和李代数是不可或缺的好书。 有了以上基础，可以看李群领域的Vinberg三卷套神书（好想吐槽，理论物理中也有Weinberg三卷套神书。。。难道叫berg的都是神？） Lie groups and algebraic groups I - A. L. Onishchik, E. B. Vinberg Lie groups and algebraic groups II - A. L. Onishchik, E. B. Vinberg Lie groups and algebraic groups III - A. L. Onishchik, E. B. Vinberg 最后研究生领域一本基础读物就是这本Operator Theory的书了 Operator Algebras, Operator Theory and Applications 学数学本就是快乐的事情，我们应该用一套易读而不失专业性的教材来学习。]]></content>
      <categories>
        <category>数学</category>
        <category>学习指导</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[对我启发最大的数学学习方法]]></title>
    <url>%2F2020%2F04%2F10%2F%E5%AF%B9%E6%88%91%E5%90%AF%E5%8F%91%E6%9C%80%E5%A4%A7%E7%9A%84%E6%95%B0%E5%AD%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[原文 1. 认清你的需要为什么需要学习数学，这是你首先需要想清楚的问题。数学学科子分类多、每一本数学书中都有许多定理和结论，需要花大量时间研究。而人的时间是宝贵的、有限的，所以你需要大体有一个目标和计划，合理安排时间。 你的目标是精通数学、钻研数学，以数学谋生，你可能立志掌握代数几何，或者想精通前沿物理。那么你需要打下坚实的现代代数、几何以及分析基础，你需要准备大量时间和精力，拥有坚定不移的决心。（要求：精通全部三级高等数学）； 你的目标是能够熟练运用高等数学，解决问题，掌握探索新应用领域的武器，你可能立志进入计算机视觉领域、经济学领域或数据挖掘领域。那么，你需要打下坚实的矩阵论、微积分以及概率统计基础。（要求：精通第一级高等数学）； 你的目标是想了解数学的乐趣，把学数学作为人生一大业余爱好。那么，你需要打下坚实的线性代数、数学分析、拓扑学以及概率统计基础，对你来说，体会学数学的乐趣是一个更重要的目标。（精通第一级高等数学，在第二级高等数学中畅游，尝试接触第三级高等数学）； 2. 给自己足够的动力学数学需要智力，更需要时间和精力。下面的几个事实相大家都深有体会： 凡是没有用的东西，或者虽然有用，但是你用不到的东西，学得快忘得也快。不信你回忆一下你大一或者初一的基础课，你还记的清楚吗？ 凡是你不感兴趣（或者感觉不到乐趣）的东西，你很难坚持完成它。很多人都有这样的经历，一本书，前三章看的很仔细，后面就囫囵吞枣，越看越快，反正既没意思也没用。 小学数学是中学数学的基础，中学数学是高中数学的基础，高中数学是大学数学的基础（你可以以此类推）。 因此，无论你的目标是什么，搞数学、用数学、还是体会数学的乐趣、满足自己从少年时就有的梦想。学有所乐、学有所用，永远是维持你动力不衰退的两个最主要的因素。 3. 高等数学学什么？ 一级： 线性代数（矩阵论），数学分析，近世代数（群环域），分别囊括了了几何、分析和代数的基础理论。别忘了还有概率论（建立在分析之上的一门基础学科）。 二级： 有了这些基础，接着是基础的基础、抽象和推广：测度论（积分的基础，当然也是概率论的基础），拓扑学（有关集合、空间、几何的一门极度重要的基础学科），泛函分析（线性代数的推广），复变函数（分析的推广），常微分方程与偏微分方程（分析的推广），数理统计和随机过程（概率论的推广），微分几何（分析和几何的结合）。然后是一些小清新和应用学科：数值分析（算法），密码学，图形学，信息论，时间序列，图论等等。 三级： 再往上是研究生课题，往往是代数、几何和分析要一起上：微分流形、代数几何、随机动力学等等。 这个科技树的三级，和小学、初中、高中数学很相似，一层学不精通，下一层看天书。 4. 如何学习 适量做题 千万千万千万不要狂做题。玩过战略对抗游戏的同学都知道，低级兵造几个就行了，要攒钱出高级兵才能在后期取胜，低级兵不仅攻击力低，还没有好玩的魔法，它们存在的意义在于让你有能力熬到后期。上面列举了那么多课程，你先花5年做完吉米诺维奇六本数学分析习题集，你就30岁了，后面的二级课程还没开始学呢。因此，做一些课后习题，帮助你复习、思考、维持大脑运转就行，要不断地向后学。如果完全学不懂了，返回来做习题帮自己理清头绪。 了解思想 数学的精髓不是做题的数量，而是掌握思想。每一个数学分支都有自己的主线思想和方法论，不同分支也有相互可供对比和借鉴的思维方式。留意它，模仿它，琐碎的知识就串成了一条项链，你也就掌握了一门课。思想并不是读一本教材就能轻易了解的，你要读好几本书，了解一些应用才能体会。举两个例子：微积分的主线有这么几条：认识到微观和宏观是有联系的，微分用来刻画事物如何变化，它把细节放大给你看，而积分用来刻画事物的整体性质；微分和积分有时是描述一个现象的不同方式，这一点你在数学分析书中可能不容易发现，但是如果学点物理，就会发现麦克斯韦方程组同时有等价的微分形式和积分形式；积分变换能够建立不同空间之间的的联系，建立空间和空间边界的联系，这就是Stokes定理：$\int_{M} d \omega=\int_{\partial M} i^{*} \omega$，这个公式最迟要在微分流形中你才能一窥全貌。矩阵是空间中线性变换的抽象，线性代数这门课的全部意义在于研究如何表达、化简、分类空间线性变换算子；SVD分解不仅在应用学科用有极为广泛的亮相，也是你理解矩阵的有力工具；矩阵是有限维空间上的线性算子，对”空间”的理解不仅能让你重新认识矩阵，更为泛函分析的学习开了个好头。 渐进式迂回式学习，对比学习 很多时候，只读一本书，可能由于作者在某处思维跳跃了一下，以后你就再也跟不上了。学习数学的一个诀窍，就是你同时拿到好几本国际知名教材，相互对比着看，或者看完一本然后再看同一主题的另一本书，已经熟悉的内容跳过去，如果看不懂了，停下来思考或者做做习题，还是不懂则往后退一退，从能看懂的部分向前推进，当你看的多了，就会发现一个东西出现在很多地方，对它的理解就加深了。举两个例子：外微分这个东西，国内有的数学分析书里可能不介绍，我第一次遇到是在彭家贵的《微分几何》里，觉得这是个方便巧妙的工具；后来读卓里奇的《数学分析》和Rudin的《数学分析原理》，都讲了这个东西，可见在西方外微分是一个基础知识。你要读懂它，可能要首先理解矩阵，明白行列式恰好是空间体积在矩阵的变换下拉伸的倍数，它是一种线性形式。最后，当你读微分流形后，将发现外微分是获得流形上的Stokes定理的工具。点集拓扑学这个东西，搞应用用不到。但是但凡你想往深处学，这一门学科就必须要掌握，因为它提供对诸如开集、紧集、连续、完备等数学基本概念的精准刻画。往后学泛函分析、微分流形，没有这些概念你将寸步难行。首先你要读芒克里斯的旷世名著《拓扑学》，接着在读其他外国人写的书时，或多或少都会接触一些相关概念，你的理解就加深了，比如读Rudin的《泛函分析》，开始就是介绍线性拓扑空间，前面的知识你就能用上了。 建立不同学科的联系 看到一个东西在很多地方用，你对它的理解就加深了，慢慢也就能体会到这个东西的精妙，最后你会发现所有的基础学科相互交织，又在后续应用中相互帮助，切实体会到它们真的很基础，很有用。这是一种体会数学乐趣的途径。 关注应用学科 没有什么比应用更能激发你对新知识、新工具的渴望。找一些感兴趣的应用学科教材，读一读，开阔眼界，为自己的未来积累资源。以下结合自己的专业（计算机视觉）和爱好说说一些优秀的专业书籍：学了微积分，就可以无压力阅读《费恩曼物理学讲义第一卷》，了解力、热、光、时空的奥秘；学了偏微分方程，就可以无压力阅读《费恩曼物理学讲义第二卷》，了解电的奥秘；学了矩阵论，可以买一本《计算机视觉中的多视图几何》，了解成像的奥秘，编程进行图像序列的三维重建；学了概率论的同学应该会听说过贝叶斯学派和频率学派，这两个学派的人把战场拉到了机器学习领域，成就了两本经典著作《Pattern Recognition And Machine Learning》和《The Elements of Statistical Learning》，读了它们，我被基础数学为机器学习领域提供的丰硕成果和深刻见解深深折服；读了《Ray Tracing from the Ground Up》，自己写了一个光线追踪器渲染真实场景，它的基础就是一点点微积分和矩阵……高等数学的应用实在是太多了，如果你喜欢编程，自动化、机器人、计算机视觉、模式识别、数据挖掘、图形图像、信息论和密码学……到处都有大量模型供你玩耍，而且只需要一点点高等数学。在这些领域，你可能能发现比数学书更有趣，也更容易找到工作的目标。 找有趣的书看 数学家写的书有时是比较死板的，但是总有一些教材，它们的作者有强烈的欲望想向你展示”这个东西其实很有趣”，”这个东西完全不是你想的那个样子”等等，他们成功了；还有些作者，他们喜欢把一个东西在不同领域的应用，和不同东西在某一领域的应用集中展示给你看。这样的书会提供给你充足的乐趣读下去。典型代表就是国内出版的一套《图灵数学统计学丛书》，这一套书实在是太棒了，比如《线性代数应该这样学》《复分析：可视化方法》《微分方程、动力系统与混沌导论》，个人认为都是学数学必读的经典教材，非常非常有趣。 5. 多读书，读好书如果只有一句话概括如何培养数学能力，那么就是这一句：多读书，读好书。因此这一步我想单独拿出来多说两句。想必大家都十分精通并能熟练应用小学数学。想读懂代数几何，或者退一步，想读懂信息论基础，你就要挑几本好的基础教材，最好是外国人写的，像掌握小学数学那样掌握它。不要只看一本，找三本不同作者的书，对比着看，逐行逐字看。有的地方肯定看不懂，记下来，说不定在另一本书的某个地方就从另一个角度说到了这个东西。如果你以后还要往后学，现在看到的每一个基础定理，以后还会用到。每一本基础书，你今天放弃，明天还要乖乖重头再来。要像读经文一样，交叉阅读对比不同教材内容的异同。 推荐教材（我读过的觉得好的书） 第一级 《线性代数应该这样学》 卓里奇《数学分析（两册）》（读英文版吧，不难。有知友说这个还是不太简单，那你可以先看个国内教材，然后回过头来再看这个） 复旦大学《概率论》 第二级 芒克里斯《拓扑学》 图灵丛书的一些分册 柯斯特利金《代数学引论》 Vapnik《统计学习理论的本质》 Rudin《数学分析原理》 Rudin《泛函分析》 Gamelin《复分析》 彭家贵《微分几何》 Cover《信息论基础》 第三级 《微分流行与黎曼几何》 《现代几何学，方法与应用》三卷 阅读一些科普教材 《数学是什么》 《高观点下的初等数学》 《巴赫、埃舍尔、哥德尔》 《e的故事》 阅读各个领域最有趣、最活泼、最让你长知识、最重视应用、文笔最易懂的教材和书籍 《费恩曼物理学讲义》三册 《混沌与分形：科学的新疆界》 《微分方程、动力系统与混沌导论》 《复分析：可视化方法》 最后想说，数学是一个无底洞，会消耗掉你宝贵的青春。一无所知的你可能励志搞懂现代数学，但是多会半途却步，同时剩下的时间又不够精通另一门科学。而且即使你精通纯数学，没有几篇好文章也并不容易找工作。我的建议是在阅读数学的过程中开拓眼界，纯数学和应用数学学科都看看，找到感兴趣、应用广泛、工作好找（来钱）的方向再一猛扎下去成为你的事业。比如数学扎实，编程能力也强的人就很有前途。]]></content>
      <categories>
        <category>数学</category>
        <category>学习指导</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux操作记录]]></title>
    <url>%2F2020%2F03%2F20%2FLinux%E6%93%8D%E4%BD%9C%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[源相关国内镜像源阿里云1http://mirrors.aliyun.com/pypi/simple/ 中国科技大学1https://pypi.mirrors.ustc.edu.cn/simple/ 豆瓣1http://pypi.douban.com/simple/ 清华大学1https://pypi.tuna.tsinghua.edu.cn/simple/ 中国科学技术大学1http://pypi.mirrors.ustc.edu.cn/simple/ 在virtualenv虚拟环境中修改pip的源临时更改源1pip install numpy -i https://pypi.tuna.tsinghua.edu.cn/simple 永久更改源 升级pip到最新的版本（&gt;=10.00）后进行配置： 1pip install pip -U 如果您到 pip 默认源的网络连接较差，临时使用本镜像站来升级 pip： 1pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pip -U 更改镜像： 1pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple]]></content>
      <categories>
        <category>操作系统</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>源</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多分类与多标签]]></title>
    <url>%2F2020%2F03%2F16%2F%E5%A4%9A%E5%88%86%E7%B1%BB%E4%B8%8E%E5%A4%9A%E6%A0%87%E7%AD%BE%2F</url>
    <content type="text"><![CDATA[多类分类与多标签分类多类分类意味着候选集是一个多分类，而不仅仅是二分类，不是是与否的问题，而是属于多类中哪一类的问题。一个样本属于且只属于多个分类中的一个，一个样本只能属于一个类，不同类之间是互斥的。而对于多标签分类而言，一个样本的标签不仅仅局限于一个类别，可以具有多个类别，不同类之间是有关联的。比如一件衣服，其具有的特征类别有长袖、蕾丝等属性等，这两个属性标签不是互斥的，而是有关联的。 各自激活函数的使用 假设神经网络模型的最后一层的全连接层输出的是一维向量logits=[1,2,3,4,5,6,7,8,9,10],这里假设总共类别数量为10，使用softmax分类器完成多类分类问题，并将损失函数设置为categorical_crossentropy损失函数，首先用softmax将logits转换成一个概率分布，然后取概率值最大的作为样本的分类 。softmax的主要作用其实是在计算交叉熵上，将logits转换成一个概率分布后再来计算，然后取概率分布中最大的作为最终的分类结果，这就是将softmax激活函数应用于多分类中。 sigmoid一般不用来做多类分类，而是用来做二分类，它是将一个标量数字转换到[0,1]之间，如果大于一个概率阈值(一般是0.5)，则认为属于某个类别，否则不属于某个类别。这一属性使得其适合应用于多标签分类之中，在多标签分类中，大多使用binary_crossentropy损失函数。它是将一个标量数字转换到[0,1]之间，如果大于一个概率阈值(一般是0.5)，则认为属于某个类别。本质上其实就是针对logits中每个分类计算的结果分别作用一个sigmoid分类器，分别判定样本是否属于某个类别同样假设，神经网络模型最后的输出是这样一个向量logits=[1,2,3,4,5,6,7,8,9,10], 就是神经网络最终的全连接的输出。这里假设总共有10个分类。sigmoid应该会将logits中每个数字都变成[0,1]之间的概率值，假设结果为[0.01, 0.05, 0.4, 0.6, 0.3, 0.1, 0.5, 0.4, 0.06, 0.8], 然后设置一个概率阈值，比如0.3，如果概率值大于0.3，则判定类别符合，那么该输入样本则会被判定为类别3、类别4、类别5、类别7及类别8。即一个样本具有多个标签。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>多分类</tag>
        <tag>多标签</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转】好的想法从哪里来]]></title>
    <url>%2F2020%2F03%2F13%2F%E5%A5%BD%E7%9A%84%E6%83%B3%E6%B3%95%E4%BB%8E%E5%93%AA%E9%87%8C%E6%9D%A5%2F</url>
    <content type="text"><![CDATA[好的研究想法从哪里来（刘知远）王家卫的电影《一代宗师》中有段经典的比武桥段，宫会长对叶问说“今天我们不比武术，比想法”。其实，好的点子或者想法（idea），也是一篇优秀研究成果的灵魂。而计算机领域流行着一句话“IDEA is cheap, show me the code”，也说明对于重视实践的计算机学科而言，想法的好坏还取决于它的实际效能。这里就来谈下好的研究想法从哪里来。 什么算是好的想法2015年，我在微博上写过一个调侃的小段子： ML派坐落美利坚合众山中，百年来武学奇才辈出，隐然成江湖第一大名门正派，门内有三套入门武功，曰：图模型加圈，神经网加层，优化目标加正则。有童谣为证：熟练ML入门功，不会作文也会诌。 到了2018年，我又续了一小段： 不期数年，北方DL神教异军突起，内修表示学习，外练神经网络，心法众多，曰门，曰注意，曰记忆，曰对抗，曰增强。经ImageNet一役威震武林，豢Alpha犬一匹无人可近。一时家家筑丹炉，人人炼丹忙，门徒云集，依附者众，有一统江湖之势。有童谣为证：左手大数据，右手英伟达，每逢顶会炼丹忙。 这里面提到的图模型加圈、神经网络加层、优化目标加正则，神经网络中的门、注意、记忆等，都是一些改进模型性能的创新思路，被各大NLP任务广泛使用并发表论文，也许就是因为被不同NLP任务的重复使用和发表，多少有些审美疲劳而缺少更深的创新思想，被有些网友和学者诟为“灌水”，似乎都不算好的想法。 那么什么才是好的想法呢？我理解这个”好“字，至少有两个层面的意义。 学科发展角度的”好“学术研究本质是对未知领域的探索，是对开放问题的答案的追寻。所以从推动学科发展的角度，评判什么是好的研究想法的标准，首先就在一个“新”字。 过去有个说法，人工智能学科有个魔咒，凡是人工智能被解决（或者有解决方案）的部分，就不再被认为代表“人类智能”。计算机视觉、自然语言处理、机器学习、机器人之所以还被列为人工智能主要方向，也许正是因为它们尚未被解决，尚能代表“人类智能”的尊严。而我们要开展创新研究，就是要提出新的想法解决这些问题。这其中的”新“字，可以体现在提出新的问题和任务，探索新的解决思路，提出新的算法技术，实现新的工具系统等。 在保证”新“的基础上，研究想法好不好，那就看它对推动学科发展的助力有多大。深度学习之所以拥有如此显赫的影响力，就在于它对于人工智能自然语言处理、语音识别、计算机视觉等各重要方向都产生了革命性的影响，彻底改变了对无结构信号（语音、图像、文本）的语义表示的技术路线。 研究实践角度的”好“那是不是想法只要够”新“就好呢？是不是越新越好呢？我认为应该还不是。因为，只有能做得出来的想法才有资格被分析好不好。所以，从研究实践角度，还需要考虑研究想法的可实现性和可验证性。 可实现性，体现在该想法是否有足够的数学或机器学习工具支持实现。可验证性，体现在该想法是否有合适的数据集合和广泛接受的评价标准。很多民间科学家的想法之所以得不到学术界的认同，就是因为这些想法往往缺乏可实现性和可验证性，只停留在天马行空的纸面，只是些虚无缥缈的理念。 好的研究想法从哪里来想法好还是不好，并不是非黑即白的二分问题，而是像光谱一样呈连续分布，因时而异，因人而宜。计算机科技领域的发展既有积累的过程，也有跃迁的奇点，积累量变才会产生质变，吃第三个馒头饱了，也是因为前面两个馒头打底。 现在的学术研究已经成为高度专业化的职业，有庞大的研究者群体。”Publish or Perish“，是从事学术职业（如教授、研究员、研究生）的人必须做好平衡的事情，不能要求研究者的每份工作都是“诺贝尔奖”或“图灵奖”级的才值得发表。只要对研究领域的发展有所助力，就值得发表出来，帮助同行前进。鲁迅说：天才并不是自生自长在深林荒野里的怪物，是由可以使天才生长的民众产生，长育出来的，所以没有这种民众，就没有天才。这个庞大研究者群体正是天才成长的群众基础。同时，学术新人也是在开展创新研究训练中，不断磨砺寻找好想法能力，鲁迅也说：即使天才，在生下来的时候的第一声啼哭，也和平常的儿童的一样，决不会就是一首好诗。 那么，好的研究想法从哪里来呢？我总结，首先要有区分研究想法好与不好的能力，这需要深入全面了解所在研究方向的历史与现状，具体就是对学科文献的全面掌握。人是最善于学习的动物，完全可以将既有文献中不同时期研究工作的想法作为学习对象，通过了解它们提出后对学科发展的影响——具体体现在论文引用、学术评价情况等各方面——建立对研究想法好与不好的评价模型。我们很难条分缕析完美地列出区分好与不好想法的所有特征向量，但人脑强大的学习能力，只要给予足够的输入数据，就可以在神经网络中自动学习建立判别的模型，鉴古知今，见微知著，这也许就是常说的学术洞察力。 做过一些研究的同学会有感受，仅阅读自己研究方向的文献，新想法还是不会特别多。这是因为，读到的都是该研究问题已经完成时的想法，它们本身无法启发新的想法。如何产生新的想法呢？我总结有三种可行的基本途径： 实践法。即在研究任务上实现已有最好的算法，通过分析实验结果，例如发现这些算法计算复杂度特别高、训练收敛特别慢，或者发现该算法的错误样例呈现明显的规律，都可以启发你改进已有算法的思路。现在很多自然语言处理任务的Leaderboard上的最新算法，就是通过分析错误样例来有针对性改进算法的 [1]。 类比法。即将研究问题与其他任务建立类比联系，调研其他相似任务上最新的有效思想、算法或工具，通过合理的转换迁移，运用到当前的研究问题上来。例如，当初注意力机制在神经网络机器翻译中大获成功，当时主要是在词级别建立注意力，后来我们课题组的林衍凯和沈世奇提出建立句子级别的注意力解决关系抽取的远程监督训练数据的标注噪音问题 [2]，这就是一种类比的做法。 组合法。即将新的研究问题分解为若干已被较好解决的子问题，通过有机地组合这些子问题上的最好做法，建立对新的研究问题的解决方案。例如，我们提出的融合知识图谱的预训练语言模型，就是将BERT和TransE等已有算法融合起来建立的新模型 [3]。 正如武侠中的最高境界是无招胜有招，好的研究想法并不拘泥于以上的路径，很多时候是在研究者对研究问题深刻认知的基础上，综合丰富的研究阅历和聪明才智产生”顿悟“的结果。这对初学者而言恐怕还很难一窥门径，需要从基本功做起，经过大量科研实践训练后，才能有登堂入室之感。 在科研实践过程中，除了通过大量文献阅读了解历史，通过深入思考总结产生洞察力外，还有一项必不可少的工作，那就是主动开放的学术交流和合作意识。不同研究领域思想和成果交流碰撞，既为创新思想提供了新的来源，也为”类比“和”顿悟“提供了机会。了解一下历史就可以知晓，人工智能的提出，就是数学、计算机科学、控制论、信息论、脑科学等学科交叉融合的产物。而当红的深度学习的起源，1980年代的Parallel Distributed Processing （PDP），也是计算机科学、脑认知科学、心理学、生物学等领域研究者通力合作的产物。下面是1986年出版的名著《Parallel Distributed Processing: Explorations in the Microstructure of Cognition》第一卷的封面。 作者在前言中是这么讲他们的合作过程的，在最初长达六个月的时间里，它们每周见面交流两次讨论研究进展。 We expected the project to take about six months. We began in January 1982 by bringing a number of our colleagues together to form a discussion group on these topics. During the first six months we met twice weekly and laid the foundation for most of the work presented in these volumes. 而书中提供的PDP研究组的成员名单，40年后的今天仍让我惊叹其高度的跨机构、跨学科的交叉特点。所以，特别建议同学们在科研训练中，在专注研究问题的前提下，保持主动的学术交流意识，无论是听讲座报告，参加学术会议，还是选修课程，都有意识地扩宽学术交流的广度，不仅与小同行打成一片，更有看似八竿子打不着的研究领域的学术伙伴。随着研究经历的丰富，会越来越强烈地感受到，越是大跨度交叉的学术报告，越让你受到更大的启发，产生更多让自己兴奋的研究想法。 初学者应该怎么做与阅读论文、撰写论文、设计实验等环节相比，如何产生好的研究想法，是一个不太有章可循的环节，很难总结出固定的范式可供遵循。像小马过河，需要通过大量训练实践，来积累自己的研究经验。不过，对于初学者而言，仍然有几个简单可行的原则可以参考。 一篇论文的可发表价值，取决于它与已有最直接相关工作间的Delta。我们大部分研究工作都是站在前人工作的基础上推进的。牛顿说：如果说我看得比别人更远些，那是因为我站在巨人的肩膀上。在我看来，评判一篇论文研究想法的价值，就是看它站在了哪个或哪些巨人的肩膀上，以及在此基础上又向上走了多远。反过来，在准备开始一项研究工作之前，在形成研究想法的时候，也许要首先明确准备站在哪个巨人的肩膀上，以及计划通过什么方式走得更远。与已有最直接相关工作之间的Delta，决定了这个研究想法的价值有多大。 兼顾摘果子和啃骨头。人们一般把比较容易想到的研究想法，叫做Low Hanging Fruit（低垂果实）。低垂果实容易摘，但同时摘的人也多，选择摘果子就容易受到想法装车的困扰。例如，2018年以BERT为首的预训练语言模型取得重大突破，2019年中就出现大量改进工作，其中以跨模态预训练模型为例，短短几个月里arxiv.org上挂出了超过六个来自不同团队的图像与文本融合的预训练模型 [4]。设身处地去想，进行跨模态预训练模型研究，就是一个比较容易想到的方向，你一定需要有预判能力，知道世界上肯定会有很多团队也同时开展这方面研究，这时你如果选择入场，就一定要做得更深入更有特色，有自己独特的贡献才行。相对而言，那些困难的问题，愿意碰的人就少，潜下心来啃硬骨头，也是不错的选择，当然同时就会面临做不出来的风险，或者做出来也得不到太多关注的风险。同学需要根据自身特点、经验和需求，兼顾摘果子和啃骨头两种类型的研究想法。 注意多项研究工作的主题连贯性。同学的研究训练往往持续数年，需要注意前后多项研究工作的主题连贯性，保证内在逻辑统一。需要考虑，在个人简历上，在出国申请Personal Statement中，或者在各类评奖展示中，能够将这些研究成果汇总在一起，讲出自己开展这些研究工作的总目标、总设想。客观上讲，人工智能领域研究节奏很快，技术更新换代快，所以成果发表也倾向于小型化、短平快。我有商学院、社科的朋友，他们一项研究工作往往需要持续一年甚至数年以上；高性能计算、计算机网络方向的研究周期也相对较长。人工智能这种小步快跑的特点，决定了很多同学即使本科毕业时，也会有多篇论文发表，更不用说硕士生、博士生。在这种情况下，就格外需要在研究选题时，注意前后工作的连贯性和照应关系。几项研究工作放在一起，到底是互相割裂说不上话，还是在为一个统一的大目标而努力，格外反映研究的大局意识和布局能力。例如，下图是我们课题组涂存超博士2018年毕业时博士论文《面向社会计算的网络表示学习》的章节设置，整体来看就比《社会计算的若干重要问题研究》等没有内在关联的写法要更让人信服一些。当然，对于初学者而言，一开始就想清楚五年的研究计划，根本不可能。但想，还是不去想，结果还是不同的。 注意总结和把握研究动态和趋势，因时而动。2019年在知乎上有这样一个问题：”2019年在NLP领域，资源有限的个人/团队能做哪些有价值有希望的工作？“ 我当时的回答如下： 我感觉，产业界开始集团化搞的问题，说明其中主要的开放性难题已经被解决得差不多了，如语言识别、人脸识别等，在过去20年里面都陆续被广泛商业应用。看最近的BERT、GPT-2，我理解更多的是将深度学习对大规模数据拟合的能力发挥到极致，在深度学习技术路线基本成熟的前提下，大公司有强大计算能力支持，自然可以数据用得更多，模型做得更大，效果拟合更好。成熟高新技术进入商用竞争，就大致会符合摩尔定律的发展规律。现在BERT等训练看似遥不可及，但随着计算能力等因素的发展普及，说不定再过几年，人人都能轻易训练BERT和GPT-2，大家又会在同一个起跑线上，把目光转移到下一个挑战性难题上。所以不如提前考虑，哪些问题是纯数据驱动技术无法解决的。NLP和AI中的困难任务，如常识和知识推理，复杂语境和跨模态理解，可解释智能，都还没有可行的解决方案，我个人也不看好数据驱动方法能够彻底解决。更高层次的联想、创造、顿悟等认知能力，更是连边还没碰到。这些正是有远见的研究者们应该开始关注的方向。 需要看到，不同时期的研究动态和趋势不同。把握这些动态和趋势，就能够做出研究社区感兴趣的成果。不然的话，即使研究成果没有变化，只是简单早几年或晚几年投稿，结果也会大不相同。例如，2013年word2vec发表，在2014-2016年之间开展词表示学习研究，就相对比较容易得到ACL、EMNLP等会议的录用；但到了2017-2018年，ACL等会议上的词表示学习的相关工作就比较少见了。 最后的补充这篇短文，主要是希望面向初学者，介绍一些求新过程中的经验和注意事项，希望大家少走一些弯路。但阅读文献，深入思考，接收拒稿不断改进的苦，该吃的还是要吃。学术研究和论文发表，对个人而言也许意味着高薪资和奖学金，但其最终的目的还是真正的推动学科的发展。所以，要做经得起考验的学术研究，关键就在”真“与”新“，需要我们始终恪守和孜孜以求。著名历史学家、清华校友何炳棣先生曾在自传《读史阅世六十年》中提及著名数学家林家翘的一句嘱咐：“要紧的是不管搞哪一行，千万不要做第二等的题目。” 具体到每个领域，什么是一等的题目本身见仁见智，其实更指向内心“求真”的态度。 参考文献[1] https://paperswithcode.com/ &amp; http://nlpprogress.com/ [2] Yankai Lin, Shiqi Shen, Zhiyuan Liu, Huanbo Luan, Maosong Sun. Neural Relation Extraction with Selective Attention over Instances. The 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016). [3] Zhengyan Zhang, Xu Han, Zhiyuan Liu, Xin Jiang, Maosong Sun, Qun Liu. ERNIE: Enhanced Language Representation with Informative Entities. The 57th Annual Meeting of the Association for Computational Linguistics (ACL 2019). [4] https://github.com/thunlp/PLMpapers]]></content>
  </entry>
  <entry>
    <title><![CDATA[自回归语言模型与自编码语言模型]]></title>
    <url>%2F2020%2F03%2F03%2F%E8%87%AA%E5%9B%9E%E5%BD%92%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8E%E8%87%AA%E7%BC%96%E7%A0%81%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[自回归语言模型（Autoregressive LM）在ELMO／BERT出来之前，大家通常讲的语言模型其实是根据上文内容预测下一个可能跟随的单词，就是常说的自左向右的语言模型任务，或者反过来也行，就是根据下文预测前面的单词，这种类型的LM被称为自回归语言模型。GPT 就是典型的自回归语言模型。ELMO尽管看上去利用了上文，也利用了下文，但是本质上仍然是自回归LM，这个跟模型具体怎么实现有关系。ELMO是做了两个方向（从左到右以及从右到左两个方向的语言模型），但是是分别有两个方向的自回归LM，然后把LSTM的两个方向的隐节点状态拼接到一起，来体现双向语言模型这个事情的。所以其实是两个自回归语言模型的拼接，本质上仍然是自回归语言模型。 自回归语言模型有优点有缺点，缺点是只能利用上文或者下文的信息，不能同时利用上文和下文的信息，当然，貌似ELMO这种双向都做，然后拼接看上去能够解决这个问题，因为融合模式过于简单，所以效果其实并不是太好。它的优点，其实跟下游NLP任务有关，比如生成类NLP任务，比如文本摘要，机器翻译等，在实际生成内容的时候，就是从左向右的，自回归语言模型天然匹配这个过程。而Bert这种DAE（去噪自编码）模式，在生成类NLP任务中，就面临训练过程和应用过程不一致的问题，导致生成类的NLP任务到目前为止都做不太好。 自编码语言模型（Autoencoder LM）自回归语言模型只能根据上文预测下一个单词，或者反过来，只能根据下文预测前面一个单词。相比而言，Bert通过在输入X中随机Mask掉一部分单词，然后预训练过程的主要任务之一是根据上下文单词来预测这些被Mask掉的单词，如果你对Denoising Autoencoder比较熟悉的话，会看出，这确实是典型的DAE的思路。那些被Mask掉的单词就是在输入侧加入的所谓噪音。类似Bert这种预训练模式，被称为DAE LM。 这种DAE LM的优缺点正好和自回归LM反过来，它能比较自然地融入双向语言模型，同时看到被预测单词的上文和下文，这是好处。缺点是啥呢？主要在输入侧引入[Mask]标记，导致预训练阶段和Fine-tuning阶段不一致的问题，因为Fine-tuning阶段是看不到[Mask]标记的。DAE吗，就要引入噪音，[Mask] 标记就是引入噪音的手段，这个正常。 参考 XLNet:运行机制及和Bert的异同比较]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>Autoregressive Language Model</tag>
        <tag>Autoencoder Language Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自编码器]]></title>
    <url>%2F2020%2F03%2F03%2F%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8%2F</url>
    <content type="text"><![CDATA[1. 概念也称自动编码器，是一种人工神经网络，在无监督学习中用于有效编码。自编码的目的是对一组数据学习出一种表示（也称表征，编码），通常用于降维。是一种利用反向传播算法使得输出值等于输入值的神经网络，它先将输入压缩成潜在空间表征，然后通过这种表征来重构输出。为何要用输入来重构输出?如果自编码器的唯一目的是让输出值等于输入值，那这个算法将毫无用处。事实上，我们希望通过训练输出值等于输入值的自编码器，让潜在表征h将具有价值属性。这可通过在重构任务中构建约束来实现。从自编码器获得有用特征的一种方法是，限制h的维度使其小于输入x，这种情况下称作有损自编码器。通过训练有损表征，使得自编码器能学习到数据中最重要的特征。如果自编码器的容量过大，它无需提取关于数据分布的任何有用信息，即可较好地执行重构任务。如果潜在表征的维度与输入相同，或是在过完备案例中潜在表征的维度大于输入，上述结果也会出现。在这些情况下，即使只使用线性编码器和线性解码器，也能很好地利用输入重构输出，且无需了解有关数据分布的任何有用信息。在理想情况下，根据要分配的数据复杂度，来准确选择编码器和解码器的编码维数和容量，就可以成功地训练出任何所需的自编码器结构。 2. 作用 数据去噪； 降维，为可视化服务； 3. 优缺点 优点 属于自监督学习（并不是一个真正的无监督学习的算法）； 缺点 属于有损压缩，解压缩的输出与原来的输入相比是退化的（这是针对图像的，针对语言而言不一定）； 4. 种类4.1 普通自编码器在这种自编码器的最简单结构中，只有三个网络层，即只有一个隐藏层的神经网络。它的输入和输出是相同的，可通过使用Adam优化器和均方误差损失函数，来学习如何重构输入。在这里，如果隐含层维数（64）小于输入维数（784），则称这个编码器是有损的。通过这个约束，来迫使神经网络来学习数据的压缩表征。 4.2 深层自编码器是普通自编码的在增加隐藏层的基础上搭建而成 4.3 正则自编码器正则自编码器不需要使用浅层的编码器和解码器以及小的编码维数来限制模型容量，而是使用损失函数来鼓励模型学习其他特性（除了将输入复制到输出）。这些特性包括稀疏表征、小导数表征、以及对噪声或输入缺失的鲁棒性。 即使模型容量大到足以学习一个无意义的恒等函数，非线性且过完备的正则自编码器仍然能够从数据中学到一些关于数据分布的有用信息。 4.3.1 稀疏自编码器一般用来学习特征，以便用于像分类这样的任务。稀疏正则化的自编码器必须反映训练数据集的独特统计特征，而不是简单地充当恒等函数。以这种方式训练，执行附带稀疏惩罚的复现任务可以得到能学习有用特征的模型。 还有一种用来约束自动编码器重构的方法，是对其损失函数施加约束。比如，可对损失函数添加一个正则化约束，这样能使自编码器学习到数据的稀疏表征。 4.3.2 降噪自编码器这里不是通过对损失函数施加惩罚项，而是通过改变损失函数的重构误差项来学习一些有用信息。 向训练数据加入噪声，并使自编码器学会去除这种噪声来获得没有被噪声污染过的真实输入。因此，这就迫使编码器学习提取最重要的特征并学习输入数据中更加鲁棒的表征，这也是它的泛化能力比一般编码器强的原因。 4.4 变分自编码器 科学空间：变分自编码器 4.5 卷积自编码器5. 参考 自编码器和去噪编码器 DeepLearning.net的DA部分 Extracting and Composing Robust Features with Denoising Autoencoders]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>自编码器</tag>
        <tag>正则自编码器</tag>
        <tag>降噪自编码器</tag>
        <tag>稀疏自编码器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[过拟合理解和解决方法]]></title>
    <url>%2F2020%2F01%2F04%2F%E8%BF%87%E6%8B%9F%E5%90%88%E7%90%86%E8%A7%A3%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1.过拟合是什么？过拟合（overfitting）是指在模型参数拟合过程中的问题，由于训练数据包含抽样误差，训练时，复杂的模型将抽样误差也考虑在内，将抽样误差也进行了很好的拟合。具体表现就是最终模型在训练集上效果好，在测试集上效果差，模型泛化能力弱。 2.为什么要解决过你和现象？因为我们拟合的模型一般是用来预测未知的结果（不在训练集内），过拟合虽然在训练集上效果好，但是在实际使用时（测试集）效果差。同时，在很多问题上，我们无法穷尽所有状态，不可能将所有情况都包含在训练集上，所以必须解决过拟合问题。 为什么在机器学习中比较常见？这是因为机器学习算法为了满足尽可能复杂的任务，其模型的拟合能力一般远远高于问题复杂度，也就是说，机器学习算法有拟合出正确规则的前提下，进一步拟合噪声的能力。而传统的函数拟合问题（如机器人系统辨识），一般都是通过经验、物理、数学等导出一个含参模型，模型复杂度确定了，只需要调整个别参数即可。模型无多余能力拟合噪声。 3.如何解决过拟合问题？3.1 数据角度这是解决过拟合最有效的方法，只要给足够多的数据，让模型看见尽可能多的例外情况，它就会不断修正自己，从而得到好的结果。以下是几种获取更多数据的方法： 从数据源头获取更多数据：这个是最容易想到的，例如物体分类，再多拍几张照片就好等等，但是，在很多情况下，大幅增加数据本身并不容易，另外，我们并不清楚需要获取多少数据才够； 根据当前数据集估计数据分布参数，使用该分布产生更多数据：这个一般不用，以为估计分布参数的过程也会代入抽样误差； 使用数据增强：通过一定规则扩充数据； 3.2 模型角度过拟合产生的原因主要有两个：数据太少+模型太复杂。所以，可以通过使用合适复杂度的模型来防止过拟合，所以通过物理、数学建模等确定模型复杂度是关键。对于神经网络而言，可以从以下几个方面来限制网络能力： 网络结构（Architecture）：减少网络的层数、神经元个数等； 训练时间（Early Stopping）：对于每个神经元而言，其激活函数在不同区间的性能是不同的，当网络权值较小时，神经元的激活函数工作在线性区，此时神经元的拟合能力较弱（类似线性神经元）。有了这样的共识之后，我们就可以解释为什么限制训练时间有用，因为在初始化网络的时候一般都是选用较小的权值作为初始值，训练时间越长，部分网络权值可能越大，如果再合适时间停止训练，就可以将网络的能力限制在一定范围内； 限制权值（Weight-decay），也叫正则化（regularization）； 增加噪声（Noise）： 在输入中增加噪声：噪声会随着网络传播，按照权值的平方放大，并传播到输出层，对误差Cost产生影响，例如在输入中加高斯噪声，会在输出中生成$\sum_{i} \sigma_{i}^{2} \cdot w_{i}^{2}$的干扰，训练时，减小误差，同时也会对噪声产生的干扰项进行惩罚，达到减小权值的平方的目的，起到了与L2正则化类似的效果； 在权值上增加噪声：在初始化网络的时候，用0均值的高斯分布作为初始化； 对网络的响应增加噪声：如在前向传播过程中，让神经元的输出变为binary或random。显然，这种有点乱来的做法会打乱网络的训练过程，让训练更慢，但据Hinton说，在测试集上效果会有显著提升； 结合多种模型：训练多个模型，平均值或者投票形式结合各个模型的结果作为最后输出，这类方法有以下几种： Bagging； Boosting； dropout方法：随机选择神经元进行失活，让模型不能依靠任何一个特征； 4.贝叶斯方法5.参考 机器学习中用来防止过拟合的方法有哪些？]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>过拟合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则化作用原理与比较]]></title>
    <url>%2F2019%2F11%2F21%2F%E6%AD%A3%E5%88%99%E5%8C%96%E4%BD%9C%E7%94%A8%E5%8E%9F%E7%90%86%E4%B8%8E%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[L1正则化与L2正则化 l1 相比于 l2 为什么容易获得稀疏解？ 机器学习中的范数规则化之（一）L0、L1与L2范数 机器学习中的范数规则化之（二）核范数与规则项参数选择 L1正则化的稀疏性解释 浅谈L0,L1,L2范数及其应用]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>L0范式</tag>
        <tag>L1范式</tag>
        <tag>L2范式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Normalization]]></title>
    <url>%2F2019%2F11%2F19%2FNormalization%2F</url>
    <content type="text"><![CDATA[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift Layer Normalization Instance Normalization:The Missing Ingredient for Fast Stylization Group Normalization 详解深度学习中的Normalization，BN/LN/WN 深度学习中 Batch Normalization为什么效果好？ 模型优化之Layer Normalization 【深度学习】深入理解Batch Normalization批标准化]]></content>
      <categories>
        <category>深度学习</category>
        <category>Normalization</category>
      </categories>
      <tags>
        <tag>Batch Normalization</tag>
        <tag>Layer Normalization</tag>
        <tag>Weight Normalization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各种距离（相似度）计算方法]]></title>
    <url>%2F2019%2F11%2F19%2F%E5%90%84%E7%A7%8D%E8%B7%9D%E7%A6%BB%EF%BC%88%E7%9B%B8%E4%BC%BC%E5%BA%A6%EF%BC%89%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[余弦相似度（Cosine Similarity）以及调整余弦相似度（Adjusted Cosine Similarity） 皮尔森相关系数（Pearson Correlation Coefficient）3Jaccard相似系数（Jaccard Coefficient） Tanimoto系数（广义Jaccard相似系数）对数似然相似度/对数似然相似率 互信息/信息增益，相对熵/KL散度 信息检索–词频-逆文档频率（TF-IDF） 词对相似度–点间互信息]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>距离算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[神经网络中的各种问题及解决]]></title>
    <url>%2F2019%2F11%2F06%2F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E5%90%84%E7%A7%8D%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[troubleshooting-deep-neural-networks]]></content>
      <categories>
        <category>机器学习</category>
        <category>优化</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[矩阵理解]]></title>
    <url>%2F2019%2F11%2F06%2F%E7%9F%A9%E9%98%B5%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[1. 前言前不久chensh出于不可告人的目的，要充当老师，教别人线性代数。于是我被揪住就线性代数中一些务虚性的问题与他讨论了几次。很明显，chensh觉得，要让自己在讲线性代数的时候不被那位强势的学生认为是神经病，还是比较难的事情。可怜的chensh，谁让你趟这个地雷阵？！色令智昏啊！线性代数课程，无论你从行列式入手还是直接从矩阵入手，从一开始就充斥着莫名其妙。比如说，在全国一般工科院系教学中应用最广泛的同济线性代数教材（现在到了第四版），一上来就介绍逆序数这个“前无古人，后无来者”的古怪概念，然后用逆序数给出行列式的一个极不直观的定义，接着是一些简直犯傻的行列式性质和习题——把这行乘一个系数加到另一行上，再把那一列减过来，折腾得那叫一个热闹，可就是压根看不出这个东西有嘛用。大多数像我一样资质平庸的学生到这里就有点犯晕：连这是个什么东西都模模糊糊的，就开始钻火圈表演了，这未免太“无厘头”了吧！于是开始有人逃课，更多的人开始抄作业。这下就中招了，因为其后的发展可以用一句峰回路转来形容，紧跟着这个无厘头的行列式的，是一个同样无厘头但是伟大的无以复加的家伙的出场——矩阵来了！多年之后，我才明白，当老师犯傻似地用中括号把一堆傻了吧叽的数括起来，并且不紧不慢地说：“这个东西叫做矩阵”的时候，我的数学生涯掀开了何等悲壮辛酸、惨绝人寰的一幕！自那以后，在几乎所有跟“学问”二字稍微沾点边的东西里，矩阵这个家伙从不缺席。对于我这个没能一次搞定线性代数的笨蛋来说，矩阵老大的不请自来每每搞得我灰头土脸，头破血流。长期以来，我在阅读中一见矩阵，就如同阿Q见到了假洋鬼子，揉揉额角就绕道走。事实上，我并不是特例。一般工科学生初学线性代数，通常都会感到困难。这种情形在国内外皆然。瑞典数学家Lars Garding在其名著Encounter with Mathematics中说：“如果不熟悉线性代数的概念，要去学习自然科学，现在看来就和文盲差不多。”，然而“按照现行的国际标准，线性代数是通过公理化来表述的，它是第二代数学模型，…，这就带来了教学上的困难。”事实上，当我们开始学习线性代数的时候，不知不觉就进入了“第二代数学模型”的范畴当中，这意味着数学的表述方式和抽象性有了一次全面的进化，对于从小一直在“第一代数学模型”，即以实用为导向的、具体的数学模型中学习的我们来说，在没有并明确告知的情况下进行如此剧烈的paradigm shift，不感到困难才是奇怪的。大部分工科学生，往往是在学习了一些后继课程，如数值分析、数学规划、矩阵论之后，才逐渐能够理解和熟练运用线性代数。即便如此，不少人即使能够很熟练地以线性代数为工具进行科研和应用工作，但对于很多这门课程的初学者提出的、看上去是很基础的问题却并不清楚。比如说： 矩阵究竟是什么东西？ 向量可以被认为是具有n个相互独立的性质（维度）的对象的表示，矩阵又是什么呢？ 我们如果认为矩阵是一组列（行）向量组成的新的复合向量的展开式，那么为什么这种展开式具有如此广泛的应用？特别是，为什么偏偏二维的展开式如此有用？如果矩阵中每一个元素又是一个向量，那么我们再展开一次，变成三维的立方阵，是不是更有用？ 矩阵的乘法规则究竟为什么这样规定？ 为什么这样一种怪异的乘法规则却能够在实践中发挥如此巨大的功效？ 很多看上去似乎是完全不相关的问题，最后竟然都归结到矩阵的乘法，这难道不是很奇妙的事情？难道在矩阵乘法那看上去莫名其妙的规则下面，包含着世界的某些本质规律？如果是的话，这些本质规律是什么？ 行列式究竟是一个什么东西？为什么会有如此怪异的计算规则？ 行列式与其对应方阵本质上是什么关系？ 为什么只有方阵才有对应的行列式，而一般矩阵就没有（不要觉得这个问题很蠢，如果必要，针对mxn矩阵定义行列式不是做不到的，之所以不做，是因为没有这个必要，但是为什么没有这个必要）？而且，行列式的计算规则，看上去跟矩阵的任何计算规则都没有直观的联系，为什么又在很多方面决定了矩阵的性质？难道这一切仅是巧合？ 矩阵为什么可以分块计算？分块计算这件事情看上去是那么随意，为什么竟是可行的？ 对于矩阵转置运算AT，有(AB)T=BTAT，对于矩阵求逆运算A-1，有(AB)-1=B-1A-1。两个看上去完全没有什么关系的运算，为什么有着类似的性质？这仅仅是巧合吗？ 为什么说P-1AP得到的矩阵与A矩阵“相似”？这里的“相似”是什么意思？ 特征值和特征向量的本质是什么？它们定义就让人很惊讶，因为Ax=λx，一个诺大的矩阵的效应，竟然不过相当于一个小小的数λ，确实有点奇妙。但何至于用“特征”甚至“本征”来界定？它们刻划的究竟是什么？ 这样的一类问题，经常让使用线性代数已经很多年的人都感到为难。就好像大人面对小孩子的刨根问底，最后总会迫不得已地说“就这样吧，到此为止”一样，面对这样的问题，很多老手们最后也只能用：“就是这么规定的，你接受并且记住就好”来搪塞。然而，这样的问题如果不能获得回答，线性代数对于我们来说就是一个粗暴的、不讲道理的、莫名其妙的规则集合，我们会感到，自己并不是在学习一门学问，而是被不由分说地“抛到”一个强制的世界中，只是在考试的皮鞭挥舞之下被迫赶路，全然无法领略其中的美妙、和谐与统一。直到多年以后，我们已经发觉这门学问如此的有用，却仍然会非常迷惑：怎么这么凑巧？我认为，这是我们的线性代数教学中直觉性丧失的后果。上述这些涉及到“如何能”、“怎么会”的问题，仅仅通过纯粹的数学证明来回答，是不能令提问者满意的。比如，如果你通过一般的证明方法论证了矩阵分块运算确实可行，那么这并不能够让提问者的疑惑得到解决。他们真正的困惑是：矩阵分块运算为什么竟然是可行的？究竟只是凑巧，还是说这是由矩阵这种对象的某种本质所必然决定的？如果是后者，那么矩阵的这些本质是什么？只要对上述那些问题稍加考虑，我们就会发现，所有这些问题都不是单纯依靠数学证明所能够解决的。像我们的教科书那样，凡事用数学证明，最后培养出来的学生，只能熟练地使用工具，却欠缺真正意义上的理解。自从1930年代法国布尔巴基学派兴起以来，数学的公理化、系统性描述已经获得巨大的成功，这使得我们接受的数学教育在严谨性上大大提高。然而数学公理化的一个备受争议的副作用，就是一般数学教育中直觉性的丧失。数学家们似乎认为直觉性与抽象性是矛盾的，因此毫不犹豫地牺牲掉前者。然而包括我本人在内的很多人都对此表示怀疑，我们不认为直觉性与抽象性一定相互矛盾，特别是在数学教育中和数学教材中，帮助学生建立直觉，有助于它们理解那些抽象的概念，进而理解数学的本质。反之，如果一味注重形式上的严格性，学生就好像被迫进行钻火圈表演的小白鼠一样，变成枯燥的规则的奴隶。 对于线性代数的类似上述所提到的一些直觉性的问题，两年多来我断断续续地反复思考了四、五次，为此阅读了好几本国内外线性代数、数值分析、代数和数学通论性书籍，其中像前苏联的名著《数学：它的内容、方法和意义》、龚昇教授的《线性代数五讲》、前面提到的Encounter with Mathematics（《数学概观》）以及Thomas A. Garrity的《数学拾遗》都给我很大的启发。不过即使如此，我对这个主题的认识也经历了好几次自我否定。比如以前思考的一些结论曾经写在自己的blog里，但是现在看来，这些结论基本上都是错误的。因此打算把自己现在的有关理解比较完整地记录下来，一方面是因为我觉得现在的理解比较成熟了，可以拿出来与别人探讨，向别人请教。另一方面，如果以后再有进一步的认识，把现在的理解给推翻了，那现在写的这个snapshot也是很有意义的。因为打算写得比较多，所以会分几次慢慢写。也不知道是不是有时间慢慢写完整，会不会中断，写着看吧。 2. 理解矩阵（一） 原文 今天先谈谈对线形空间和矩阵的几个核心概念的理解。这些东西大部分是凭着自己的理解写出来的，基本上不抄书，可能有错误的地方，希望能够被指出。但我希望做到直觉，也就是说能把数学背后说的实质问题说出来。首先说说空间(space)，这个概念是现代数学的命根子之一，从拓扑空间开始，一步步往上加定义，可以形成很多空间。线形空间其实还是比较初级的，如果在里面定义了范数，就成了赋范线性空间。赋范线性空间满足完备性，就成了巴那赫空间；赋范线性空间中定义角度，就有了内积空间，内积空间再满足完备性，就得到希尔伯特空间。总之，空间有很多种。你要是去看某种空间的数学定义，大致都是“存在一个集合，在这个集合上定义某某概念，然后满足某些性质”，就可以被称为空间。这未免有点奇怪，为什么要用“空间”来称呼一些这样的集合呢？大家将会看到，其实这是很有道理的。我们一般人最熟悉的空间，毫无疑问就是我们生活在其中的（按照牛顿的绝对时空观）的三维空间，从数学上说，这是一个三维的欧几里德空间，我们先不管那么多，先看看我们熟悉的这样一个空间有些什么最基本的特点。仔细想想我们就会知道，这个三维的空间：1.由很多（实际上是无穷多个）位置点组成；2.这些点之间存在相对的关系；3.可以在空间中定义长度、角度；4.这个空间可以容纳运动，这里我们所说的运动是从一个点到另一个点的移动（变换），而不是微积分意义上的“连续”性的运动，上面的这些性质中，最最关键的是第4条。第1、2条只能说是空间的基础，不算是空间特有的性质，凡是讨论数学问题，都得有一个集合，大多数还得在这个集合上定义一些结构（关系），并不是说有了这些就算是空间。而第3条太特殊，其他的空间不需要具备，更不是关键的性质。只有第4条是空间的本质，也就是说，容纳运动是空间的本质特征。认识到了这些，我们就可以把我们关于三维空间的认识扩展到其他的空间。事实上，不管是什么空间，都必须容纳和支持在其中发生的符合规则的运动（变换）。你会发现，在某种空间中往往会存在一种相对应的变换，比如拓扑空间中有拓扑变换，线性空间中有线性变换，仿射空间中有仿射变换，其实这些变换都只不过是对应空间中允许的运动形式而已。因此只要知道，“空间”是容纳运动的一个对象集合，而变换则规定了对应空间的运动。下面我们来看看线性空间。线性空间的定义任何一本书上都有，但是既然我们承认线性空间是个空间，那么有两个最基本的问题必须首先得到解决，那就是：1.空间是一个对象集合，线性空间也是空间，所以也是一个对象集合。那么线性空间是什么样的对象的集合？或者说，线性空间中的对象有什么共同点吗？2.线性空间中的运动如何表述的？也就是，线性变换是如何表示的？我们先来回答第一个问题，回答这个问题的时候其实是不用拐弯抹角的，可以直截了当的给出答案。线性空间中的任何一个对象，通过选取基和坐标的办法，都可以表达为向量的形式。通常的向量空间我就不说了，举两个不那么平凡的例子：L1.最高次项不大于n次的多项式的全体构成一个线性空间，也就是说，这个线性空间中的每一个对象是一个多项式。如果我们以x0,x1,…,xn为基，那么任何一个这样的多项式都可以表达为一组n+1维向量，其中的每一个分量ai其实就是多项式中x(i-1)项的系数。值得说明的是，基的选取有多种办法，只要所选取的那一组基线性无关就可以。这要用到后面提到的概念了，所以这里先不说，提一下而已。L2.闭区间[a,b]上的n阶连续可微函数的全体，构成一个线性空间。也就是说，这个线性空间的每一个对象是一个连续函数。对于其中任何一个连续函数，根据魏尔斯特拉斯定理，一定可以找到最高次项不大于n的多项式函数，使之与该连续函数的差为0，也就是说，完全相等。这样就把问题归结为L1了。后面就不用再重复了。所以说，向量是很厉害的，只要你找到合适的基，用向量可以表示线性空间里任何一个对象。这里头大有文章，因为向量表面上只是一列数，但是其实由于它的有序性，所以除了这些数本身携带的信息之外，还可以在每个数的对应位置上携带信息。为什么在程序设计中数组最简单，却又威力无穷呢？根本原因就在于此。这是另一个问题了，这里就不说了。下面来回答第二个问题，这个问题的回答会涉及到线性代数的一个最根本的问题。线性空间中的运动，被称为线性变换。也就是说，你从线性空间中的一个点运动到任意的另外一个点，都可以通过一个线性变化来完成。那么，线性变换如何表示呢？很有意思，在线性空间中，当你选定一组基之后，不仅可以用一个向量来描述空间中的任何一个对象，而且可以用矩阵来描述该空间中的任何一个运动（变换）。而使某个对象发生对应运动的方法，就是用代表那个运动的矩阵，乘以代表那个对象的向量。简而言之，在线性空间中选定基之后，向量刻画对象，矩阵刻画对象的运动，用矩阵与向量的乘法施加运动。是的，矩阵的本质是运动的描述。如果以后有人问你矩阵是什么，那么你就可以响亮地告诉他，矩阵的本质是运动的描述。（chensh，说你呢！）可是多么有意思啊，向量本身不是也可以看成是nx1矩阵吗？这实在是很奇妙，一个空间中的对象和运动竟然可以用相类同的方式表示。能说这是巧合吗？如果是巧合的话，那可真是幸运的巧合！可以说，线性代数中大多数奇妙的性质，均与这个巧合有直接的关系。（待续） 3. 理解矩阵（二） 原文 接着理解矩阵。上一篇里说“矩阵是运动的描述”，到现在为止，好像大家都还没什么意见。但是我相信早晚会有数学系出身的网友来拍板转。因为运动这个概念，在数学和物理里是跟微积分联系在一起的。我们学习微积分的时候，总会有人照本宣科地告诉你，初等数学是研究常量的数学，是研究静态的数学，高等数学是变量的数学，是研究运动的数学。大家口口相传，差不多人人都知道这句话。但是真知道这句话说的是什么意思的人，好像也不多。简而言之，在我们人类的经验里，运动是一个连续过程，从A点到B点，就算走得最快的光，也是需要一个时间来逐点地经过AB之间的路径，这就带来了连续性的概念。而连续这个事情，如果不定义极限的概念，根本就解释不了。古希腊人的数学非常强，但就是缺乏极限观念，所以解释不了运动，被芝诺的那些著名悖论（飞箭不动、飞毛腿阿喀琉斯跑不过乌龟等四个悖论）搞得死去活来。因为这篇文章不是讲微积分的，所以我就不多说了。有兴趣的读者可以去看看齐民友教授写的《重温微积分》。我就是读了这本书开头的部分，才明白“高等数学是研究运动的数学”这句话的道理。不过在我这个《理解矩阵》的文章里，“运动”的概念不是微积分中的连续性的运动，而是瞬间发生的变化。比如这个时刻在A点，经过一个“运动”，一下子就“跃迁”到了B点，其中不需要经过A点与B点之间的任何一个点。这样的“运动”，或者说“跃迁”，是违反我们日常的经验的。不过了解一点量子物理常识的人，就会立刻指出，量子（例如电子）在不同的能量级轨道上跳跃，就是瞬间发生的，具有这样一种跃迁行为。所以说，自然界中并不是没有这种运动现象，只不过宏观上我们观察不到。但是不管怎么说，“运动”这个词用在这里，还是容易产生歧义的，说得更确切些，应该是“跃迁”。因此这句话可以改成：“矩阵是线性空间里跃迁的描述”。可是这样说又太物理，也就是说太具体，而不够数学，也就是说不够抽象。因此我们最后换用一个正牌的数学术语——变换，来描述这个事情。这样一说，大家就应该明白了，所谓变换，其实就是空间里从一个点（元素/对象）到另一个点（元素/对象）的跃迁。比如说，拓扑变换，就是在拓扑空间里从一个点到另一个点的跃迁。再比如说，仿射变换，就是在仿射空间里从一个点到另一个点的跃迁。附带说一下，这个仿射空间跟向量空间是亲兄弟。做计算机图形学的朋友都知道，尽管描述一个三维对象只需要三维向量，但所有的计算机图形学变换矩阵都是4x4的。说其原因，很多书上都写着“为了使用中方便”，这在我看来简直就是企图蒙混过关。真正的原因，是因为在计算机图形学里应用的图形变换，实际上是在仿射空间而不是向量空间中进行的。想想看，在向量空间里相一个向量平行移动以后仍是相同的那个向量，而现实世界等长的两个平行线段当然不能被认为同一个东西，所以计算机图形学的生存空间实际上是仿射空间。而仿射变换的矩阵表示根本就是4x4的。又扯远了，有兴趣的读者可以去看《计算机图形学——几何工具算法详解》。一旦我们理解了“变换”这个概念，矩阵的定义就变成：“矩阵是线性空间里的变换的描述。”到这里为止，我们终于得到了一个看上去比较数学的定义。不过还要多说几句。教材上一般是这么说的，在一个线性空间V里的一个线性变换T，当选定一组基之后，就可以表示为矩阵。因此我们还要说清楚到底什么是线性变换，什么是基，什么叫选定一组基。线性变换的定义是很简单的，设有一种变换T，使得对于线性空间V中间任何两个不相同的对象x和y，以及任意实数a和b，有：T(ax+by)=aT(x)+bT(y)，那么就称T为线性变换。定义都是这么写的，但是光看定义还得不到直觉的理解。线性变换究竟是一种什么样的变换？我们刚才说了，变换是从空间的一个点跃迁到另一个点，而线性变换，就是从一个线性空间V的某一个点跃迁到另一个线性空间W的另一个点的运动。这句话里蕴含着一层意思，就是说一个点不仅可以变换到同一个线性空间中的另一个点，而且可以变换到另一个线性空间中的另一个点去。不管你怎么变，只要变换前后都是线性空间中的对象，这个变换就一定是线性变换，也就一定可以用一个非奇异矩阵来描述。而你用一个非奇异矩阵去描述的一个变换，一定是一个线性变换。有的人可能要问，这里为什么要强调非奇异矩阵？所谓非奇异，只对方阵有意义，那么非方阵的情况怎么样？这个说起来就会比较冗长了，最后要把线性变换作为一种映射，并且讨论其映射性质，以及线性变换的核与像等概念才能彻底讲清楚。我觉得这个不算是重点，如果确实有时间的话，以后写一点。以下我们只探讨最常用、最有用的一种变换，就是在同一个线性空间之内的线性变换。也就是说，下面所说的矩阵，不作说明的话，就是方阵，而且是非奇异方阵。学习一门学问，最重要的是把握主干内容，迅速建立对于这门学问的整体概念，不必一开始就考虑所有的细枝末节和特殊情况，自乱阵脚。接着往下说，什么是基呢？这个问题在后面还要大讲一番，这里只要把基看成是线性空间里的坐标系就可以了。注意是坐标系，不是坐标值，这两者可是一个“对立矛盾统一体”。这样一来，“选定一组基”就是说在线性空间里选定一个坐标系。就这意思。好，最后我们把矩阵的定义完善如下：“矩阵是线性空间中的线性变换的一个描述。在一个线性空间中，只要我们选定一组基，那么对于任何一个线性变换，都能够用一个确定的矩阵来加以描述。”理解这句话的关键，在于把“线性变换”与“线性变换的一个描述”区别开。一个是那个对象，一个是对那个对象的表述。就好像我们熟悉的面向对象编程中，一个对象可以有多个引用，每个引用可以叫不同的名字，但都是指的同一个对象。如果还不形象，那就干脆来个很俗的类比。比如有一头猪，你打算给它拍照片，只要你给照相机选定了一个镜头位置，那么就可以给这头猪拍一张照片。这个照片可以看成是这头猪的一个描述，但只是一个片面的的描述，因为换一个镜头位置给这头猪拍照，能得到一张不同的照片，也是这头猪的另一个片面的描述。所有这样照出来的照片都是这同一头猪的描述，但是又都不是这头猪本身。同样的，对于一个线性变换，只要你选定一组基，那么就可以找到一个矩阵来描述这个线性变换。换一组基，就得到一个不同的矩阵。所有这些矩阵都是这同一个线性变换的描述，但又都不是线性变换本身。但是这样的话，问题就来了如果你给我两张猪的照片，我怎么知道这两张照片上的是同一头猪呢？同样的，你给我两个矩阵，我怎么知道这两个矩阵是描述的同一个线性变换呢？如果是同一个线性变换的不同的矩阵描述，那就是本家兄弟了，见面不认识，岂不成了笑话。好在，我们可以找到同一个线性变换的矩阵兄弟们的一个性质，那就是：若矩阵A与B是同一个线性变换的两个不同的描述（之所以会不同，是因为选定了不同的基，也就是选定了不同的坐标系），则一定能找到一个非奇异矩阵P，使得A、B之间满足这样的关系：A=P-1BP线性代数稍微熟一点的读者一下就看出来，这就是相似矩阵的定义。没错，所谓相似矩阵，就是同一个线性变换的不同的描述矩阵。按照这个定义，同一头猪的不同角度的照片也可以成为相似照片。俗了一点，不过能让人明白。而在上面式子里那个矩阵P，其实就是A矩阵所基于的基与B矩阵所基于的基这两组基之间的一个变换关系。关于这个结论，可以用一种非常直觉的方法来证明（而不是一般教科书上那种形式上的证明），如果有时间的话，我以后在blog里补充这个证明。这个发现太重要了。原来一族相似矩阵都是同一个线性变换的描述啊！难怪这么重要！工科研究生课程中有矩阵论、矩阵分析等课程，其中讲了各种各样的相似变换，比如什么相似标准型，对角化之类的内容，都要求变换以后得到的那个矩阵与先前的那个矩阵式相似的，为什么这么要求？因为只有这样要求，才能保证变换前后的两个矩阵是描述同一个线性变换的。当然，同一个线性变换的不同矩阵描述，从实际运算性质来看并不是不分好环的。有些描述矩阵就比其他的矩阵性质好得多。这很容易理解，同一头猪的照片也有美丑之分嘛。所以矩阵的相似变换可以把一个比较丑的矩阵变成一个比较美的矩阵，而保证这两个矩阵都是描述了同一个线性变换。这样一来，矩阵作为线性变换描述的一面，基本上说清楚了。但是，事情没有那么简单，或者说，线性代数还有比这更奇妙的性质，那就是，矩阵不仅可以作为线性变换的描述，而且可以作为一组基的描述。而作为变换的矩阵，不但可以把线性空间中的一个点给变换到另一个点去，而且也能够把线性空间中的一个坐标系（基）表换到另一个坐标系（基）去。而且，变换点与变换坐标系，具有异曲同工的效果。线性代数里最有趣的奥妙，就蕴含在其中。理解了这些内容，线性代数里很多定理和规则会变得更加清晰、直觉。这个留在下一篇再写吧。因为有别的事情要做，下一篇可能要过几天再写了。 4. 理解矩阵（三） 原文 这两篇文章发表于去年的4月。在第二部分结束的时候，我说：“矩阵不仅可以作为线性变换的描述，而且可以作为一组基的描述。而作为变换的矩阵，不但可以把线性空间中的一个点给变换到另一个点去，而且也能够把线性空间中的一个坐标系（基）表换到另一个坐标系（基）去。而且，变换点与变换坐标系，具有异曲同工的效果。线性代数里最有趣的奥妙，就蕴含在其中。理解了这些内容，线性代数里很多定理和规则会变得更加清晰、直觉。这个留在下一篇再写吧。因为有别的事情要做，下一篇可能要过几天再写了。”然而这一拖就是一年半。一年半以来，这两篇粗糙放肆的文章被到处转载，以至于在Google的搜索提示中，我的名字跟“矩阵”是一对关联词汇。这对于学生时代数学一直很差的我来说，实在是令人惶恐的事情。数学是何等辉煌精致的学问！代表着人类智慧的最高成就，是人与上帝对话的语言。而我实在连数学的门都还没进去，不要说谈什么理解，就是稍微难一些的题目我也很少能解开。我有什么资格去谈矩阵这样重要的一个数学概念呢？更何况，我的想法直观是直观，未见的是正确的啊，会不会误人子弟呢？因此，算了吧，到此为止吧，我这么想。是时不时收到的来信逐渐改变了我的想法。一年半以来，我收到过不下一百封直接的来信，要求我把后面的部分写出来。这些来信大部分是国内的网友和学生，也有少数来自正在国外深造的朋友，大部分是鼓励，有的是诚挚的请求，也有少数严厉斥责我不守承诺。不管是何种态度，这都表明他们对我这一点点小小的思考成果的鼓励，特别是对于我这种思维的视角和尝试的鼓励。他们在信中让我知道，尽管我的数学水平不高，但是我这种从普通人（而不是数学家）视角出发，强调对数学概念和规则的直觉理解的思路，对于很多人是有益的。也许这条路子在数学中绝非正道，也不会走得很远，但是无论如何，在一定的阶段，对一部分人来说，较之目前数学教材普遍采用的思路，这种方式可能更容易理解一些。既然是可能对一部分人有帮助的事情，那么我就不应该心存太多杂念，应该不断思考和总结下去。所以，下面就是你们来信要求我写出来的东西。首先来总结一下前面两部分的一些主要结论：1.首先有空间，空间可以容纳对象运动的。一种空间对应一类对象。2.有一种空间叫线性空间，线性空间是容纳向量对象运动的。3.运动是瞬时的，因此也被称为变换。4.矩阵是线性空间中运动（变换）的描述。5.矩阵与向量相乘，就是实施运动（变换）的过程。6.同一个变换，在不同的坐标系下表现为不同的矩阵，但是它们的本质是一样的，所以本征值相同。下面让我们把视力集中到一点以改变我们以往看待矩阵的方式。我们知道，线性空间里的基本对象是向量，而向量是这么表示的：[a1,a2,a3,…,an]矩阵呢？矩阵是这么表示的：a11,a12,a13,…,a1na21,a22,a23,…,a2n…an1,an2,an3,…,ann不用太聪明，我们就能看出来，矩阵是一组向量组成的。特别的，n维线性空间里的方阵是由n个n维向量组成的。我们在这里只讨论这个n阶的、非奇异的方阵，因为理解它就是理解矩阵的关键，它才是一般情况，而其他矩阵都是意外，都是不得不对付的讨厌状况，大可以放在一边。这里多一句嘴，学习东西要抓住主流，不要纠缠于旁支末节。很可惜我们的教材课本大多数都是把主线埋没在细节中的，搞得大家还没明白怎么回事就先被灌晕了。比如数学分析，明明最要紧的观念是说，一个对象可以表达为无穷多个合理选择的对象的线性和，这个概念是贯穿始终的，也是数学分析的精华。但是课本里自始至终不讲这句话，反正就是让你做吉米多维奇，掌握一大堆解偏题的技巧，记住各种特殊情况，两类间断点，怪异的可微和可积条件（谁还记得柯西条件、迪里赫莱条件…？），最后考试一过，一切忘光光。要我说，还不如反复强调这一个事情，把它深深刻在脑子里，别的东西忘了就忘了，真碰到问题了，再查数学手册嘛，何必因小失大呢？言归正传。如果一组向量是彼此线性无关的话，那么它们就可以成为度量这个线性空间的一组基，从而事实上成为一个坐标系体系，其中每一个向量都躺在一根坐标轴上，并且成为那根坐标轴上的基本度量单位（长度1）。现在到了关键的一步。看上去矩阵就是由一组向量组成的，而且如果矩阵非奇异的话（我说了，只考虑这种情况），那么组成这个矩阵的那一组向量也就是线性无关的了，也就可以成为度量线性空间的一个坐标系。结论：矩阵描述了一个坐标系。“慢着！”，你嚷嚷起来了，“你这个骗子！你不是说过，矩阵就是运动吗？怎么这会矩阵又是坐标系了？”嗯，所以我说到了关键的一步。我并没有骗人，之所以矩阵又是运动，又是坐标系，那是因为——“运动等价于坐标系变换”。对不起，这话其实不准确，我只是想让你印象深刻。准确的说法是：“对象的变换等价于坐标系的变换”。或者：“固定坐标系下一个对象的变换等价于固定对象所处的坐标系变换。”说白了就是：“运动是相对的。”让我们想想，达成同一个变换的结果，比如把点(1,1)变到点(2,3)去，你可以有两种做法。第一，坐标系不动，点动，把(1,1)点挪到(2,3)去。第二，点不动，变坐标系，让x轴的度量（单位向量）变成原来的1/2，让y轴的度量（单位向量）变成原先的1/3，这样点还是那个点，可是点的坐标就变成(2,3)了。方式不同，结果一样。从第一个方式来看，那就是我在《理解矩阵》1/2中说的，把矩阵看成是运动描述，矩阵与向量相乘就是使向量（点）运动的过程。在这个方式下，Ma=b的意思是：“向量a经过矩阵M所描述的变换，变成了向量b。”而从第二个方式来看，矩阵M描述了一个坐标系，姑且也称之为M。那么：Ma=b的意思是：“有一个向量，它在坐标系M的度量下得到的度量结果向量为a，那么它在坐标系I的度量下，这个向量的度量结果是b。”这里的I是指单位矩阵，就是主对角线是1，其他为零的矩阵。而这两个方式本质上是等价的。我希望你务必理解这一点，因为这是本篇的关键。正因为是关键，所以我得再解释一下。在M为坐标系的意义下，如果把M放在一个向量a的前面，形成Ma的样式，我们可以认为这是对向量a的一个环境声明。它相当于是说：“注意了！这里有一个向量，它在坐标系M中度量，得到的度量结果可以表达为a。可是它在别的坐标系里度量的话，就会得到不同的结果。为了明确，我把M放在前面，让你明白，这是该向量在坐标系M中度量的结果。”那么我们再看孤零零的向量b：b多看几遍，你没看出来吗？它其实不是b，它是：Ib也就是说：“在单位坐标系，也就是我们通常说的直角坐标系I中，有一个向量，度量的结果是b。”而Ma=Ib的意思就是说：“在M坐标系里量出来的向量a，跟在I坐标系里量出来的向量b，其实根本就是一个向量啊！”这哪里是什么乘法计算，根本就是身份识别嘛。从这个意义上我们重新理解一下向量。向量这个东西客观存在，但是要把它表示出来，就要把它放在一个坐标系中去度量它，然后把度量的结果（向量在各个坐标轴上的投影值）按一定顺序列在一起，就成了我们平时所见的向量表示形式。你选择的坐标系（基）不同，得出来的向量的表示就不同。向量还是那个向量，选择的坐标系不同，其表示方式就不同。因此，按道理来说，每写出一个向量的表示，都应该声明一下这个表示是在哪个坐标系中度量出来的。表示的方式，就是Ma，也就是说，有一个向量，在M矩阵表示的坐标系中度量出来的结果为a。我们平时说一个向量是[2357]T，隐含着是说，这个向量在I坐标系中的度量结果是[2357]T，因此，这个形式反而是一种简化了的特殊情况。注意到，M矩阵表示出来的那个坐标系，由一组基组成，而那组基也是由向量组成的，同样存在这组向量是在哪个坐标系下度量而成的问题。也就是说，表述一个矩阵的一般方法，也应该要指明其所处的基准坐标系。所谓M，其实是IM，也就是说，M中那组基的度量是在I坐标系中得出的。从这个视角来看，M×N也不是什么矩阵乘法了，而是声明了一个在M坐标系中量出的另一个坐标系N，其中M本身是在I坐标系中度量出来的。回过头来说变换的问题。我刚才说，“固定坐标系下一个对象的变换等价于固定对象所处的坐标系变换”，那个“固定对象”我们找到了，就是那个向量。但是坐标系的变换呢？我怎么没看见？请看：Ma=Ib我现在要变M为I，怎么变？对了，再前面乘以个M-1，也就是M的逆矩阵。换句话说，你不是有一个坐标系M吗，现在我让它乘以个M-1，变成I，这样一来的话，原来M坐标系中的a在I中一量，就得到b了。我建议你此时此刻拿起纸笔，画画图，求得对这件事情的理解。比如，你画一个坐标系，x轴上的衡量单位是2，y轴上的衡量单位是3，在这样一个坐标系里，坐标为(1，1)的那一点，实际上就是笛卡尔坐标系里的点(2,3)。而让它原形毕露的办法，就是把原来那个坐标系:2 00 3的x方向度量缩小为原来的1/2，而y方向度量缩小为原来的1/3，这样一来坐标系就变成单位坐标系I了。保持点不变，那个向量现在就变成了(2,3)了。怎么能够让“x方向度量缩小为原来的1/2，而y方向度量缩小为原来的1/3”呢？就是让原坐标系：2 00 3被矩阵：1/2 00 1/3左乘。而这个矩阵就是原矩阵的逆矩阵。下面我们得出一个重要的结论：“对坐标系施加变换的方法，就是让表示那个坐标系的矩阵与表示那个变化的矩阵相乘。”再一次的，矩阵的乘法变成了运动的施加。只不过，被施加运动的不再是向量，而是另一个坐标系。如果你觉得你还搞得清楚，请再想一下刚才已经提到的结论，矩阵MxN，一方面表明坐标系N在运动M下的变换结果，另一方面，把M当成N的前缀，当成N的环境描述，那么就是说，在M坐标系度量下，有另一个坐标系N。这个坐标系N如果放在I坐标系中度量，其结果为坐标系MxN。在这里，我实际上已经回答了一般人在学习线性代数是最困惑的一个问题，那就是为什么矩阵的乘法要规定成这样。简单地说，是因为：1.从变换的观点看，对坐标系N施加M变换，就是把组成坐标系N的每一个向量施加M变换。2.从坐标系的观点看，在M坐标系中表现为N的另一个坐标系，这也归结为，对N坐标系基的每一个向量，把它在I坐标系中的坐标找出来，然后汇成一个新的矩阵3.至于矩阵乘以向量为什么要那样规定，那是因为一个在M中度量为a的向量，如果想要恢复在I中的真像，就必须分别与M中的每一个向量进行內积运算。我把这个结论的推导留给感兴趣的朋友吧。应该说，其实到了这一步，已经很容易了。综合以上1/2/3，矩阵的乘法就得那么规定，一切有根有据，绝不是哪个神经病胡思乱想出来的。我已经无法说得更多了。矩阵又是坐标系，又是变换。到底是坐标系，还是变换，已经说不清楚了，运动与实体在这里统一了，物质与意识的界限已经消失了，一切归于无法言说，无法定义了。道可道，非常道，名可名，非常名。矩阵是在是不可道之道，不可名之名的东西。到了这个时候，我们不得不承认，我们伟大的线性代数课本上说的矩阵定义，是无比正确的：“矩阵就是由m行n列数放在一起组成的数学对象。”好了，这基本上就是我想说的全部了。还留下一个行列式的问题。矩阵M的行列式实际上是组成M的各个向量按照平行四边形法则搭成一个n维立方体的体积。对于这一点，我只能感叹于其精妙，却无法揭开其中奥秘了。也许我掌握的数学工具不够，我希望有人能够给我们大家讲解其中的道理了。我不知道是否讲得足够清楚了，反正这一部分需要您花些功夫去推敲。此外，请大家不必等待这个系列的后续部分。以我的工作情况而言，近期内很难保证继续投入脑力到这个领域中，尽管我仍然对此兴致浓厚。不过如果还有（四）的话，可能是一些站在应用层面的考虑，比如对计算机图形学相关算法的理解。但是我不承诺这些讨论近期内会出现了。]]></content>
      <categories>
        <category>数学</category>
        <category>知识点</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[HMM之参数学习问题]]></title>
    <url>%2F2019%2F11%2F02%2FHMM%E4%B9%8B%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1. Baum-Welch算法原理鲍姆-韦尔奇算法使用的就是EM算法的原理，那么在第 h+1 次迭代时我们需要在E步求出联合分布$P(O,I；\lambda)$基于条件概率$P(I|O; \lambda^{(h)})$的期望，其中 $\lambda^{(h)}$ 为第 h 次迭代时的模型参数，然后在M步最大化这个期望，就能得到更新的模型参数$λ$，它就是 h+1 次迭代得到的模型参数。接着不停的进行EM迭代，直到模型参数的值收敛为止。 E步：联合分布$P(O,I; \lambda)$基于条件概率$P(I|O; \lambda^{(h)})$的期望表达式为： $$Q\left(\lambda, \lambda^{(h)}\right)=\sum_{I} P\left(I | O ; \lambda^{(h)}\right) \log P(O, I ; \lambda) \tag{1}$$ M步，极大化(1)式，然后得到更新后的模型参数： $$\lambda^{(h+1)}=\underset{\lambda}{\arg \max } \sum_{I} P\left(I | O ; \lambda^{(h)}\right) \log P(O, I ; \lambda) \tag{2}$$ 通过不断的E步和M步的迭代，直到$\lambda^{(h+1)}$ 收敛。 2. 推导已知条件：假设训练数据是长度为 T 的观测序列 $O = (o_1, o_2, … , o_T)$，所有可能的状态集合为 $Q = {q_1, q_2, … , q_N}$，所有可能的观测集合为$V = {v_1, v_2, … , v_M}$。 未知条件：假设长度为 T 的观测序列 O = (o1, o2, … , oT) 所对应的状态序列为 I = (i1, i2, … , iT)，它是未知的。 模型参数：$λ=(A,B,\pi)$ 首先来计算一下联合分布P(O, I；λ)的表达式： $$P(O, I ; \lambda)=\pi_{i_{1}} b_{i_{1}}\left(o_{1}\right) a_{i_{1} i_{2}} b_{i_{2}}\left(o_{2}\right) a_{i_{2} i_{3}} \ldots b_{i_{T-1}}\left(o_{T-1}\right) a_{i_{T-1} i_{T}} b_{i_{T}}\left(o_{T}\right) \tag{3}$$ 求Q函数的表达式： $$\begin{aligned} Q\left(\lambda, \lambda^{(h)}\right) &amp;=\sum_{I} P\left(I | O ; \lambda^{(h)}\right) \log P(O, I ; \lambda) \\ &amp;=\sum_{I} \frac{P\left(O, I ; \lambda^{(h)}\right)}{P\left(O ; \lambda^{(h)}\right)} \log P(O, I ; \lambda) \end{aligned} \tag{4}$$ 由于 $\lambda^{(h)}$ 是由上一次迭代推出的已知项，所以$P(O ; \lambda^{(h)})$ 也是一个固定值可以省略，等价于(5)式的极大化值： $$Q\left(\lambda, \lambda^{(h)}\right)=\sum_{I} P\left(O, I ; \lambda^{(h)}\right) \log P(O, I ; \lambda) \tag{5}$$ 最终的Q函数表达式为： $$\begin{aligned} Q\left(\lambda, \lambda^{(h)}\right) &amp;=\sum_{T} P\left(O, I ; \lambda^{(h)}\right) \log P(O, I ; \lambda) \\ &amp;=\sum_{I} P\left(O, I ; \lambda^{(h)}\right) \log \left(\pi_{l_{1}} \prod_{t=1}^{T} b_{i_{t}}\left(o_{t}\right) \prod_{t=1}^{T-1} a_{i_{t} i_{t+1}}\right) \\ &amp;=\sum_{I} P\left(O, I ; \lambda^{(h)}\right) \log \pi_{i_{1}}+\sum_{I}\left(\sum_{t=1}^{T} \log b_{i_{t}}\left(o_{t}\right)\right) P\left(O, I ; \lambda^{(h)}\right) \\ &amp;+\sum_{I}\left(\sum_{t=1}^{T-1} \log a_{i_{t} i_{t+1}}\right) P\left(O, I ; \lambda^{(h)}\right) \end{aligned} \tag{6}$$ 接下来极大化Q函数，求模型参数$\lambda (A,B,\pi)$, 分别对Q函数的三个子式进行极大化来求参数。 2.1 初始状态向量$\pi_i$的推导对(6)式中第一项极大化： $$\begin{aligned} \sum_{I} P\left(O, I ; \lambda^{(h)}\right) L o g \pi_{i_{1}} &amp;=\sum_{i_{1}} \sum_{i_{2}} \cdots \sum_{i_{T}} P\left(O, i_{1}, i_{2}, \ldots, i_{T} ; \lambda^{(h)}\right) \log \pi_{i_{1}} \\ &amp;=\sum_{i_{1}} P\left(O, i_{1} ; \lambda^{(h)}\right) \log \pi_{i_{1}} \\ &amp;=\sum_{i=1}^{N} P\left(O, i_{1}=q_{i} ; \lambda^{(h)}\right) \log \pi_{i_{1}=q_{i}} \\ &amp;=\sum_{i=1}^{N} P\left(O, i_{1}=q_{i} ; \lambda^{(h)}\right) \log \pi_{i} \end{aligned} \tag{7}$$ 因为有约束$\sum_{i=1}^{N} \pi_{i}=1$，所以使用拉格朗日函数： $$L(\pi_i) = \sum_{\mathrm{i}=1}^{N} P\left(O, i_{1}=q_{i} ; \lambda^{(h)}\right) \log \pi_{i}+\gamma\left(\sum_{i=1}^{N} \pi_{i}-1\right) \tag{8}$$ (8)式对$\pi_{i}$求导并令得到的式子等于0： $$P(O, i_1=q_i; \lambda^{(h+1)}) + \gamma \pi_i = 0 \tag{9}$$ 两边同时对i求和（连续函数求积分）： $$\sum_{\mathrm{i}=1}^{N} P\left(O, i_{1}=q_{i} ; \lambda^{(h)}\right)+\gamma \sum_{i=1}^{N} \pi_{i}=0 \tag{10}$$ 得到$\gamma$: $$\gamma=-P\left(O ; \lambda^{(h)}\right) \tag{11}$$ 将$\gamma$代回(9)式： $$\pi_{i}^{(h+1)}=\frac{P\left(O, i_{1}=q_{i} ; \lambda^{(h)}\right)}{\mathrm{P}\left(O ; \lambda^{(h)}\right)} \tag{12}$$ 2.2 发射矩阵$b_j(k)$的推导对(6)式中第二项极大化，因为最外层的累加和不影响最内层的累加和，所以去掉括号： $$\begin{array}{l}{\sum_{I}\left(\sum_{t=1}^{T} \log b_{i_{t}}\left(o_{t}\right)\right) P\left(O, I ; \lambda^{(h)}\right)} \\ {\quad=\sum_{I} \sum_{t=1}^{T} P\left(O, I ; \lambda^{(h)}\right) \log b_{i_{t}}\left(o_{t}\right)} \\ {\quad=\sum_{i_{1}} \sum_{i=1}^{T} P\left(O, I ; \lambda^{(h)}\right) \log b_{i_{t}}\left(o_{t}\right)} \\ {\quad=\sum_{i_{1}} \sum_{i_{2}} \ldots \sum_{i_{t}} \cdots \sum_{i_{T}} \sum_{t=1}^{T} P\left(O, i_{1}, i_{2}, \ldots, i_{t}, \ldots, i_{T} ; \lambda^{(h)}\right) \log b_{i_{t}}\left(o_{t}\right)} \\ {\quad=\sum_{i_{t}} \sum_{t=1}^{T} P\left(O, i_{t} ; \lambda^{(h)}\right) \log b_{i_{t}}\left(o_{t}\right)} \\ {\quad=\sum_{j=1}^{N} \sum_{t=1}^{T} P\left(O, i_{t}=q_{j} ; \lambda^{(h)}\right) \log b_{j}\left(o_{t}\right)} \\ {\quad=\sum_{j=1}^{N} \sum_{t=1}^{T} P\left(O, i_{t}=q_{j} ; \lambda^{(h)}\right) \log b_{j}\left(o_{t}\right)} \\ {\quad=\sum_{j=1}^{N} \sum_{t=1}^{T} P\left(O, i_{t}=q_{j} ; \lambda^{(h)}\right) \log b_{j}\left(o_{t}\right)}\end{array} \tag{13}$$ $b_{j}(k)$同样有约束条件，即$\sum_{k=1}^{M} b_{j}(k) = 1$ ，所以求出化简后的第二个子式的拉格朗日函数： $$L(b_{j}(k)) = \sum_{j=1}^{N} \sum_{t=1}^{T} P\left(O, i_{t}=q_{j} ; \lambda^{(h)}\right) \log b_{j}\left(o_{t}\right)+\gamma\left(\sum_{k=1}^{M} b_{j}(k)-1\right) \tag{14}$$ 拉格朗日函数对$b_{j}(k)$求导并令得到的式子为0，注意，在对第一项进行求导过程中，只有当$o_{t}=v_{k}$时才有导数，否则导数为0，可以加上一个指示函数$I(o_{t}=v_{k})$作为提示（更为严谨）： $$\sum_{t=1}^{T} \frac{P\left(O, i_{t}=q_{j} ; \lambda^{(h)}\right) I\left(o_{t}=v_{k}\right)}{b_{j}(k)}+\gamma=0 \tag{15}$$ 化简： $$\sum_{t=1}^{T} P\left(O, i_{t}=q_{j} ; \lambda^{(h)}\right) I\left(o_{t}=v_{k}\right)+\gamma b_{j}(k)=0 \tag{16}$$ 增加一个对t求和消除$\gamma$的系数项$b_j(k)$： $$\sum_{t=1}^{T} \sum_{\mathrm{k}=1}^{M} P\left(O, i_{t}=q_{j} ; \lambda^{(h)}\right) I\left(o_{t}=v_{k}\right)+\gamma=0 \tag{17}$$ 求出$\gamma$的值为： $$\gamma=-\sum_{\mathfrak{t}=1}^{T} P\left(O, i_{t}=q_{j} ; \lambda^{(h)}\right) \tag{18}$$ 将$\gamma$函数代入(16)式得到： $$b_{j}(k)^{(h+1)}=\frac{\sum_{t=1}^{T} P\left(O, i_{t}=q_{j} ; \lambda^{(h)}\right) I\left(o_{t}=v_{k}\right)}{\sum_{t=1}^{T} P\left(O, i_{t}=q_{j} ; \lambda^{(h)}\right)} \tag{18}$$ 2.3 转移矩阵$a_{ij}$的推导对(6)式中第三项极大化： $$\begin{array}{l}{\sum_{I}\left(\sum_{t=1}^{T-1} \log a_{i, i_{t-1}}\right) P\left(O, I ; \lambda^{(h)}\right)} \\ {\quad=\sum_{I} \sum_{t=1}^{T-1} P\left(O, I ; \lambda^{(h)}\right) \log a_{i, j+1+1}} \\ {\quad=\sum_{i_{1}} \sum_{i_{2}} \cdots \sum_{i_{t}} \sum_{i_{t+1}} \cdot \sum_{i_{T}} \sum_{t=1}^{T-1} P\left(O, i_{1}, i_{2}, \ldots, i_{t}, i_{t+1}, \ldots, i_{T}, \lambda^{(h)}\right) \log a_{i_{t},i_{t+1}}} \\ {\quad=\sum_{i_{t}} \sum_{i_{t+1}} \sum_{t=1}^{T-1} P\left(O, i_{t}, i_{t+1}, \lambda^{(h)}\right) \log a_{i_{t}, i_{t+1}}} \\ {\quad=\sum_{i=1}^{N} \sum_{j=1}^{N} \sum_{t=1}^{T-1} P\left(O, i_{t}=q_{i}, i_{t+1}=q_{j} ; \lambda^{(h)}\right) \log a_{i j}} \\ {\quad=\sum_{i=1}^{N} \sum_{j=1}^{N} \sum_{t=1}^{T-1} P\left(O, i_{t}=q_{i}, i_{t+1}=q_{j} ; \lambda^{(h)}\right) \log a_{i j}}\end{array} \tag{19}$$ $a_{ij}$ 的约束条件为$\sum_{j=1}^{N} a_{i j}=1$，求出其对应的拉格朗日函数： $$L=\sum_{i=1}^{N} \sum_{j=1}^{N} \sum_{k=1}^{T} P\left(O, i_{t}=q_{i}, i_{t+1}=q_{j}; \lambda^{h}\right)\log a_{ij}+\gamma\left(\sum_{j=1}^{N} a_{ij}-1\right) \tag{20}$$ 拉格朗日函数对$a_{ij}$求导，并令得到的式子为0： $$\sum_{t=1}^{T-1} \frac{P\left(O, i_{t}=q_{i}, i_{t+1}=q_{j} ; \lambda^{(h)}\right)}{a_{i j}}+\gamma=0 \tag{21}$$ 对$a_{ij}$中的j求和： $$\sum_{j=1}^{N} \sum_{t=1}^{T-1} P\left(O, i_{t}=q_{i}, i_{t+1}=q_{j} ; \lambda^{\left(h\right)}\right)+\sum_{j=1}^{N} \gamma a_{i j}=0 \tag{22}$$ 求得$\gamma$： $$\gamma=-\sum_{t=1}^{T-1} P\left(O, i_{t}=q_{i} ; \lambda^{(h)}\right) \tag{23}$$ 将$\gamma$代回(21)式：$$a_{i j}^{(h+1)}=\frac{\sum_{t=1}^{T-1} P\left(O, i_{t}=q_{i}, i_{t+1}=q_{j} ; \lambda^{(h)}\right)}{\sum_{t=1}^{T-1} P\left(O, i_{t}=q_{i} ; \lambda^{(h)}\right)} \tag{24}$$]]></content>
      <categories>
        <category>机器学习</category>
        <category>算法模型</category>
      </categories>
      <tags>
        <tag>HMM</tag>
        <tag>Baum-welch算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二分类与多分类]]></title>
    <url>%2F2019%2F11%2F01%2F%E4%BA%8C%E5%88%86%E7%B1%BB%E4%B8%8E%E5%A4%9A%E5%88%86%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[1. 如何使用二分类模型进行多分类？1.1 方法一：One Vs ALL假设我们要解决一个分类问题，该分类问题有三个类别，分别用△，□和×表示，每个实例（Entity）有两个属性（Attribute），如果把属性 1 作为 X 轴，属性 2 作为 Y 轴，训练集（Training Dataset）的分布可以表示为图a。One-Vs-All（或者叫 One-Vs-Rest）的思想是把一个多分类的问题变成多个二分类的问题。转变的思路就如同方法名称描述的那样，选择其中一个类别为正类（Positive），使其他所有类别为负类（Negative）。比如第一步，我们可以将三角形所代表的实例全部视为正类，其他实例全部视为负类，得到的分类器如图b。同理我们把 X 视为正类，其他视为负类，可以得到第二个分类器，如图c。最后，第三个分类器是把正方形视为正类，其余视为负类，如图d。 对于一个三分类问题，我们最终得到 3 个二元分类器。在预测阶段，每个分类器可以根据测试样本，得到当前正类的概率。即 P(y = i | x; θ)，i = 1, 2, 3。选择计算结果最高的分类器，其正类就可以作为预测结果。One-Vs-All 最为一种常用的二分类拓展方法，其优缺点也十分明显。 优点： 普适性还比较广，可以应用于能输出值或者概率的分类器，同时效率相对较好，有多少个类别就训练多少个分类器。 缺点： 很容易造成训练集样本数量的不平衡（Unbalance），尤其在类别较多的情况下，经常容易出现正类样本的数量远远不及负类样本的数量，这样就会造成分类器的偏向性。 可能会产生决策模糊区域，如下图绿色标记的区域无法判断属于哪一类： 1.2 方法二：One Vs One相比于 One-Vs-All 由于样本数量可能的偏向性带来的不稳定性，One-Vs-One 是一种相对稳健的扩展方法。对于同样的三分类问题，我们像举行车轮作战一样让不同类别的数据两两组合训练分类器，可以得到 3 个二元分类器。它们分别是三角形与 x 训练得出的分类器（图f），三角形与正方形训练的出的分类器（图g），以及正方形与 x 训练得出的分类器（图h）。 假如我们要预测的一个数据在图中红色圆圈的位置，那么第一个分类器会认为它是 x，第二个分类器会认为它偏向三角形，第三个分类器会认为它是 x，经过三个分类器的投票之后，可以预测红色圆圈所代表的数据的类别为 x，如下图所示。 优点： 在一定程度上规避了数据集 unbalance 的情况，性能相对稳定，并且需要训练的模型数虽然增多，但是每次训练时训练集的数量都降低很多，其训练效率会提高。 多个分类器的划分线如上图红色“人”字形所示，避免了产生决策模糊区域； 缺点： 虽然在本文的例子中，One-Vs-All 和 One-Vs-One 都得到三个分类器，但实际上仔细思考就会发现，如果有 k 个不同的类别，对于 One-Vs-All 来说，一共只需要训练 k 个分类器，而 One-Vs-One 则需训练 $C_{k}^{2}$ 个分类器，只是因为在本例种，k = 3 时恰好两个值相等，一旦 k 值增多，One-Vs-One 需要训练的分类器数量会大大增多，同时在预测的时候需要用到的分类器数量也同样会增多，所费时间会多一点。 2. 多个二分类器组成的多分类器与Softmax分类器的区别 Softmax理解之二分类与多分类——(这个涉及梯度的各种问题，有利于自己对梯度的理解)]]></content>
      <categories>
        <category>机器学习</category>
        <category>策略</category>
      </categories>
      <tags>
        <tag>二分类</tag>
        <tag>多分类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解高斯分布]]></title>
    <url>%2F2019%2F10%2F30%2F%E7%90%86%E8%A7%A3%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%2F</url>
    <content type="text"><![CDATA[1. 正态分布的前世今生 正态分布的前世今生 2. 从一维推导多维高斯分布 知乎第二个回答 3. 高斯分类模型与其他模型的联系 监督学习–生成学习算法]]></content>
      <categories>
        <category>数学</category>
        <category>知识点</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[高等数学和数学分析教材推荐及其学习方法浅谈]]></title>
    <url>%2F2019%2F10%2F03%2F%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%92%8C%E6%95%B0%E5%AD%A6%E5%88%86%E6%9E%90%E6%95%99%E6%9D%90%E6%8E%A8%E8%8D%90%E5%8F%8A%E5%85%B6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%B5%85%E8%B0%88%2F</url>
    <content type="text"><![CDATA[原文 不管哪个科目的教材选择，一旦决定要学我总试图找一本较好的来，次一点的我也懒得花时间精力投入在上面——这就是我的完美主义情节！当我进入大学想自学高等数学时，我也同样试图去找一本较好的教材。刚找的时候，网上很多人推荐同济大学的那本高等数学书，说是好多学校都在用，又因为同济大学在国内也算是名牌，基于这两个因素我就开始用它来学习高等数学，但是跟着这本书学了一段时间后，我经常会就课本上的内容问一些更深入的问题，也就是说这本书对于我来说在一些细节上没有进行深入，或在一些内容的讲解上不够彻底（比如说洛必达法则为什么也适用于$x→∞$时的0/0型未定式该书第七版上就根本没有证明，仅仅是告诉你个结论），当我老是带着这类问题去请教别人的时候，有人就建议说：如果我想好好学习大学数学的话那么就不要在高等数学上浪费时间，去看数学分析的书，因为数学分析的书讲得更全面、更透彻，就这样我告别了同济大学的高数书（这本书估计还是不太好，其不足之处这里的讨论也很有道理），接下来的任务就是去找一本好一点数学分析教材（后文我还会推荐高数学习用书，别走开）。我在网上看了好多数学分析教材推荐的帖子，综合这些帖子里各本书被提及的频繁程度、网友的好评度还有作者的名气，我罗列了如下一个供选择的书单： 常庚哲，史济怀，《数学分析教程》 陈纪修，於崇华，金路，《数学分析》 华东师范大学数学系，《数学分析》 张筑生，《数学分析新讲》 菲赫金哥尔茨，《微积分学教程》 华罗庚，《高等数学引论》 柯朗，约翰，《微积分和数学分析引论（中文版）》 小平邦彦，《微积分入门》 陶哲轩，《实分析》 Walter Rudin，《数学分析原理》 Adrian Banner，《普林斯顿微积分读本》 每本我大体上都看过一下，但最终未能看完其中任何一本的四分之一，究其原因，一是这些书基本上都讲得太详细了，里面涉及数学分析的各种细枝末节，概念和内容都比较多，并且还有好多证明，这些内容理解掌握起来并不是很容易，在用这些书的学习过程中我经常碰到理解不了或者要花很长时间才能解决的问题，比如说一开始除了要弄清楚为什么要学习实数基本理论这个大问题外，每个人都不得不面对的另外一大阻碍是对极限的 $(ε, δ)$定义的理解，这个严谨的极限定义一下子就把原本看似简单直观好理解的极限概念变得面目全非、不知所云起来，不花一番大功夫是很难理解这种表述的意义的。我尝试过对这个极限定义的囫囵吞枣——能用所谓的$(ε, δ)$语言证明极限，但是每当这样做的时候我心中还是没有多少底气，也不知道自己在干什么，即便是硬着头皮往后学，但对该定义的不理解始终让我耿耿于怀。对于一个初学者来说，若不花长时间和下苦功夫是很难彻底搞懂这些内容的。用这些书学起来太慢，也比较困难，以至于时常给我带来学习高等数学的挫败感，所以最终我未能用这些书坚持学下去。我差不多有过三次用这些书屡学屡败的高数学习经历，后来我认识到这些写得较为全面详细的书基本上是不适于初学者用来自学的，原因且看下文。在怀着高数难学的挫败感停滞学习一段时间后，我发现了美国俄亥俄州立大学的Calculus One课程，它算是高数的入门课，课程里不讲让很多人不知所云的极限 (ε, δ)定义，而是用直观易理解的方式讲解了高数里的基本概念和原理，我一开始对这种减去严谨极限定义的教学方式也是有点不放心，但想着老美总有自己的教学理念和想法，况且还是美国名校出的课程，所以就暂时放下了这种纠结跟着课程走。在学了三四个单元之后我发现跟着这个课程可以把高数学下去了！好高兴！终于没有再出现屡学屡败的高数学习状况了！就这样我的高数学习信心又慢慢地建立起来了！“每个教学视频的开头和结尾带感的音乐、极其富有激情的讲师、简单直观的讲解方式”——这一切让我渐渐地喜欢上了这个课程。在完成了这个课程三分之二内容后，我在该课程的学习中碰到了一个迈不过去的问题，我开始放下这个课程去思考这个问题，同时也去思考高数和数学里的一些基本问题，如公理、实数理论等。当我们在用一本书（或跟一门课）学习的时候，基本上不可能不在学习中产生疑问，除去我们自己的原因之外，也有书本的原因：正如人无完人一样，没有哪一本书是完美无瑕的，以至于能解决你在该科目学习过程中的所有问题，所以我强烈建议自学者除了选一本较好的教材作为学习主轴后也要再多找几本同类教材作参考书，以便一本书上的知识点讲解看不懂的时候可以看另一本上的来打开思路。若看书也不能解决问题，那么还可以把你的数学问题用英文写了发在Mathematics Stack Exchange这个网络社区里问一问，老外们乐于助人的品质、对数学的热情、认真负责的态度都很感染我——向他们学习！顺便一提：中学时期看不懂教材我们可以买很多参考书来看，但到大学来想找本参考书就不太容易了，原因之一我想是高等教育领域的应试教育市场经济不够繁荣所致。再回来说Calculus One这个课程，它是很不错的入门课，可以把初学者领进高数学习的大门。该课程不讲极限的 $(ε, δ)$定义极有可能是考虑到了该课程的受众——高数初学者，相反如果一开始就带初学者去折腾实数基本理论和这个严谨的极限定义，那么正如你我认识到的那样，这很大程度上会给初学者带来高数学习的挫败感和畏难情绪，我在高数自学过程中就走过这条坎坷路，也还好找到了这个课程，从此终于可以把高数学下去！后来我又了解到：即便是国外名校的数学系课程也基本上是先开这种入门课，课程名通常是Calculus（微积分，相当于国内的“高等数学”），甚至还会有更基础、更简单的微积分先修课程PreCalculus，等学生掌握了基础课程后才会开数学分析之类的深度课程。这种循序渐进、由易到难的安排有效降低了高数学习的难度，也体现了一种对新手的关怀。在这里我摘录美国几所大学的高数入门和深入课程的先后顺序给大家看下（课号大的课都是安排在后面上的）： 斯坦福大学数学系 课程代码 课程名 Math 19 Calculus（相当于“高数入门课”） Math 205A Real Analysis（相当于“数学分析”） 普林斯顿数学系 课程代码 课程名 MAT 103 Calculus I MAT 215 Honors Analysis (Single Variable) 麻省理工学院数学系 课程代码 课程名 18.01 Calculus 18.100A / 1001 Real Analysis 国内高数教学又是怎样的状况？！在此我不想多抱怨，只是认识到：在国内如果想要学好高等数学的话，“自学”应该是绝大多数人的不二之选。对于一个想要学习高数的人来说，首先应该弄清楚的是自己的角色——初学者。在我看来，高数初学者一开始不用学得那么全面，甚至不用去管极限的 (ε, δ)定义，而是要先观其大略地过它一遍、先入门，这并非是走马观花，而是要理解核心思想、掌握主干，等掌握了大略之后再深入细节会轻松很多，这样才不会一开始学就被各种细枝末节绕得云里雾里的以至于不能对这门学科有全局的把握，我们要有的是一个循序渐进的过程！北京大学的张筑生教授也在其《数学分析新讲》的序言里表达了同样的观点：“微积分本来是一件完整的艺术杰作，现在却被拆成碎片，对每一细部进行详尽的、琐细的考察。每一细节都弄得很清楚了，完整的艺术形象却消失了。今日的初学者在很长一段时间里只见树木不见森林……我们希望尽可能早一点让初学者对分析的全貌有一个轮廓的印象，尽可能早一点让初学者学会用分析的方法去解决问题……等到学生对全貌有了初步的印象之后，再具体进行涉及细节的讨论……”（题外话：虽然张老师在写他这本教材的时候也有了这种考量，但这本书在我看来还是写得过于详细繁琐了些）这种先观大略的学习方法也适合其他科目的学习，《斯坦福大学公开课：编程方法学》里也提到过这种方法 “工欲善其事，必先利其器”，为了做到高数学习上面的“先观大略”，我推荐的入门教材是Morris Kline的 Calculus: An Intuitive and Physical Approach (Second Edition)（可在Google Play上购买），这本书可说就是为此而生的——各位读完该书的序言后便知，我推荐每个想要学好高数的人都去看看这个序言，大有裨益！下面我转述序言中几个可能会对大家学习有帮助的观点。微积分入门课的教学有严谨和直观两种方式，Morris Kline认为应该采用直观的方式进行，并且在教学中应该多谈其应用，严谨的方式适合于微积分的高阶课程。入门课就用严谨的方式（我认为这是当今国内的普遍做法）有以下几种弊端： 其一，严谨的方式要求初学者学习很多微妙、难以捉摸的概念，这对初学者来说是很有难度的，更何况有些概念的提出还曾困扰了数学家两百年之久。在那个为微积分建立严谨基础的时代里，即便是柯西（Cauchy）这样的大数学家也搞混了连续和可导（continuity and differentiability）、收敛和一致收敛（convergence and uniform convergence）间的区别。 其二，如果一个学生要学懂一个概念或定理的严谨化表述，那么在这之前他必须知道这种严谨化表述所要传达的思想的雏形是什么、起始时的直观思想是什么（这就很可能需要去看相关的数学史，顺便一提：看数学史对我们学习数学也是非常有帮助的），进而才可能理解严谨化表述的意义——严谨化表述为什么能够避免直观化表达的不足、严谨化表述所要得到的是什么样的结果和传达什么样的思想，这就势必会增加学生的学习量，而一个初学者若要循此道学习，那么他要学习的内容将会是非常庞大的，以至于可想而知的是他的学习进度会很慢，他也极有可能会陷入这门学科的细枝末节中纠缠不清，进而看不清这门学科的全貌； 其三，让初学者一开始就学习经过严谨化整理出来的内容会让他们看不到知识的产生过程，也容易让他们以为：“高等数学是推导出来的，建立这门学科的每一步都是有根有据、正确无疑的，好的数学家的思考方式也是一步一步走的、在出结论之前所有的细节都已经缜密地处理好”，但实际上并非都如此，数学知识的产生也是可以通过“认识到之前的做法有问题，然后再改正”来产生的， “微积分这座大厦是从上往下施工建造起来的。微积分诞生之初就显示了强大的威力，解决了许多过去认为是高不可攀的困难问题，取得了辉煌的胜利。创始微积分的大师们着眼于发展强有力的方法，解决各式各样的问题。他们没有来得及为这门新学科建立起经得起推敲的严格的理论基础。在以后的发展中，后继者才对逻辑的细节作了逐一的修补”（选自张筑生《数学分析新讲》的序言），也就是说数学家的思维方式并非总是循序渐进的，他们的思维方式也可以是跳跃性的、天马行空的，也有可能不严谨或出错，并非像写证明过程那样非常讲究每个点的先后顺序、是一步一步走到最终结论的，有时候甚至是先有“猜想”然后才去求证中间过程的。Morris Kline在他这本书中也通过展示数学理论是可以通过先猜想，然后尝试和摸索，进而认识到犯错了，然后再更正的方式探索出来的，这种做法我认为很有价值，因为它向初学者完整地揭示数学理论产生的思路历程，向我们展示了如何研究数学，这也避免了我们看有些别的同类书时碰到的一些匪夷所思的“神来之笔”时所产生的惊奇——为什么作者会想到这个变换、这种构造？ 严谨化在数学里有其重要意义，它是对起始时的想法的核实、对初步想法的精炼，可以避免直觉可能带来的错误或遗漏之处，但如Henri Lebesgue（亨利·勒贝格，著名数学家）所说：“严谨化、逻辑化可以帮助我们否定猜想和假设，但是它不能创造任何猜想和假设。” 数学的核心思想来源于直观思维，严谨化并不能对这些数学思想产生质的改观，它起到的作用只是巩固和对这些思想的去伪存真。此外，严谨的表达方式不容易掌握，对我们理解数学思想的帮助也不大，所以严谨化方式的微积分入门课教学对初学者是不利的， Morris Kline引用Samuel Johnson（英国作家、文学评论家和诗人）的话对这种方式的教学效果评价到：“我为你提供了它的证明过程，但是帮助你理解它并不是我的义务。”Morris Kline也谈到了好多高等数学入门教材共有的一个严重问题——把数学和它的应用完全割裂开来。这些书里基本都是些符号的演算，也差不多全然不谈数学理论的运用，乍看之下会让人觉得高等数学就是一堆折腾符号的玩意儿，写这些书的人忽略的大问题是：学习微积分这门课程的不少学生未来将会是工程师或科学家，他们必须知道怎么应用微积分、应用数学才行，如果只是教他们折腾符号、搞些不知所云的、看不到什么应用的证明，那么整个数学教育的意义便会大打折扣。通过以上这些Morris Kline的观点，大家或许也和我一样感受到了他对初学者的微积分教学的深刻认识，也正是如此我才推荐初学者去看他这本书。我首先接触到的Morris Kline的书是《Mathematical Thought from Ancient to Modern Times》（中译本：古今数学思想），看过几个章节1后便深深佩服其对数学本质及其发展史的深刻认识，后来又看到这个书的序言后就更是对Morris Kline佩服无比了，从此自认为他是我的数学导师！我上文“建议自学者选一本较好的教材作为学习主轴后再多找几本同类教材作参考书，以便一本书上的知识点讲解看不懂的时候可以看另一本上的来打开思路”，我个人常用的两本高数学习辅助教材（参考书）分别是Richard Courant, Fritz John, Introduction to Calculus and Analysis(Reprint of the 1989 edition) 和 陈纪修、於崇华、金路的《数学分析》。各位学完如上面推荐的这种入门教材后，若要深入学习高数，可以看Richard Courant, Fritz John, Introduction to Calculus and Analysis(Reprint of the 1989 edition)，这本书也是大师之作，该书的一大难能可贵之处在于对一些数学定理的揭示，作者仅用很直白的语言叙述就可以让读者洞见定理的本质，每当看到这种内容时我不禁感叹：“原来如此！作者的功力也太深厚了吧！”而国内的书多半倾向于用各种符号去证明定理的正确性，这些证明不是很好掌握，我个人看后通常的感触是“该定理正确”，然后并没有什么深刻的认识，更别说和之前学过的知识融会贯通了。与这本书对应的辅助教材我就暂时无法推荐了，因为我还没有深入学习高数。上面给大家推荐的这两本皆是英文教材，为什么要看英文版呢？因为优秀的中文学习资料不太多，所以想只用中文资料学好科学或技术类学科的支援不太多，学起来会很费劲，并且这年头英语是学术界的主流语言，很多新的、一流的资料都用英文写成，也就是说优秀的英文学习资源是比较丰富的，在优质资源充裕的环境里学习会不会更好更轻松呢？大家自有评判！其实阅读英文写的专业资料并不是太难，如果大学之前的那些英文语法和单词你掌握得都还行，那么接下来你在英文版专业资料阅读过程中主要的障碍是陌生单词多的问题，对此大家找个词典软件辅助阅读就会顺畅很多，比如有道词典、欧路词典之类的，当然也可以考虑使用我的英酷词典，它主要就是为助力我们的英文阅读而生的。如果你不能做到通畅阅读英文但还有个科学梦的话，那么你实现梦想的几率是不太高的。你也许会问：看中译本行不行？如果你看的是小说传记之类的对逐字逐句准确度要求不高的书，那么可以看，但若要看如高数之类的对逐字逐句准确度要求较高的书的话，那么看中译本很难行！主要问题是中文翻译不容易做到准确传达英文原版的意思（这要求译者花费大量心思去尽可能地做到准确翻译，然而因为各种原因鲜有这种高标准翻译的促成），这就会导致翻译过来的内容有失真或曲解的情况，以至于中译本的读者读起来在理解内容上很费力，花了很多功夫尝试去理解而最终却无果的情况也不少有，然而这时候要再去看下英文原版，原来的疑惑很可能突然就拨云见日了——全是翻译问题搞的鬼！ 总体来说高数算是西学，而我们用的中文版高数教材的很多定理的名称都是翻译过来的，这些翻译显得很有“文言功底”，我认为这是不好的翻译，因为当代人看起来不易见名会义，而看英文版的教材的话很大程度上能够避免这个问题。以上就是我自学高数探索出来的一些经验总结，希望后来者看后有一定帮助。本篇成文于2018年10月16日，文中所描述的一些事实可能会随着时间的推移而发生变化，请读者自行分辨！ 有兴趣的读者可以看一下我当时阅读的摘要与记录 建议跟着书本/练习题学习，推荐一个不错的网址 https://docs.irudder.me/further-mathematics-docs/ 挺不错的在线的高数课本 ie好像有毒，建议使用google浏览器]]></content>
      <categories>
        <category>数学</category>
        <category>学习指导</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[对Bug的认知与处理（Debug）]]></title>
    <url>%2F2019%2F09%2F25%2F%E5%AF%B9Bug%E7%9A%84%E8%AE%A4%E7%9F%A5%E4%B8%8E%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[1. 对于Bug的态度 Bug的“好处” 我们可以通过Bug的级别、数量、形式等判断一个程序员的编码、逻辑等方面的成长和对项目、编程语言、使用的库的熟练度等等；可以说，Bug的修复史就是程序员的成长史，好的程序员（或者说有经验的程序员）会有足够多的经验做出预判，并且在他们交付测试之前，往往会比测试人员测试得更加仔细，以便提前发现自己的问题，从而减少bug，即便是在debug的时候他们也能更快地修复bug。 Bug的坏处 它会影响程序的运行甚至中断运行或者说执行错误的操作； 它的产生是不可避免的，产生bug的原因既有内在原因（程序员能力、经验…）也有内在原因（程序员所处环境、状态…），所以说它是不可能完全避免的，虽然说不可完全避免，但我们可以尽可能减少它； 综上，对于Bug的态度应该是积极的，因为无论如何我们都不能完全避免，既然不能完全避免，那我们不如有一个积极的态度，这样对于debug也是有利的，对于自己的心态也算是一个磨炼。 2. Bug的级别 Bug区分优先级的原因 决定什么时候可以发布系统，什么时候应该放弃发布系统，什么时候应该舍弃一些功能； 决定了程序员修复bug的顺序； Bug的级别 Critical的Bug是最严重的，代表着系统崩溃，完全不可用。这种Bug出现，就是最严重的事故，完全打不开，比如说，网站无法访问，点击出现系统错误，直接跳转到404页面。要注意的就是，Bug的严重程度和它易于修复的程度并不总是一致，举个例子，当用户打开修真院网址的时候发现打不开，这是非常严重的，Critical级别的Bug。最后发现原因很简单，域名过期，解决方案也很简单，就是交钱续费而已。一个系统是否能正常运行，并不在于导致它不能运行的问题复杂或简单。 Block的Bug也是非常严重的，它的含义是，用户的操作被卡住了，无法进行下一步。系统并没有大规模的崩溃，而是无法进行到下一步。拿12306来说，当你选好车票的时候，想要点击购买，这个时候却发现购买按钮点击之后无法使用，而其他的一切功能都正常。这就是Block级别的Bug，一个地方卡死，导致你无法进行下一步的操作。 Major的Bug是严重的，也是在Bug体系里的一个分界线，通常也是决定系统上线与否的分界线，绝大多数团队在初期的目标，都应该是在提交测试之前，完全消除Major级别的Bug，减少Normal级别的Bug数量。Major的Bug通常是指流程可以走的通，但是关键的业务或者是数据错误，影响用户的正常使用。比如说，在修真院的师兄弟体系中，你加入了班级，按理来说应该分配一个师兄。你按提示完成操作，但是却没有被分配到任何师兄。这种级别的Bug往往是不没有任何操作流程上的问题，但是就是和预期的结果不对，而且影响了用户的正常使用，特别是在关键业务逻辑上。 Normal的Bug就比较常见了，像一些分支业务逻辑里，偶尔会出现的问题，又或者是一些不太重要的地方出现的错误。通常我们知道他是一个Bug，但是对大部分用户来说都无关紧要，可以用，可以不用，我们知道他有Bug，噢，没关系，我可以等等。Normal的Bug应该被控制数量，我们建议的数量，是在开发人员提交测试之后，不超过3个。- - - Normal的Bug通常情况下都很容易被发现，不需要花太大的力气去寻找。Minor的Bug，指那些无伤大雅的小问题，通常是指兼容性，不重要的文案错别字，样式错误等。这种Bug上原则上的修复时间看开发人员的空闲期。 3. 编码阶段（防止Bug） 在写程序的时候就应该注意细节，并且不要养成以为有堆栈这种帮你检测出错地方的组件而不注重细节的习惯和依赖性，这是对于防止bug出现的措施； 4. Debug阶段 优先解决可重现的，测试环境、前提条件是重现问题的关键。可重现的bug一般比较好找，反复调试测试就好了，这也是一种排除问题产生原因的方法之一，为找到更难的bug节约时间； 对于一些没有头绪地稀奇古怪的bug，可以直接询问有此经验的同事，特别是针对于做了很久的项目，他们也许比你更熟悉这些bug； 放大现象，有些bug现象不太明显，那么就想办法增大它的破坏性，把现象放大。这只是个思路，具体怎么放大只能根据具体的代码来定。比如：美剧《豪斯医生》里有一集，怀疑病人心肺有问题，就让病人去跑步机上跑步，加重心肺负担，从而放大症状。 注释排查法（二分查找法），把程序逻辑一点点注释掉，看看还会不会出问题，逐步缩小问题范围； 打印中间结果，把程序运行过程中容易出问题的变量打印出来，看看是否是它们真的出了问题； 模拟现场，有时候我会问自己，如果我要实现bug描述的现象我要怎么写代码才行？ 制作工具，针对某些类型的bug，自己写一套检测工具； 重读（写）程序，从头到尾再阅读一遍程序，但是这种方法比较耗费时间，并且针对的是比较容易查出来的错误，对于隐藏比较深的特别是逻辑上的错误，这种方法并不是很适用，但它可以帮你排除编码上的错误，而大部分的bug，其实都是typo（打字错误），从而让你从逻辑的角度审视这个bug产生的原因； 讲故事（小黄鸭调试法），很多时候在给别人讲自己的问题的时候，自己就找到原因了，也可以试试这种方法；（传说程序大师都会随身携带一只小黄鸭，在调试代码的时候就把它放在桌子上，然后向小黄鸭解释每行代码）； 用好IDE，一些好用的IDE也是帮助自己节省时间的利器； 了解专业的测试技术，适当学习一些专业的测试技术可以更准确、更快的debug； 参考]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>bug</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[逻辑回归的延伸拓展]]></title>
    <url>%2F2019%2F08%2F27%2F%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E5%BB%B6%E4%BC%B8%E6%8B%93%E5%B1%95%2F</url>
    <content type="text"><![CDATA[1. LR基本特点逻辑回归（LR,Logistic Regression）是传统机器学习中的一种分类模型，由于LR算法具有简单、高效、易于并行且在线学习（动态扩展）的特点，在工业界具有非常广泛的应用。 逻辑回归强化路线： 线性模型LR(没有考虑特征间的关联)——&gt;LR +多项式模型（特征组合，不适用于特征稀疏场景，泛化能力弱）——&gt;FM（适用于稀疏特征场景*，泛化能力强）——&gt;FFM【省去零值特征，提高FFM模型训练和预测的速度，这也是稀疏样本采用FFM的显著优势】 在线学习算法：LR属于一种在线学习算法，可以利用新的数据对各个特征的权重进行更新，而不需要重新利用历史数据训练。 实际开发中，一般针对该类任务首先都会构建一个基于LR的模型作为Baseline Model，实现快速上线，然后在此基础上结合后续业务与数据的演进，不断的优化改进！ 逻辑回归是假设数据服从Bernoulli分布，因此LR属于参数模型 2. LR如何解决线性不可分问题逻辑回归本质上是一个线性模型，但是，这不意味着只有线性可分的数据能通过LR求解，实际上，我们可以通过2种方式帮助LR实现： 利用特殊核函数，对特征进行变换：把低维空间转换到高维空间，而在低维空间不可分的数据，到高维空间中线性可分的几率会高一些； 扩展LR算法，提出FM算法； 2.1 使用核函数（特征组合映射）针对线性不可分的数据集，可以尝试对给定的两个feature做一个多项式特征的映射，例如： $$\text { mapFeature }(x)=\left[\begin{array}{c}{1} \\ {x_{1}} \\ {x_{2}} \\ {x_{1}^{2}} \\ {x_{1} x_{2}} \\ {x_{2}^{2}} \\ {x_{1}^{3}} \\ {\cdots} \\ {x_{1} x_{2}^{5}} \\ {x_{2}^{6}}\end{array}\right]$$ 下面两个图的对比说明了线性分类曲线和非线性分类曲线（通过特征映射） 左图是一个线性可分的数据集，右图在原始空间中线性不可分，但是利用核函数，对特征转换 $[x_1,x_2]=&gt;[x_1,x_2,x^2_1,x^2_2,x_1 x_2]$ 后的空间是线性可分的，对应的原始空间中分类边界为一条类椭圆曲线。 在LR中，我们可以通过在基本线性回归模型的基础上引入交叉项，来实现非线性分类，如下： $$\hat{y} :=w_{0}+\sum_{i=1}^{n} w_{i} x_{i}+\sum_{i=1}^{n-1} \sum_{j=i+1}^{n} w_{i j} x_{i} x_{j}$$ 但是这种直接在交叉项$x_i x_j$的前面加上交叉项系数$w_{ij}$的方式在稀疏数据的情况下存在一个很大的缺陷，即在对于观察样本中未出现交互的特征分量，不能对相应的参数进行估计。即，在数据稀疏性普遍存在的实际应用场景中，二次项参数的训练是很困难的。其原因是，每个参数$w_{ij}$的训练需要大量$x_i$和$x_j$都非零的样本；由于样本数据本来就比较稀疏，满足$x_i$和$x_j$都非零的样本将会非常少。训练样本的不足，很容易导致参数 $w_{ij}$ 不准确，最终将严重影响模型的性能。 2.1.1 为什么特征稀疏 —— one-hot编码带来的问题在机器学习中，尤其是计算广告领域，特征并不总是数值型，很多时候是分类值，对于categorical feature，通常会采用one-hot encoding转换成数值型特征，转化过程会产生大量稀疏数据（如果不使用one-hot转换，那么必然使用整数进行序号替代，但是对整数进行权重训练，整数（即序号）越大的相当于变相增大了相应的特征权重从而造成了偏差）。 可以这么理解：对于每一个特征，如果它有m个可能取值，那么经过one-hot encoding之后，就变成了m个二元特征，并且，这些特征互斥，每次只有一个激活，因此，数据会变得稀疏。 one-hot编码带来的另一个问题是特征空间变大。同样以上面淘宝上的item为例，将item进行one-hot编码以后，样本空间有一个categorical变为了百万维的数值特征，特征空间一下子暴增一百万。所以大厂动不动上亿维度，就是这么来的。 在工业界，很少直接将连续值（eg.年龄特征）作为逻辑回归模型的特征输入，而是将连续特征离散化为一系列0、1特征交给LR。 2.1.2 LR为什么要对连续数值特征进行离散化 离散特征的增加和减少都很容易，易于模型的快速迭代； 稀疏向量內积乘法速度快，计算结果方便存储，容易扩展； 离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄 &gt; 30 是 1，否则 0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰； 逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合； 离散化后可以进行特征交叉，由$M+N$个变量变为$M*N$个变量，进一步引入非线性，提升表达能力； 特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄增长了一岁就变成了一个完全不同的人。当然处于区间相邻处的样本会刚好相反，所以怎么划分区间是门学问； 特征离散化以后，起到了简化逻辑回归模型的作用，降低了模型过拟合的风险； 李沐曾经说过：模型是使用离散特征还是连续特征，其实是一个“海量离散特征+简单模型” 同 “少量连续特征+复杂模型”的权衡。既可以离散化用线性模型，也可以用连续特征加深度学习。就看是喜欢折腾特征还是折腾模型了。通常来说，前者容易，而且可以n个人一起并行做，有成功经验；后者目前看很赞，能走多远还须拭目以待。 2.2 使用FM模型因子分解机（Factorization Machine，FM）是对LR算法的扩展。FM模型是一种基于矩阵分解的机器学习模型，对于稀疏数据具有很好的学习能力；对于因子分解机FM来说，最大的特点是对于稀疏的数据具有很好的学习能力。FM解决了LR泛化能力弱的问题，其目标函数如下所示： $$\hat{y}=w_{0}+\sum_{i=1}^{n} w_{i} x_{i}+\sum_{i=1}^{n-1} \sum_{j=i+1}^{n}\left\langle V_{i}, V_{j}\right\rangle x_{i} x_{j}$$ 3. LR与SVM的参照比较3.1 LR与SVM的联系与区别3.1.1 联系 LR和SVM都可以处理分类问题，且一般都用于处理线性二分类问题（在改进的情况下可以处理多分类问题）； 两个方法都可以增加不同的正则化项，如l1、l2等等。所以在很多实验中，两种算法的结果是很接近的； 3.1.2 区别 LR是参数模型[逻辑回归是假设y服从Bernoulli分布]，SVM是非参数模型，LR对异常值更敏感； 从目标函数来看，区别在于逻辑回归采用的是logistical loss，SVM采用的是hinge loss，这两个损失函数的目的都是增加对分类影响较大的数据点的权重，减少与分类关系较小的数据点的权重； SVM的处理方法是只考虑support vectors，也就是和分类最相关的少数点，去学习分类器。而逻辑回归通过非线性映射，大大减小了离分类平面较远的点的权重，相对提升了与分类最相关的数据点的权重； 逻辑回归相对来说模型更简单，好理解，特别是大规模线性分类时比较方便。而SVM的理解和优化相对来说复杂一些，SVM转化为对偶问题后,分类只需要计算与少数几个支持向量的距离,这个在进行复杂核函数计算时优势很明显,能够大大简化模型和计算； LR能做的svm能做，但可能在准确率上有问题，svm能做的logic有的做不了； 模型复杂度：SVM支持核函数，可处理线性非线性问题;LR模型简单，训练速度快，适合处理线性问题;决策树容易过拟合，需要进行剪枝损失函数：SVM hinge loss; LR L2正则化; adaboost 指数损失数据敏感度：SVM添加容忍度对outlier不敏感，只关心支持向量，且需要先做归一化; LR对远点敏感数据量：数据量大就用LR，数据量小且特征少就用SVM非线性核 3.2 如何选择LR与SVM 如果Feature的数量很大，跟样本数量差不多，这时候选用LR或者是Linear Kernel的SVM； 如果Feature的数量比较小，样本数量一般，不算大也不算小，选用SVM+Gaussian Kernel； 如果Feature的数量比较小，而样本数量很多，需要手工添加一些feature变成第一种情况； 4. 扩展4.1 什么是参数模型（LR）与非参数模型（SVM）在统计学中，参数模型通常假设总体（随机变量）服从某一个分布，该分布由一些参数确定（比如正太分布由均值和方差确定），在此基础上构建的模型称为参数模型；非参数模型对于总体的分布不做任何假设，只是知道总体是一个随机变量，其分布是存在的（分布中也可能存在参数），但是无法知道其分布的形式，更不知道分布的相关参数，只有在给定一些样本的条件下，能够依据非参数统计的方法进行推断。 5. ToDo FM的进一步研究； 6. 参考 万字干货|逻辑回归最详尽解释]]></content>
      <categories>
        <category>机器学习</category>
        <category>算法模型</category>
      </categories>
      <tags>
        <tag>Softmax</tag>
        <tag>Logistics Regression</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Softmax求导详解]]></title>
    <url>%2F2019%2F08%2F24%2FSoftmax%E6%B1%82%E5%AF%BC%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[1. Softmax函数设输入向量$x \in \mathbb{R}^{n}$，$z_ {i}=w_{i}^{T} x+b_{i}, i=1,2, \ldots, k$，则$z=\left[z_{1}, z_{2}, \ldots, z_{k}\right] \in \mathbb{R}^{k}$。直观上来看如图： 那么softmax函数就是一个输入、输出均为向量的函数，其输入向量为$z \in \mathbb{R}^{k}$，输出向量为$s \in \mathbb{R}^{k}$，定义： $$s=\operatorname{softmax}(z) \tag{1}$$ 对向量$s$的第$i$个分量有： $$s_{i}=\frac{e^{z_{i}}}{\sum_{j=1}^{K} e^{z_{j}}}, i=1,2, \ldots, k \tag{2}$$ 2. 交叉熵损失函数假设某个样本$x$对应的标签y为一个向量，且$y=\left[y_{1}, y_{2}, \ldots, y_{k}\right] \in \mathbb{R}^{k}$。而样本经过某个神经网络模型的softmax层后输出的向量为$s \in \mathbb{R}^{k}$。如果使用交叉熵损失函数，那么该样本上的损失为： $$L=-\sum_{k=1}^{K} y_{k} \ln s_{k} \tag{3}$$ 3. Softmax函数的导数我们的目标是要求$\frac{\partial L}{\partial w_ {i}}$和 $\frac{\partial L}{\partial b_{i}}$显然： $$\frac{\partial L}{\partial w_ i}=\frac{\partial L}{\partial z_{i}} \frac{\partial z_{i}}{\partial w_{i}} \tag{4}$$ $$\frac{\partial L}{\partial b_ {i}}=\frac{\partial L}{\partial z_{i}} \frac{\partial z_{i}}{\partial b_{i}} \tag{5}$$ 由于： $$\frac{\partial z_{i}}{\partial w_{i}}=x \tag{6}$$ $$\frac{\partial z_{i}}{\partial b_{i}}=1 \tag{7}$$ 所以，当前的核心问题转换为了求$\frac{\partial L}{\partial z_ {i}}$。由于式（2）表示$s$的任意分量$s_{k}$均包含$z$的所有分量，所以有： $$\frac{\partial L}{\partial z_ {i}}=\sum_{k=1}^{K}\left[\frac{\partial L}{\partial s_{k}} \frac{\partial s_{k}}{\partial z_{i}}\right] \tag{8}$$ 由于式（3）有： $$\frac{\partial L}{\partial s_{k}}=\frac{\partial\left(-\sum_{k=1}^{K} y_{k} \ln s_{k}\right)}{\partial s_{k}}=-\frac{y_{k}}{s_{k}} \tag{9}$$ 由式（2）的定义再来求$\frac{\partial s_{k}}{\partial z_{i}}$，此时分两种情况：当$k \neq i$时， $$\begin{split}{\frac{\partial s_{k}}{\partial z_{i}}} &amp; {=\frac{\partial\left(\frac{e^{z_{k}}}{\sum_{j=1}^{K} e^{z_{j}}}\right)}{\partial z_{i}}} \\&amp; {=-e^{z_{k}} \cdot \frac{1}{\left(\sum_{j=1}^{K} e^{z_{j}}\right)^{2}} \cdot e^{z_{i}}}\\&amp; {=-\frac{e^{z_{k}}}{\sum_{j=1}^{K} e^{z_{j}}} \cdot \frac{e^{z_{i}}}{\sum_{j=1}^{K} e^{z_{j}}}} \\&amp; {=-s_{k} s_{i}}\end{split} \tag{10}$$ 当$k=i$时， $$\begin{split}{\frac{\partial s_{k}}{\partial z_{i}}} &amp; {=\frac{\partial s_{i}}{\partial z_{i}}} \\&amp; {=\frac{\partial\left(\frac{e^{z_{i}}}{\sum_{j=1}^{K} e^{z_{j}}}\right)}{\partial z_{i}}} \\&amp; {=\frac{e^{z_{i}} \sum_{j=1}^{K} e^{z_{j}}-\left(e^{z_{i}}\right)^{2}}{\left(\sum_{j=1}^{K} e^{z_{j}}\right)^{2}}} \\&amp; {=\frac{e^{z_{i}}}{\sum_{j=1}^{K} e^{z_{j}}} \cdot \frac{\sum_{j=1}^{K} e^{z_{j}}-e^{z_{i}}}{\sum_{j=1}^{K} e^{z_{j}}}} \\&amp; {=\frac{e^{z_{i}}}{\sum_{j=1}^{K} e^{z_{j}}}\left(1-\frac{e^{z_{i}}}{\sum_{j=1}^{K} e^{z_{j}}}\right)} \\&amp; {=s_{i}\left(1-s_{i}\right)}\end{split}\tag{11}$$ 将式（9）、（10）和（11）代入到式（8）中，有： $$\begin{split}{\frac{\partial L}{\partial z_{i}}} &amp; {=\sum_{k=1}^{K}\left[\frac{\partial L}{\partial s_k} \frac{\partial s_{k}}{\partial z_{i}}\right]} \\ &amp; {=\sum_{k=1}^{K}\left[-\frac{y_{k}}{s_{k}} \frac{\partial s_{k}}{\partial z_{i}}\right]} \\ &amp; {=-\frac{y_{i}}{s_{i}} \frac{\partial s_{i}}{\partial z_{i}}+\sum_{k=1, k \neq i}^{K}\left[-\frac{y_{k}}{s_{k}} \frac{\partial s_{k}}{\partial \varepsilon_{i}}\right]} \\ &amp; {=-\frac{y_{i}}{s_{i}} s_{i}\left(1-s_{i}\right)+\sum_{k=1, k \neq i}^{K}\left[-\frac{y_{k}}{s_{k}} \cdot-s_{k} s_{i}\right]} \\ &amp; {=y_{i}\left(s_{i}-1\right)+\sum_{k=1, k \neq i}^{K} y_{k} s_{i}} \\ &amp; {=-y_{i}+y_ {i} s_{i}+\sum_{k=1, k \neq i}^{K} y_{k} s_{i}} \\ &amp; {=-y_{i}+s_{i} \sum_{k=1}^{K} y_{k}}\end{split}\tag{12}$$ 由于上面定义$y=\left[y_{1}, y_{2}, \ldots, y_{k}\right] \in \mathbb{R}^{k}$是样本的标签，对于多分类问题，整个向量中只有一个为$1$，其余均为$0$，那么有$\sum_{k=1}^{K} y_{k}=1$，因此在多分类问题下式（12）就是： $$\frac{\partial L}{\partial z_ {i}}=s_{i}-y_{i} \tag{13}$$ 综上，在多分类问题下，将式（6）、（7）、（13）分别代入式（4）、（5）中有， $$\frac{\partial L}{\partial w_ {i}}=\left(s_ {i}-y_{i}\right) x \tag{14}$$ $$\frac{\partial L}{\partial {b}_ {i}}=s_{i}-y_{i} \tag{15}$$ 参考文章： 【深度学习】：超详细的Softmax求导 softmax相关问题：多类分类下为什么用softmax而不是用其他归一化方法? softmax相关问题：Softmax vs. Softmax-Loss: Numerical Stability softmax相关问题：从最优化的角度看待Softmax损失函数——(这个涉及梯度的各种问题，有利于自己对梯度的理解)]]></content>
      <categories>
        <category>机器学习</category>
        <category>算法模型</category>
      </categories>
      <tags>
        <tag>Softmax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Useful AI & ML Slides]]></title>
    <url>%2F2019%2F08%2F01%2FUseful%20slides%20for%20AI%20and%20ML%2F</url>
    <content type="text"><![CDATA[分析的演进 分析是发现、解释和交流数据中有意义的模式，以及将这些模式应用于有效决策的过程。换句话说，分析可以理解为组织内数据和有效决策之间的连接组织。特别是在有记录的信息丰富的领域，分析依赖于同时应用统计、计算机编程和运筹学来量化性能。 组织可以对业务数据应用分析来描述、预测和改进业务性能。具体来说，区域内分析包括预测分析、规范的分析，企业决策管理、描述性分析、认知分析，大数据分析，零售分析、供应链分析、存储分类和库存单位优化、营销优化和营销组合建模、网络分析,调用分析、语音分析，销售队伍规模和优化，价格和促销建模、预测科学、信用风险分析和欺诈行为分析。 由于分析需要大量的计算，用于分析的算法和软件利用了计算机科学、统计学和数学中最流行的方法。 数据科学的未来 人们普遍认为，由于先进的工具，未来的数据科学项目将扩展到新的高度，需要更多的人类专家来非常有效地处理高度复杂的任务。然而，据麦肯锡全球研究所(MGI)称，仅在美国，未来10年就将出现约25万名数据科学家的严重短缺。问题是机器是否能够实现技术、工具、流程和最终用户之间的无缝协作。 自动化工具和助手可以帮助人类思维更快、更准确地完成任务，但机器永远无法取代人类的思维。解决问题的核心是智力思维，这是任何机器，无论多么复杂，都无法复制的。 机器学习工作流程 深度学习工作流程 深度学习持续集成和交付 剖析聊天机器人 人工智能面临的五大伦理挑战 NLP/NLU技术栈自然语言处理(NLP)是计算机科学、信息工程和人工智能的一个子领域，涉及计算机与人类(自然)语言的交互，特别是如何编写计算机程序来处理和分析大量的自然语言数据。自然语言处理的挑战通常包括语音识别、自然语言理解和自然语言生成。状态监视/预测维护解决方案体系结构 营销中的人工智能 统计学在数据领域的分支]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>Machine_Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[arXiv论文怎么读]]></title>
    <url>%2F2019%2F06%2F14%2FarXiv%E8%AE%BA%E6%96%87%E6%80%8E%E4%B9%88%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[总的来说，arXiv学海无涯，泛舟有道：想清楚，巧选择，多泛读，勤总结。其实不止arXiv，其他论文也一样，只是arXiv流量大，更需要技巧。 有人说arXiv垃圾太多，不值一读，这种说法，我深感不以为然。我在微博上曾说过——如果你爱它，就把它发到arXiv，因为那里是圣殿；如果你恨它，就把它发到arXiv，因为那里是垃圾场。 arXiv就是这么个鱼龙混杂，让人又爱又恨的地方。平心而论，arXiv上高素质的论文不在少数，且有快速上升之势，废话少说，看数据：2017年，理论计算机科学与机器学习领域，超过60％的发表论文都有arXiv电子版。且不说arXiv还有最美的两点：快 &amp; 多 。“快”自不必细表， 第一时间洞悉实力团队最新方向/成果，零延时跟踪最新问题/技术前沿，arXiv是个太理想的地方，期刊、会议绝无胜算；“多”怎么也成了优点？因为多，所以杂，统计上才能更有效代表整体趋势——占坑也好，废稿也罢，良莠不齐，总量庞大，一分析，哪有路、哪是坑、哪深哪浅自然清清楚楚——噪声不可怕，因为噪声，才真实，分布才有连续性，才可信。说arXiv全是垃圾的，八成是没深入研究、懒得淘金的人。怎么读？光靠勤奋还不够，得讲方法，讲策略。 第一步，想清楚想什么？想定位，想目标，想方法。 为啥而看？跟踪前沿？找问题？找方法？膜拜？探坑？找人？找撕？学写作？凑谈资？打发时间？定位清楚了，题材范围自然清晰，不了解自己，只能“通吃”，结果往往是“消化不良”。 不管什么定位，有一点很重要：抱着学习的心态去读，收获往往更多。挑剔不会让你显得更有水平，取其精华，取长补短，才是成长正道。 前阵子Kyunghyun Cho在关于博士生为学之道的访谈里提到了“过度阅读”： Excessive reading can create additional boundaries, holding a researcher away from trying out new ideas 说的是“过度阅读”有反作用，像“砌墙”，会妨碍你尝试新想法。解决方法很简单——摆正心态，就无所谓“过度”：读论文读的不是边界，是思考，是启迪，读完该做什么坚持去做： Pursue your direction, try yourself, no matter if someone was successful or not in this direction so far. 读论文的同时也不要忽略读书——打好基础很重要，尤其是论文作者认为“大家都懂”的“常识性”知识。基础好才有“根”，新来的知识和思考才有关联和生长的“干”，终能长成一棵健康茂密的参天之“树”。 第二步，巧选择读arXiv，选择很关键，选对了，就成功了一半。 简言之，选择看三点：形、神、从。 形：看的是论文的表象，具体包括出处、题目、文字和图表。 无疑，题目和出处是粗筛最有效的特征——题目言之有物、简短有趣、问题方法立意新颖，作者、机构耳熟能详，可迅速排除50%的论文，当然，根据具体定位，对作者、出处相对陌生的文章，不妨多一些宽容，如果标题有趣可以泛读试试，有时也会出现“惊喜”； 文字部分，一看摘要和导言，二看全文结构。摘要开门见山，重点突出，导言对问题、难点、相关工作和本文工作交代清楚、逻辑严谨，全文结构紧凑不拖沓，引用全面的论文，可优先入选； 图表部分，要求说明完整，自成一体又与文字相呼应。好的图表，应该能体现本文的思想和特色，配合文字说明，能了解论文的角度和作者的思考。 神：看的是论文的内涵，具体包括主旨、韵律和风格。 好的论文，主旨明确，角度合理，思路清晰，一条线索贯穿全文； 论文的韵律，是对内容轻重详略的编排，好的论文焦点明确，节奏得当，一眼能找到作者重点要表达的内容； 好的论文，一定不是自说自话，更像是与读者之间的对话，对于读者关心的方面和潜在的问题，都会贴心地预先作答，用主线引领读者顺畅阅读。 从：看其他读者的推荐和反馈，可从一人，也可从众。 跟随他人，恐怕是最便捷的一条选择之路，但有时可遇不可求。 跟随一个人，看的是对方的方向和品味。选择跟着谁，这是个不小的难题，就像是推荐系统做到最后，重点不在物物关联，而在找对要协同的用户。如何衡量对方是否值得“追随”呢？可以看是不是满足多、少、信三个条件。多是指不但乐于分享，还能坚持不懈的持续分享；少是指在选读论文方面有统一的品味和态度，宁缺毋滥；信是说可信，水准稳定，不轻易“夹带私货”。如果找到一位符合以上三点的人，又恰巧和你方向相似或部分重合，那绝对是可喜可贺！我在努力寻找这样的人，也在努力做这样的人，利己，利人，希望你也一样。 从众，也许算得上是条捷径，大众关注的，必有其看点，炒作也好，批判也罢，“焦点”就是这么一种特别的东西，你不必完全“明白”，但“知道”一定有益无害。 以上所说，只是用来判断论文质量的一些粗浅“招式”，当你借助这些方法帮自己找出一定量的“好”论文，就会逐渐找到筛选论文的感觉和自信，这时候，就像习武的更高境界——“无招”胜”有招”，可以轻松给论文打个比较客观的总分了，相信这一天不会太远。 第三步，多泛读终于到了读论文的时候，别激动，也别忙着深入细节，先把策略搞清楚。建议大量泛读，极少量精读，避免走读。 泛读看什么？看问题、看难点、看相关工作、看本文的角度和特色，重在拓展视野、延伸思考、充实基本面； 精读看什么？深入学习，不错过每一点细节，避免道听途说遗漏重点。只有对自己特别“有用”的论文才精读，一旦选定切勿浅尝辄止、囫囵吞枣。 打定主意，严格区分，不要在“知道”和“明白”之间徘徊，做到精力的高效优化分配。 读论文，重在思考，因联系、深化而增值的部分是最可宝贵的。多思考，多关联，加深、拓宽，为自己的知识体系添枝散叶，才是阅读的意义所在。 第四步，勤总结把阅读的收获及时总结、适时回顾是个很好的习惯。学习的过程，就是不断地抽象、巩固，适当的重复不但会加强你的记忆，也会启发出一些更深入的思考。 试着多和别人分享，尤其是精读的文章。就像费曼先生说的：“要是你无法用简单朴素的语言解释清楚，说明你还没有真正理解”，讲给别人听，是检验自己是否真正读懂的有效基准。 可以听别人分享，但不要迷信，更不要当做了解新知的捷径，偷懒取巧只会得不偿失，老话说得没错：“想要知道梨的滋味，就要亲口尝一尝” 再细致的阅读分享，也不如老老实实阅读一遍原文来得实在。]]></content>
      <categories>
        <category>软实力</category>
      </categories>
      <tags>
        <tag>arXiv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各种范式的理解与比较]]></title>
    <url>%2F2019%2F06%2F01%2F%E5%90%84%E7%A7%8D%E8%8C%83%E5%BC%8F%E7%9A%84%E7%90%86%E8%A7%A3%E4%B8%8E%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[监督机器学习问题无非就是“minimizeyour error while regularizing your parameters”，也就是在规则化参数的同时最小化误差。最小化误差是为了让我们的模型拟合我们的训练数据，而规则化参数是防止我们的模型过分拟合我们的训练数据。多么简约的哲学啊！因为参数太多，会导致我们的模型复杂度上升，容易过拟合，也就是我们的训练误差会很小。但训练误差小并不是我们的最终目标，我们的目标是希望模型的测试误差小，也就是能准确的预测新的样本。所以，我们需要保证模型“简单”的基础上最小化训练误差，这样得到的参数才具有好的泛化性能（也就是测试误差也小），而模型“简单”就是通过规则函数来实现的。 另外，规则项的使用还可以约束我们的模型的特性。这样就可以将人对这个模型的先验知识融入到模型的学习当中，强行地让学习到的模型具有人想要的特性，例如稀疏、低秩、平滑等等。要知道，有时候人的先验是非常重要的。前人的经验会让你少走很多弯路，这就是为什么我们平时学习最好找个大牛带带的原因。一句点拨可以为我们拨开眼前乌云，还我们一片晴空万里，醍醐灌顶。对机器学习也是一样，如果被我们人稍微点拨一下，它肯定能更快的学习相应的任务。只是由于人和机器的交流目前还没有那么直接的方法，目前这个媒介只能由规则项来担当了。 还有几种角度来看待规则化的。规则化符合奥卡姆剃刀(Occam’s razor)原理。这名字好霸气，razor！不过它的思想很平易近人：在所有可能选择的模型中，我们应该选择能够很好地解释已知数据并且十分简单的模型。从贝叶斯估计的角度来看，规则化项对应于模型的先验概率。民间还有个说法就是，规则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项(regularizer)或惩罚项(penalty term)。 一般来说，监督学习可以看做最小化下面的目标函数： $$w^{*}=\arg \min_{w} \sum_{i} L\left(y_{i}, f\left(x_{i} ; w\right)\right)+\lambda \Omega(w)$$ 其中，第一项$L(yi,f(xi;w))$ 衡量我们的模型（分类或者回归）对第i个样本的预测值$f(x_i;w)$和真实的标签$y_i$之前的误差。因为我们的模型是要拟合我们的训练样本的嘛，所以我们要求这一项最小，也就是要求我们的模型尽量的拟合我们的训练数据。但正如上面说言，我们不仅要保证训练误差最小，我们更希望我们的模型测试误差小，所以我们需要加上第二项，也就是对参数w的规则化函数$Ω(w)$去约束我们的模型尽量的简单。 OK，到这里，如果你在机器学习浴血奋战多年，你会发现，机器学习的大部分带参模型都和这个不但形似，而且神似。是的，其实大部分模型无非就是变换这两项而已。对于第一项Loss函数，如果是Square loss，那就是最小二乘了；如果是Hinge Loss，那就是著名的SVM了；如果是exp-Loss，那就是牛逼的 Boosting了；如果是log-Loss，那就是Logistic Regression了等等。不同的loss函数，具有不同的拟合特性，这个也得就具体问题具体分析的。但这里，我们先不究loss函数的问题，我们把目光转向“规则项$Ω(w)$”。 规则化函数$Ω(w)$也有很多种选择，一般是模型复杂度的单调递增函数，模型越复杂，规则化值就越大。比如，规则化项可以是模型参数向量的范数。然而，不同的选择对参数w的约束不同，取得的效果也不同，但我们在论文中常见的都聚集在：零范数、一范数、二范数、迹范数、Frobenius范数和核范数等等。这么多范数，到底它们表达啥意思？具有啥能力？什么时候才能用？什么时候需要用呢？不急不急，下面我们挑几个常见的娓娓道来。 1. L0范数与L1范数L0范数是指向量中非0的元素的个数。如果我们用L0范数来规则化一个参数矩阵W的话，就是希望W的大部分元素都是0。换句话说，让参数W是稀疏的。OK，看到了“稀疏”二字，大家都应该从当下风风火火的“压缩感知”和“稀疏编码”中醒悟过来，原来用的漫山遍野的“稀疏”就是通过这玩意来实现的。但你又开始怀疑了，是这样吗？看到的papers世界中，稀疏不是都通过L1范数来实现吗？脑海里是不是到处都是$||W||_1$影子呀！几乎是抬头不见低头见。没错，这就是这节的题目把L0和L1放在一起的原因，因为他们有着某种不寻常的关系。那我们再来看看L1范数是什么？它为什么可以实现稀疏？为什么大家都用L1范数去实现稀疏，而不是L0范数呢？ L1范数是指向量中各个元素绝对值之和，也有个美称叫“稀疏规则算子”（Lasso regularization）。现在我们来分析下这个价值一个亿的问题：为什么L1范数会使权值稀疏？有人可能会这样给你回答“它是L0范数的最优凸近似”。实际上，还存在一个更美的回答：任何的规则化算子，如果他在Wi=0的地方不可微，并且可以分解为一个“求和”的形式，那么这个规则化算子就可以实现稀疏。这说是这么说，W的L1范数是绝对值，|w|在w=0处是不可微，但这还是不够直观。这里因为我们需要和L2范数进行对比分析。所以关于L1范数的直观理解，请待会看看第二节。 对了，上面还有一个问题：既然L0可以实现稀疏，为什么不用L0，而要用L1呢？个人理解一是因为L0范数很难优化求解（NP难问题），二是L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解。所以大家才把目光和万千宠爱转于L1范数。 OK，来个一句话总结：L1范数和L0范数可以实现稀疏，L1因具有比L0更好的优化求解特性而被广泛应用。 好，到这里，我们大概知道了L1可以实现稀疏，但我们会想呀，为什么要稀疏？让我们的参数稀疏有什么好处呢？这里扯两点： 1）特征选择(Feature Selection)：大家对稀疏规则化趋之若鹜的一个关键原因在于它能实现特征的自动选择。一般来说，xi的大部分元素（也就是特征）都是和最终的输出yi没有关系或者不提供任何信息的，在最小化目标函数的时候考虑xi这些额外的特征，虽然可以获得更小的训练误差，但在预测新的样本时，这些没用的信息反而会被考虑，从而干扰了对正确yi的预测。稀疏规则化算子的引入就是为了完成特征自动选择的光荣使命，它会学习地去掉这些没有信息的特征，也就是把这些特征对应的权重置为0。 2）可解释性(Interpretability)：另一个青睐于稀疏的理由是，模型更容易解释。例如患某种病的概率是y，然后我们收集到的数据x是1000维的，也就是我们需要寻找这1000种因素到底是怎么影响患上这种病的概率的。假设我们这个是个回归模型：$$y=w_1*x_1+w_2*x_2+ … +w_1000*x_1000+b$$ （当然了，为了让y限定在[0,1]的范围，一般还得加个Logistic函数）。通过学习，如果最后学习到的w*就只有很少的非零元素，例如只有5个非零的wi，那么我们就有理由相信，这些对应的特征在患病分析上面提供的信息是巨大的，决策性的。也就是说，患不患这种病只和这5个因素有关，那医生就好分析多了。但如果1000个wi都非0，医生面对这1000种因素，累觉不爱。 2. L2范数2.1 L2范数除了L1范数，还有一种更受宠幸的规则化范数是L2范数: $||W||_2$。它也不逊于L1范数，它有两个美称，在回归里面，有人把有它的回归叫“岭回归”（Ridge Regression），有人也叫它“权值衰减weight decay”。这用的很多吧，因为它的强大功效是改善机器学习里面一个非常重要的问题：过拟合。至于过拟合是什么，上面也解释了，就是模型训练时候的误差很小，但在测试的时候误差很大，也就是我们的模型复杂到可以拟合到我们的所有训练样本了，但在实际预测新的样本的时候，糟糕的一塌糊涂。通俗的讲就是应试能力很强，实际应用能力很差。擅长背诵知识，却不懂得灵活利用知识。例如下图所示（来自Ng的course）： 上面的图是线性回归，下面的图是Logistic回归，也可以说是分类的情况。从左到右分别是欠拟合（underfitting，也称High-bias）、合适的拟合和过拟合（overfitting，也称High variance）三种情况。可以看到，如果模型复杂（可以拟合任意的复杂函数），它可以让我们的模型拟合所有的数据点，也就是基本上没有误差。对于回归来说，就是我们的函数曲线通过了所有的数据点，如上图右。对分类来说，就是我们的函数曲线要把所有的数据点都分类正确，如下图右。这两种情况很明显过拟合了。 OK，那现在到我们非常关键的问题了，为什么L2范数可以防止过拟合？回答这个问题之前，我们得先看看L2范数是个什么东西。 L2范数是指向量各元素的平方和然后求平方根。我们让L2范数的规则项$||W||_2$最小，可以使得W的每个元素都很小，都接近于0，但与L1范数不同，它不会让它等于0，而是接近于0，这里是有很大的区别的哦。而越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象。为什么越小的参数说明模型越简单？我也不懂，我的理解是：限制了参数很小，实际上就限制了多项式某些分量的影响很小（看上面线性回归的模型的那个拟合的图），这样就相当于减少参数个数。其实我也不太懂，希望大家可以指点下。 这里也一句话总结下：通过L2范数，我们可以实现了对模型空间的限制，从而在一定程度上避免了过拟合 L2范数的好处是什么呢？这里也扯上两点：1）学习理论的角度：从学习理论的角度来说，L2范数可以防止过拟合，提升模型的泛化能力。 2）优化计算的角度：从优化或者数值计算的角度来说，L2范数有助于处理 condition number不好的情况下矩阵求逆很困难的问题。哎，等等，这condition number是啥？我先google一下哈。 2.2 小谈优化问题这里我们也故作高雅的来聊聊优化问题。优化有两大难题，一是：局部最小值，二是：ill-condition病态问题。前者俺就不说了，大家都懂吧，我们要找的是全局最小值，如果局部最小值太多，那我们的优化算法就很容易陷入局部最小而不能自拔，这很明显不是观众愿意看到的剧情。那下面我们来聊聊ill-condition。ill-condition对应的是well-condition。那他们分别代表什么？假设我们有个方程组AX=b，我们需要求解X。如果A或者b稍微的改变，会使得X的解发生很大的改变，那么这个方程组系统就是ill-condition的，反之就是well-condition的。我们具体举个例子吧： 咱们先看左边的那个。第一行假设是我们的AX=b，第二行我们稍微改变下b，得到的x和没改变前的差别很大，看到吧。第三行我们稍微改变下系数矩阵A，可以看到结果的变化也很大。换句话来说，这个系统的解对系数矩阵A或者b太敏感了。又因为一般我们的系数矩阵A和b是从实验数据里面估计得到的，所以它是存在误差的，如果我们的系统对这个误差是可以容忍的就还好，但系统对这个误差太敏感了，以至于我们的解的误差更大，那这个解就太不靠谱了。所以这个方程组系统就是ill-conditioned病态的，不正常的，不稳定的，有问题的，哈哈。这清楚了吧。右边那个就叫well-condition的系统了。 还是再啰嗦一下吧，对于一个ill-condition的系统，我的输入稍微改变下，输出就发生很大的改变，这不好啊，这表明我们的系统不能实用啊。你想想看，例如对于一个回归问题y=f(x)，我们是用训练样本x去训练模型f，使得y尽量输出我们期待的值，例如0。那假如我们遇到一个样本x’，这个样本和训练样本x差别很小，面对他，系统本应该输出和上面的y差不多的值的，例如0.00001，最后却给我输出了一个0.9999，这很明显不对呀。就好像，你很熟悉的一个人脸上长了个青春痘，你就不认识他了，那你大脑就太差劲了，哈哈。所以如果一个系统是ill-conditioned病态的，我们就会对它的结果产生怀疑。那到底要相信它多少呢？我们得找个标准来衡量吧，因为有些系统的病没那么重，它的结果还是可以相信的，不能一刀切吧。终于回来了，上面的condition number就是拿来衡量ill-condition系统的可信度的。condition number衡量的是输入发生微小变化的时候，输出会发生多大的变化。也就是系统对微小变化的敏感度。condition number值小的就是well-conditioned的，大的就是ill-conditioned的。 如果方阵A是非奇异的，那么A的condition number定义为：$$\kappa(A)=||A|| ||A^{-1}||$$ 也就是矩阵A的norm乘以它的逆的norm。所以具体的值是多少，就要看你选择的norm是什么了。如果方阵A是奇异的，那么A的condition number就是正无穷大了。实际上，每一个可逆方阵都存在一个condition number。但如果要计算它，我们需要先知道这个方阵的norm（范数）和Machine Epsilon（机器的精度）。为什么要范数？范数就相当于衡量一个矩阵的大小，我们知道矩阵是没有大小的，当上面不是要衡量一个矩阵A或者向量b变化的时候，我们的解x变化的大小吗？所以肯定得要有一个东西来度量矩阵和向量的大小吧？对了，他就是范数，表示矩阵大小或者向量长度。OK，经过比较简单的证明，对于AX=b，我们可以得到以下的结论： $$\frac{||\Delta x||}{||x||} \leq||A|| \cdot ||A^{-1} || \cdot\ \frac{||\Delta b||}{||b||}$$ $$ \quad \frac{||\Delta x||}{||x||} \leq K(A) \cdot \frac{||\Delta b||}{||b||}$$ $$ \frac {||\Delta x||}{||x+\Delta x||} \leq K(A) \frac{||\Delta A||}{||A||}$$ 也就是我们的解x的相对变化和A或者b的相对变化是有像上面那样的关系的，其中k(A)的值就相当于倍率，看到了吗？相当于x变化的界。 对condition number来个一句话总结：condition number是一个矩阵（或者它所描述的线性系统）的稳定性或者敏感度的度量，如果一个矩阵的condition number在1附近，那么它就是well-conditioned的，如果远大于1，那么它就是ill-conditioned的，如果一个系统是ill-conditioned的，它的输出结果就不要太相信了。 好了，对这么一个东西，已经说了好多了。对了，我们为什么聊到这个的了？回到第一句话：从优化或者数值计算的角度来说，L2范数有助于处理 condition number不好的情况下矩阵求逆很困难的问题。因为目标函数如果是二次的，对于线性回归来说，那实际上是有解析解的，求导并令导数等于零即可得到最优解为$$\hat{\mathbf{w}}=\left(X^{T} X\right)^{-1} X^{T} \mathbf{y}$$ 然而，如果当我们的样本X的数目比每个样本的维度还要小的时候，矩阵$X^TX$将会不是满秩的，也就是$X^TX$会变得不可逆，所以$w*$就没办法直接计算出来了。或者更确切地说，将会有无穷多个解（因为我们方程组的个数小于未知数的个数）。也就是说，我们的数据不足以确定一个解，如果我们从所有可行解里随机选一个的话，很可能并不是真正好的解，总而言之，我们过拟合了。 但如果加上L2规则项，就变成了下面这种情况，就可以直接求逆了：$$\boldsymbol{w}^{*}=\left(\boldsymbol{X}^{T} \boldsymbol{X}+\boldsymbol{\lambda} \boldsymbol{I}\right)^{-1} \boldsymbol{X}^{T} \boldsymbol{y}$$ 这里面，专业点的描述是：要得到这个解，我们通常并不直接求矩阵的逆，而是通过解线性方程组的方式（例如高斯消元法）来计算。考虑没有规则项的时候，也就是λ=0的情况，如果矩阵XTX的 condition number 很大的话，解线性方程组就会在数值上相当不稳定，而这个规则项的引入则可以改善condition number。 另外，如果使用迭代优化的算法，condition number 太大仍然会导致问题：它会拖慢迭代的收敛速度，而规则项从优化的角度来看，实际上是将目标函数变成λ-strongly convex（λ强凸）的了。哎哟哟，这里又出现个λ强凸，啥叫λ强凸呢？ 当f满足：$$f(\mathrm{y}) \geq \mathrm{f}(\mathrm{x})+&lt;\nabla f(\mathrm{x}), \mathrm{y}-\mathrm{x}&gt;+\frac{\lambda}{2}|\mathrm{y}-\mathrm{x}|^{2}$$ 时，我们称f为λ-stronglyconvex函数，其中参数λ&gt;0。当λ=0时退回到普通convex 函数的定义。 在直观的说明强凸之前，我们先看看普通的凸是怎样的。假设我们让f在x的地方做一阶泰勒近似（一阶泰勒展开忘了吗？f(x)=f(a)+f’(a)(x-a)+o(||x-a||).）：$$f(\mathrm{y}) \geq \mathrm{f}(\mathrm{x})+&lt;\nabla f(\mathrm{x}), \mathrm{y}-\mathrm{x}&gt;+o(|\mathrm{y}-\mathrm{x}|)$$ 直观来讲，convex 性质是指函数曲线位于该点处的切线，也就是线性近似之上，而 strongly convex 则进一步要求位于该处的一个二次函数上方，也就是说要求函数不要太“平坦”而是可以保证有一定的“向上弯曲”的趋势。专业点说，就是convex 可以保证函数在任意一点都处于它的一阶泰勒函数之上，而strongly convex可以保证函数在任意一点都存在一个非常漂亮的二次下界quadratic lower bound。当然这是一个很强的假设，但是同时也是非常重要的假设。可能还不好理解，那我们画个图来形象的理解下。 大家一看到上面这个图就全明白了吧。不用我啰嗦了吧。还是啰嗦一下吧。我们取我们的最优解$W^{*}$的地方。如果我们的函数$f(w)$，见左图，也就是红色那个函数，都会位于蓝色虚线的那根二次函数之上，这样就算$w_t$和$w*$离的比较近的时候，$f(w_t)$和$f(w*)$的值差别还是挺大的，也就是会保证在我们的最优解$w*$附近的时候，还存在较大的梯度值，这样我们才可以在比较少的迭代次数内达到w*。但对于右图，红色的函数f(w)只约束在一个线性的蓝色虚线之上，假设是如右图的很不幸的情况（非常平坦），那在wt还离我们的最优点$w*$很远的时候，我们的近似梯度$(f(w_t)-f(w*))/(w_t-w*)$就已经非常小了，在wt处的近似梯度∂f/∂w就更小了，这样通过梯度下降$w_t+1=w_t-α*(∂f/∂w)$，我们得到的结果就是w的变化非常缓慢，像蜗牛一样，非常缓慢的向我们的最优点$w*$爬动，那在有限的迭代时间内，它离我们的最优点还是很远。 所以仅仅靠convex 性质并不能保证在梯度下降和有限的迭代次数的情况下得到的点w会是一个比较好的全局最小点$w*$的近似点（插个话，有地方说，实际上让迭代在接近最优的地方停止，也是一种规则化或者提高泛化性能的方法）。正如上面分析的那样，如果f(w)在全局最小点$w*$周围是非常平坦的情况的话，我们有可能会找到一个很远的点。但如果我们有“强凸”的话，就能对情况做一些控制，我们就可以得到一个更好的近似解。至于有多好嘛，这里面有一个bound，这个 bound 的好坏也要取决于strongly convex性质中的常数α的大小。看到这里，不知道大家学聪明了没有。如果要获得strongly convex怎么做？最简单的就是往里面加入一项$(α/2)*||w||_2$。 呃，讲个strongly convex花了那么多的篇幅。实际上，在梯度下降中，目标函数收敛速率的上界实际上是和矩阵XTX的 condition number有关，XTX的 condition number 越小，上界就越小，也就是收敛速度会越快。 这一个优化说了那么多的东西。还是来个一句话总结吧：L2范数不但可以防止过拟合，还可以让我们的优化求解变得稳定和快速。 好了，这里兑现上面的承诺，来直观的聊聊L1和L2的差别，为什么一个让绝对值最小，一个让平方最小，会有那么大的差别呢？我看到的有两种几何上直观的解析： 1）下降速度：我们知道，L1和L2都是规则化的方式，我们将权值参数以L1或者L2的方式放到代价函数里面去。然后模型就会尝试去最小化这些权值参数。而这个最小化就像一个下坡的过程，L1和L2的差别就在于这个“坡”不同，如下图：L1就是按绝对值函数的“坡”下降的，而L2是按二次函数的“坡”下降。所以实际上在0附近，L1的下降速度比L2的下降速度要快。所以会非常快得降到0。不过我觉得这里解释的不太中肯，当然了也不知道是不是自己理解的问题。 L1在江湖上人称Lasso，L2人称Ridge。不过这两个名字还挺让人迷糊的，看上面的图片，Lasso的图看起来就像ridge，而ridge的图看起来就像lasso。 2）模型空间的限制：实际上，对于L1和L2规则化的代价函数来说，我们可以写成以下形式：$$Lasso:\min_{w} \frac{1}{n}||\mathrm{y}-X \mathrm{w}||^{2}, \quad \text { s.t. }||\mathrm{w}||_{1} \leq C$$ $$Ridge:\min_{w} \frac{1}{n}||\mathrm{y}-X \mathrm{w}||^{2}, \quad \text { s.t. }||\mathrm{w}||_{2} \leq C$$ 也就是说，我们将模型空间限制在w的一个L1-ball 中。为了便于可视化，我们考虑两维的情况，在(w1, w2)平面上可以画出目标函数的等高线，而约束条件则成为平面上半径为C的一个 norm ball 。等高线与 norm ball 首次相交的地方就是最优解： 可以看到，L1-ball 与L2-ball 的不同就在于L1在和每个坐标轴相交的地方都有“角”出现，而目标函数的测地线除非位置摆得非常好，大部分时候都会在角的地方相交。注意到在角的位置就会产生稀疏性，例如图中的相交点就有w1=0，而更高维的时候（想象一下三维的L1-ball 是什么样的？）除了角点以外，还有很多边的轮廓也是既有很大的概率成为第一次相交的地方，又会产生稀疏性。 相比之下，L2-ball 就没有这样的性质，因为没有角，所以第一次相交的地方出现在具有稀疏性的位置的概率就变得非常小了。这就从直观上来解释了为什么L1-regularization 能产生稀疏性，而L2-regularization 不行的原因了。 因此，一句话总结就是：L1会趋向于产生少量的特征，而其他的特征都是0，而L2会选择更多的特征，这些特征都会接近于0。Lasso在特征选择时候非常有用，而Ridge就只是一种规则化而已。 OK，就聊到这里。下一篇博文我们聊聊核范数和规则化项参数选择的问题。全篇的参考资料也请见下一篇博文，这里不重复列出。谢谢。 3. 其他好的理解角度 “L2 正则项的作用是让所有的 w 都变小，而 w 越小模型越简单”，大家普遍感到难以理解，我在这里讲讲我自己的不同看法，希望能够帮到大家。 我认为 L2 正则项的作用并不是让所有的 w 都变小，而是【有选择地让某些 w 变小】。正如题主举得医生预测疾病的例子，样本中的特征有很多，但大部分特征都是无关紧要的，只有一小部分关键的特征支撑起了整个预测模型。表现在系数 w 上就是，大部分的 w_i 都是不幸的，因为它们刚好与那些无关紧要的特征结对，它们的大小对整个模型的效果影响不大，于是在正则项的约束下它们都变小了，甚至趋近于0；而只有小部分的 w_i 比较幸运，它们刚好对应到了好的特征，于是它们肩负起了非常重大的责任，它们的微小变化会引起模型曲线在走势上的根本性变化，损失函数会急剧增大。如果正则项妄图约束这些关键的 w_i，使它们变小，那么由此造成的损失函数的扩大将远大于从正则项上获得的微小收益，所以这些关键的 w_i 可以几乎不受正则项的干涉。 但也不尽然，如果你把正则项之前的系数 λ 调到非常大，那么它就会敢于压迫那些关键的 w_i，最终造成的结果是，模型确实变简单了，但也严重偏离了预期方向，没什么卵用了。相反，如果你把 λ 调得非常小，那么正则项对每个 w_i 都惹不起，即使是那些无关紧要的 w_i 它也无力约束，最终就会导致模型过拟合（试想 λ 等于0的情况）。所以，损失函数与正则项就像是博弈的双方，它们之间的力量对比通过参数 λ 进行调和。只有把 λ 调合适了，才能得到既不过拟合，又相对简单的好模型。从这种意义上来说，L2正则项与L1正则项类似，也有“特征选择”的效果。 上面的描述比较感性，是我为了方便直观理解做的一些比喻，如果把模型的预测曲线做出来会更加严谨一些。即每个 w_i 都影响着曲线的形态，但是有主次之分。那些低阶的、关键的 w_i 控制着曲线的整体走势；而那些高阶的、次要的 w_i 则是在曲线整体走势的基础上稍微扭曲曲线的形态；当然，还会有更高阶的 w_i，它们负责在大的扭曲之上制造更小的扭曲，以此类推。 这样看来L2正则项的作用就很明显了，要改变预测曲线的整体走势肯地会造成损失函数的不满，但是把曲线的形态熨平似乎并没有什么不妥。而 λ 的大小则决定了正则项的视野，即多大的弯曲算作走势？多小的弯曲算作扭曲？ 参考资料： 机器学习中的范数规则化之（一）L0、L1与L2范数 机器学习中的范数规则化之（二）核范数与规则项参数选择]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>L0范式</tag>
        <tag>L1范式</tag>
        <tag>L2范式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12 Useful Things to Know about Machine Learning]]></title>
    <url>%2F2019%2F05%2F02%2F12%20Useful%20Things%20to%20Know%20about%20Machine%20Learning%2F</url>
    <content type="text"><![CDATA[我最近读了华盛顿大学的Pedro Domingos教授的一篇十分惊艳的技术论文，题是“A Few Useful Things to Know about Machine Learning”。 它总结了机器学习研究人员和实践者所学到的12个关键的经验及教训，包括要避免的陷阱，需要关注的重点问题以及常见问题的答案。我想在本文中分享这些十分宝贵的经验教训，因为当你思考解决下一个机器学习问题时，这些经验会对你十分有用。原文 1.学习 = 表示 + 评估 + 优化所有的机器学习算法通常由3个部分组成： 表示：就是指在网络中对信息进行编码的方式。分类器必须用计算机能处理的某种形式语言来表示。 反过来讲，为学习器选择一种表示就等于选择它可能学习的一组分类器集合。这个集合被称为学习器的假设空间。如果某个分类器不在假设空间中，那么就不能被学习到。与此相关的一个问题是如何表示输入，也就是说要用哪些特征，本文稍后介绍。 评估：需要一个评估函数来区分好的分类器和坏的分类器。机器学习算法内部使用的评估函数可能与我们希望分类器优化的外部评估函数有所不同，为了更好的优化，接下来会进一步讨论。 优化：最后，我们需要一种方法可以在假设空间中找到评价函数得分最高的那个分类器。优化技术的选择对于学习器的效率至关重要，并且当评估函数有多个最优值时，优化技术也有助于确定所产生的分类器。 初学者开始使用现成的优化器是很常见的，之后这些方法会被定制设计的优化器所取代。 2.泛化才是关键机器学习的最终目的是将训练模型应用在除训练样本之外的其他数据中。因为无论我们训练时有多少数据，在测试的时候我们都不太可能再次遇到与这些训练时的详细数据完全相同的情况。在训练集上获得好的结果很容易。机器学习初学者中最常见的错误就是对训练数据进行测试并自以为大获成功。如果选择的分类器在全新的数据上进行测试，它们通常表现的还不如随机猜测所得的结果好。所以，如果你要雇佣某人来构建分类器，一定要保留一些数据给你自己，之后再用这些数据来测试他们给你的分类器。反过来讲，如果你被雇来构建分类器，从一开始就划分出一些数据用作之后的测试，在你用全部数据进行训练并得到您的分类器过后，再用这部分数据来测试你最终选择的分类器。 3.只有数据是不够的将泛化作为目标还有另一个主要的问题：只有数据是不够的，不管你有多少数据。这似乎是个相当令人沮丧的消息。那么我们还怎么希望学到所有东西呢？幸运的是，在现实世界中我们想学习的函数并不是均匀的来自所有可能函数的！事实上，许多通用的假设往往会起很大的作用 ——像平滑性、相似的示例有相似的分类、有限的相关性、或有限的复杂性等，这也是机器学习会取得成功的很大一部分原因。与演绎法一样，归纳法是一种知识杠杆：将少量的知识输入转化成大量的知识输出。归纳是一个比演绎更强大的杠杆，需要更少的知识输入来获取有用的结果，但是，它终究还是不能在没有知识输入的情况下工作。而且，正如杠杆一样，我们投入的越多，我们可以获取的知识就越多。 综上来看，机器学习需要知识这点并不奇怪。机器学习不是魔术， 它并不能做到从无到有。它可以做到的是从少变多。像所有的工程技术一样，编程有很多工作要做：我们必须从抓取开始构建所有的东西。机器学习更像是种田，让大自然完成大部分的工作。农民将种子与营养物质结合起来种植庄稼。而机器学习则是将知识与数据结合起来，来构建模型。 4.过拟合有多张面孔如果我们的知识和数据不足以完全学习出正确的分类器怎么办？那么我们就冒着得到一个幻想中的分类器的风险来构建，这些分类器可能与实际情况相差甚远，它简单的将数据中的巧合当做了一般情况。这个问题被称为“过拟合”，是机器学习中的难题。当你的学习器输出的分类器在训练数据上有100％的准确率，但在测试数据上只有50％的准确率的时候，这就是过拟合。在正常情况下，无论在训练集还是在测试集它的准确率都应该为75%。 在机器学习中，每个人都知道过拟合，但它有很多形式，有些并不会马上显现出来。理解过拟合的一种方法是将泛化误差分解为偏差和方差。偏差是学习器有不断学习同样错误的倾向。方差是学习器倾向于去学习随机事物，不考虑真实信号是如何。线性学习器有很高的偏差，因为当两个类的交界不是一个超平面时，线性学习器就无法进行归纳。决策树就不存在这个问题，因为它们可以表示任意布尔函数，但在另一方面，决策树有较大的方差：决策树在同一现象产生的不同训练集上学习，所便显出的结果是完全不同的，但理论上它们的结果应该是相同的。 交叉验证有助于减弱过拟合，例如通过使用交叉验证来选择决策树的最佳尺寸来学习。但这不是万能的，因为如果我们使用了过多的参数，那模型本身就已经开始过拟合了。 除了交叉验证之外，还有很多方法可以预防过拟合的问题。最常用的方法就是给评估函数添加一个正则项。这样做可以惩罚许多较为复杂的模型，从而有利于产生较为简单的模型。另一种方法是在添加新的结构之前，通过像卡方检验来测试统计显著性，以确定加入这种结构是否会有帮助。当数据十分稀少时，这些技术特别有用。尽管如此，你还是应该对存在某种技术可以“解决”过拟合问题这样的说法持怀疑态度，这十分容易就会让过拟合变为欠拟合。想要同时避免这两种情况需训练出一个完美的分类器，根据天下没有免费的午餐原理，如果事先并没有足够的知识，不会有任何一种单一技术可以一直表现最好。 5.高维度下直觉失效在过拟合之后，机器学习中最大的问题就是维度灾难。 这个表达式是由Bellman在1961年提出的，指出了一个事实：当输入是高维度时，许多在低维度上工作正常的算法效果变得很差。 但是在机器学习领域，维度灾难这个词还有更多的含义。随着示例数据的维数（特征数量）的升高，正确地泛化的难度在以指数增加，因为固定大小的训练集只覆盖了输入空间的一小部分。 高维空间中比较普遍的问题是我们直觉失效，我们来自三维世界的直觉通常不适用于高维空间。在高维空间中，多元高斯分布的大部分质量并不接近平均值，而是在逐渐远离均值的一层“壳”上;打个比方，一个高维度的橙子的大部分质量都在皮上，而不在瓤里。如果恒定数量的示例在高维超立方体中均匀分布，那么超出某个维度后，大多数示例将更接近于超立方体的一个面。如果我们在超立方体内内接一个超球面，那么在高维度下，超立方体的几乎所有质量都将分布在超球面之外。这对于机器学习来说是个坏消息，因为机器学习经常用一种类型的形状来近似另一种类型的形状。 在二维或三维空间内建立分类器是很容易的;我们可以通过肉眼观察找出不同类别的示例之间合理的分界线。但是在高维度空间中我们很难理解正在发生什么。反过来说这让设计一个好的分类器变得很难。人们可能会天真的认为收集更多的特征并不会有什么害处，因为在最坏的情况下，它们也只不过不提供关于类别的新信息而已，但在实际情况下，这样做的好处可能远小于维度灾难所带来的问题。 6.理论担保与实际看上去并不一样机器学习论文中充满了理论的担保。最常见的类型是可以确保良好泛化所需要的示例数据的界限。你应该如何理解这些担保呢？首先，需要注意它们是否可行。归纳传统上与演绎是相反的：在演绎中你可以保证结论是正确的;在归纳中这些都不好说。或者说这是许多世纪以来留下的传统观点。近几十年来的一个显著的提升是，我们认识到在实际情况中我们可以对归纳的结果的正确性有所保证，特别是如果我们愿意接受概率担保。 我们必须小心边界所包含的意义。例如，边界并不意味着，如果你的学习器返回了一个与特定训练集上相一致的假设，那么这个假设可能泛化的很好。边界的意思是，给定一个足够大的训练集，很有可能你的学习器要么可以返回一个泛化良好的假设，要么无法找到一个保持正确的假设。这个边界也无法告诉我们如何去选择一个好的假设空间。它只告诉我们，如果假设空间包含了真实的分类器，那么学习器输出一个不好的分类器的概率会随着训练数据的增加而减少。如果我们缩小假设空间，边界就会有所改善，但是假设空间包含真实分类器的几率也会降低。 另一种常用的理论担保是渐近：给定无限的数据，可以保证学习器输出正确的分类器。这个保证让人欣慰，但仅仅因为渐进的保证而确定一个学习器是十分草率的。在实践中，我们很少处于渐近状态。而且，由于上文讨论的偏差 - 方差的权衡，在无限数据下，如果学习器A比学习器B表现好，则在有限数据中，学习器B往往比学习器A表现的要好。 机器学习中理论保证的主要作用不是作为实践中决策的标准，而是在算法设计中作为理解和驱动的来源。在这方面，他们是相当有用的;事实上，理论与实践的密切配合是机器学习多年来取得如此巨大进步的主要原因之一。但要注意：学习是一个复杂的现象，因为学习器既有理论证实，并且可实际应用，但这并不意味着前者是后者的依据。 7.特征工程是关键在一天结束时，总有一些机器学习项目会成功，而一些会失败。是什么造成了它们之间的差异？显然最重要的影响因素是特征的使用。如果你有许多独立的特征， 这些特征类别都有很好的关联，那么学习起来就很容易。另一方面，如果这个类别与特征的关系十分复杂，那么你可能就无法学习它。通常情况下，原始数据不可直接用来学习，但是可以从中构建特征。这通常是机器学习项目中主要工作所在。它往往也是机器学习中最有趣的一部分，直觉，创造力和“black art”与技术一样重要。 初学者常常惊讶于机器学习项目中真正用于学习的时间太少。但是，如果你考虑了在数据收集，整合，清理和预处理上所花费的时间，以及在特征设计中进行的无数次试验与失败，这些就都说得通了。另外，机器学习不是建立数据集和运行学习器的一个一次性过程，而是一个运行学习器，分析结果，修改数据和/或学习器等不断重复，反复迭代过程。真正的学习通常是这些内容中最快的一部分，这是因为我们已经非常精通它了！特征工程更加困难，因为它是一个特定领域的，而学习器在很大程度上是通用的。但是，这两者之间没有明确的界限，这也是最有用的学习器往往是那些可以促进知识整合的学习器的另一个原因。 8.更多的数据胜过更聪明的算法在大多数计算机科学中，有两种主要资源是有限的：时间和内存。在机器学习中，还有第三种：训练数据。其中哪一个资源会成为瓶颈是随着时间而改变的。在八十年代，瓶颈往往是数据。当今通常是时间。现在大量的可用数据，但并没有足够的时间来处理它们，所以这些数据常常被弃用。这就造成了一个悖论：即使原则上更多的数据意味着我们可以学习更复杂的分类器，而实际上我们通常会使用简单的分类器，因为复杂的分类器需要很长的时间去学习。 使用更聪明的算法取得的回报要比你预期的更少，一部分原因是，机器学习的工作机制都十分的相似。这个结论也许令你十分吃惊，特别是当你考虑到规则集和神经网络的表示方法差异是很明显时。但事实上，命题规则可以很容易被编码为神经网络，并且其他表示之间也存在类似的关系。所有学习器本质上都是通过将附近的示例分到同一类内来工作；关键的区别在于对“附近”的定义。对于非均匀分布的数据，不同的学习器可以产生广泛不同的边界，同时在重要领域（即具有大量训练示例，并且测试示例也有很大概率出现的领域）仍能做出相同的预测。这也有助于解释为什么强大的学习器虽然不稳定，但仍然准确。 通常，首先尝试最简单的学习器是值得的（例如，在逻辑回归之前先尝试朴素贝叶斯，在支持向量机之前先尝试近邻）。更复杂的学习器固然诱人，但他们通常来说更难使用，因为它们需要调节更多的参数才能获得好的结果，并且他们的内部机制更不透明）。学习器可以分为两大类：一类的表示具有固定大小的，比如线性分类器，另一类的表示可以随着数据一起增长，如决策树。固定大小的学习器只能利用有限的数据。原则上可变大小的学习器可以利用给定的充足数据学习任何函数，但实际上由于算法和计算成本的限制，这些通常是无法做到的。而且，由于维度灾难，不存在会被认为充足的数据量。正是因为这些原因，只要你愿意付出努力，聪明的算法（那些充分利用数据和计算资源的算法）往往最终会得到回报。设计学习器和学习分类器之间没有明确的界限;相反，任何给定的知识都可以在学习器中编码或从数据中学习。所以机器学习项目往往会有学习器设计这一重要组成部分，机器学习实践者需要在这方面具备一定的专业知识。 9.要学习许多模型，不仅仅是一个在机器学习的早期，每个人都有自己喜欢的学习器，并有一些先入为主的观念坚信它的优越性。人们付出大量的努力去尝试它的多种变化，并选择其中最好的一个。之后，通过系统的实践比较表明，最好的学习器是随着应用的改变而有所不同的，因此包含许多不同学习器的系统开始出现。现在，努力尝试许多学习器的不同变化，仍然是为了选择最好的那一个。但随后研究人员注意到，如果不是只选最好的那一个，而是将多种情况进行结合，结果会更好——通常要好得多——而且对用户来说几乎不需花费额外的努力。 现在创建这样的模型集成已经实现标准化。最简单的集成技术称为bagging，我们通过重采样简单地随机生成不同的训练集，每个集合上分别学习一个分类器，并通过投票的方式将结果进行合并。这是有效的，因为它大大降低了方差，而只是稍微增加了偏差。在boosting方法中，每个训练样本都有权重，而且这些都是不同的，以至于每个新的分类器都集中在前面那些往往会出错的例子上。在stacking方法中，单个分类器的输出会成为“高级”学习器的输入，这个学习器可以计算出如何最好地组合这些来自“低层”的输出。还存在许多其他技术，现在的趋势是越来越大的集成。在Netflix大奖中，来自世界各地的团队争相构建最佳视频推荐系统。随着比赛的进行，团队们发现通过将他们的学习器与其他团队的学习器进行合并，会取得了最好的结果，并且可以合并为越来越大的团队。冠军和亚军都合并超过了100个学习器，并且这两者集成后又进一步提升了效果。毫无疑问，我们将来会看到更大的集成学习器。 10.简单并不意味着准确著名的奥卡姆剃刀原理称，如果没有必要就不要增加实体。在机器学习中，这通常意味着，给定两个具有相同训练误差的分类器，两者中较简单的那个可能具有最低的测试误差。有关这一说法的证明在文献中经常出现，但实际上有很多反例，并且“没有免费的午餐”定理也暗示它不可能是真实的。 我们在前一节已经看到一个反例：模型集成。集成模型的泛化误差会随着添加分类器而不断的改进。因此，与直觉相反，一个模型的参数的数量与其过拟合之间并没有必然的联系。 相反，一个更成熟的观点是将复杂性等同于假设空间的大小，基于以下事实，较小的假设空间允许由较短的代码表示。像上面的理担保证那节提到的边界可能被视为在暗示更短的假设泛化的更好。这还可以通过给有一些先验偏好空间中的假设分配更短的代码做进一步改善。但是，如果把这看作准确性和简单性之间权衡的“证明”，这就是是循环论证了：我们更喜欢简单的假设，如果它们是准确的，那是因为我们的偏好是准确的，而并不是因为这些假设在我们选择的表述中是“简单”。 11.可表示并不意味着可学习本质上，用于大小可变的学习器的所有表示都具有形式为“每个函数都可以被表示，或者以无限接近的方式近似被表示”的相关定理。正因如此，某种表示方法的忠实使用者经常忽视所有其他的方法。然而，仅仅因为一个函数可以被表示并不意味着它是可以被学习的。例如，标准的决策树学习器并不能学习出比其训练样本更多的叶子节点。 在连续空间中，使用一组固定的基元来表示很简单的函数通常都需要无限数量的项来表示。 而且，如果假设空间具有许多评价函数的局部最优值，那么往往是这样，学习器即使可以表示，也很可能找不到真正的函数。对于有限的数据，时间和内存，标准学习器只能学习所有可能函数的很小一部分子集，这些子集对于学习器来说会随着表示方法的不同而改变。 因此，关键问题不是“它能否被表示”，答案往往是无关紧要的，而是“它能否被学习？”而且这让我们去尝试不同的学习器（也可能是把它们结合起来）是值得的。 12.相关并不意味着因果相关并不意味着因果这一点经常被提起，就不值得在这里做过多地说明了。但是，尽管我们所讨论的那种学习器只能学习相关性，但他们的结果往往被视为代表因果关系。这么做是错的吗？如果是，那么人们为什么都这样做呢？ 往往学习预测模型的目标是用它们作为行动的指南。 如果我们发现啤酒和尿布经常在超市中被一起购买，那么也许把啤酒放在尿布旁边就会增加销量。但除非真正的做实验，否则很难说明这一点。机器学习通常被应用在观测数据上。 一些学习算法可以潜在地从观测数据中提取因果信息，但是它们的适用性相当有限。另一方面，相关性是一个潜在的因果关系的标志，我们可以用它作为进一步考察的指导。 结论像任何学科一样，机器学习有许多“民间智慧”在书本上很难了解到，但这些知识对成功运用机器学习来说至关重要。多明戈斯教授的论文总结了其中几条最重要的内容。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>tricks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Attention]]></title>
    <url>%2F2019%2F05%2F01%2FAttention%2F</url>
    <content type="text"><![CDATA[最近两年，注意力模型（Attention Model）被广泛使用在自然语言处理、图像识别及语音识别等各种不同类型的深度学习任务中，是深度学习技术中最值得关注与深入了解的核心技术之一。 本文以机器翻译为例，深入浅出地介绍了深度学习中注意力机制的原理及关键计算机制，同时也抽象出其本质思想，并介绍了注意力模型在图像及语音等领域的典型应用场景。 1. 人类的视觉注意力从注意力模型的命名方式看，很明显其借鉴了人类的注意力机制，因此，我们首先简单介绍人类视觉的选择性注意力机制。 视觉注意力机制是人类视觉所特有的大脑信号处理机制。人类视觉通过快速扫描全局图像，获得需要重点关注的目标区域，也就是一般所说的注意力焦点，而后对这一区域投入更多注意力资源，以获取更多所需要关注目标的细节信息，而抑制其他无用信息。 这是人类利用有限的注意力资源从大量信息中快速筛选出高价值信息的手段，是人类在长期进化中形成的一种生存机制，人类视觉注意力机制极大地提高了视觉信息处理的效率与准确性。 图1形象化展示了人类在看到一副图像时是如何高效分配有限的注意力资源的，其中红色区域表明视觉系统更关注的目标，很明显对于图1所示的场景，人们会把注意力更多投入到人的脸部，文本的标题以及文章首句等位置。 深度学习中的注意力机制从本质上讲和人类的选择性视觉注意力机制类似，核心目标也是从众多信息中选择出对当前任务目标更关键的信息。 2. Encoder-Decoder框架要了解深度学习中的注意力模型，就不得不先谈Encoder-Decoder框架，因为目前大多数注意力模型附着在Encoder-Decoder框架下，当然，其实注意力模型可以看作一种通用的思想，本身并不依赖于特定框架，这点需要注意。 Encoder-Decoder框架可以看作是一种深度学习领域的研究模式，应用场景异常广泛。图2是文本处理领域里常用的Encoder-Decoder框架最抽象的一种表示。 图2. 抽象的文本处理领域的Encoder-Decoder框架 文本处理领域的Encoder-Decoder框架可以这么直观地去理解：可以把它看作适合处理由一个句子（或篇章）生成另外一个句子（或篇章）的通用处理模型。对于句子对&lt;Source,Target&gt;，我们的目标是给定输入句子Source，期待通过Encoder-Decoder框架来生成目标句子Target。Source和Target可以是同一种语言，也可以是两种不同的语言。而Source和Target分别由各自的单词序列构成： Encoder顾名思义就是对输入句子Source进行编码，将输入句子通过非线性变换转化为中间语义表示C： 对于解码器Decoder来说，其任务是根据句子Source的中间语义表示C和之前已经生成的历史信息$y_1,y_2,…,y_{i-1}$来生成i时刻要生成的单词$y_i$： 每个yi都依次这么产生，那么看起来就是整个系统根据输入句子Source生成了目标句子Target。如果Source是中文句子，Target是英文句子，那么这就是解决机器翻译问题的Encoder-Decoder框架；如果Source是一篇文章，Target是概括性的几句描述语句，那么这是文本摘要的Encoder-Decoder框架；如果Source是一句问句，Target是一句回答，那么这是问答系统或者对话机器人的Encoder-Decoder框架。由此可见，在文本处理领域，Encoder-Decoder的应用领域相当广泛。 Encoder-Decoder框架不仅仅在文本领域广泛使用，在语音识别、图像处理等领域也经常使用。比如对于语音识别来说，图2所示的框架完全适用，区别无非是Encoder部分的输入是语音流，输出是对应的文本信息；而对于“图像描述”任务来说，Encoder部分的输入是一副图片，Decoder的输出是能够描述图片语义内容的一句描述语。一般而言，文本处理和语音识别的Encoder部分通常采用RNN模型，图像处理的Encoder一般采用CNN模型。 3. Attention模型本节先以机器翻译作为例子讲解最常见的Soft Attention模型的基本原理，之后抛离Encoder-Decoder框架抽象出了注意力机制的本质思想，然后简单介绍最近广为使用的Self Attention的基本思路。 4. Soft Attention模型图2中展示的Encoder-Decoder框架是没有体现出“注意力模型”的，所以可以把它看作是注意力不集中的分心模型。为什么说它注意力不集中呢？请观察下目标句子Target中每个单词的生成过程如下： 其中f是Decoder的非线性变换函数。从这里可以看出，在生成目标句子的单词时，不论生成哪个单词，它们使用的输入句子Source的语义编码C都是一样的，没有任何区别。 而语义编码C是由句子Source的每个单词经过Encoder 编码产生的，这意味着不论是生成哪个单词，还$y_1,y_2$还是$y_3$，其实句子Source中任意单词对生成某个目标单词yi来说影响力都是相同的，这是为何说这个模型没有体现出注意力的缘由。这类似于人类看到眼前的画面，但是眼中却没有注意焦点一样。 如果拿机器翻译来解释这个分心模型的Encoder-Decoder框架更好理解，比如输入的是英文句子：Tom chase Jerry，Encoder-Decoder框架逐步生成中文单词：“汤姆”，“追逐”，“杰瑞”。 在翻译“杰瑞”这个中文单词的时候，分心模型里面的每个英文单词对于翻译目标单词“杰瑞”贡献是相同的，很明显这里不太合理，显然“Jerry”对于翻译成“杰瑞”更重要，但是分心模型是无法体现这一点的，这就是为何说它没有引入注意力的原因。 没有引入注意力的模型在输入句子比较短的时候问题不大，但是如果输入句子比较长，此时所有语义完全通过一个中间语义向量来表示，单词自身的信息已经消失，可想而知会丢失很多细节信息，这也是为何要引入注意力模型的重要原因。 上面的例子中，如果引入Attention模型的话，应该在翻译“杰瑞”的时候，体现出英文单词对于翻译当前中文单词不同的影响程度，比如给出类似下面一个概率分布值： （Tom,0.3）(Chase,0.2) (Jerry,0.5) 每个英文单词的概率代表了翻译当前单词“杰瑞”时，注意力分配模型分配给不同英文单词的注意力大小。这对于正确翻译目标语单词肯定是有帮助的，因为引入了新的信息。 同理，目标句子中的每个单词都应该学会其对应的源语句子中单词的注意力分配概率信息。这意味着在生成每个单词的时候，原先都是相同的中间语义表示C会被替换成根据当前生成单词而不断变化的$C_i$。理解Attention模型的关键就是这里，即由固定的中间语义表示C换成了根据当前输出单词来调整成加入注意力模型的变化的$C_i$。增加了注意力模型的Encoder-Decoder框架理解起来如图3所示。 图3. 引入注意力模型的Encoder-Decoder框架 即生成目标句子单词的过程成了下面的形式： 而每个$C_i$可能对应着不同的源语句子单词的注意力分配概率分布，比如对于上面的英汉翻译来说，其对应的信息可能如下： 其中，f2函数代表Encoder对输入英文单词的某种变换函数，比如如果Encoder是用的RNN模型的话，这个f2函数的结果往往是某个时刻输入$x_i$后隐层节点的状态值；g代表Encoder根据单词的中间表示合成整个句子中间语义表示的变换函数，一般的做法中，g函数就是对构成元素加权求和，即下列公式： 其中，$L_x$代表输入句子Source的长度，$a_{ij}$代表在Target输出第i个单词时Source输入句子中第j个单词的注意力分配系数，而$h_j$则是Source输入句子中第j个单词的语义编码。假设$C_i$下标i就是上面例子所说的“ 汤姆” ，那么$L_x$就是3，h1=f(“Tom”)，h2=f(“Chase”),h3=f(“Jerry”)分别是输入句子每个单词的语义编码，对应的注意力模型权值则分别是0.6,0.2,0.2，所以g函数本质上就是个加权求和函数。如果形象表示的话，翻译中文单词“汤姆”的时候，数学公式对应的中间语义表示$C_i$的形成过程类似图4。 图4. Attention的形成过程 这里还有一个问题：生成目标句子某个单词，比如“汤姆”的时候，如何知道Attention模型所需要的输入句子单词注意力分配概率分布值呢？就是说“汤姆”对应的输入句子Source中各个单词的概率分布：(Tom,0.6)(Chase,0.2) (Jerry,0.2) 是如何得到的呢？ 为了便于说明，我们假设对图2的非Attention模型的Encoder-Decoder框架进行细化，Encoder采用RNN模型，Decoder也采用RNN模型，这是比较常见的一种模型配置，则图2的框架转换为图5。 图5. RNN作为具体模型的Encoder-Decoder框架 那么用图6可以较为便捷地说明注意力分配概率分布值的通用计算过程。 图6. 注意力分配概率计算 对于采用RNN的Decoder来说，在时刻i，如果要生成yi单词，我们是可以知道Target在生成yi之前的时刻i-1时，隐层节点i-1时刻的输出值$H_{i-1}$的，而我们的目的是要计算生成$y_i$时输入句子中的单词“Tom”、“Chase”、“Jerry”对yi来说的注意力分配概率分布，那么可以用Target输出句子i-1时刻的隐层节点状态$H_{i-1}$去一一和输入句子Source中每个单词对应的RNN隐层节点状态hj进行对比，即通过函数$F(h_j,H_{i-1})$来获得目标单词和每个输入单词对应的对齐可能性，这个F函数在不同论文里可能会采取不同的方法，然后函数F的输出经过Softmax进行归一化就得到了符合概率分布取值区间的注意力分配概率分布数值。 绝大多数Attention模型都是采取上述的计算框架来计算注意力分配概率分布信息，区别只是在F的定义上可能有所不同。图7可视化地展示了在英语-德语翻译系统中加入Attention机制后，Source和Target两个句子每个单词对应的注意力分配概率分布。 图7. 英语-德语翻译的注意力概率分布 上述内容就是经典的Soft Attention模型的基本思想，那么怎么理解Attention模型的物理含义呢？一般在自然语言处理应用里会把Attention模型看作是输出Target句子中某个单词和输入Source句子每个单词的对齐模型，这是非常有道理的。 目标句子生成的每个单词对应输入句子单词的概率分布可以理解为输入句子单词和这个目标生成单词的对齐概率，这在机器翻译语境下是非常直观的：传统的统计机器翻译一般在做的过程中会专门有一个短语对齐的步骤，而注意力模型其实起的是相同的作用。 图8. Google 神经网络机器翻译系统结构图 图8所示即为Google于2016年部署到线上的基于神经网络的机器翻译系统，相对传统模型翻译效果有大幅提升，翻译错误率降低了60%，其架构就是上文所述的加上Attention机制的Encoder-Decoder框架，主要区别无非是其Encoder和Decoder使用了8层叠加的LSTM模型。 5. Attention机制的本质思想如果把Attention机制从上文讲述例子中的Encoder-Decoder框架中剥离，并进一步做抽象，可以更容易看懂Attention机制的本质思想。 图9. Google Attention机制的本质思想 我们可以这样来看待Attention机制（参考图9）：将Source中的构成元素想象成是由一系列的&lt;Key,Value&gt;数据对构成，此时给定Target中的某个元素Query，通过计算Query和各个Key的相似性或者相关性，得到每个Key对应Value的权重系数，然后对Value进行加权求和，即得到了最终的Attention数值。所以本质上Attention机制是对Source中元素的Value值进行加权求和，而Query和Key用来计算对应Value的权重系数。即可以将其本质思想改写为如下公式： 其中，$L_x = ||Source||$代表Source的长度，公式含义即如上所述。上文所举的机器翻译的例子里，因为在计算Attention的过程中，Source中的Key和Value合二为一，指向的是同一个东西，也即输入句子中每个单词对应的语义编码，所以可能不容易看出这种能够体现本质思想的结构。 当然，从概念上理解，把Attention仍然理解为从大量信息中有选择地筛选出少量重要信息并聚焦到这些重要信息上，忽略大多不重要的信息，这种思路仍然成立。聚焦的过程体现在权重系数的计算上，权重越大越聚焦于其对应的Value值上，即权重代表了信息的重要性，而Value是其对应的信息。 从图9可以引出另外一种理解，也可以将Attention机制看作一种软寻址（Soft Addressing）:Source可以看作存储器内存储的内容，元素由地址Key和值Value组成，当前有个Key=Query的查询，目的是取出存储器中对应的Value值，即Attention数值。通过Query和存储器内元素Key的地址进行相似性比较来寻址，之所以说是软寻址，指的不像一般寻址只从存储内容里面找出一条内容，而是可能从每个Key地址都会取出内容，取出内容的重要性根据Query和Key的相似性来决定，之后对Value进行加权求和，这样就可以取出最终的Value值，也即Attention值。所以不少研究人员将Attention机制看作软寻址的一种特例，这也是非常有道理的。 至于Attention机制的具体计算过程，如果对目前大多数方法进行抽象的话，可以将其归纳为两个过程：第一个过程是根据Query和Key计算权重系数，第二个过程根据权重系数对Value进行加权求和。而第一个过程又可以细分为两个阶段：第一个阶段根据Query和Key计算两者的相似性或者相关性；第二个阶段对第一阶段的原始分值进行归一化处理；这样，可以将Attention的计算过程抽象为如图10展示的三个阶段。 图10. 三阶段计算Attention过程 在第一个阶段，可以引入不同的函数和计算机制，根据Query和某个$Key_i$，计算两者的相似性或者相关性，最常见的方法包括：求两者的向量点积、求两者的向量Cosine相似性或者通过再引入额外的神经网络来求值，即如下方式： 第一阶段产生的分值根据具体产生的方法不同其数值取值范围也不一样，第二阶段引入类似SoftMax的计算方式对第一阶段的得分进行数值转换，一方面可以进行归一化，将原始计算分值整理成所有元素权重之和为1的概率分布；另一方面也可以通过SoftMax的内在机制更加突出重要元素的权重。即一般采用如下公式计算： 第二阶段的计算结果$a_i$即为$Value_i$对应的权重系数，然后进行加权求和即可得到Attention数值： 通过如上三个阶段的计算，即可求出针对Query的Attention数值，目前绝大多数具体的注意力机制计算方法都符合上述的三阶段抽象计算过程。 6. Self Attention模型通过上述对Attention本质思想的梳理，我们可以更容易理解本节介绍的Self Attention模型。Self Attention也经常被称为intra Attention（内部Attention），最近一年也获得了比较广泛的使用，比如Google最新的机器翻译模型内部大量采用了Self Attention模型。 在一般任务的Encoder-Decoder框架中，输入Source和输出Target内容是不一样的，比如对于英-中机器翻译来说，Source是英文句子，Target是对应的翻译出的中文句子，Attention机制发生在Target的元素Query和Source中的所有元素之间。而Self Attention顾名思义，指的不是Target和Source之间的Attention机制，而是Source内部元素之间或者Target内部元素之间发生的Attention机制，也可以理解为Target=Source这种特殊情况下的注意力计算机制。其具体计算过程是一样的，只是计算对象发生了变化而已，所以此处不再赘述其计算过程细节。 如果是常规的Target不等于Source情形下的注意力计算，其物理含义正如上文所讲，比如对于机器翻译来说，本质上是目标语单词和源语单词之间的一种单词对齐机制。那么如果是Self Attention机制，一个很自然的问题是：通过Self Attention到底学到了哪些规律或者抽取出了哪些特征呢？或者说引入Self Attention有什么增益或者好处呢？我们仍然以机器翻译中的Self Attention来说明，图11和图12是可视化地表示Self Attention在同一个英语句子内单词间产生的联系。 图11. 可视化Self Attention实例 图12. 可视化Self Attention实例 从两张图（图11、图12）可以看出，Self Attention可以捕获同一个句子中单词之间的一些句法特征（比如图11展示的有一定距离的短语结构）或者语义特征（比如图12展示的its的指代对象Law）。 很明显，引入Self Attention后会更容易捕获句子中长距离的相互依赖的特征，因为如果是RNN或者LSTM，需要依次序序列计算，对于远距离的相互依赖的特征，要经过若干时间步步骤的信息累积才能将两者联系起来，而距离越远，有效捕获的可能性越小。 但是Self Attention在计算过程中会直接将句子中任意两个单词的联系通过一个计算步骤直接联系起来，所以远距离依赖特征之间的距离被极大缩短，有利于有效地利用这些特征。除此外，Self Attention对于增加计算的并行性也有直接帮助作用。这是为何Self Attention逐渐被广泛使用的主要原因。 7. Attention机制的应用前文有述，Attention机制在深度学习的各种应用领域都有广泛的使用场景。上文在介绍过程中我们主要以自然语言处理中的机器翻译任务作为例子，下面分别再从图像处理领域和语音识别选择典型应用实例来对其应用做简单说明。 图13. 图片-描述任务的Encoder-Decoder框架 图片描述（Image-Caption）是一种典型的图文结合的深度学习应用，输入一张图片，人工智能系统输出一句描述句子，语义等价地描述图片所示内容。很明显这种应用场景也可以使用Encoder-Decoder框架来解决任务目标，此时Encoder输入部分是一张图片，一般会用CNN来对图片进行特征抽取，Decoder部分使用RNN或者LSTM来输出自然语言句子（参考图13）。 此时如果加入Attention机制能够明显改善系统输出效果，Attention模型在这里起到了类似人类视觉选择性注意的机制，在输出某个实体单词的时候会将注意力焦点聚焦在图片中相应的区域上。图14给出了根据给定图片生成句子“A person is standing on a beach with a surfboard.”过程时每个单词对应图片中的注意力聚焦区域。 图14. 图片生成句子中每个单词时的注意力聚焦区域 图15给出了另外四个例子形象地展示了这种过程，每个例子上方左侧是输入的原图，下方句子是人工智能系统自动产生的描述语句，上方右侧图展示了当AI系统产生语句中划横线单词的时候，对应图片中聚焦的位置区域。比如当输出单词dog的时候，AI系统会将注意力更多地分配给图片中小狗对应的位置。 图15. 图像描述任务中Attention机制的聚焦作用 图16. 语音识别中音频序列和输出字符之间的Attention 语音识别的任务目标是将语音流信号转换成文字，所以也是Encoder-Decoder的典型应用场景。Encoder部分的Source输入是语音流信号，Decoder部分输出语音对应的字符串流。 图16可视化地展示了在Encoder-Decoder框架中加入Attention机制后，当用户用语音说句子 how much would a woodchuck chuck 时，输入部分的声音特征信号和输出字符之间的注意力分配概率分布情况，颜色越深代表分配到的注意力概率越高。从图中可以看出，在这个场景下，Attention机制起到了将输出字符和输入语音信号进行对齐的功能。 上述内容仅仅选取了不同AI领域的几个典型Attention机制应用实例，Encoder-Decoder加Attention架构由于其卓越的实际效果，目前在深度学习领域里得到了广泛的使用，了解并熟练使用这一架构对于解决实际问题会有极大帮助。 原文]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Attention</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EM算法]]></title>
    <url>%2F2019%2F02%2F01%2FEM%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[《统计学习方法》中的EM算法推导及3硬币问题 2硬币问题 补充参考]]></content>
      <categories>
        <category>机器学习</category>
        <category>算法模型</category>
      </categories>
      <tags>
        <tag>EM算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据科学家成长路线]]></title>
    <url>%2F2019%2F02%2F01%2F%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AE%B6%E6%88%90%E9%95%BF%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>数据科学家</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习中的最优化算法总结]]></title>
    <url>%2F2019%2F02%2F01%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%9C%80%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[对于几乎所有机器学习算法，无论是有监督学习、无监督学习，还是强化学习，最后一般都归结为求解最优化问题。因此，最优化方法在机器学习算法的推导与实现中占据中心地位。在这篇文章中，SIGAI将对机器学习中所使用的优化算法做一个全面的总结，并理清它们直接的脉络关系，帮你从全局的高度来理解这一部分知识。 1.机器学习要求解的数学模型几乎所有的机器学习算法最后都归结为求一个目标函数的极值，即最优化问题，例如对于有监督学习，我们要找到一个最佳的映射函数f(x)，使得对训练样本的损失函数最小化（最小化经验风险或结构风险）：$$min_{w}\frac{1}{N}\sum_{i=1}^{N}L(w,x_{i},y_{i})+\lambda ||w||_{2}^{2}$$ 在这里，N为训练样本数，L是对单个样本的损失函数，w是要求解的模型参数，是映射函数的参数，xi为样本的特征向量，yi为样本的标签值。或是找到一个最优的概率密度函数p(x)，使得对训练样本的对数似然函数极大化（最大似然估计）：$$max\sum_{i=1}^{l}lnp(x_{i};\theta)$$ 在这里，θ是要求解的模型参数，是概率密度函数的参数。对于无监督学习，以聚类算法为例，算法要是的每个类的样本离类中心的距离之和最小化：$$min_{s} \sum_{i=1}^{k} \sum_{x \in S_i} \left | x - \mu_i \right |^2$$ 在这里k为类型数，x为样本向量，μi为类中心向量，si为第i个类的样本集合。对于强化学习，我们要找到一个最优的策略，即状态s到动作a的映射函数（确定性策略，对于非确定性策略，是执行每个动作的概率）：$$a=\pi (s)$$ 使得任意给定一个状态，执行这个策略函数所确定的动作a之后，得到的累计回报最大化：$$max_{\pi}v_\pi(s)$$ 这里使用的是状态价值函数。总体来看，机器学习的核心目标是给出一个模型（一般是映射函数），然后定义对这个模型好坏的评价函数（目标函数），求解目标函数的极大值或者极小值，以确定模型的参数，从而得到我们想要的模型。在这三个关键步骤中，前两个是机器学习要研究的问题，建立数学模型。第三个问题是纯数学问题，即最优化方法，为本文所讲述的核心。 2.最优化算法的分类对于形式和特点各异的机器学习算法优化目标函数，我们找到了适合它们的各种求解算法。除了极少数问题可以用暴力搜索来得到最优解之外，我们将机器学习中使用的优化算法分成两种类型（不考虑随机优化算法如模拟退火、遗传算法等，对于这些算法，我们后面会专门有文章进行介绍）： 公式解 数值优化 前者给出一个最优化问题精确的公式解，也称为解析解，一般是理论结果。后者是在要给出极值点的精确计算公式非常困难的情况下，用数值计算方法近似求解得到最优点。除此之外，还有其他一些求解思想，如分治法，动态规划等。我们在后面单独列出。一个好的优化算法需要满足： 能正确的找到各种情况下的极值点 速度快 2.1 费马定理对于一个可导函数，寻找其极值的统一做法是寻找导数为0的点，即费马定理。微积分中的这一定理指出，对于可导函数，在极值点处导数必定为0：$$f^{‘}(x)=0$$ 对于多元函数，则是梯度为0：$$\bigtriangledown f(x)=0$$ 导数为0的点称为驻点。需要注意的是，导数为0只是函数取得极值的必要条件而不是充分条件，它只是疑似极值点。是不是极值，是极大值还是极小值，还需要看更高阶导数。对于一元函数，假设x是驻点： 1.如果$f^{\prime \prime}(x)&gt;0$，则在该点处去极小值 2.如果 $f^{\prime \prime}(x)&lt;0$，则在该点处去极大值 3.如果$f^{\prime \prime}(x)=0$，还要看更高阶导数 对于多元函数，假设x是驻点： 1.如果Hessian矩阵正定，函数在该点有极小值 2.如果Hessian矩阵负定，函数在该点有极大值 3.如果Hessian矩阵不定，则不是极值点 在导数为0的点处，函数可能不取极值，这称为鞍点，下图是鞍点的一个例子（来自SIGAI云端实验室）： 除鞍点外，最优化算法可能还会遇到另外一个问题：局部极值问题，即一个驻点是极值点，但不是全局极值。如果我们对最优化问题加以限定，可以有效的避免这两种问题。典型的是凸优化，它要求优化变量的可行域是凸集，目标函数是凸函数。关于凸优化的详细讲解可以阅读SIGAI之前的公众号文章“理解凸优化”。 虽然驻点只是函数取得极值的必要条件而不是充分条件，但如果我们找到了驻点，再判断和筛选它们是不是极值点，比之前要容易多了。无论是理论结果，还是数值优化算法，一般都以找驻点作为找极值点的目标。对于一元函数，先求导数，然后解导数为0的方程即可找到所有驻点。对于多元函数，对各个自变量求偏导数，令它们为0，解方程组，即可达到所有驻点。这都是微积分中所讲授的基础方法。幸运的是，在机器学习中，很多目标函数都是可导的，因此我们可以使用这套方法。 2.2 拉格朗日乘数法费马定理给出的不带约束条件下的函数极值的必要条件。对于一些实际应用问题，一般还带有等式或者不等式约束条件。对于带等式约束的极值问题，经典的解决方案是拉格朗日乘数法。对于如下问题：$$minf(x)\\ h_{i}(x)=0,i=1,…,p$$ 构造拉格朗日乘子函数：$$L(x,\lambda )=f(x)+\sum_{i=1}^{p}\lambda_{i}h_{i}(x)$$ 在最优点处对x和乘子变量 的导数都必须为0：$$\nabla_{x}f+\sum_{i=1}^{p} \lambda_{i} \nabla x h_{i}=0$$ $$h_{i}(x)=0$$ 解这个方程即可得到最优解。对拉格朗日乘数法更详细的讲解可以阅读任何一本高等数学教材。机器学习中用到拉格朗日乘数法的地方有： 主成分分析 线性判别分析 流形学习中的拉普拉斯特征映射 隐马尔可夫模型 2.3 KKT条件KKT条件是拉格朗日乘数法的推广，用于求解既带有等式约束，又带有不等式约束的函数极值。对于如下优化问题：$$minf(x)\\ g_{i}(x)\leqslant 0\quad i=1,…q\\ h_{i}(x)=0\quad i=1,…,p$$ 和拉格朗日对偶的做法类似，KKT条件构如下乘子函数：$$L(x, \lambda, \mu)=f(x)+\sum_{j=1}^{p} \lambda_{j} h_{j}(x)+\sum_{k=1}^{q} \mu_{k} g_{k}(x)$$ $\lambda$ 和$\mu$称为KKT乘子。在最优解处$x^{*}$应该满足如下条件： $$\nabla_{x} L\left(x^{*}\right)=0$$ $$\mu_{k} \geqslant 0$$ $$\mu_{k} g_{k}\left(x^{*}\right)=0$$ $$h_{j}\left(x^{*}\right)=0$$ $$g_{k}\left(x^{*}\right) \leqslant 0$$ 等式约束 $h_{j}\left(x^{*}\right)=0$ 和不等式约束$g_{k} \quad\left(x^{*}\right) \leq 0$ 是本身应该满足的约束，$\nabla x L\left(x^{*} \quad\right)=0$和之前的拉格朗日乘数法一样。唯一多了关于$g_{i} (x)$的条件： $$μ_kg_k(x^∗)=0$$ KKT条件只是取得极值的必要条件而不是充分条件。在机器学习中用到KKT条件的地方有： 支持向量机（SVM） 2.4 数值优化算法前面讲述的三种方法在理论推导、某些可以得到方程组的求根公式的情况（如线性函数，正态分布的最大似然估计）中可以使用，但对绝大多数函数来说，梯度等于0的方程组是没法直接解出来的，如方程里面含有指数函数、对数函数之类的超越函数。对于这种无法直接求解的方程组，我们只能采用近似的算法来求解，即数值优化算法。这些数值优化算法一般都利用了目标函数的导数信息，如一阶导数和二阶导数。如果采用一阶导数，则称为一阶优化算法。如果使用了二阶导数，则称为二阶优化算法。工程上实现时通常采用的是迭代法，它从一个初始点x_{0} 开始，反复使用某种规则从x_{k}移动到下一个点 ，构造这样一个数列，直到收敛到梯度为0的点处。即有下面的极限成立：$$\lim_{k\rightarrow +\infty}\bigtriangledown f(x_{k})=0$$这些规则一般会利用一阶导数信息即梯度；或者二阶导数信息即Hessian矩阵。这样迭代法的核心是得到这样的由上一个点确定下一个点的迭代公式：$$X_{k+1}=h(X_{k})$$ 2.5 梯度下降法梯度下降法沿着梯度的反方向进行搜索，利用了函数的一阶导数信息。梯度下降法的迭代公式为：$$x_{k+1}=x_{k}-\gamma \bigtriangledown f(x_k)$$根据函数的一阶泰勒展开，在负梯度方向，函数值是下降的。只要学习率$\gamma$设置的足够小，并且没有到达梯度为0的点处，每次迭代时函数值一定会下降。需要设置学习率为一个非常小的正数的原因是要保证迭代之后的$x_{k+1}$ 位于迭代之前的值$x_{k}$的邻域内，从而可以忽略泰勒展开中的高次项，保证迭代时函数值下降。梯度下降法及其变种在机器学习中应用广泛，尤其是在深度学习中。对梯度下降法更全面的介绍可以阅读SIGAI之前的公众号文章“理解梯度下降法”。 2.6 动量项为了加快梯度下降法的收敛速度，减少震荡，引入了动量项。动量项累积了之前迭代时的梯度值，加上此项之后的参数更新公式为：$$W_{t+1}=W_{t}+V_{t+1}$$其中$V_{t+1}$是动量项，它取代了之前的梯度项。动量项的计算公式为：$$V_{t+1}=-\alpha \triangledown _{w}L(W_t)+\mu V_t$$它是上一时刻的动量项与本次梯度值的加权平均值，其中$\alpha$ 是学习率，$\mu$ 是动量项系数。如果按照时间t进行展开，则第t次迭代时使用了从1到t次迭代时的所有梯度值，且老的梯度值按 $\mu^{t}$ 的系数指数级衰减：$$\begin{aligned} V_{t+1} &amp;=-\alpha \nabla_{w} L\left(W_{t}\right)+\mu V_{t} \\ &amp;=-\alpha \nabla w L\left(W_{t}\right)+\mu\left(-\alpha \nabla_{w} L\left(W_{t-1}\ + \mu V_{t-1}\right)\right) \\ &amp;=-\alpha \nabla_{w} L\left(W_{t}\right)-\alpha \mu \nabla_{w} L\left(W_{t-1}\right)+\mu^{2} V_{t-1} \\ &amp;=-\alpha \nabla w L\left(W_{t}\right)-\alpha \mu \nabla w L\left(W_{t-1}\right)+\mu^{2}\left(-\alpha \nabla_{w} L\left(W_{t-2}\right)+\mu V_{t-2}\right.\\ &amp;=-\alpha \nabla_{w} L\left(W_{t}\right)-\alpha \mu \nabla_{w} L\left(W_{t-1}\right)-\alpha \mu^{2} \nabla w L\left(W_{t-2}\right)+\mu^{3} V_{t-2} \end{aligned}$$…….动量项累积了之前迭代时的梯度值，使得本次迭代时沿着之前的惯性方向向前走 2.7 AdaGrad算法AdaGrad算法是梯度下降法最直接的改进。梯度下降法依赖于人工设定的学习率，如果设置过小，收敛太慢，而如果设置太大，可能导致算法那不收敛，为这个学习率设置一个合适的值非常困难。AdaGrad算法根据前几轮迭代时的历史梯度值动态调整学习率，且优化变量向量x的每一个分量$x_{i}$ 都有自己的学习率。参数更新公式为： 其中 $\alpha$是学习因子，$g_{t}$ 是第t次迭代时参数的梯度向量，$\varepsilon$是一个很小的正数，为了避免除0操作，下标i表示向量的分量。和标准梯度下降法唯一不同的是多了分母中的这一项，它累积了到本次迭代为止梯度的历史值信息用于生成梯度下降的系数值。根据上式，历史导数值的绝对值越大分量学习率越小，反之越大。虽然实现了自适应学习率，但这种算法还是存在问题：需要人工设置一个全局的学习率$\alpha$ ，随着时间的累积，上式中的分母会越来越大，导致学习率趋向于0，参数无法有效更新。 2.8 RMSProp算法RMSProp算法是对AdaGrad的改进，避免了长期累积梯度值所导致的学习率趋向于0的问题。具体做法是由梯度值构造一个向量RMS，初始化为0，按照衰减系数累积了历史的梯度平方值。更新公式为：$$RMS((x_t)i)=\delta RMS((x_{t-1}))+(1-\delta )(g_t)_i^2$$ 其中$\delta$是人工设定的参数，与AdaGrad一样，这里也需要人工指定的全局学习率$\alpha$。 2.9 AdaDelta算法AdaDelta算法也是对AdaGrad的改进，避免了长期累积梯度值所导致的学习率趋向于0的问题，另外，还去掉了对人工设置的全局学习率的依赖。假设要优化的参数为x，梯度下降法第t次迭代时计算出来的参数梯度值为$g_{t}$。算法首先初始化如下两个向量为0向量：$$E\left \lfloor g^2 \right \rfloor_0=0\\ E\left \lfloor \triangle X^2 \right \rfloor_0=0$$ 其中$E\left \lfloor g^2 \right \rfloor_0$是梯度平方（对每个分量分别平分）的累计值，更新公式为： 在这里$g^{2}$是向量每个元素分别计算平方，后面所有的计算公式都是对向量的每个分量进行。接下来计算如下RMS量：$$RMS\left [ g \right ]_t=\sqrt{E\left [ g^2 \right ]_t+\varepsilon }$$ 这也是一个向量，计算时分别对向量的每个分量进行。然后计算参数的更新值：$$\triangle X_t=-\frac{RMS\left [ \triangle X \right ]_{t-1}}{RMS\left [ g \right ]_t}g_t$$ $RMS\left [ \triangle X \right ]_{t-1}$ 的计算公式和这个类似。这个更新值同样通过梯度来构造，只不过学习率是通过梯度的历史值确定的。更新公式为： 参数更新的迭代公式为：$$X_{t+1}=X_t+\triangle X_t$$ 2.10 Adam算法Adam算法整合了自适应学习率与动量项。算法用梯度构造了两个向量m和v，前者为动量项，后者累积了梯度的平方和，用于构造自适应学习率。它们的初始值为0，更新公式为： 其中$\beta_{1}$ ， $\beta_{2}$ 是人工指定的参数，i为向量的分量下标。依靠这两个值构造参数的更新值，参数的更新公式为：$$(X_{t+1})_i=(X_t)_i-\alpha \frac{\sqrt{1-(\beta _2)_{i}^{t}}}{1-(\beta _1)_{i}^{t}}\frac{(m_t)_i}{\sqrt{(v_t)_i}+\varepsilon }$$ 在这里，m类似于动量项，用v来构造学习率。 2.11 随机梯度下降法假设训练样本集有N个样本，有监督学习算法训练时优化的目标是这个数据集上的平均损失函数：$$L(w)=\frac{1}{N}\sum_{i=1}^{N}L(w,x_i,y_i)+\lambda r(w)$$ 其中$L(w, x_{i} , y_{i} )$是对单个训练样本$( x_{i} , y_{i} )$的损失函数，w是需要学习的参数，$r(w)$是正则化项， $\lambda$是正则化项的权重。在训练样本数很大时，如果训练时每次迭代都用所有样本，计算成本太高，作为改进可以在每次迭代时选取一批样本，将损失函数定义在这些样本上。批量随机梯度下降法在每次迭代中使用上面目标函数的随机逼近值，即只使用M N个随机选择的样本来近似计算损失函数。在每次迭代时要优化的目标函数变为：$$L(w)\approx \frac{1}{M}\sum_{i=1}^{N}L(w,x_i,y_i)+\lambda r(w)$$ 随机梯度下降法在概率意义下收敛。 2.12 牛顿法牛顿法是二阶优化技术，利用了函数的一阶和二阶导数信息，直接寻找梯度为0的点。牛顿法的迭代公式为：$$X_{k+1}=X_k-\gamma H_{k}^{-1}g_k$$ 其中H为Hessian矩阵，g为梯度向量。牛顿法不能保证每次迭代时函数值下降，也不能保证收敛到极小值点。在实现时，也需要设置学习率，原因和梯度下降法相同，是为了能够忽略泰勒展开中的高阶项。学习率的设置通常采用直线搜索（line search）技术。在实现时，一般不直接求Hessian矩阵的逆矩阵，而是求解下面的线性方程组：$$H_kd=-g_{k}$$ 其解d称为牛顿方向。迭代终止的判定依据是梯度值充分接近于0，或者达到最大指定迭代次数。牛顿法比梯度下降法有更快的收敛速度，但每次迭代时需要计算Hessian矩阵，并求解一个线性方程组，运算量大。另外，如果Hessian矩阵不可逆，则这种方法失效。对牛顿法更全面的介绍可以阅读SIGAI之前的公众号文章“理解牛顿法”。牛顿法在logistic回归，AdaBoost算法等机器学习算法中有实际应用。 2.13 拟牛顿法牛顿法在每次迭代时需要计算出Hessian矩阵，并且求解一个以该矩阵为系数矩阵的线性方程组，Hessian矩阵可能不可逆。为此提出了一些改进的方法，典型的代表是拟牛顿法。拟牛顿法的思路是不计算目标函数的Hessian矩阵然后求逆矩阵，而是通过其他手段得到一个近似Hessian矩阵逆的矩阵。具体做法是构造一个近似Hessian矩阵或其逆矩阵的正定对称矩阵，用该矩阵进行牛顿法的迭代。所有这些主要的数值优化算法都可以在SIGAI云端实验室上免费完成实验：www.sigai.cn通过构造目标函数，指定优化算法的参数与初始化迭代值，可以可视化的显示出算法的运行过程，并对不同参数时的求解结果进行比较。 2.14 可信域牛顿法标准牛顿法可能不会收敛到一个最优解，也不能保证函数值会按照迭代序列递减。解决这个问题可以通过调整牛顿方向的步长来实现，目前常用的方法有两种：直线搜索和可信区域法。可信域牛顿法是截断牛顿法的一个变种，用于求解带界限约束的最优化问题。在可信域牛顿法的每一步迭代中，有一个迭代序列 $x^{k}$ ，一个可信域的大小$\Delta_{k}$，以及一个二次目标函数：$$q_k(s)=(\triangledown f(x^k))^Ts+\frac{1}{2}s^T\triangledown ^2f(x^k)s$$ 这个式子可以通过泰勒展开得到，忽略二次以上的项，这是对函数下降值：$$f(x^k+s)-f(x^k)$$ 的近似。算法寻找一个$s^{k}$ ，在满足约束条件$丨丨s丨丨 \leq \Delta_{k}$ 下近似最小化 $q_{k} (s)$。接下来检查如下比值以更新 $w^{k} 和 \Delta_{k}$ ：$$\rho _k=\frac{f(w^k+s^k)-f(w^k)}{q_k(s^k)}$$ 是函数值的实际减少量和二次近似模型预测方向导致的函数减少量的比值。根据之前的计算结果，再动态调整可信域的大小。可信域牛顿法在logistic回归，线性支持向量的求解时有实际的应用，具体可以阅读liblinear开源库。 2.15 分治法分治法是一种算法设计思想，它将一个大的问题分解成子问题进行求解。根据子问题解构造出整个问题的解。在最优化方法中，具体做法是每次迭代时只调整优化向量x的一部分分量，其他的分量固定住不动。 2.16 坐标下降法坐标下降法的基本思想是每次对一个变量进行优化，这是一种分治法。假设要求解的优化问题为;$$minf(x),x=(x_1,x_2,…,x_n)^T$$ 坐标下降法求解流程为每次选择一个分量x_{i} 进行优化，将其他分量固定住不动，这样将一个多元函数的极值问题转换为一元函数的极值问题。如果要求解的问题规模很大，这种做法能有效的加快速度。坐标下降法在logistic回归，线性支持向量的求解时有实际的应用，具体可以阅读liblinear开源库。 2.17 SMO算法SMO算法也是一种分治法，用于求解支持向量机的对偶问题。加上松弛变量和核函数后的对偶问题为：$$minf_\alpha \frac{1}{2}\alpha ^Tq\alpha -e^T\alpha \\ y^T\alpha =0\\ 0\leq \alpha _i\leq C,i=1,…,l$$ SMO算法的核心思想是每次在优化变量中挑出两个分量$\alpha_{i}$ 和 $\alpha_{j}$ 进行优化，让其他分量固定，这样能保证满足等式约束条件。之所以要选择两个变量进行优化而不是选择一个变量，是因为这里有等式约束，如果只调整一个变量的值，将会破坏等式约束。 假设选取的两个分量为 $\alpha_{i}$ 和 $\alpha_{j}$，其他分量都固定即当成常数。对这两个变量的目标函数是一个二元二次函数。这个问题还带有等式和不等式约束条件。对这个子问题可以直接求得公式解，就是某一区间内的一元二次函数的极值。 2.18 分阶段优化分阶段优化的做法是在每次迭代时，先固定住优化变量x一部分分量a不动，对另外一部分变量b进行优化；然后再固定住b不动，对b进行优化。如此反复，直至收敛到最优解处。AdaBoost算法是这种方法的典型代表。AdaBoost算法在训练时采用了指数损失函数：$$L(y,F(x))=exp(-yF(x))$$ 由于强分类器是多个弱分类器的加权和，代入上面的损失函数中，得到算法训练时要优化的目标函数为：$$(\beta _j,f_j)=argmin_{\beta ,f}\sum_{i=1}^{l}exp(-y_i(F_{j-1}(x_i)+\beta f(x_i)))$$ 这里将指数损伤函数拆成了两部分，已有的强分类器$F_{j-1}$ ，以及当前弱分类器f对训练样本的损失函数，前者在之前的迭代中已经求出，因此可以看成常数。这样目标函数可以简化为：$$min_{\beta ,f}\sum_{i=1}^{l}w_{i}^{j-1}exp(-\beta y_if(x_i))$$ 其中：$$w_{i}^{j-1}=exp(-y_jF_{j-1}(X_i))$$ 这个问题可以分两步求解，首先将弱分类器权重 $\beta$ 看成常数，得到最优的弱分类器f。得到弱分类器之后，再优化它的权重系数 $\beta$ 。 2.19 动态规划算法动态规划也是一种求解思想，它将一个问题分解成子问题求解，如果整个问题的某个解是最优的，则这个解的任意一部分也是子问题的最优解。这样通过求解子问题，得到最优解，逐步扩展，最后得到整个问题的最优解。隐马尔可夫模型的解码算法（维特比算法），强化学习中的动态规划算法是这类方法的典型代表，此类算法一般是离散变量的优化，而且是组合优化问题。前面讲述的基于导数的优化算法都无法使用。动态规划算法能高效的求解此类问题，其基础是贝尔曼最优化原理。一旦写成了递归形式的最优化方程，就可以构造算法进行求解。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>优化算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查准率和查全率]]></title>
    <url>%2F2019%2F02%2F01%2F%E6%9F%A5%E5%87%86%E7%8E%87%E5%92%8C%E6%9F%A5%E5%85%A8%E7%8E%87%2F</url>
    <content type="text"><![CDATA[1.准确率与召回率（Precision &amp; Recall）我们先看上面这张图来加深对概念的理解，然后再具体分析。其中，用P代表Precision，R代表Recall 一般来说，Precision 就是检索出来的条目中（比如：文档、网页等）有多少是准确的，Recall就是所有准确的条目有多少被检索出来了。 下面这张表介绍了True Positive，False Negative等常见的概念，P和R也往往和它们联系起来。 正类 副类 检索到 True Positive False Positive 未检索到 False Negative True Negative 那么，$$P = \frac{tp}{tp + fp}$$$$R = \frac{tp}{tp + fn}$$ 我们当然希望检索的结果P越高越好，R也越高越好，但事实上这两者在某些情况下是矛盾的。比如极端情况下，我们只搜出了一个结果，且是准确的，那么P就是100%，但是R就很低；而如果我们把所有结果都返回，那么必然R是100%，但是P很低。 因此在不同的场合中需要自己判断希望P比较高还是R比较高。如果是做实验研究，可以绘制Precision-Recall曲线来帮助分析。 2.F1-Measure前面已经讲了，P和R指标有的时候是矛盾的，那么有没有办法综合考虑他们呢？我想方法肯定是有很多的，最常见的方法应该就是F-Measure了，有些地方也叫做F-Score，其实都是一样的。 F-Measure是Precision和Recall加权调和平均：$$F = \frac{(a^2+1)P*R}{a^2(P+R)}$$当参数a=1时，就是最常见的F1了：$$F1 = \frac{2PR}{P + R}$$很容易理解，F1综合了P和R的结果，当F1较高时则比较说明实验方法比较理想。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>查准率</tag>
        <tag>查全率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[激活函数作用机制]]></title>
    <url>%2F2019%2F02%2F01%2F%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E4%BD%9C%E7%94%A8%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[激励函数的作用 可视化超参数作用机制：动画化激活函数 激活函数可视化 可视化超参数作用机制：权重初始化]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>激活函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代数]]></title>
    <url>%2F2015%2F10%2F26%2F%E3%80%90%E6%95%B0%E5%AD%A6%E4%B8%A8%E5%9F%BA%E7%A1%80%E3%80%91%E4%BB%A3%E6%95%B0%2F</url>
    <content type="text"><![CDATA[一、代数概览1.1 代数的整体概览1.2 对子领域间关系的理解 二、代数子领域2.1 高等代数基础高等代数与进阶高等代数的关系的理解 2.1.1 基础2.1.1.1 关键知识点2.1.1.2 资料及其概述 《线性代数及其应用》 - David C.Lay 简介：这本书的内容跟中国的教材相比，并没有增加多少，甚至有些东西还有欠缺。但是跟国内图书的不同在于，它详细的讲解了每个公式的来龙去脉和其中的代数和几何意义，使得读者对于那些公式的理解可以提高一个档次。而且整本书的翻译工作也完成的相当出色，绝对不会影响对内容的阅读和理解。 《高等代数》（版本有几个，需要注意）- 丘维声 《Introduction to Linear Algebra》 - Gilbert Strang 《线性代数》 - Steven J.Leon 《Introduction to Applied Linear Algebra–Vectors, Matrices, and Least Squares》 - Stephen Boyd（《凸优化的作者》） 2.1.2 进阶2.1.2.1 关键知识点2.1.2.2 资料及其概述 《线性代数应该这样学》 (Linear_Algebra_Done_Right)》 作者：Sheldon Axler 简介：这本教材写法非常新颖，用向量空间和线性算子的观点贯穿全文，把行列式的内容放在后面，风格上是比较抽象，喜欢逻辑推理和抽象观点的人可以考虑选用这本教材。这本教材最大的优势是和泛函分析等现代数学的语言比较契合； 《线性代数及其应用》 - Peter D. Lax（数学大家） 简介：比前两本Linear Algebra and It’s Applications立意要高，难度要大。 《矩阵分析》 - Horn 简介：矩阵分析领域的圣经级著作，数学专业教材，内容比较庞杂。 《Matrix_Differential_Calculus_with_Applications_in_Statistics_and_Econometrics》 - Jan R.Magnus 简介：矩阵微积分专著。 《矩阵计算》 - Gene H. Golub(已故著名数值计算专家) 简介：被称为数值线性代数的“圣经”。 2.2 抽象代数2.2.1 各抽象对象之间的关系2.2.2 资料及其概述 《A First Course in Abstract Algebra》（2000） - Joseph J.Rotman 《A First Course in Abstract Algebra》（抽象代数基本教程） - John B.Fraleign 《代数学引论》（经典）- 柯斯特利金 《Algebra》（代数学） - B.L.van der Waerden 《Basic Abstract Algebra》 - Robert B.Ash 证明过程非常标准； 《Adanced Modern Algebra》3rd（2015） - Joseph J.Rotman 《Algebra》（经典）- Michael Artin 《Basic Algebra》 I/II - Jacobson 《Abstract Algebra》 - Dummit 《Algebra》（GTM73） - Thomas W.Hungerfod 《Algebra》（GTM211） - Serge Lang 2.2.3 子领域2.2.3.1 群论2.2.3.1.1 关键知识点2.2.3.1.2 资料及其概述 《An Introduction to the Theory of Groups》（GTM148）（1995） - Joseph J.Rotman 《Groups and Symmetry》 - Mark Armstrong 《Group Theory》 - J.S.Milne 《Permutation Groups》 - John D.Dixon, Brian Mortimer “Visual Group Theory“ 2.2.3.2 交换代数2.2.3.2.1 关键知识点2.2.3.2.2 资料及其概述 《Introduction to Commutative Algebra》 - Atiyah 《Commutative Algebra with a view Toward Algebraic Geometry》（GTM150） - David Eisenbud 2.2.3.3 伽罗瓦理论2.2.3.3.1 关键知识点2.2.3.3.2 资料及其概述 《Galois Theory》 J.J Rotman 《Fields and Galois Theory》 J.S.Milne 《Galois Theory》 - E.Artin 2.2.3.4 同调代数2.2.3.4.1 对同调代数的认知 同调代数作为工具（偏于工具化）和层论（和交换代数这样局部概念）结合可以得到整体代数几何结果参考哈茨霍恩的《代数几何》第三章 上同调，单独学习同调代数的抽象工具和语言意义不大，结合起来研究具体的代数几何才有意义。数学不是抽象的产生，而是具体的抽象！ 2.2.3.4.2 关键知识点2.2.3.4.1 资料及其概述 《An Introduction to Homological Algebra》（1979） - Joseph J.Rotman 2.2.3.5 范畴论范畴论是由eilenberg等人为了将同调论公理化给出的一套语言。在格罗腾迪克（导出函子）等名家手上有很大的发展。配边论，广义同调论都可以用这套语言来叙述。所以“经典”的同调代数，广义同调论的书都是很好的； 资料 《Categories for working mathematician》 需要一定的基础才可以看； 《Category Theory for Computing Science》 《Category Theory》Steve Awodey 2.2.3.5 李群李代数2.2.3.5.1 关键知识点2.2.3.5.2 资料及其概述 《Introduction to Lie Algebras and Representation Theory》（GTM9） - James E. Humphreys]]></content>
      <categories>
        <category>数学</category>
        <category>子领域</category>
      </categories>
      <tags>
        <tag>代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[几何与拓扑]]></title>
    <url>%2F2015%2F10%2F26%2F%E3%80%90%E6%95%B0%E5%AD%A6%E4%B8%A8%E5%9F%BA%E7%A1%80%E3%80%91%E5%87%A0%E4%BD%95%E4%B8%8E%E6%8B%93%E6%89%91%2F</url>
    <content type="text"><![CDATA[一、几何概览1.1 几何整体概览1.2 对子领域间关系的理解 区分几何和拓扑的一个东西是研究对象是否具有几何结构，比如度量结构、复结构、辛结构，等等，或者是几种结构混在一起； 流形是曲面的高维推广。之所以在学现代微分几何以前数学系会安排一门“微分几何”的本科课程来学习曲线曲面论，就是为了让你熟悉曲面这个流形的原型。微分几何会用到微积分是因为曲率的定义需要微分，回忆一下，空间曲线的曲率是什么？本质上就是切向量的导数，也就是曲线本身的二阶导数。当然实际上在不光滑的奇异空间上我们也可以定义某种类型的曲率记号，比如Alexandrov space, CAT(0) space 等等，但是那个就比流形还要抽象了。 欧氏几何是平坦的微分几何，就是没有曲率，而且整个空间的拓扑也是平凡的。和群论有联系是因为几何里面有很多对称性，而群论是刻画对称性的工具，所以微分几何里面会有isometry group, holonomy group等等，当然基本群同调群这种拓扑不变量也会经常用到。 1.3 几何子领域1.3.1 解析几何国外很多数学专业没有开设解析几何而我国一直都有解析几何，为什么要学解析几何？解析几何有什么用 解析几何当然有用，但必须要清楚什么是解析几何以及解析几何应该怎么教。首先，解析几何应该看成是$R^n$，尤其是2、3维空间中的线性代数，和线性代数存在明显的对应关系，比如解析几何里面的数量积是线性代数里面内积限制在3维情况下的特殊情况，外积本质上是张量。至于仿射空间和射影空间，都会在后续课程里面遇到，比如代数几何。所以解析几何意义在于给众多相关数学对象给出了2维，3维情况下的特例。但为什么我们不直接讲线性代数和高维的射影几何等等？这主要是因为不管是数学的发展还是我们对数学的理解始终都是按照从具体到抽象，再从抽象到具体的形式演进的，当然，其中的抽象和具体的层次都是不断上升的，比如对于中学生，3维向量是抽象的，但对于大一大二学生，3维向量就是具体的，而仿射、射影空间和代数簇就算抽象的了，对于大三学生，仿射、射影空间和代数簇是具体的，这时候，概型才算是抽象的，但对于硕士来说，这些都是很具体的。在每次抽象程度提高的过程中，都需要在前一阶段的抽象化基础上掌握足够多的例子，如果不知道足够多的例子，是很难理解抽象概念的。所以数学系的教学当然不能回避抽象，当然也要现代化，但仍然讲究逐步抽象的原则。比如我们不能直接给大一学生第一节课就讲范畴论。而对于数学研究本身，也需要知道足够多的例子，以便于在进行抽象的逻辑论证的时候不断对比，以便于验证正确性或者发现证明思路，而避免陷入盲目的抽象推理中； 1.3.2 微分几何概念：研究微分流形（光滑曲线曲面，光滑流形）的几何性质，是广义相对论基础； 1.3.2.1 子领域间关系的理解 古典微分几何为现代微分几何提供了更形象的实例，是现代微分几何形成的基础； 整体微分几何：法国数学家E·嘉当在微分几何中强调联络的概念，建立了外微分的概念。这是整体微分几何的奠基性的工作。随后，中国数学家陈省身从外微分的观点出发，推广了曲面上的高斯-博内定理。从此微分几何成为现代数学不可缺少的领域； 微分流形：也称为光滑流形（smooth manifold），是拓扑学和几何学中一类重要的空间，是带有微分结构的拓扑流形。 微分流形是微分几何与微分拓扑的主要研究对象，是三维欧式空间中曲线和曲面概念的推广，可以有更高的维数，而不必有距离和度量的概念； 1.3.2.2 分类 古典微分几何 研究三维空间中的曲线和曲面； 现代微分几何 研究高维流形的性质； 1.3.2.3 子领域 黎曼几何 —— 黎曼几何以黎曼流形为主要研究对象； 复几何 —— 研究的对象是复流形 辛几何 —— 这是研究辛流形的学科 切触几何 —— 这是辛几何在奇数维上的对应物 芬斯勒几何 —— 以芬斯勒流形为主要研究对象 1.3.2.4 资料及其评述 微分几何教材 《Riemannian Geometry》 - Peter Petersen 《Riemannian Geometry》 - Manfredo do Carmo 1.3.3 代数几何 经典代数几何研究多项式方程的零点。现代代数几何将抽象代数，尤其是交换代数，同几何学的语言和问题结合起来。基本研究对象是在任意维数的（仿射或射影）空间中，由若干个代数方程的公共零点所构成的集合的几何特性； 二、拓扑概览2.1 拓扑整体概览2.2 对子领域间关系的理解2.3 拓扑子领域资料 有哪些值得推荐的拓扑学入门资料？ Allen Hatcher写的拓扑学书单（2003年以前的书目） 《Basic Topology》 - Mark Armstrong 《Topology》 - James R.Munkres 子领域 一般拓扑学：建立拓扑的基础，并研究拓扑空间的性质，以及与拓扑空间相关的概念。一般拓扑学亦被称为点集拓扑学，被用于其他数学领域（如紧致性与连通性等主题）之中； 《Topology》 - Janich 《Basic Topology》 - Armstrong 《Topology》 - J.R.Munkres 这本书讲的很清楚，但是缺点显然，各个部分很零碎，没有整体观念； 《General Topology》 - Kelly 这本相对应的缺点就是很多概念都已经不是拓扑学甚至点集拓扑学里面的主流概念了。比如局部可加细的覆盖这些概念没人用，同样会造成上面我们说的太零碎的感觉； 代数拓扑学：是用抽象代数的方法来研究拓扑的一门数学分支，它试图将拓扑问题转换成一个代数问题，然后利用代数的相关理论工具来加以解决。很多时候，拓扑问题非常抽象复杂，轻易超乎人类的想象力，并且会使得直觉也不再可靠。代数拓扑定义了从拓扑范畴到代数范畴的一个态射，此态射将拓扑空间映成了群，把拓扑映射变成了群同态。至为重要的是，这个态射是“函子”的，这意味着这种范畴间的转化是“保结构的”，信息被尽量保留。 分支： 同伦群 同调 上同调 流形 纽结理论 复形 资料： 《Algebraic Toplology》 - Allen Hatcher 典型的“入门”教本，事无巨细一一列举，例子丰富，相当好。Hatcher本人也是一个很好的老师，自己在代数拓扑中也做出了成果，但是作为专著似乎又太浅白了。而且这本书不含完整的obstruction theory，似乎缺了点强力工具，因此tammo那本估计在这些方面会有所补充； 《Algebraic Topology》 - Tammo 写得相当清晰，读起来就好像上世纪的苏联课本； 《Algebraic Topology》 - Spanier 这本通常是不可能读完的，就像辞海一样。不可能读完的原因其一是其对代数和同调代数的要求比较高，assume的读者通常是已经修完一年级课程的学生，因此你去看的话，很多模论(Module)和追图（chasing diagram）它完全就neglect掉了。而且在当时几何拓扑大行其道的时候Spanier逆风而动写出如此代数化的东西，很不简单。目前的深度上恐怕只有Petermay那本A course可能与之比高低； 微分拓扑学：研究微分流形和可微映射的一个数学分支，是不同于代数拓扑的一个独立的数学分支，但它与代数拓扑的关系极为密切：解决微分拓扑问题的许多基本工具，例如同调群、同伦群都是从代数拓扑中借用过来的。 子领域 微 微分同胚（2个页面） 微分形式（12个页面） 辛 辛拓扑（6个页面） 几何拓扑学：主要研究流形与其对其他流形的嵌入。几何拓扑学中一个特别活跃的领域为“低维拓扑学”，研究四维以下的流形。几何拓扑学亦包括“纽结理论”，研究数学上的纽结； 资料： 《Three-dimensional geometry and topology》 - Thurston 作为几何拓扑开风气之先的人，Poincare几何化猜想的提出者的著作，即便晦涩，你，值得拥有； 组合拓扑学 资料： 《Classical topology and combinatorial group theory》 - Stillwell 这类书不多，硬是要找可以找一本。Stillwell的东西通常是浅显有余深度不足，在现在代数拓扑和微分拓扑都略显颓势，经典组合拓扑慢慢回潮的状况下相信这类书应该会变多； 《Combinatorial topology》 - Aleksandrov 搞组合拓扑的大都是苏联人，因为他们的祖师爷是Aleksandrov，即便是上个世纪此公一直在点集拓扑里面转悠，但是功力深厚，所以欧美的组合拓扑在我看来还是略逊一筹，但是苏联在Aleksandrov死后却没有很好的接续这个传统，直到上个世纪80年代Postnikov在Moscow重开拓扑讨论班，才产生了Novikov这种大将，但是主题也已经是代数拓扑了，颇有岁岁年年人不同之怀；]]></content>
      <categories>
        <category>数学</category>
        <category>子领域</category>
      </categories>
      <tags>
        <tag>几何</tag>
        <tag>拓扑</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[概率]]></title>
    <url>%2F2015%2F10%2F26%2F%E3%80%90%E6%95%B0%E5%AD%A6%E4%B8%A8%E5%BA%94%E7%94%A8%E3%80%91%E6%A6%82%E7%8E%87%2F</url>
    <content type="text"><![CDATA[一、概率论概览 二、资料及其评述 《概率论与数理统计》 - 陈希孺 《数理统计学教程》 - 陈希孺 《概率导论》 - Dimitri P. Bertsekas（最优化领域的大师） 《统计学》 - William M.Mendenhall 《统计推断》 - George M.Ross 《概率、随机变量与随机过程》 - A. Papoulis 《Probability Theory: The Logic of Science》 《A Course in Probability Theory》（概率论教程） - 钟开莱 《Bayesian Data Analysis》（贝叶斯数据分析） 《Statistic Decision Theory and Bayesian Analysis》（统计决策理论和贝叶斯分析） 《Bayesian Choice》 三、子领域3.1 概率图模型3.1.1 关键知识点3.1.2 资料及其评述 《Probabilistic Graphical Models: Principles and Techniques》 - Daphne Koller、Nir Friedman 配套视频 CS228 Koller]]></content>
      <categories>
        <category>数学</category>
        <category>子领域</category>
      </categories>
      <tags>
        <tag>概率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分析学]]></title>
    <url>%2F2015%2F10%2F26%2F%E3%80%90%E6%95%B0%E5%AD%A6%E4%B8%A8%E5%9F%BA%E7%A1%80%E3%80%91%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[一、分析概览 二、分析子领域2.1 微积分入门 《普林斯顿微积分读本》 - Adrian Banner 《托马斯微积分》 - George B. Thomas 简介：很厚的一本书，比国内大多数理工科微积分教材简单，但是内容比国内教材丰富，而且里面运用了很多计算机辅助手段，例如很多三维立体图像就很直观地展现在读者眼前，该书强调数学建模，利用数学解决实际问题，本书虽然内容丰富，但是理论细节并未深入，适合刚初学和侧重应用的受众； 《数学分析新讲》 - 张筑生（前北大教授） 《Calculus Early Transcendentals》5th Ed - James Stewart 简介：被称为立体化教材，大量的二维及伪三维的配图运用与配套的两套光盘中的内容（及相应计算机软件）形成 “可视化的微积分”演示与教学环境，内容从浅入深，循序渐进，配有丰富的习题；全书充分展示了微积分理论的丰富内容、及其在工程实践中的应用，并展现了其作为一门引导人类走向新的文明与进步的数学理论的内在之美。其最大的特点是作者及其合作者花费大量经历所搜集的大量有关微积分在现实生活中适用的示例 《简明微积分》 - 龚昇 简介：龚昇的《简明微积分》是非常有特色的，一开始就抛开实属和极限的严格性问题，迅速直奔微积分的主题，特别是微积分学基本定理，这种处理方式最接近历史，也最突出微积分的思想； 《微积分大意》 - 项武义 简介：和龚昇的《简明微积分》一样，这本书也是抛开严格性问题，注重讲述微积分的思想，作者愿意花大量篇幅，通过许多非常简单的例子(比如圆的面积，抛物线围成的面积，锥体体积)，来传递微积分的思想。所以《微积分大意》 和《简明微积分》这两本书起点不高，适合非常宽广的读者群； 《微积分入门》 - 小平邦彦 简介：小平邦彦这套教材虽然比较精炼，但还是照顾到了微积分学的严格性，风格非常亲切，课后习题也非常不错。书中处理欧拉公式的方法比较新颖，但显得有些啰嗦，大家可以比较一下我的科普文章《》中的处理方式； 进阶 《微积分学教程》（共三卷）- F.M.菲赫金哥尔茨（前苏联） 内容相当全面丰富，是古典方法的微积分权威教材和集大成之作，所有定理都有详尽的讨论，案例很多； 《微积分与数学分析引论》（共两卷四分册） - R.柯朗（德） 简介：循序渐进，包罗万象，它有很丰富的实例和应用，又不乏严密性。虽然本书入门容易，但这套书的总体深度还是相当深的； 《数学分析原理》 - Walter Rudin 简介：Rudin的这本《原理》是强烈推荐的，尤其适合有志于基础数学研究的人。在风格上，这本书的语言是最接近现代数学。实数系八大定理是点集拓扑学的最主要发源地，而鲁丁的处理方式是直接把这些基本性质融入到点集拓扑的语言中。另外每个章节背后都有不少优秀习题，非常适合辅助学习。整本书才三百多页，但内容极为精练，除了数学分析的基本内容外，还涵盖了Fourier级数，微分形式，Lebesgue 积分理论等内容； 《数学分析》 - Apostol 《数学分析八讲》 - 辛钦 简介：很薄的一本小册子，但是把数学分析最核心最本质的东西体现出来了，可以解答诸如“为什么要学数学分析”、“数学分析是干嘛的”此类问题。 《陶哲轩实分析》 - 陶哲轩 简介：从逻辑的角度来看，陶哲轩的这套教材是最完美的，因为从自然数公理体系和集合论，从自然数，到整数，到有理数，再到实数，每一步都有坚实的逻辑基础。另一个特色是用Cauchy(柯西)序列的方法，而不是用Dedekind(戴德金)分割构造实数。虽然书名叫实分析，其实是数学分析的教材，只是在最后讲到Lebesgue 测度和Lebesgue 积分。整本书在语言上也非常接近现代数学，习惯抽象语言的同学可以挑战这本书； 历史相关 《自然哲学的数学原理》 《纯数学教程》 《无穷分析引论》 - 欧拉 2.2 傅里叶分析2.3 复分析 《复分析一种可视方法》 复分析在十九世纪的三位代表人物分别对应三种处理方式:Cauchy–积分公式;Riemann–几何化的处理;Weierstrass–幂级数方法.这三种方法各有千秋,一半的课本多少在其中互有取舍； 2.4 实分析2.5 泛函分析2.6 调和分析2.6.1 傅里叶分析2.6.2 小波分析]]></content>
      <categories>
        <category>数学</category>
        <category>子领域</category>
      </categories>
      <tags>
        <tag>分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数学历史]]></title>
    <url>%2F2015%2F10%2F26%2F%E3%80%90%E6%95%B0%E5%AD%A6%E4%B8%A8%E5%9F%BA%E7%A1%80%E3%80%91%E5%8E%86%E5%8F%B2%2F</url>
    <content type="text"><![CDATA[一、资料及其概述 《普林斯顿数学指南》 《什么是数学:对思想和方法的基本研究》 - R·柯朗（Richard Courant）、H·罗宾（Herbert Robbins） 《数学：它的内容，方法和意义》 - 柯尔莫哥洛夫等苏联数学 《数学概观》 - 戈丁(LarsGarding)(瑞典) 《古今数学思想》（新版）- 莫里斯·克莱因 《微积分的历程：从牛顿到勒贝格》 - William Dunham 《数学在19世纪的发展》克莱因 《数论：从汉穆拉比到勒让德》Andre Weil 《泛函分析史》迪厄多内]]></content>
      <categories>
        <category>数学</category>
        <category>子领域</category>
      </categories>
      <tags>
        <tag>数学历史</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运筹学]]></title>
    <url>%2F2015%2F10%2F26%2F%E3%80%90%E6%95%B0%E5%AD%A6%E4%B8%A8%E5%BA%94%E7%94%A8%E3%80%91%E8%BF%90%E7%AD%B9%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>数学</category>
        <category>子领域</category>
      </categories>
      <tags>
        <tag>运筹学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[统计]]></title>
    <url>%2F2015%2F10%2F26%2F%E3%80%90%E6%95%B0%E5%AD%A6%E4%B8%A8%E5%BA%94%E7%94%A8%E3%80%91%E7%BB%9F%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[一、统计学概览 二、资料及其评述 《概率论与数理统计》 - 陈希孺 《数理统计学教程》 - 陈希孺 《概率导论》 - Dimitri P. Bertsekas（最优化领域的大师） 《统计学》 - William M.Mendenhall 《统计推断》 - George M.Ross 《概率、随机变量与随机过程》 - A. Papoulis 《Probability Theory: The Logic of Science》 《A Course in Probability Theory》（概率论教程） - 钟开莱 《Bayesian Data Analysis》（贝叶斯数据分析） 《Statistic Decision Theory and Bayesian Analysis》（统计决策理论和贝叶斯分析） 《Bayesian Choice》]]></content>
      <categories>
        <category>数学</category>
        <category>子领域</category>
      </categories>
      <tags>
        <tag>统计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《 关于 》]]></title>
    <url>%2FMenu-About%2Findex.html</url>
    <content type="text"><![CDATA[About 项目 刘焕勇（中科院研究所）]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 行业 》]]></title>
    <url>%2FMenu-Industry%2Findex.html</url>
    <content type="text"><![CDATA[1. 自然语言处理的“难点” 语言的多变性； 多义性； 2. 现状和进展2.1 学者视野2020年 《Experience Grounds Language》（2020-11-02） 2019年 李航：自然语言处理中的深度学习：评析与展望（2019-09-01） 刘群：基于深度学习的自然语言处理：边界在哪里（2019-08-24） ACL2019周明：The Bright Future of ACL（NLP）（2019-07-29） CCF-GAIR2019周明：自然语言处理的技术体系和未来之路（2019-07-23） 对话MSRA副院长周明：回望过去，展望未来，NLP有哪些发展趋势（2019-02-12） 现有模型还「不懂」自然语言：20多位研究者谈NLP四大开放性问题（2019-01-22） 2018年NLP应用和商业化调查报告（2019-01-10） 2018年 李生：自然语言处理研究的五点体会（2018-12-24） 会议：语言智能与社会发展时间：2018-12-24学者身份：哈尔滨工业大学教授观点：第一，语言智能是人工智能的最高层次或者最高阶段，语言智能在未来人工智能的应用上有着举足轻重的作用语言和文字是人类区别于其他动物的至关重要的标志，我觉得它对人类社会目前发展至少起到两方面作用。一是大家的协同合作，比如在座各位教授不同课题组之间的合作，例如合作协议也是用语言文字记下的。第二就是代与代之间的文化传承，这也是靠文字。第二，自然语言处理的核心问题（或难度最大的问题）是机器翻译机器翻译分为三个阶段：第一个阶段是基于规则的机器翻译。那个阶段会先把文章中打乱的句子变成单词，之后再查字典，然后进行翻译，翻译之后，可能中文跟英文并不完全对应，需要再按照语法规则进行调整，最主要是调序的问题。第二个阶段是基于统计的机器翻译，在 15、16 年之前，我们都是使用这个方法。第三个阶段是最近几年的基于多层人工神经网络的深度学习机器翻译。机器翻译在近些年间，在这三个阶段其实有两个重大的变化，一是语法上的，乔姆斯基的生成语法理论，第二就是深度学习。原来大家一直对语义分析犯愁，但是深度学习已经开始对语义分析进行探险，大家知道词嵌入的方法，现在把词向量再进一步发展到句子向量，含有语义信息了。在处理过程中，对于单语种，比如说词汇的语义信息，可以把语义相近的靠在一起，不同语种的源语言和目标语言的分布式处理办法，也可以把源语言和目标语言语义相近的一起靠。这个虽然不能说从根本上解决问题，但是减轻了人对语义分析很大的忧愁。第三个，机器翻译的难点和重点我很头疼的是科学性和艺术性，如艺术性的规律怎么总结出来。另外，自然语言具有高度开放性和高度灵活性。在开放性上，如网络出现以后，新词不断涌现，例如粉丝这个词汇。在灵活性方面，可以自己随便去组词，这些新组成的词也很让人头疼。语义理解说白了就是对说话人意图的理解。意图理解与上下文有关系，但是语言本身存在歧义性和多样性，另外，语言高度依赖知识，大家都知道常识知识，例如煤球是黑的，元宵是白的，小孩子常说，「地球人都知道」，但是机器不知道。另外还有领域知识，上下文、语言、环境等都会影响对语义的准确理解。实际上在多对多的翻译中，根据当前的语境找出一种最为合适的译文，我觉得这是个难题。第四，人工智能也好，机器智能也好，人类对他们有个共同要求——学习和求解问题的能力对于学习，人一开始通过感性认识，即感知，进行自主学习，到了一定阶段，他就从家长的不断教导、老师讲的课程或者从媒体上接触新东西，不断积累知识，这是间接知识。前面这种学习方法叫无监督学习，后面这种学习方法叫监督学习。人的学习是小样本学习，将无监督学习和监督学习结合起来，而机器现在需要依赖大量标注数据来进行学习，即监督学习，例如前面描述的图像识别，就是通过大量的标注图像不断学习。机器学习相对于人的学习来说，受限太多。我的观点就是，如果不能解决常识性问题和逻辑推理，要想实现通用人工智能或者机器认知，就会非常困难。现在的研究应该在这方面多下些功夫。虽说现在也有思考对语义的理解，比如 18 年 10 月，谷歌推出了 BERT 双向编码语言模型，但这个模型消耗的资源代价还是比较高的。另外，深度学习确实解决了人工智能的很多问题，但是除了深度学习之外，还可以探讨其他人工智能的算法和模型。我们需要做更多的深度的理论研究和探讨，掌握好核心技术。理论深入之后才能有技术，有了技术之后才能有算法和模型。第五，机器替代不了人类现在的人工智能还只是弱人工智能，不是强人工智能，也不是超强人工智能。现在人工智能的作用，还是用机器代替简单的、重复的以及危险性的劳动，想要解决找不到规律的问题，人工智能还不能做到，也代替不了人。人要尽量用好机器这个助手，自如地运用好机器，这样既可以提高工作效率，也可以保证质量。今天大家谈到外语教学，我觉得人工智能对外语老师和外语专业的学生都不会有太大的影响。低水平淘汰是自然规律，例如讲不好的，没有科研能力的教师，该淘汰就得被淘汰。原来大家争论最多的是医生，说医生要被淘汰，医生与教师一样，是很难被淘汰的。医疗影像诊断还得靠水平高的医生来看。包括我前面说的翻译，也是一样，我觉得最好的翻译、最好的教师和医生，一定是那些对人工智能系统或者教育机器深入了解，能运用自如的人。把这些作为辅助手段，水平会越来越高，效果会越来越好。不是谁淘汰谁的问题，机器永远是人的工具。 NLP的巨人肩膀（2018-12-09） 刘挺：中文信息处理前沿技术进展（2018-11） 微软亚洲研究院：NLP将迎来黄金十年（2018-11） 张金超：微信研究员解析深度学习在NLP中的发展和应用（2018-06-15） 2017年 刘挺：知识获取对自然语言处理的意义所在（2017-06） 自然语言处理NLP技术里程碑、知识结构、研究方向和机构导师(2018-10) 阿里上乘：NLP技术的应用及思考（2017-05） 华为李航：NLP有5个基本问题，深度学习有4个做得很好（2017-04） 李航：迎接自然语言处理新时代（2017-02） 2.2 客观报告2.2.1 官方报告 【NLP】2017-2019ACL各子领域论文统计 【NLP】（2018）清华与中国工程院：2018自然语言处理研究报告 【NLP】（2017）腾讯：自然语言应用和研究 【NLP】（2016）中国中文信息学会：中文信息处理发展报告 【AI】（2018）CSDN：AI技术人才成长路线图 【AI】（2018）年度指数报告 【AI】（2017）年度指数报告 2.2.2 报告解读 解读《AI指数2018年度报告》 3. 趋势和方向探索 2019年在NLP领域，资源有限的个人_团队能做哪些有价值有希望的工作？ 刘铁岩的多次技术转型 启示： 模型运用到时间中，是会改变人的行为的 –&gt; 解决办法是研究博弈论 主动转型的目的是扩大知识面、开拓学术边界、增大实践价值 NLP前路何在？Bengio等27位NLP顶级研究者有话说 冯志伟：语言学家在自然语言处理研究中大有可为——语言探秘(书) 香侬科技对话斯坦福计算机学院Jurafsky教授 香侬科技独家对话斯坦福大学计算机系教授Percy_Liang nlp向左，通用AI向右（佚名） 刚接触nlp时，当我了解大家处理任务的方式时，我的直觉就是：现在大家的做法是有问题的，这样做很快就达到瓶颈，或者用现在时髦的话说：很快低处的果实就会被采摘完毕。当前大家做nlp的方式本质上都是将字词句段篇章表达出来，然后计算距离和概率，最后一通softmax，大功告成。在这个背景下大家要解决的问题就是怎么能embedding出更多的信息，怎么能把距离和概率计算的更精准，我们看到学术界的百花齐放，一片繁荣大抵也都是在这些方向，我们表示文本的方法也从one-hot到Word2vec，再到elmo，glov，然后是gpt，bert。但是我觉得这个方向很快会进展缓慢，因为我们拿到的文本所能表达的信息只有该文本语义信息的万分之一，而我们现在在做的事情的上限就是这万分之一。可能有人会觉得是不是太夸张了，我觉得这个语句表达的很清楚啊，怎么就只有万分之一的信息？但我觉得真实的情况可能更差，连万分之一的信息都不到。看看我们现在对话系统就知道了，能帮我们解决的问题其实万分之一都不到，一句话换个说法就不知道什么意思了，理解能力跟人相比差了不知道多少级别。不夸张的说，当前工业界的对话系统都是一大堆规则加算法堆砌起来的大玩具而已，连最先进的小冰也没有什么质的区别，离可用还差十万八千里。一般会认为cv，语音方向的难度要远小于nlp，而且进展速度也要远快于nlp。常见的说法是cv和语音都是对于信号的拟合和处理，属于感知层面。而nlp属于语义的理解，属于认知层面，所以nlp问题的解决必将伴随着通用人工智能的解决。我基本上认同，但是有一点，当前处理nlp的手段其实也是单纯的把文本当做信号来处理，并没有过多考虑严格意义上的语义。从这个层面讲nlp和cv还有语音都属于一类问题。更通用的讲，我觉得他们都是一个编码和解码的问题。举个例子，“帮我订一张从上海到北京的机票”这句话，当前的主流对话系统处理方式有，规则，意图识别+槽抽取，语义相似判断等。但是人去理解这句话时，或者说人对于这句文本信息进行解码时包含的背景知识是很复杂和庞大的。“北京是一座城市，上海是一座城市，从北京到上海要实现物理空间移动需要借助交通工具，通常的交通工具是火车，火车分一等座和二等座，买票要登录12306网站，坐车要到车站，北京到上海要经过数个小时才能到达。。。”，我们脑海里面因为有这个庞大的常识体系，推理体系，所以才能对于这句话有一个非常准确的语义解析，或者叫解码。这句话本身是有庞大语义信息的，但是落到文字上就没有了，成了单纯的信号，然后人阅读之后再用自己的密码本（知识体系）去解码的时候就又恢复了这些庞大的语义。这就是我理解的单纯依靠文本处理很难去获得文本之后语义信息的根本原因。我们脑海里面的知识体系和推理体系其实包括了很多不同范畴的体系：时间体系，物理运动体系，空间体系，常识体系等等。我们可以统称为世界模型，也就是人相对于nlp模型来说多了一个复杂的世界模型，帮助我们理解语义。而为什么人与人一般可以很流畅交流，是因为我们用的都是人教版教材，做的都是全国一卷和全国二卷，早年的教育和环境已经强行把我们的世界模型统一了。有了同一套密码本（世界模型），我们再想传电报就容易多了。所以我认为，是时候花精力在世界模型的创建和使用上了，这个是目前看来实现通用AI的必经之路。如果非要举例的话，知识图谱算是用计算机可以处理的方式描述世界模型的一种尝试，但是知识图谱还是太粗了，而且表达的关系也很稀疏，几乎不可用。路还有很长，同志仍需努力。 NLP博士答辩41页PPT，面向自然语言处理的神经网络迁移学习 原PPT]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 分类 》]]></title>
    <url>%2FMenu-Category%2Findex.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[《 Life 》]]></title>
    <url>%2FMenu-Life%2Findex.html</url>
    <content type="text"><![CDATA[电影 《我爱你》（韩国电影） 《有熊谷守一在的地方》 书籍 《规模：复杂世界的简单法则》 《春夜十话》 埃尔温·薛定谔 《生命是什么》 埃尔温·薛定谔 《意识与物质》 埃尔温·薛定谔 《自然与希腊人》 埃尔温·薛定谔 《科学与人文主义》 视频 《当幸福来敲门》 《肖申克的救赎》 生命觉者-尹烨 TED演讲 李开复：人工智能将拯救人类 待购 与几何相关的古典名著 几何原本 圆锥曲线论 与数论相关的古典名著 算数探究 数论导引（哈代） 数学物理学方法（柯朗） 不等式 一个数学家的辩白 叔本华哲学随笔（韦启昌版） 集成学习]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 趣文 》]]></title>
    <url>%2FMenu-InterestingPaper%2Findex.html</url>
    <content type="text"><![CDATA[《Cold-Start and Interpretability: Turning Regular Expressions into Trainble Recurrent Neural Networks》 创新点：提出了将正则表达式规则与神经网络深度融合的新思路; 《Glyce：Glyph-vectors for Chinese Character Representations》 创新点：将汉字的形与田字格相结合；]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 足迹 》]]></title>
    <url>%2FMenu-Log%2Findex.html</url>
    <content type="text"><![CDATA[2019年足迹 2020年足迹 2021年足迹]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 问题 》]]></title>
    <url>%2FMenu-Question%2Findex.html</url>
    <content type="text"><![CDATA[一、自我思考 从事NLP这个行业对于自己的意义在哪里 xxx 对于30岁才进入IT行业，相比于其他更早进入这个行业的人，应该更注重哪些东西的积累 xxx 把数学作为兴趣的理由 - 锻炼自己思考的整密性和逻辑性；- 体会数学中的美；- 数学是AI走向更深的可能途径之一，也是支撑AI的有利工具； 二、技术性思考 attention原理是什么，有多少种不同的？ Teacher Forcing 是 Seq2Seq 模型的经典训练方式，它的缺点除了有Exposure Bias还有什么？ 评估指标与损失函数的关系？]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 地图 》]]></title>
    <url>%2FMenu-Map%2Findex.html</url>
    <content type="text"><![CDATA[1. 理论研究1.1 基础学科 基础学科 1.1.1 数学 数学 1.2 学习框架 学习框架 1.3 NLP体系1.3.1 NLP基础技术 NLP基础技术 基于神经网络的NLP体系 1.3.2 NLP系统架构 NLP系统架构 2. 工程实践 工程实践]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 规划 》]]></title>
    <url>%2FMenu-Plan%2Findex.html</url>
    <content type="text"><![CDATA[一、长期规划1.1 职业规划1.1.1 领域定位1.1.1.1 为什么选择NLP ？ 从涉及面的角度来看： NLP主要涉及的是语言学、数学、英语和计算机科学，数学为语言建模提供依据，计算机使模型能够大规模实现与应用，英语作为全球化的语言为研究提供了共同的语言平台从而广泛交流。对人类语言的研究，本身就不能独立于人的各种活动之外，所以还涉及了大量人类社会活动的学科，包括认知学、心理学、哲学等等，对这些内容的理解，更能帮助自己科学地建立价值观、人生观和金钱观，甚至于理解生命的意义； 从困难性的角度看： 语言是人类社会活动的结晶，区别于感知层面的智能，它涉及的学科之广、变化之多，导致了在短时间内要完全解决它的概率几乎为零，即使现在强大的神经网络，也只是“理解了皮毛”，更多的是需要各个科学的结合、人类活动的深入理解等等来共同解决这一难题，这是一个很大、很难的课题，值得用一生去解答； 从个人需求的角度看： 正是因为NLP的深难，所以科研人员需要不断地努力去研究新的方法、模型、和思路，这可以满足自己对“新鲜感”的需要； 从时代的发展看： 大量的非结构化的数据不管是过去积累的还是正在产生的亦或是将来要产生的都是一笔巨大的财富，而NLP正是利用好这笔财富的利器； 从发展空间的角度看： NLP在一定程度上是作为基础工具来使用，这表明了其发展空间十分巨大，落地场景也会随着其发展程度而越来越广泛和实用； 从现实的角度看： 从事这个领域的薪资待遇在目前看来也非常不错； 1.1.1.2 对未来NLP的构想未来的NLP系统应该是具有可解释性的、有知识的、能自我学习的、甚至是有自己独立三观的系统。 1.1.1.3 做中文还是做英文？关于如何选择NLP中子领域，更多的应该是对这些子领域有一定认知的情况下选择，建议可以浏览近几年ACL、EMNLP、NAACL论文；参考：中文NLP vs 英文NLP 中文更接地气，与日常生活更为相关； 英文相关标注语料更多； 1.1.1.4 做对话还是文本？关于如何选择NLP中子领域，更多的应该是对这些子领域有一定认知的情况下选择，建议可以浏览近几年ACL、EMNLP、NAACL论文； 以下是已有的倾向选择： 对话系统组成中涉及到的很多方面的模块也是自己比较喜欢的，比如情感分析、自然语言生成、意图识别、推理、个性化等等； 对话系统的表现更为生活化一点，不像纯文本表现得比较“死板”； 对话系统几乎涉及了NLP的所有基础领域，各个子领域的进步都有可能促进对话系统的提升； 1.1.1.5 选择学术界还是工业界？ 更多的可能是选择工业界，因为考虑到自己学历等相关问题，在学术界可能并没有太多机会； 生产出产品更能给自己带来实际的成就感，比较符合自己的性格和提升对NLP的兴趣； 1.1.2 职业定位 智能时代技术人才的职业成长路径 研究员、算法工程师、软件工程师之间的区别与联系： 研究员的职责在于算法的正确性和创新性； 软件工程师的职责在于保证支持算法的工具的稳定性和高效性； 算法工程师的职责在于算法与工程的衡量； 很多情况下，软件工程师和算法工程师的之间并没有明显的界限； 智能时代科技团队的典型思维模式 定位选择——算法工程师： 理论能力：具有改进模型的能力。这就要求工程师持续追踪NLP前沿动态，吸收新的模型和知识，并把它们融入自己的业务中； 工程能力：具有算法实现能力。优秀的算法工程师一定是一个好的软件工程师，因为： 产品的落地和运行才能为算法产生实际的效用，检验实际的效果； 即使是同一种模型，在实现上也是有不同的，这就可能导致了效率的不同，而效率的不同也反过来影响了改进并迭代新模型的时间，所以编码能力强也是优秀算法工程师必备技能之一； 智能时代技术人才的学习积累路径 1.1.3 能力定位 交流能力：与同行交流； 学术资料的筛选-理解-复现-修改并应用的能力； 搜索筛选资源能力； 资源甄别能力； 1.1.4 参考 沈向洋：你给自己的定位是什么，你就会得到什么 经验1：你不能什么都做（要专注）刚从学校毕业时，我就决定在一家致力于虚拟现实（VR）的初创企业工作，在当时，VR 是一项远远领先于时代的技术。在初创企业，所有的事情都必须你自己做，甚至这样都远远不够。在那个时候，我有了一个孩子。我很快意识到照顾孩子和创业这两件事是不能同时兼顾的。我选择了照顾孩子！我第一次意识到，我的时间和精力并不是无穷无尽的。你不能一次做所有的事情。经验2：要拓宽，先深入在微软研究院（MSR）成立之初，我就加入了它。不知何故，我觉得这将是一个可以开拓新天地的地方。我遇到了很多像Rick Szeliski这样的非凡人物，是他们教会了我在计算机视觉中深入研究运动估计等基本问题的重要性。我学到了当你在做某件事情的时候，理解它，以一种令人信服的方式来书写它，并且真正把它做好，这将会给你带来巨大的进步。我和 Rick 一起合作了很多文章，这里面有一篇论文名为“Creating full view panoramic image mosaics and environment maps”，发表于 1997 年。今天，当你用手机拍摄全景照片时，你可能正在使用我们的算法！寻求重要的问题、解决棘手的挑战，这就是通往领导的道路。成为某个领域的专家，并让这成为自己的个人标签，然后再扩展知识的广度。经验3：会讲故事很重要，对工程师亦然在科研、商业和生活中，你交流你的想法的方式可能比工作本身更重要。我从计算机图形学和交互技术领域的TED——SIGGRAPH中学到了这一点。十多年来，SIGGRAPH教会了我才能的新标准。即使作为工程师，在做技术演示的时候，你也需要通过讲故事来向同事解释你的想法，激励人们去推进你的工作。如果没有人相信，即使你做的工作再好也是无用功。经验4：定位是什么，就会得到什么我决定在北京担任微软亚洲研究院院长，在四年多的时间里，我真正了解了成为一名负责人意味着什么。在刚开始的时候，我们不知道跨国公司在中国的研究院应该做到怎样才算成功。我们是第一个在中国成立研究院的跨国公司！我们制定了三个目标：（1）推进计算机科学领域的发展；（2）为微软的产品贡献技术；（3）造福中国学术界和本土产业。为了实现这些目标，我们不懈地努力。在早期，我们定义的成功标准是使研究院处于领先地位。我在中国的同事们将把微软亚洲研究院变成世界领先的研究院之一。所以，明智地定位你的目标。经验5：把握可控的，留心可见的我被要求回到美国并加入Bing项目，担任产品开发副总裁，尽管我在项目管理、测试和开发方面几乎没有工程经验。对当时的微软来说，Bing是一项新的工作。我必须重新学习最基础的知识：项目如何活下来、如何快速学习和增值。我发现解决Bing项目中最重要的问题需要深入的研究知识：搜索质量机器学习和分布式系统，而我们只有2个相关研究人员。因此，我回到微软研究院并招聘了50多个人。面对竞争对手Google，我们经验匮乏的团队面临着巨大的压力。我们坚持不懈地度过了最艰难的时期，在研究过程中，团队成员经常产生分歧。在这段时间，我总结出一句话：”把握可控的，留心可见的，不管其他。”人们很容易被没有意义的事情所激怒，也经常会把自己困在那些不能解决的问题上。你必须先看看你的身边在发生什么。如果你不能后退一步观察全局，那你什么也不能做。经验6：专注于项目，而不是名头在微软研究院，我遇到了图灵奖获得者、伟大的技术领袖Jim Gray。我曾经问过Jim，“你在微软研究院和SQL都工作过，你似乎从不担心自己是在产品团队还是研究团队。”Jim的回答是，你不应该以你的头衔来定义你的职业生涯。他说，“我跟进的是能产生影响的项目。”他并不关心自己在产品团队还是研究团队。相反，他会思考有什么有趣的项目可以做，以及有什么团队可以一起解决重大难题。不要陷入头衔的泥潭，相反，潜心沉入研究吧。经验7：走中庸之道，不偏不倚无论在职业道路的哪个阶段，你都会做很多事情，你会做决定，你会编程，你会创造，你会实现。但比这些更重要的是，你会是谁？你会因为你是谁而为人所知？很久以前，当我还是一个年轻的中国学生的时候，我接触到了孔子的中庸之道。中庸之道的字面意思是走在路中间，保持你的方向。对我来说，孔子所教东西的本质是要在各方之间保持平衡，倾听、体贴和尊重。人们可能是极端的，并且不知道他们的极端立场是否正确。不要过河拆桥。你永远不知道哪位同事会成为你的下一任老板，哪位实习生会继续创造下一个独角兽。宽宏大量，敞开心扉，友善仁慈。 李纪为：初入NLP领域的一些小建议 ACL2019投稿刚刚落幕，投稿数超过了2800篇，可以说是历史以来最盛大的一届ACL。在深度学习的推动下，自然语言处理这个子领域也逐渐被推上人工智能大舞台的最前列。最近在跟同学的邮件、或者知乎留言中的交流中，不少同学尤其是刚入（jin）门（keng）的同学，提到了深度学习背景下做NLP科研的很多迷茫。基本可以归纳为如下几点：如今一个模型，几十行TensorFlow或者PyTorch就可以解决掉，大家不厌其烦地刷数据集的benchmark，但是因为如今实现模型的门槛低一些，SOTA很难再刷的上去；就算好不容易刷上去了，因为模型千篇一律无非修修补补，文章投出去了因为novelty 受限，文章中不中看天；即便是文章中了，似乎并无太大新意，灌水中已然迷茫。深度算法的风靡会让研究者过度关心这些算法本身，而层出不穷模型结构的调整和改进又让我们眼花撩乱。当侃侃而谈深度学习网络结构变成一个很cool的事情的时候，人们的虚荣心会使得不约而同地忽略了几个重要点。基于我自己多年来曾经走过的弯路，踩过的坑，这篇文章做一点点小的总结。希望会对刚刚进入NLP领域的同学有所帮助。1、了解NLP的最基本知识：Jurafsky和Martin的Speech and Language Processing是领域内的经典教材，里面包含了NLP的基础知识、语言学扫盲知识、基本任务以及解决思路。阅读此书会接触到很多NLP的最基本任务和知识，比如tagging, 各种parsing，coreference, semantic role labeling等等等等。这对于全局地了解NLP领域有着极其重要的意义。书里面的知识并不需要烂熟于心，但是刷上一两遍，起码对于NLP任务有基本认识，下次遇到了知道去哪里找还是非常有意义的。另外 Chris Manning 的 introduction to information retrieval 也是一本可以扫一下盲的书，当然我认为依然不需要记住所有细节，但轮廓需要了解。IR里面的很多基本算法跟NLP有不少的重合。说说我自己曾经走过的弯路。Stanford NLP的qualification考试的一部分就是选一些jurafsky 和 manning书里面的一些chapter来读，然后老师来问相关问题。开始我一直对里面的东西懒得看，所以qualification考试一拖再拖。但博士最后一年没办法拖的时候，才发现如果早知道这些东西，博士早年可以少走很多弯路。为什么了解NLP基础知识的重要，我给大家举几个例子。最近跟同学一起做语言模型 language modeling相关的事情，很多同学用LSTM或者transformers做language model随手就能实现，但是实现一个 bigram 或者 trigram的language model（LM）却因为里面的OOV的平滑问题卡了大半天（熟悉的同学可能知道，需要拉普拉斯平滑或者更sophisticated的Kneser-Ney平滑）。为什么bigram 或者 trigram的LM很重要呢？去做一个语言模型的问题，实现深度模型之前，第一步其实就要去写一个 bigram 或者 trigram的LM。为什么呢？ 因为这些N-gram模型实现简单，并且robust。通过这样简单的实现，可以告诉你这个数据集的LM模型的下限。这样我们心里会有数，神经网络模型至少不应该比这个模型差的。神经网络模型因为其超参数、梯度爆炸等问题，有时候我们不太容易决定是真的模型不行、参数没调好还是代码有bug。那么通过N-gram LM的给出的下限，我们就可以直观地知道神经网络是有bug还是没调好参数。第二个例子就是涉及发文章了，不知道有没有同学想过，BERT里面训练LM的随机替换为什么就使结果变好，随机替换是什么鬼，怎么结果就好了。其实在BERT之前，斯坦福的吴恩达组的Ziang Xie的 Data Noising as Smoothing in Neural Network Language Models ICLR2017 就首次提出了此方法，而且给出了理论解释。这种random替换其实本质上属于language modeling里面基于interpolation的平滑方式， 而基于interpolation的LM平滑，就躺在jurafsky那本书的第3.4.3节。2、了解早年经典的NLP模型以及论文：相比简单粗暴的神经网络模型，早年的NLP算法确实比较繁琐复杂，但里面确实有很多早年学者在硬件条件艰苦情况下的智慧结晶。熟悉了这些模型，可以在现在神经网络里面融会贯通。去年在人民大学做seminar。Seminar有大概30-40位同学参加。Seminar中，我问了一个问题，有谁知道机器翻译中的IBM模型大概是干嘛的，举手的同学大概有五分之一。我再问，谁能来手写（或者大概手写）一下IBM model1，一个人都没有。仅仅从基于IBM模型的Hierarchical Phrase-based MT, 近几年就有很多篇引用量很高的文章是基于里面的思想的。例子数不胜数：1) chris dyer 组的Incorporating structural alignment biases into an attentional neural translation model (NAACL16) 提出用双向attention做neural机器翻译的约束项，意思是如果在英语翻译法语生成的target中的一个法语词attend到了一个source中的英语词，那么反过来，法语翻译英文 target中相同这个英语词应该也attend到source中的这个英语词。其实这个思想就是完完全全相似 Percy Liang 曾经的成名作之一，早在NAACL06年 Alignment by Agreement，大家通过题目的意思就可以猜到文章的内容，正向翻译与反向翻译中的 对齐(alignment) 要 一致(agree)。如今做neural MT的同学，有多少同学读过Percy的这篇大作呢 （大家知道Percy最多的应该是Squad吧）。2) 处理对话系统的无聊回复，用反向概率p(source|target)做reranking现在应该已经是标配。再比如Rico Sennrich的成名作之一将Monolingual data 跟seq2seq 模型结合。其实这连个思想在phrase-base MT 里面早就被广发的使用。Neural之前的MT，需要对一个大的N-best list用MERT做 reranking， 反向概率 p(source|target) 以及语言模型概率 p(target)是reranking中feature的标配。3) Harvard NLP组, Sam Wiseman 和Alex 发表的EMNLP16 best paper runner-up, Sequence-to-Sequence Learning as Beam-Search Optimization, 基本上传承了Daume´ III and Daniel Marcu 2005年的 LaSO模型，将其思想adapt到neural里面。如果再追本溯源，诞生于neural MT的attention，不就是IBM模型的神经网络版本嘛。3、了解机器学习的基本模型：神经网络的简单暴力并且有效。但是从科研的角度讲，熟悉基本的机器学习算法是必修课。比如吴恩达的 machine learning就是必要之选。记得前段时间我面试一个小伙子，一看就是很聪明的同学，而且很短的时间就有一篇NAACL在投。我就问小伙子，EM算法是什么，小伙子说没有听说过EM，而且自己的科研也用不到EM。我认为这其实是一个挺大的误区。当我想起我自己，曾经就吃过很多类似的亏。因为早期数学基础偏弱，也没有决心恶补一下数学，所以早年每次看到跟variational inference相关的算法就头大，这种偏科持续了很久，限制了科研的广度。相比粗暴的神经网络，CRF等模型的inference确实相对复杂（当年我自己也看了很多次才彻底搞明白）。但搞懂这些，是一个NLP researcher的基本素养。Pattern Recognition and Machine Learning那本书，尤其是某些小节确实比较难（又暴露了数学基础差的事实），即便是只是为了过一遍，也需要很强的耐力才能看完，更不用说完全看懂了。我自己也曾经半途而废很多次，如今依然有很多章节是不太懂的。但是其中的很多基础chapter，我认为还是很值得一读的。其实可以组成那种两三个人的学习小组，不需要有太雄伟的目标，用个一年哪怕两年的时间，把几个重要的chapter 过一遍。NLP相对是应用科学，并不是特别的数学。但是我们天天用的算法的基本数学逻辑我认为还是需要搞懂，比如dropout, 比如天天用到的优化(SGD, momentum, adaboost, adagrad)，比如各种 batch, layer normalization。这样其实可以省去很多浪费的时间，磨刀不误砍柴工。这些年来，在帮同学调bug的过程中，我至少遇见过3-5个同学 training 的时候开dropout, test 的时候没有对每个cell用 (1-dropout)去 scale （大家不要笑，这是真的）。然后画出dropout曲线就是 dropout 值越大，结果越差。在讨论的时候，同学一脸茫然并且不清楚test时候需要scale。其实本质就是并不了解dropout背后的数学原理。4、多看NLP其他子领域的论文：NLP有很多子领域，MT，信息抽取，parsing，tagging，情感分析，MRC等等。多多熟悉其他子领域的进展是必要的。其实不同子领域所运用的模型不会相差太大。但是最开始看不熟悉领域的问题可能会有一点难，原因是对问题的formalization不是很了解。这可能就需要多花一些时间，多找懂的同学去问。其实了解不同问题的formalization也是对领域知识最好的扩充。5、了解 CV和data mining领域的基本重大进展：当熟悉了上面所说的点之后（当然可能至少也需要一年的时间）。熟悉CV领域的基本任务、基本算法我认为对于打开科研视野很重要。但是不可否认，因为领域不同，写作风格、术语表达相差很大，又因为缺乏背景知识（文章中会省略一些基础知识，默认大家都懂。但是跨领域的人可能不懂），第一次想读懂跨领域的文章其实并不容易。我就出现过竟然在讨论班上直接把faster-RCNN讲错了的情况，以为自己看懂了，然后就讲错了（至今昱先天天还在因为这个事情调侃我）。不过重要的是，NLP领域里面一些重要的文章其实或多或少借鉴了CV里面的思想，当然也同样出现CV借鉴NLP的情况。NLP神经网络可视化、可解释性的研究，时间上还是落后于CV里面对CNN的可视化。所以很多工作大量借鉴了CV里面的类似工作。NLP运用GAN其实也是借鉴CV的。其实两个领域很多是很相通的。比如，如果不考虑question query, vision里面detection中的 region proposal（在一个大的图片背景下找一个特定区域）, 大家想是不是跟MRC里面的 span extraction （在一大堆文字里面找一个span）有异曲同工之妙。更不用说image caption generation与sequence-to-sequence模型了，本质上几乎没什么太大的区别。强化学习在生成领域generation，发完了MT(Ranzato et al., ICLR2016)再发 image caption generation, 再回到summarization. Actor-critic 模型也是类似的，还是很多做generation diversity的文章。因为跨领域不好懂，所以第一次推荐看tutorial, 如果有 sudo code 的tutorial那就更好了。另外看看扫盲课的视频，比如Stanford CS231n也是个好办法。另外，一个NLP组里面有一个很懂CV的人也很重要（拜谢昱先）， and vise versa。graph embedding近两年崛起于data mining领域。目测会在（或者已经在）NLP的不少任务得到广泛应用。想到几年前，deep walk借鉴了word2vec, 开始在data mining领域发迹，然后似乎又要轮转回NLP了。—— 香侬科技 李纪为 2019年3月11日 吴华（百度） Q：从 AI 学术研究到工业界落地有哪些难点？A：应用的场景和时机的选择：技术成熟度，工业界关注技术的普适性，而研究人员关注技术在单点的突破性，这两者的差距，容易造成对技术成熟度的误判。另外，场景的选择很重要，针对不同的场景和用户，需求可能很不一样，NLP 属于基础技术，一方面要有通用性，一方面要提供定制化能力。改进的手段：从用户的角度、实际的应用场景出发思考问题，不能闭门造车。 比如同传技术，并不是只追求翻译质量，还需要考虑到时延的影响，做到两方面的平衡。比如语音唤醒除了考虑唤醒的识别率，还要考虑误报、噪声问题，麦克风的数量及布置方式；技术上需要反复迭代，针对应用问题优化，不断打磨细节。合作的方式：应用落地需要多方合作，PM、RD、运营等等；产品上往往也不是一种技术的应用，而是多种技术的综合应用，一个客服机器人，不仅仅需要语音识别、还需要合成、知识和自然语言理解，需要各个技术团队之间的合作，各种技术如何融合、相互提升，出了问题如何排查和解决。Q：在长期奋进中保持专注，是 AI 时代人才最宝贵的特质A：从研究角度看：一方面要紧跟技术进展，另一方面需要提高定义问题的能力，做出引领技术方向的成果。同时心怀探索科技奥秘的好奇心和以科技改变世界的信念，才可能一直保有对 AI 的热情。从应用角度看：在技术方面，关注最新的技术动态以及实用的工具平台；在落地方面，关注用户的真实需求和应用场景，采用合适的技术方案很重要，切勿好高骛远。不论从事 AI 研究还是应用落地，都要有“严谨务实、持之以恒”的精神，要磨练好基本功，往往需要长期的积累才会产生突破，比如机器翻译、人机对话等都是螺旋式上升的技术领域。能够在长期奋进中保持专注，才是人工智能时代人才最宝贵的特质。 周志华：做研究与写论文 How to do research at the MIT （中文翻译链接） 张驰原：Engineer和Scientist的界限 在数值计算（或者任何其他工程领域）里，知道一个东西的基本算法和写出一个能在实际中工作得很好的程序之间还是有一段不小的距离的。有很多可能看似无关紧要的小细节小 trick，可能会对结果带来很大的不同。当然这样的现象其实也很合理：因为理论上的工作之所以漂亮正是因为抓住了事物的主要矛盾，忽略“无关”的细节进行了简化和抽象，从而对比较“干净”的对象进行操作，在一系列的“assumption”下建立起理论体系。但是当要将理论应用到实践中的时候，又得将这些之前被忽略掉了的细节全部加回去，得到一团乱糟糟，在一系列的“assumption”都不再严格满足的条件下找出会出现哪些问题并通过一些所谓的“engineering trick”来让原来的理论能“大致地”继续有效，这些东西大概就主要是 Engineer 们所需要处理的事情了吧。这样说来 Engineer 其实也相当不容易。这样的话其实 Engineer 和 Scientist 的界线就又模糊了，就是工作在不同的抽象程度下的区别的样子。 Serena&nbspGao：NLP的学习建议 我觉得应该先了解nlp是干嘛的，做中文还是英文，对话还是文本，然后看你的兴趣点和老板的兴趣点是不是一致，老板能帮到什么。nlp借用我们老板的话说是”unstructured data converted to structure data”。 想明白task是什么，充分熟悉你手头的数据集，再来想应该用ml/dl算法才对吧。推荐先看nlp基本知识，什么是pos, chunker, lemmatize, tokenize, 什么情况下用dependency parser, constituent parser。什么情况下用name entity recognition。我见过有做nlp的人熟用tensorflow，但不知道ner是做啥的。还有些编程的基本功：输入一个语法树怎么把主干抽出来，怎么找到并列结构，etc。nltk, scikit learn，stanford corenlp这些包应该翻来覆去的熟用。然后可以找一些小的数据集，可以先建个小的模型练练手，比如拿一个长篇小说来训练一个模型，然后给定一些词看下一个词模型会输出什么。这其中会涉及clean, preprocessing, 建模，训练数据集。如果想了解nlp下都有哪些小方向，推荐看acl 会议的网站，比如2017 acl, program下面细分了很多个section： discourse, machine translation, sentiment, summarization etc.. 太多了就不细说了。为啥要强调以上的基本功？当你拿到一些数据集，文本也好对话也好，第一件事应该是仔细阅读，找出language phenomenon／pattern, etc,然后决定应该做什么预处理，接下来再去想应该用哪个算法。如果只是依赖ml/dl，当成一个黑匣子，那只能叫probablistic language modeling。 邱锡鹏：能力进阶列表 第一阶段：实现模型，调参能力给一个idea或者论文，能够快速实现（可以基于开源），并复现结果；第二阶段：实际问题抽象能力将实际的繁琐问题抽象为某个典型的NLP任务（比如分类或序列标注），并用成熟的模型来解决；第三阶段：新问题的解决能力有些问题无法用现有模型解决，需要改进模型或别的办法来解决；第四阶段：经验积累的能力经过长时间的打磨，不管是使用了高大上的技术还是人工规则，成功开发了一种核心技术，具有不可替代性；第五阶段：技术路线的把控能力结合公司的业务，确定团队的整个技术路线。要有适当的前瞻性，不走弯路。正确衡量某个任务的工作量，合理进行团队分工，执行工作计划； 张志华：机器学习的发展历程及启示 斤木 Q：自然语言处理专业，如何切入更有效，为什么？A：我的建议是，这些好书需要读，但以泛读为主，精读为辅。如果你已经了解了NLP中的基础知识，比如language model, n-gram, syntax, 对于绝大多数对你真正需要的学科知识，更好的选择是定向精读一两篇好的survey。NLP领域的知识体系过于庞杂。下有machine learning, 上顶data mining, 左接cognition, 右连linguistics, 内含MT, QA, SA, TE, SP等只有你想不到没有别人没做过的任务。了解“整体结构”当然有益，但在这种情况下，在前期如果试图通过花过多时间在把握大局上，几乎没有尽头。另外，你所以为的“整体结构”常常并不是真正的“整体结构”。一个研究者的宏观视角，是在实践中随着对于学科的深入理解而不断变化的。管中窥豹，性价比太低。我的建议是选择感兴趣的一二切入点：可以是任务，比如MT；也可以是方法，比如NN. 了解经典的思想和最新的进展，然后从此出发向周边的任务、方法探索，是更平衡的做法。从这个角度看，survey远远比大部头的著作要实惠。其实很多survey也是好几百页，打出来和书也没什么分别。如果你读了NMT的survey觉得不过瘾，就去读SMT的survey和seq2seq的survey, 相信你获得inspiration的概率要比不带目标的精读宗成庆老师的统计自然语言处理要大。NLP发展速度太快，绝大多数东西都没有定论。书籍的滞后性要比期刊强，期刊的滞后性要比会议强。所以，了解了大概就做起来吧少年。 机器学习需要的数学知识 如何成为一名对话系统工程师 writing code for nlp research Sebastian&nbspRuder：NLP领域的学习故事 Q：对于那些对NLP感兴趣的读者、初学者，你有什么好建议呢？A：通过浏览NLP发展历程，先找到一个感兴趣的任务。如果你喜欢做科研，选择一个不是大家都在做的、特别的子任务。比如，情感分类是基于对话的，所以不适用于电影评论任务。总的来说，读一些过去的论文而不是新论文。读一些和自己研究领域相关的论文，尝试着理解那些先进的算法是如何工作的。尝试那些有开源代码的、你自己可以实现的任务。一旦你对这些基本的原理有了大体了解，对于科研，想一想你是否被某篇论文所启发。想一想你的模型会出什么错误，并想方设法地解决它们，比如我们可以尝试错误分析，并使用一些合成工具来判断模型是否包含了某种信息。Q：考虑到学术研究的迅猛发展，如何时刻保持在领域前沿呢？A：我每天都会去arXiv看日常更新，添加一些相关的论文到我的阅读清单里，成批地完成阅读。Jeff Dean最近在一个深度学习大会上说，粗略地读10篇论文比精钻1篇论文要好。我非常赞同他的看法，你要尽可能多地阅读，这样心中就能了解大概，并能在日后的工作中获得启发。有一个良好的论文管理体系也是关键，我一直都在用Mendeley。最近我在用arXiv的整理工具来保存相关的论文。Q：你一直坚持写博文，我也是拜读者之一。请问你能分享一些高效书写科技类文章的经验吗？A：写博客是一种能使我加深对某个特定领域理解的绝好方式。如果你发现自己要费很大劲才能培养学术直觉，或者要做大量研究才能掌握一门学科，那么，把这个过程写进博客，这样你就能在将来加速其他人的学习。科研论文通常没有足够的篇幅，详细阐述进行的工作，充分说明自己灵感来源和学术直觉。而博客就能让这些技术部分显得更加易于接受与了解。写博客好的地方是它不苛求完美。你可以用他来提升自己的沟通能力，也可以得到关于自己想法的反馈，防止遗漏掉自己没有考虑的事。Q：总结之前，有什么建议给那些因为感觉深度学习是高技术含量领域，而迟迟不敢开始的初学者呢？A：- 不要相信别人跟你说你做不到。- 上网课加深自己的理解。一旦你感觉自己已经入门了，有时间就读论文以获得启发。- 选择你感兴趣的领域，然后立即开始工作。- 不要觉得解决有意义的问题需要大量计算，特别在NLP领域，很多问题只需要少量标记数据就能解决。- 把自己在做的、在学的写下来。- 和那些有相同兴趣或研究领域的人多多交流，比如fast.AI社区，我觉得很赞。- 上推特。推特上有很棒的机器学习社区，你能比发邮件更快地得到大牛的回复。- 找个导师。如果你咨询某人，一定要注意他们的时间。- 尊重并乐于帮助他人。- 看淡褒奖，也要警醒批评。 那些高产的学者都是怎样工作的？ 1、坚持阅读。多跟优秀的学者交流你会发现，读文献、持续读文献、读最新的文献是他们一辈子持续在做的事情。事实上，保持大量的、高质量的阅读是写出好文章的必备条件，没有人能绕道而行。研究这件事本质上就是一个依托于持续学习、持续输入新知识、持续跟进新方法才能达到不断高产出的过程。让自己坚持阅读的具体方法有很多，比如每周制定计划必须读几篇新的文献，比如加入本学科最重要的几个期刊的新文章提示mailing list, 比如借阅知名大学某领域博士课程的syllabus（课程大纲）并按其日程列表完成每周的阅读等。路径万变而不离其宗，总之一句话：never stop reading。2、保护你的做研究时间。要学会有意识、有目的、雷打不动地去保护好自己每周的写作时间和做研究的时间，否则你的时间注定会被各种杂事填满。所谓“预则立不预则废”，你自己不去计划如何使用时间，你的时间就注定会被其他人和其他事带跑。年轻学者最容易出现的问题是常常花过多的、不必要的时间在教学或者其他琐碎的事情上，并不是因为这样做一定是有必要的，而往往是因为做这些事情比做研究“更容易”，更能给我们完成任务的成就感。于是所有容易的事情都被一件件的做完了，重要的事情却一拖再拖。所以时间管理的概念就再次显得尤为重要（比如，各种时间管理书籍中建议的每天早晨要列出今天一定要做的三件事情）。另外《Essentialism》（《精要主义》）一书中倡导的给工作和生活做减法而不是做加法以保证最重要的事情能被有效的完成也是这个道理。3、“深耕”还是“兼顾”对于年轻学者来说，是应该多花时间在某一个专门的小领域深耕，还是在相关的一些领域都应该有涉及?作为年轻学者最好能更多的在一个领域深耕，要尽量让自己成为某个领域的专家。相对而言，在不同的领域做涉猎会分散人的很多精力和时间，因此要学会有选择的开始新的项目和对有一些机会说“不”。你的论文成果可能横跨几个大题目，但是如果没有一个集中的方向，就会给人没有专长的感觉。但这并不是说完全不能涉猎其他题目，总体来说70%-80%的精力应该首先放在某一个专门的领域，其他的时间和精力可以做一些自己感兴趣的其他研究。当你在某个方面的成果越来越多的时候，相对而言去做其他感兴趣的话题的机会和条件也会越来越成熟。 算法工程师必须要知道的面试技能雷达图 1.2 生活规划 保持健康，增强记忆力； 形成良好的性格、习惯； 形成良好的世界观、价值观、金钱观； 形成自己的思维模式； 衡量好工作与生活的时间； 增强人际关系； 找到适合自己的学习方式； 二、中期规划 三、短期规划找工作1. NLP模块 基础模块 词法：分词、词性标注、命名实体识别（与知识图谱关联）； 句法：依存分析、短语分析（语法分析） 常用模型：HMM、MaxEnt、CRF、LDA、PCFG、语言模型（+平滑种类）、编辑距离； 正则表达式（传统规则方法工具）； 文本预处理； 文本表示； 中间任务 信息抽取、意图识别、文本分类、文本匹配、情感分析、query理解/改写/扩展/简化、拼写纠错、关键词提取、阅读理解、文本摘要、文本生成； 应用 对话 常用库 NLTK、Spacy、fasttext、gensim； 模型部署； 前沿模型 word2vec、Glove、Elmo、attention、transformer、Bert、XLNet、AlBert、GPT、textRNN、textCNN； 加分项 知识图谱； 大数据； 2. ML模块 传统ML常用模型 CRF、HMM、EM、提升方法、SVM、逻辑回归、最大熵模型、决策树、朴素贝叶斯、KNN、感知机； 模型的评估与选择； 深度学习常用模型 前馈神经网络、CNN、RNN（循环神经网络）、GRU、LSTM、RNN（递归神经网络）； 深度学习中的优化技巧 过拟合/欠拟合、网络正则化、超参数搜索、归一化、参数初始化、优化算法（SGD等）、梯度消失/爆炸、激活函数； 相关库及工具 TensorFlow、Pytorch、sklearn、numpy、scipy、pandas、matplotlib； 资料参考 《统计学习方法》 《神经网络与深度学习》 3. 数学模块 微积分：使用《普林斯顿微积分读本》； 完成情况描述：基本概念、重要思想基本掌握，但是对于计算题训练较少，对于公式的应用不是很熟悉； 线性代数：使用《线性代数及其应用》； 概率论与数理统计：使用《概率论与数理统计》陈希孺； 4. 编程模块 目标 对数据结构和算法有相对深入的理解和掌握； 熟练掌握python，对python的内部实现有一定的了解，对常用库做到熟练使用，包括正则表达式、网络编程，多线程编程、数据库编程和图形化编程； 熟悉Linux的操作环境，学会脚本编程； 学会C++的使用； 了解一定的网络知识，掌握sql语言； 资料参考 《流畅的Python》 《Python核心编程》 《Essential C++》 《鸟哥的Linux私房菜》 《剑指Offer》 《数据结构与算法：Python语言描述》 LeetCode 5. 英语 目标 形成英文思维以便很好的理解英文内容，文化和思想等等； 读，听，写，说四种能力的重要性就目前需求而言是依次递减的； 安排 环境浸泡，刻意为自己创造英文环境，让自己对英文环境更为熟悉和适应，方式包括： 阅读英文论文； 听英语课程和演讲； 下载英文的APP看新闻； 电脑软件设置为英文； 用英文做笔记，写总结； 用英文写博客，记事； 每天学习； 6. 面试 在网上找模型的考点在哪？更有针对性 基于Pytorch的自然语言处理]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 资源 》]]></title>
    <url>%2FMenu-Source%2Findex.html</url>
    <content type="text"><![CDATA[Source 一、前沿1.1 网址 arXiv.org 主要是最新发表的论文，但是鱼龙混杂，需要自己分辨； paperswithcode 主要用于浏览人工智能各个领域的SOTA及其模型和论文； 谷歌学术 主要用于查找论文，同时也可以用于查找优秀学者相关的信息； AMiner 主要是关于华人学者的排名等； 中国中文信息学会 主要是展示国内的一些与NLP相关的活动； CSRanking：Computer Science Rankings 主要用于查看领域的前沿学术机构及其相关学者排名； 智源社区 国内的关于AI行业发展的最新动态； dflp 关于计算机科学的各领域目录； 二、会议2.1 国际会议2.1.1 NLP相关 ACL：Annual Meeting of the Association for Computational Linguistics EMNLP：Empirical Methods in Natural Language Processing NAACL：The North American Chapter of the Association for Computational Linguistics CoNLL：Conference on Computational Nautral Language Learning COLING：International Conference on Computational Linguistics 2.1.2 AI相关 AAAI：Association for the Advancement of Artificial Intelligence ACM：Association for Computing Machinery ICLR：International Conference on Learning Representations 2.2 国内会议 NLPCC：The CFF Internation conference on Natural Language Processing and Chinese Computing 中文名：CCF国际自然语言处理与中文计算会议 CCL：China National Conference on Computational Linguistics 中文名：全国计算语言学大会 CCIR：China Conference on Information Retrieval 中文名：中国信息检索学术会议 SMP：National Conference on Social Media Processing 全国社会媒体处理大会 CCKS：China Conference on Knowledge Graph and Semantic Computing 中文名：全国知识图谱与语义计算大会 CWMT：China Workshop on Machine Translation 中文名：全国机器翻译研讨会 三、学者$Tips:$这个可以根据 CSRanking 中得到NLP行业中大学的排名（没有公司的），并且每个大学下面有每个教授的名字和个人网页等情况。 3.1 国外 Dan Jurafsky： 个人网站 Micheal Collins: 个人网站 Ruder Abi 3.2 国内 李航： 个人网站 邱锡鹏（复旦）： 个人网站、Github、微博、知乎、邮箱 黄民烈（清华）： 个人网站 刘知远（清华）： 个人网站、知乎、邮箱 周志华（南大）： 个人网站 吴恩达：个人网站 52nlp 我爱自然语言处理 hankcs 码农场 语言日志博客 立委NLP频道 刘建平 四、书籍4.1 书目Todo：给下列每本书的内容写个大概综述，包括了哪些，没包括哪些，特点有哪些。 《自然语言处理综论》冯志伟（译） 《speech and language prcocessing》Daniel Jurafsky 《基于深度学习的自然语言处理》车万翔（译） 《Natural Language Processing》(Jacob Eisenstein) Jianfeng Gao, Michel Gallery, Lihong Li 新书《Neural Approaches to Conversational AI》 翟成祥 新书《文本数据管理与分析：信息检索与文本挖掘的实用导论》 4.2 下载国外书籍的网站 http://gen.lib.rus.ec/ https://b-ok.global/ https://en.booksee.org/ 五、课程5.1.1 基于深度学习的NLP CS224N：神经网络自然语言处理（斯坦福大学2017） 第01讲 - 深度自然语言处理第02讲 - 词向量表示：word2vec第03讲 - 高级词向量表示第04讲 - Word Window分类与神经网络第05讲 - 反向传播和项目建议第06讲 - 依存分析第07讲 - Tensorflow入门第08讲 - RNN第09讲 - 神经机器翻译和高级循环神经网络第10讲 - 期中复习第10讲 - 神经机器翻译和注意力模型第11讲 - 神经机器翻译模型的更多话题和各种循环神经模型第12讲 - 语音处理的端对端模型第13讲 - 应用于NLP的CNN第14讲 - 树形递归神经网络和短语句法分析第15讲 - 共指消解第16讲 - 用于QA的动态神经网络第17讲 - NLP的争议和可能性架构第18讲 - 深度学习应用于NLP的局限性 CS224N：神经网络自然语言处理（斯坦福大学2019） 第01讲 - 简介和词向量第02讲 - 词向量与词义第03讲 - Word Window 分类，神经网络和微分矩阵第04讲 - 反向传播和计算图第05讲 - 语言学结构中的依存分析第06讲 - RNN计算句子概率和语言模型第07讲 - 梯度消失和各种RNNs结构第08讲 - 机器翻译，seq2seq和注意力机制第09讲 - 项目实践建议第10讲 - QA第11讲 - NLP中的CNN第12讲 - 词的部分信息：子词模型第13讲 - 上下文词表示和预训练第14讲 - 生成模型中的Transformers和自注意力第15讲 - 自然语言生成第16讲 - 共指消解第17讲 - QA中的多任务学习第18讲 - 短语解析和树递归网络第19讲 - 安全性，偏差和公平性第20讲 - DeepNLP的未来 CS11-747：神经网络自然语言处理（卡耐基梅隆大学2019） 第一讲：课程介绍 &amp; 使用神经网络做自然语言处理的原因第二讲：简单练习 ：预测句子中的下一个单词第三讲：分布语义和词向量第四讲：针对语言的卷积神经网络第五讲：语句或语言建模的循环神经网络第六讲：条件生成第七讲：注意力机制第八讲：语句和上下文词语的表示第九讲：调试用于自然语言处理的神经网络第十讲：使用局部独立假设的结构化预测第十一讲：强化学习第十二讲：使用局部独立假设的结构化预测第十三讲：模型解读第十四讲：潜在随机变量第十五讲：文本的对抗方法第十六讲：基于转换的句法分析模型第十七讲：使用动态规划的句法分析第十八讲：神经语义分析第十九讲：无监督和半监督结构学习第二十讲：对话模型第二十一讲：文档级模型第二十二讲：知识图谱学习第二十三讲：使用神经网络的机器阅读第二十四讲：多任务多语言学习模型第二十五讲：高阶搜索算法 CS224U：自然语言理解（斯坦福大学2019） 第01讲 - 课程概览第02讲 - 词向量1第03讲 - 词向量2第04讲 - 词向量3第05讲 - 语义分析1第06讲 - 语义分析2第07讲 - 关系抽取第08讲 - 自然语言推理1第09讲 - 自然语言推理2第10讲 - 基础第11讲 - 情感分析第12讲 - 评估方法第13讲 - 评估矩阵第14讲 - 上下文向量第15讲 - 展示做的工作 神经网络自然语言处理（牛津大学2017） 第01讲 导论-课程内容概率第02讲 导论-深度神经网络使我们的朋友第03讲 词向量与词汇语义学（1）第04讲 词向量与词汇语义学（2）第05讲 实践课程第06讲 RNN和语言建模（1）第07讲 RNN和语言建模（2）第08讲 RNN和语言建模（3）第09讲 RNN和语言建模（4）第10讲 文本分类（1）第11讲 文本分类（2）第12讲 NLP的软件和硬件-英伟达GPU（1）第13讲 NLP的软件和硬件-英伟达GPU（2）第14讲 条件语言模型（1）第15讲 条件语言模型（2）第16讲 注意力模型（1）第17讲 注意力模型（2）第18讲 注意力模型（3）第19讲 语音识别（1）第20讲 语音识别（2）第21讲 语音识别（3）第22讲 文本转语音（1）第23讲 文本转语音（2）第24讲 文本转语音（3）第25讲 QA第26讲 记忆第27讲 神经网络中的语言学知识 fast.ai自然语言处理（2019） 第01讲 - 什么是自然语言第02讲 - 主题模型1第03讲 - 主题模型2第04讲 - 使用朴素贝叶斯进行情感分类1第05讲 - 使用朴素贝叶斯进行情感分类2第06讲 - 贝叶斯求导和数值计算第07讲 - 回顾贝叶斯和正则表达第08讲 - 语言模型第09讲 - 迁移学习第10讲 - 用于非英语的ULMFit第11讲 - 理解RNNs第12讲 - Seq2Seq翻译第13讲 - 词嵌入第14讲 - 文本生成算法第15讲 - 实践GRU第16讲 - 算法偏差第17讲 - Transformer简介第18讲 - Transformer应用于翻译第19讲 - 你需要知道的造谣 CS 330: Deep Multi-Task and Meta Learning（2019） 5.1.2 基于传统ML的NLP CS124：NLP（Daniel_Jurafsky） 第01讲 - Course Introduction第02讲 - Basic Text Processing第03讲 - Edit Distance第04讲 - Language Modeling第05讲 - Spelling Correction第06讲 - Text Classification第07讲 - Sentiment Analysis第08讲 - Discriminative Classifier（MaxEnt）第09讲 - NER and MaxEnt Sequence Models第10讲 - Relation Extraction第11讲 - Advanced MaxEnt Model第12讲 - POS Tagging第13讲 - Parsing Introduction第14讲 - Instructor Chat I第15讲 - Probabilitic Parsing第16讲 - Lexicalized Parsing第17讲 - Dependency Parsing（Optional）第18讲 - Information Retrieval第19讲 - Ranked Information Retrieval第20讲 - Semantics第21讲 - Question Answering第22讲 - Summarization第23讲 - Instructor Chat II COMSW4705：NLP（Micheal_Collins） 第01讲 - Introduction to NLP第02讲 - The Language Modeling Problem第03讲 - Parameter Estimation in Language Models第04讲 - Summary第05讲 - Tagging Problems and HMM第06讲 - Parsing and CFG第07讲 - PCFGs第08讲 - Weaknesses of PCFGs第09讲 - Lexicalized PCFGs第10讲 - Introduction to Machine Translation第11讲 - The IBM Translation Models第12讲 - Phrase-based Translation Models第13讲 - Decoding of Phrase-based Translation Models第14讲 - Log-Linear Models第15讲 - Log-Linear Models fot Tagging MEMMs第16讲 - Log-Linear Models for History-based Parsing第17讲 - Unsupervised Learning Brown Clustering第18讲 - Global Linear Models（GLMs）第19讲 - GLMs for Tagging第20讲 - GLMs for Dependency Parsing 翟成祥(一共六门课程)：Text Mining and Analytics 六、常用库6.1 NLP工具类 NLTK Spacy CoreNLP Gensim 6.2 Machine Learning 工具类 sklearn 6.3 Deep Learning工具类 Tensorflow Pytorch 七、语料库7.1 语料来源 各种会议； 各种比赛； 网络零散语料； 7.2 具体语料 大规模中文概念图谱CN-Probase 公众号介绍 农业知识图谱 农业领域的信息检索，命名实体识别，关系抽取，分类树构建，数据挖掘 CLDC中文语言资源联盟 中文 Wikipedia Dump 98年人民日报词性标注库@百度盘 搜狗20061127新闻语料(包含分类)@百度盘 UDChinese (for training spaCy POS) 中文word2vec模型 上百种预训练中文词向量 Synonyms:中文近义词工具包 基于维基百科中文和word2vec训练的近义词库，封装为python包文件。 Chinese_conversation_sentiment A Chinese sentiment dataset may be useful for sentiment analysis. 中文突发事件语料库 Chinese Emergency Corpus dgk_lost_conv 中文对白语料 chinese conversation corpus 用于训练中英文对话系统的语料库 Datasets for Training Chatbot System 八卦版問答中文語料 中国股市公告信息爬取 通过python脚本从巨潮网络的服务器获取中国股市（sz,sh）的公告(上市公司和监管机构) tushare财经数据接口 TuShare是一个免费、开源的python财经数据接口包。 保险行业语料库 [52nlp介绍Blog] OpenData in insurance area for Machine Learning Tasks 最全中华古诗词数据库 唐宋两朝近一万四千古诗人, 接近5.5万首唐诗加26万宋诗. 两宋时期1564位词人，21050首词。 DuReader中文阅读理解数据 中文语料小数据 包含了中文命名实体识别、中文关系识别、中文阅读理解等一些小量数据 中文人名语料库 中文姓名,姓氏,名字,称呼,日本人名,翻译人名,英文人名。 中文敏感词词库 敏感词过滤的几种实现+某1w词敏感词库 中文简称词库 A corpus of Chinese abbreviation, including negative full forms. 中文数据预处理材料 中文分词词典和中文停用词 漢語拆字字典 SentiBridge: 中文实体情感知识库 刻画人们如何描述某个实体，包含新闻、旅游、餐饮，共计30万对。 OpenCorpus A collection of freely available (Chinese) corpora.]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 标签 》]]></title>
    <url>%2FMenu-Tag%2Findex.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[《 总结 》]]></title>
    <url>%2FMenu-Summary%2Findex.html</url>
    <content type="text"><![CDATA[1. 基类1.1 培养对NLP的兴趣：兴趣为自己提供了源源不断的动力，让人能更主动地去规划和学习，同时记忆力、专注度、理解力等等都会比被动学习更有效率； 先经历（哪怕是强迫着做），然后引起兴趣（正面激励），不知道自己的兴趣爱好在哪儿，其实很大程度上不是因为我们的兴趣太匮乏，而恰恰是因为经历匮乏、视野匮乏，少不经事才迷茫。兴趣的产生如下图所示： 学习新的未接触过的东西，比如新算法、模型等等知识。兴趣的维持如下图所示： 编程实现一些有趣的应用，用于实践； 初体验非常重要： 找讲得好的老师（由浅入深地、通俗地、形象化地讲解）； 好的教材（循序渐进式的难度，启发式的诱导）； 不要想花大力气面面俱到，专注于一点，太过宽泛的内容很容易东西兼顾不到，精力过于分散，到头来哪一点都没做好； 1.2 培养创造力 阅读其他相关领域的内容，比如：语言学、认知学、脑科学、生物学…，从这些领域与工作相结合获得创新的灵感； 不要轻易相信任何理论和模型，毕竟没有完美的模型，特别要注意数学模型中的各种假设和成立前提，这往往就是模型的限制所在，要有质疑的态度，提出一个好的问题比解决一个问题更为重要； 1.3 时间管理 分清哪些事情应该先做，哪些应该后做这个顺序，这个与自己的时间和精力管理能力有关，处理不好的话会导致精力和时间的大量浪费： 做事之前先思考这件事和待会儿要做的事哪个更为重要，然后再集中时间和精力做事； 学一些时间管理上的技巧（彼得德鲁克）； 分清事情的重要性和急迫性： 急迫且重要； 重要但不急迫； 急迫但不重要； 不急迫且不重要； 2. 性格类 缺乏挑战的精神 习惯于躲在舒适区里，不敢踏出舒适区； 3. 习惯类 把好的习惯和时间规划固化下来，刻在生物钟里，形成自觉的行为习惯； 严格的自律，不轻易改变原有计划； 总想把线路规划好了再行动，但是受限于个人知识程度的影响总会有所偏差，所以规划得“差不多”（大的方向定确定）了就该行动了； 执行力必须强烈： 不要忽视积累的力量，再小的行为在时间轴上的延续也会最终有所体现； 不要删除自己写的日志，有些东西从时间的线性特征上才体现得出来； 比要求的做得更多，不仅仅满足于要求的内容； 4. 工作类 实践是检验真理的唯一标准，在学习理论的时候，由于自己的知识限制或者作者的知识限制，对于知识点并不理解得很透彻，而实践一方面可以帮助自己去理解，另一方面也可以验证自己的理解； 分清哪些模型需要自己实现，是实现全部环节还是部分内容，实现的目的是为了什么，哪些是只需要学会使用现成库或者软件的； 意义（1）：检验模型的效果，适合哪些环境，如何修改去适应新的项目； 意义（2）：清楚实现细节以便更好的使用现成的软件，与已有的实现相对比，提高工程能力； 对于一时不能完全理解的知识点应该如何记录以便以后有时间来弄清楚； 开阔自己的视野，提高对NLP行业的理解力，这样才能指引未来的方向 多看看著名学者的报告，比如刘挺、李航等人的（当前阶段英语能力和时间有限，不能更多的了解国外著名学者的报告等），这些报告能够高屋建瓴的帮助自己了解行业的现状和更高的视野，可以提高自己对这个行业的理解，更好地把控行业未来的发展方向； 多与其他学者多交流； 多参加像kaggle一样的比赛，这里面有实际的需求和数据，能够更加接近实际需求； 思考如何将新学到的东西融入到自己的知识体系中，思考新的知识点与自己知识体系中各个知识点的联系； 注意各种资源的积累和分类整理，不要看过之后就忘了； 5. 方式方法类 如何检验自己对模型和知识点的掌握程度？ 编码实践； 如何用自己的话以最简单精准的方式表达出来（费曼学习法）； 学习金字塔 准备式学习方式，了解某个模型之前，先将其涉及的基础数学组件掌握，以便于学习模型的顺畅度和提高理解深度（《word2vec中的数学》就是一个很好的例子）； 如何一次性掌握知识点，避免重复性学习（虽然有时候重复性学习是必要的，这里所说的是那些没有必要的）： 理解概念之后，用多个实例来反复练习，直到熟练掌握其本质为止； 基础的深入理解至关重要，打牢基础再前行是必要的，把基础从深层次的角度理解，例如EM的九层理解境界，会发现很多东西都是相通的，这种方式看起来慢，其实是快，快体现在将此知识点应用于其他项目或者理解其他涉及此知识点的模型的时候，但有必要分清哪些东西需要深层次的理解，哪些只需要浅层次的掌握就行了； 学习模型的三重境界 会使用：利用已知方法解决问题； 把模型当作一个黑箱，不关心里面如何运作，只要能把输入的数据映射成为需要的结果就行； 能看懂：理解已知方法的数学原理； 知道模型的基本原理和各个细节，能推导其相关的数学公式； 懂设计：根据问题特征开发新方法； 通过对问题的理解和对模型的内部掌握，根据问题特点对模型进行修改甚至重新设计使之能够适应新问题，从而解决问题； 了解性地学习某些内容，视频的方式可能是最直接和最快的； 以点带面式的学习，因为很多东西并没有成体系化的整理比较零散，只能靠时间上的积累； 搜集优秀的网站、博主网址，学习别人从更深刻或者更本质、新颖的角度理解事物； 你实践中学到的最重要的机器学习经验是什么？ 六千字干货文：到底要怎么去学习？ 1. 不要完美主义！我们不应该过度着眼于我们还不够完美。学习不是要么 0 分，要么 100 分的。80 分是收获；60 分是收获；20 分也是收获。有收获最重要。但是因为着眼于自己的不完美，最终放弃了，那就是彻底的 0 分了。仔细想，这种“完美主义害死人”的例子特别多。我看到过很多同学，其实是在学习的路上，被自己的“完美主义”逼得“放弃了”——由于学习中有一点没有做好，遭受到了一点点挫折，最终就放弃了整个学习计划。每个人都一定要接受自己的不完美。想开一点：我们都不是小升初考了满分，才能上初中的；也不是中考考了满分，才能读高中的；更不是高考考了满分，才能念大学的；将来也不会是大学所有科目都是满分，才能出来工作。不完美其实是常态，根本不会影响我们学习更多更深入的内容。但是在自学过程中，很多同学却要求自己在自己制定的每一步计划中都达到“完美”，才进行下一步。最终结果，通常都是“放弃”：（可能有的同学会跳出来反驳我：学习当然要认真啊！在这里，我必须强调，我所说的“不要完美主义”，和“学习认真”是不冲突的。什么是“完美主义”，什么又是“囫囵吞枣”，这是一个“度”，每个人其实不一样。不要“完美主义”，不代表学习可以草率前行。每个人都必须要找到适合自己的学习节奏。我的经验是：在一些情况下，问自己一句：是不是自己又犯“完美主义”的毛病了：）2.不要过度“学习路径依赖”，学习要冲着自己的目标去什么意思？就是现在信息太发达了，对于大多数领域的知识，网上会有很多所谓的“学习路径”。我不是说这些学习路径没有用，但是不能“过度”依赖这些所谓的学习路径。比如，很多同学想学机器学习，大多数学习路径都会告诉你，机器学习需要数学基础。于是，很多同学就转而学习数学去了，非要先把数学学好再去学机器学习。可是发现数学怎么也学不好（在这里，可能完美主义的毛病又犯了），而机器学习却一点儿都没学。最终放弃了机器学习，非常可惜。其实，如果真正去接触机器学习，就会发现，至少在入门阶段，机器学习对数学的要求没有那么高。正因为如此，我一直建议：只要你在本科接触过高数，线数，概率这些科目的基础概念，想学机器学习，就去直接学习机器学习。学习过程中发现自己的数学不够用，再回头补数学。在这种情况下，数学学习得也更有目标性，其实效果更好。类似这样的例子还有很多，很多同学想学习做 iOS app，就先去精通 Swift 语言，或者想做android app，就先去精通 java 语言。在我看来大可不必。以我的经验，只要你有一门编译型语言基础，大概看一下这些语言的基础语法，就可以直接上手 iOS 或者 android app 的开发了。先能做出一个最基本的 app，在这个过程中，就会意识到语言特性的意义，再回头深入研究语言也不迟。此时还能结合真实的开发任务去理解语言特性，比没有上手 app 开发，抽象地理解语言特性，有意义的多。虽然我一再强调对预算法的学习，语言不重要，但还是有很多同学表示，要先把 C++ 学透，再回来把课程中的算法学好。这是完全没必要的。事实上，在我的这两门课程中，我看到的收获最大的同学，是那些能够把课程中的算法思想理解清楚，然后用自己熟悉的语言去实现的同学：）依然是：不要“过度”学习路径依赖，什么叫“过度”，每个人的标准不一样。每个人都需要寻找自己的那个“度”。3. 不要迷信权威的“好”教材不是说权威教材不好，而是每一本教材都有其预设的读者群，如果你不在这个预设的读者群的范畴里，教材再好也没用。最简单的例子：再好的高数教材，对于小学生来说，都是一堆废纸。我经常举的一个例子是《算法导论》。我个人建议如果你是研究生或者博士生，已经有了一定的算法底子，才应该去阅读《算法导论》，我在我的课程的问答区，也谈过如何学习使用算法导论。但是对大多数本科同学，尤其是第一次接触算法的同学，《算法导论》实在不是一个好的教材。但很可惜，很多同学在学习中有上面的两个毛病，既过度路径依赖，别人说《算法导论》好，学习算法要走学《算法导论》这个路径，自己就不探索其他更适合自己的学习路径了，一头扎进《算法导论》里；同时还“完美主义”，对于《算法导论》的前几章，学习的事无巨细，但其实接触了很多在初学算法时没必要学习的内容。最后终于觉得自己学不下去了，放弃了对“算法”整个学科的学习。认为算法太难了。诚然，算法不容易，但是，一上来就抱着《算法导论》啃，实在是选择了一条完全没必要的，更难的，甚至可能是根本走不通的路。对于一个领域的学习，了解市面上有什么好的教材是必要的，单也不能迷信权威教材。每个人必须要去探索学习如何寻找适合自己的学习材料。4. 不要看不起“薄薄”的“傻”教材，这些你看不起的学习材料，可能是你入门某个领域的关键很多同学问我最初学习算法的是什么教材，我告诉他们是这本教材：《算法设计与分析基础》 。在这里，我完全没有推荐这本教材的意思。事实上，现在我有点儿“鄙视”这本教材。因为我在学习它的过程中，发现这本教材有很多错误（帮助它纠正错误其实也提高了我的水平：）当然，现在这本书的版本可能也和我当时学习的版本不同了，大部分错误应该已经纠正了。）但它确实是我的一本很重要的算法启蒙教材。关键原因是，它够薄。在大多数时候，如果有人问我教材推荐，基本上我的回答都是，如果是入门水平：随便找一本在京东，亚马逊，豆瓣上，评分不太差的“薄”的教材，就 ok 了。在这里，关键字是够“薄”。因为“薄”的教材能让你以最快的速度看完，对整个学科有一个全盘的认识：这个领域是做什么的？解决什么问题了？整体解决问题的思路是怎样？解决问题的方法大致是怎样划分的？一些最基础的方法具体是怎样的。这些在初学阶段是至关重要！是让你全盘把握整个领域脉络的。虽然通过这么一本薄薄的教材，你的脉络把握肯定不够全面细致，但比没有强太多！我看过不少同学，一上来学习《算法导论》，关于复杂度分析的笔记做了好几页，然后就放弃了，可是连什么是动态规划都不知道。这样完全没有对“算法”这个领域有全面的认识，甚至可以说根本没有学过“算法”！先用薄教材入门，再找“厚”教材，细细体会其中的细节，是我百试不爽的学习方法。另外，在这里，我还要强调“入门教材”，很多教材虽然够“薄”，但不是“入门教材”。大家要注意。5. 不要迷信单一教材很多同学理解了要找“薄”教材入门的道理，却还是非要我推荐一本具体的“薄”教材，说实话，很多时候这让我有点儿哭笑不得。因为我随便推荐一本，我确实不敢保证它是“最好的”，“最适合你的”，但是各个领域那么多教材，我又不可能都一一看过，一一比较过。最最重要的是，我的学习经验告诉我，在大多数情况下，学习不是一本固定教材可以搞定的。非要找到一本“最适合自己的”教材，然后就一头扎进去，其实是不科学的。我印象很深刻，我读本科的时候，那会儿申请了一个项目，要做一个网站（那时候服务端都用 ASP.NET ），我一口气从图书馆借了 10 本 ASP.NET 的教材，然后以一本最薄的书为主干去看，发现这本书介绍不清楚的概念，马上就从其他书里找答案。通常不同的作者对同一个事物从不同的角度做解读，是能够帮助你更深刻的认识一个概念的。基本上一个月的时间，我就从一个完全的网站搭建小白，做出了这个项目需要的那个网站。这个习惯我一直延续，研究生的时候，对什么领域感兴趣了，第一件事就是到图书馆，借十本相关书籍回来翻看。但是，大多数同学喜欢仅仅扎进一本书里，一旦选定了自己的学习材料，就对其他材料充耳不闻，甚至是排斥的心理。这种做法，一方面又是“完美主义”的表现——非要把这本教材学透；另一方面，其实也是“犯懒”的表现，不愿意多翻翻，多看看，自己多比较比较，自己去寻找最适合自己的材料，一味地盲目相信所谓“大神”的推荐，殊不知，这些推荐，不一定是更适合自己的材料；更何况，还有很多大神，明明是靠不出名的“薄”教材入的门，但给别人做推荐的时候，就突然变成自己是算法奇才，自幼阅读《算法导论》而所成的神话了：）6. 实践前面说了很多和教材选择相关的话题，但对于计算机领域的学习来说，教材的意义其实远远小于实践的意义。如果仅仅是看学习材料就是学习的话，那么慕课网的视频后期处理人员就是水平最高的工程师了。因为每段视频，他们都需要看一遍。但是，很显然，仅仅是看视频，是无法学到知识的。对于计算机领域的学习来说，真正动手实践去编程是异常重要的。怎么夸大其中的作用都不过分。这就好比学游泳，必须下水去游泳；或者学开车，必须亲自上路。否则你说的再头头是道，一个小学生文化水平的人，只要他开过车，游过泳，都能在这两个领域瞬间秒杀你。很多同学都说我的算法讲得好，其实，我一直认为，这其中的一个最简单的秘诀就是：我带领大家把大多数算法都非常细致的实现了一遍；或者对其中的应用进行了非常具体的实践。反观大多数高校教育，对于算法或者机器学习这种一定程度偏理论的学习，通常非常不强调实践。最终的结果是学习者只是接受了很多抽象的概念，但对其中具体的实现细节，却是云里雾里。我见过太多同学，都明白什么是 O(n^2) 复杂度，什么是 O(nlogn) 的复杂度，却问我对于 100 万的数据规模，为什么自己的选择排序运行起来就没反应了。答案很简单：O(n^2) 的复杂度太慢了，100 万的数据规模太大了，一般家用计算机转选择排序一时半会儿是转不完的。这些同学一定理解 O(n^2) 的算法比 O(nlogn) 的算法慢，却没有真正实践过，不知道这个差距到底是多少。在我的课程中，经常遇到有些同学提出这样的问题：这个算法的某句话（或者某段逻辑），为什么要写成 A 的样子，而不是 B 的样子？这种问题其实很好，但我觉得解决方法也很简单，实际的去把算法改写成 B 的样子，实际的运行试试看，看会发生什么。如果发生了错误，仔细分析一下，为什么会有错误？如果没有错误，具体比较一下：A和B两种不同的写法，为什么都正确？又有什么区别？真正的学习上的提高，就发生在这个过程中。我当然可以告诉给同学们一个结果，但是自己亲自实践一遍，相比阅读我给出的一个答案，自己对其中问题理解的深刻程度，是完全不可比拟的。7. debug非常非常重要我看到的另一类“经典”问题就是：老师，这个代码为什么错了，然后贴一大段代码。这种问题背后，依然是，透露着学习方法的不对劲：提问的同学懒得 debug 。在计算机领域，debug 近乎和实践是一个意思。如果只是把材料上的代码“抄”一遍，这不叫实践，这叫抄代码。小学生也能做。但是“抄”一遍，不小心没抄对，发生了错误，然后自己一点一点调试，找到错误的根源，这叫真的实践。小学生不能做。（当然，我更推崇的是：自己理解了算法的逻辑，按照自己的理解，把算法写出来：）不过很多同学不喜欢 debug，我当然理解。其实谁都不喜欢 debug ，但是，debug 才是最重要的能力。（通常在一个领域里，你最不喜欢做的事情，就是这个领域的核心竞争力：）是计算机领域异常重要的一项技能。我见过的所有计算机领域的“高手”，不管是在哪个细分领域，都无一例外，是个 debug 好手。我经常告诉大家，在实际工作中，其实 debug 的时间要占你真正编程时间的 70%。如果你做一个项目，根本不需要 debug ，要么是你的项目对你来说太简单了，要么是你根本没有接触到这个项目的核心。debug 不仅仅是找到代码错误，解决错误的手段，其实更是一个重要的学习手段。通过 debug，看看自己写的程序执行逻辑，哪里和自己设想的不一致？再回头看自己哪里想错了，或者想漏了，分析一下自己为什么想错了，或者想漏了，等等等等，依然是，进步就是发生在这个过程的。在我的算法课程中，很多同学对递归想不明白，我的建议都是：用一个小数据量，一步步跟踪程序，看看程序到底是怎么运行的。通常这么做，1 个小时的时间，就足以让你深刻理解递归程序的运转逻辑。可是，很多同学懒得花这1个小时的时间，最终的结果是，花了一个下午，对着代码生看，硬想，最终还是没有理解程序的运转逻辑8. 量变到质变还有很多同学，对于算法的一些问题，会问：老师，你是怎么想到用这样的方法的？对于这类问题，我的回答一般都是：你见的还不够多。不知道是不是受高中阶段学习的影响，有一些同学特别执着于就着一个单一的问题，寻找其中的“解题路径”。当然，我不是说这是完全错误的，但也有一个“度”。我的经验是：与其把时间花在这里，不如去见更多问题。比如动态规划，是算法学习的一个难点，很多同学在学会了背包问题的解法之后，总是执着于去追寻：是怎么想到这种状态定义的方法的。可能是我个人水平有限，我无法清楚地解释是如何想到这种状态定义的方法的。但是我的经验告诉我：再去看，去实践 100 个动态规划相关的问题，然后回头看背包问题，你会发现这种状态定义的方式非常自然。仅仅对着一个问题思考，很多时候都是死胡同。你见识的还不够多，就不足以帮助你总结出更加“普遍”的问题解决的规律。当你见得足够多的时候，一切就都变得很自然，所谓的“量变到质变”。不过，大多数同学在这个环节都会“犯懒”，企图通过一个问题就理解问题的本质，这其实和企图通过一本教材就精通一个领域的想法是一样的，是不现实的，不可能的。同时，这里又包含着学习过程中的“完美主义”的思想，遇到一个问题一定要把它想的无比透彻。但是我的经验告诉我：大多数问题，其实都是需要“回头看”的。随着你对一个领域理解的越深入，回头再去看那些曾经的问题，都会产生新的视角，对于很多曾经想不明白的问题也豁然开朗。这也是“进步”的根源。如果卡在一个问题上不前进，不给自己“回头看”的机会，甚至最后是放弃了，就什么也没有学会了。所以，很多时候，你发现对一些问题“百思不得其解”，或许不是因为自己“笨”，而是因为“还不够努力”：）9. 一定要相信时间的力量有一天，在我的一个算法课程群里，有个滴滴的后端大神发招聘，结果大家七嘴八舌的就议论开了，大致主题思想就是：自己什么时候能够成为滴滴的后端大神。这位滴滴的后端大神今年 32 岁；大多数议论的同学，其实连 22 岁都不到。我告诉他们，其实 10 年后，你们就是大神。这其实很好理解，回想十年前，也就是 12 岁的你，和现在的你比较，是不是天壤之别？如果把你扔到一堆 12 岁的小朋友中间，22 岁的你是不是就是个大神？同理，32 岁的人，已经在业界摸爬滚打了那么多年，扔回到22岁的大学生中间，当然是大神：）很多时候，所谓的“大神”并不神秘，很多时候，仔细观察，会发现时间有着不可磨灭的作用。只要你没有虚度时间，每天都在进步，通常结果都不会太差的。如果再加上一点点机遇，可能就不仅仅是大神 6. 客观条件类 提高对模型和知识的记忆力，这点需要特别强调，自己本身记忆力不是很好，但是要灵活处理遇到的各种困难，必须要记忆大量的模型、算法等等： 首先理解必须深刻； 多角度理解； 深层次理解； 通过实践反复重现理论细节以增强记忆； 时常复习； 从营养学的角度出发要补充增强记忆力的食物； 锻炼身体，增强身体活性，记忆力会好点； 7. 感悟类 针对自己学历不高的劣势如何弥补 比赛中取得好的名次也是证明自己能力的方式之一，在缺少学历优势的条件下这可能是比较有用的途径之一； 与更多的学者进行交流，扩大知名度； 学会如何表达自己的意见和见解很重要，一方面流畅地表达现了自己对这个领域的思路是否清晰，另一方面能促使别人来一起研究增加实现的可能性；]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 元学习 》]]></title>
    <url>%2FSubMenu-Frame-MetaLearning%2Findex.html</url>
    <content type="text"><![CDATA[Meta Learning]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 深度学习 》]]></title>
    <url>%2FSubMenu-Frame-DeepLearning%2Findex.html</url>
    <content type="text"><![CDATA[Deep Learning 1. 对深度学习的理解2. 深度学习的优点3. 深度学习的缺点 Deep Learning ：A Critical Appraisal.pdf 4. 相关地图 深度学习概念 深度学习架构]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 生成对抗网络 》]]></title>
    <url>%2FSubMenu-Frame-GAN%2Findex.html</url>
    <content type="text"><![CDATA[Generative Adversarial Networks]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 建站 》]]></title>
    <url>%2FMenu-Web%2Findex.html</url>
    <content type="text"><![CDATA[1. 建站说明 2. 博文书写Tips: 在书写了公式或者插入了图片之后一定要记得空行； 2.1 段落样式类 空格1$\&amp;nbsp$ 2.2 关键字或句子（1）下划线利用的是b标签，id=“line” （2）强调利用的是b标签，id=“em” 2.3 图片类（1）插入超宽图片（百分比调节宽度）1&lt;center&gt;&lt;div style="width: 50%"&gt;![link](/DIY/picture/xxxxxx.png)&lt;/div&gt;&lt;/center&gt; 图片名称1&lt;center&gt;&lt;p id="picture"&gt;xxx&lt;a id="download" href="/DIY/download/xxx.xmind" download&gt;&lt;i class="fa fa-download"&gt;&lt;/i&gt;&lt;/a&gt;&lt;/p&gt;&lt;/center&gt; （2）折叠内容123- &#123;% fold xxx %&#125;&lt;center&gt;&lt;div id="fold"&gt;&lt;img src="/DIY/picture/xxx.png"&gt;&lt;/div&gt; &lt;/center&gt;&#123;% endfold %&#125; 2.4 各种零散设置（1）下载按钮下载的东西如果能直接在浏览器打开则直接打开，就需要打包压缩成压缩文件。1&lt;a id="download" href="https://91nlper.com/download/NLP技术体系细分.zip" download&gt;&lt;i class="fa fa-download"&gt;&lt;/i&gt;&lt;/a&gt; （2）图标 专业图标网站 &lt;i class=&quot;fa fa-github&quot;&gt;&lt;/i&gt; &lt;i class=&quot;fa fa-github fa-lg&quot;&gt;&lt;/i&gt; 3. 博客建设3.1 web级优化和设置3.1.1 博客部署 清空已有的网站缓存：hexo clean 生成网站文件：hexo g 本地预览：hexo s 部署网站：hexo d 初始化文件夹： 1234hexo initnpm installnpm install hexo-deployer-git --savegit clone https://github.com/theme-next/hexo-theme-next themes/next 更新主题： 12cd themes/nextgit pull 选择Mist主题： 主题配置文件中，查找“Schemes”关键字，选择Mist 再到站点配置文件中，查找关键字“theme”,将默认的landscape值改为next； 在github上创建一个用户名+.github.io的仓库 在站点配置文件中，查找“deploy”关键字,改成一下配置： 1234deploy: type: git repo: https://github.com/lNeo-Nia-2015l/lNeo-Nia-2015l.github.io.git branch: master 在站点配置文件中查找关键字“language”， 将其修改为 zn-CN; 设置网站logo： 在F:\Hexo\themes\next\source\images目录下替换名为：favicon-32x32-next.png和favicon-16x16-next.png的文件； 3.1.2 更改博客部署仓库步骤： 更改git用户名 12git config --global user.name "xray2lan"git config --global user.email "xray2lan@gmail.com" 查看、清除、添加远程原始仓库 123git remote -vgit remote rm origingit remote add origin https://gitee.com/X-Ray2Lan/X-Ray2Lan.git 在主题配置文件中修改仓库地址和url地址 添加公共秘钥，检查秘钥是否生效 12ssh-keygen -t rsa -C “35835129@qq.com”ssh git@gitee.com（测试在选择yes/no的时候输入yes） 在站点文件上修改repo和url $Tips:$ 在使用hexo d第一次部署的时候会弹出yes/no的选项框，以往在这里都是直接敲回车，结果链接不上，下一次试试敲yes； 3.2 page级优化和设置3.2.1 新建标签和分类页面 在主题配置文件中查找关键字“menu”，将tags和categories前面的#号去掉； 在hexo文件夹下执行下面创建页面命令： hexo n page tags hexo n page categories 在hexo/source目录下分别进入tags和categories的目录，修改各自的index.html文件，内容如下： 3.2.2 在标签页添加词云和修改标签列表为随机彩色 在hexo根目录下安装依赖包： npm install hexo-tag-cloud@^2.0.* –save 在F:\Hexo\themes\next\layout目录下找到page.swig文件，在文件中找到以下所示段代码：123&lt;div class="tag-cloud-tags"&gt; &#123;&#123; tagcloud(&#123;min_font: 12, max_font: 30, amount: 500, color: true, start_color: "#ccc", end_color: "#111&#125;)&#125;&#125;&lt;/div&gt; 替换为： 在站点配置文件中增加下面代码： 12345tag_cloud: # 颜色配置 textColour: \#000000 outlineColour: \#9999ff textHeight: 12 # 字的大小配置 rgb随机颜色(可代替#xxxxxx颜色) 1rgb(random-color(0, 255), random-color(0, 255), random-color(0, 255)); 1rgb(random-color(0, 255) - 50%, random-color(0, 255) - 50, random-color(0, 255) - 50%); 透明颜色设置 1rgba(0,0,0,0); 3.2.3 分类页面 分类页面中数量标签样式： G:\博客\themes\next\source\css_common\components\pages\categories.styl 3.2.4 css背景样式图参考第一个网站上的代码可以在线修改然后复制： SVG Patterns Gallery CSS3 Patterns Gallery 3.3. header优化和设置3.3.1 添加站内搜索 3.3.2 修改header中的logo在 F:\博客\themes\next\layout\_partials\header 目录下的 brand.swig 文件中修改如下：1234567891011&lt;div class="site-brand-wrapper"&gt; &lt;div class="site-meta &#123;% if theme.custom_logo.enabled %&#125;custom-logo&#123;% endif %&#125;" style="margin-left: 0px"&gt; &#123;% if theme.custom_logo.image and theme.scheme === 'Mist' %&#125; &lt;div class="site-meta-headline"&gt; &lt;a href="https://91nlper.com/"&gt; &lt;img class="custom-logo-image" src="/images/logo.png" alt="&#123;&#123; title &#125;&#125;"/&gt; &lt;/a&gt; &lt;/div&gt; &#123;% endif %&#125; &lt;/div&gt; 3.3.3 修改nav-toggle按钮（手机端右上角的菜单按钮改为文字版按钮）在 F:\博客\themes\next\layout\_partials\header 目录下的 brand.swig 文件中修改如下：12345&lt;div class="site-nav-toggle"&gt; &lt;button aria-label="&#123;&#123; __('accessibility.nav_toggle') &#125;&#125;" style="outline: none;-webkit-tap-highlight-color: rgba(0,0,0,0);-webkit-tap-highlight-color: transparent;"&gt; &lt;p id="nav-toggle"&gt;&lt;b&gt;Natural&amp;nbsp Language&amp;nbsp Processing ...&lt;/b&gt;&lt;/p&gt; &lt;/button&gt;&lt;/div&gt; 在 F:\博客\themes\next\source\css\_custom 目录下的custom.styl文件中添加如下代码：12345678p#nav-toggle &#123; font-family: aba; font-weight: bolder; font-size: 10px; margin-bottom: -10px; margin-top: 10px; padding-bottom: 0px;&#125; 3.3.4 其它相关修改目录 header中menu按钮菜单的背景#61：G:\博客\themes\next\source\css_schemes\Mist_menu.styl 手机模式下右上角菜单按钮（修改为图片或者文字）：H:\博客\themes\next\layout_partials\header\brand.swig 顶部菜单栏字体样式H:\博客\themes\next\source\css_schemes\Mist_menu.styl header中的logo（及其链接）和手机页面下右上角的字：H:\博客\themes\next\layout_partials\header\brand.swig 3.3.5 在header增加下拉菜单 在下拉菜单下载下载现成的css和html框架； 将css文件放在next的css新建的一个文件夹下，注意，在html中写路径时“/“就代表source文件夹，也就是根目录，然后顺着往下写就行了； 在layout的_layout.swig文件中写入html中需要的部分； 修改合适的样式； 3.4 post优化和设置3.4.1 修改底部标签样式 3.4.2 在文章末尾添加“文章结束”标记 在路径Blog\themes\next\layout_macro文件夹中新建passage-end-tag.swig文件； 在passage-end-tag.swig添加以下内容，直接用文本编辑器打开，粘贴以下内容后保存； 12345&lt;div&gt; &#123;% if not is_index %&#125; &lt;div style="text-align:center; color: #ccc; font-size: 14px;"&gt;---------本文结束&lt;i class="fa fa-paw"&gt;&lt;/i&gt;感谢您的阅读----&lt;/div&gt; &#123;% endif %&#125;&lt;/div&gt; 打开Blog\themes\next\layout_macro\post.swig，在post-body之后，post-footer之前（post-footer之前两个DIV），添加以下代码： 12345&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include "passage-end-tag.swig" %&#125; &#123;% endif %&#125;&lt;/div&gt; 添加位置如下图所示： 修改主题配置文件_config.yml，在末尾添加：123# 文章末尾添加“本文结束”标记passage_end_tag: enabled: true 3.4.3 文章时长和文章字数 3.4.4 打赏功能主题配置文件中修改：12345# Rewardreward_comment: 谢主隆恩！wechatpay: /images/wechatpay.pngalipay: /images/alipay.png# bitcoin: /images/bitcoin.png 3.4.5 顶部阅读进度条 在../next/layout/_partials/header/brand.swig模板文件中加上进度条的div,加在这个位置： /source/css/_custom/custom.styl文件中为我们的进度条添加样式： 12345678910.top-scroll-bar &#123; position: fixed; top: 0; left: 0; z-index: 9999; display: none; width: 0; height: 2px; background: #6d6d6d;&#125; 在/source/js/src/下新建custom文件夹，再在此文件下创建custom.js文件，文件中添加一下内容： 12345$(document).ready(function() &#123; $(window).scroll(function() &#123; $(".top-scroll-bar").attr("style", "width:" + ($(this).scrollTop() / ($(document).height() - $(this).height)) * 100 + "%; display: block;") &#125;);&#125;); -最后，将我们新建的js脚本引入到模板，使其生效，在/layout/_scripts/commons.swig中的如下位置加入代码： 3.4.6 修改博客列表样式在F:\博客\themes\next\source\css_common\components\post目录下找到post-expand.styl文件，修改其中ul li{}中的值 3.4.7 修改博文各级别标题在F:\博客\themes\next\source\css_common\components\post目录下找到post-expand.styl文件，修改h*标题 3.4.8 将博文最下面的下一个博客和上一个博客换位置（原左为next，右为prev，现左为prev，右为next）在F:\博客\themes\next\layout_partials目录下修改pagination.swig文件的内容； 3.4.9 添加折叠块功能添加折叠代码块 折叠块 3.4.10 去除移动端按钮阴影在 F:\博客\themes\next\source\css\_custom 目录的 custom.styl 文件中加入以下代码：1234567891011button &#123; outline: none; -webkit-tap-highlight-color: rgba(0,0,0,0); -webkit-tap-highlight-color: transparent;&#125;a &#123; -webkit-tap-highlight-color: transparent; -webkit-touch-callout: none; -webkit-user-select: none;&#125; 3.4.11 自定义博文显示顺序Hexo博文置顶（自定义排序） 3.4.12 使用七牛云存储七牛云存储 3.4.13 阿里巴巴矢量库图标引用首先，前往 阿里巴巴矢量库 挑选自己需要的图标，在想要的图标上点击 把它们都加入购物车。 然后，点击页面右上方 进入购物车，选择「下载代码」。 将下载的文件解压后，找到 iconfont.css 文件，打开后将其中的所有内容都复制加入到 /themes/next/source/css/_custom/custom.styl 文件中的任意位置。这里需要修改部分内容，使得图标样式可以和主题样式保持一致。 第一段 @font-face 的所有属性都不用改；第二段 .iconfont 的属性中，需要将字体大小修改为 font-size:inherit;，如果需要将这些图标用于侧边栏社交账号展示，还要再加入间距的属性 padding: 2px;，以适配主题默认的样式；最后的几行 .icon-zhihu 类似字样的就是后续需要引用图标的名称，短线 - 之后的名字可以自己修改定义。在这样设置好以后，就可以在博客需要额外图标的地方使用 的进行引用了。 3.4.14 添加背景彩带在\博客\themes\next\layout_layout.swig或者page.swig中添加以下两种脚本：动态彩带效果 和 点击更改彩带效果12&lt;script src="https://g.joyinshare.com/hc/piao.js" type="text/javascript"&gt;&lt;/script&gt;&lt;script src="https://g.joyinshare.com/hc/ribbon.min.js" type="text/javascript"&gt;&lt;/script&gt; 3.4.15 其它相关修改目录 post的read more按钮样式修改 62：G:\博客\themes\next\source\css_schemes\Mist_posts-expanded.styl post的tags的样式修改 #42：G:\博客\themes\next\source\css_schemes\Mist_posts-expanded.styl post的背景页面修改（总的）#14：G:\博客\themes\next\source\css_schemes\Mist_posts-expanded.styl post页面内的总标题 #30：G:\博客\themes\next\source\css_schemes\Mist_posts-expanded.styl post标题下统计信息：（分为在page页下和post主页下） G:\博客\themes\next\source\css_schemes\Mist_posts-expanded.styl G:\博客\themes\next\source\css_common\components\post\post-title.styl G:\博客\themes\next\source\css_common\components\post\post-meta.styl post文章内容字体颜色 #1：G:\博客\themes\next\source\css_common\components\post\post.styl post body部分（不包含标题和统计信息）：G:\博客\themes\next\source\css_custom\custom.styl post各级标题设置：G:\博客\themes\next\source\css_common\components\post\post-expand.styl post列表开头符号修改：G:\博客\themes\next\source\css_common\components\post\post-expand.styl post图片圆角等：G:\博客\themes\next\source\css_common\components\post\post-expand.styl 代码块高亮样式：G:\博客\themes\next\source\css_common\components\highlight\theme.styl 3.5 footer优化和设置3.5.1 底部隐藏由Hexo强力驱动、主题–NexT.Mist 打开Blog/themes/next/layout/_partials/footer.swig，注释掉相应代码; 3.6 sidebar优化和设置3.6.1 设置侧边栏头像及转动效果 在F:\Hexo\themes\next\source\images目录下替换名为：avatar.gif的文件； 在主题配置文件中查找关键字“avatar”，设置url文件路径，将rotated的值改为true（头像转动）； 3.6.2 侧边栏设置为左边并更改宽度 更改宽度 主题配置文件中查找关键字“sidebar”，将width值修改为240； 3.6.3 添加RSS 3.6.4 在next主题的Mist风格下打开手机侧边栏功能 在主题配置文件中查找关键字“onmobile”，将其值改为true； 3.6.5 修改侧边栏背景颜色和字体颜色在 ./hexo/themes/next/source/css/_variables/base.stl文件中查找关键字“sidebar-xxx”，修改其值； 3.6.6 目录自动全部展开（不折叠）在 F:\博客\themes\next\source\css_custom的cutom.styl文件中加.post-toc .nav .nav-child { display: block; } 3.6.7 目录超长自动换行在主题配置文件中找到toc: 更改属性wrap的值为true 3.6.8 修改页面侧边栏显示按钮sidebar-toggle在F:\博客\themes\next\layout_macro目录下打开sidebar.swig，修改如下图：1234567&#123;% macro render(is_post) %&#125; &lt;div class="sidebar-toggle"&gt; &lt;p id="ai"&gt;学&lt;/p&gt; &lt;/div&gt; &lt;asige id="sidebar" class="sidebar"&gt; &#123;% if theme.sidebar.onmobile %&#125; 在F:\博客\themes\next\source\css_custom的custom.styl文件中添加如下类容：123456789101112.sigebar-toggle &#123; right: 10px; bottom: 43px; color: #1cff37;&#125;p#ai &#123; font-family: aba; font-size: 1.1em; margin-top: 6px; margin-left: -2px; color: #1cff37;&#125; 3.6.9 目录折叠功能 折叠目录 3.6.10 侧边栏添加音乐播放器在../themes/next/layout/_macro/sidebar.swig文件中的名为sidebar-inner的div中添加网易云播放器代码 3.7 更多博客参考 打造个性超赞博客Hexo+NexT+GitHubPages的超深度优化 hexo next主题美化 HEXO+NEXT主题个性化配置 基于Hexo搭建个人博客——进阶篇(从入门到入土) TRHX’S BLOG]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 机器学习 》]]></title>
    <url>%2FSubMenu-Frame-MachineLearning%2Findex.html</url>
    <content type="text"><![CDATA[Machine Learning 一、基本概念 二、派别2.1 Symbolists（符号主义）2.2 Connectionists（联结主义）2.3 Evolutionaries（进化主义）2.4 Bayesians（贝叶斯派）2.5 Analogizer（分析派） 三、相关地图 传统机器学习 参考： 机器学习数据预处理 机器学习概念 机器学习处理过程 机器学习中的数学 机器学习模型分类]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 图神经网络 》]]></title>
    <url>%2FSubMenu-Frame-GNN%2Findex.html</url>
    <content type="text"><![CDATA[Graph Neural Network 一、概览1.1 综述 Graph Neural Networks: A Review of Methods and Applications A Comprehensive Survey on Graph Neural Networks 1.2 资源 清华NLP图神经网络GNN论文分门别类，16大应用200+篇论文 图神经网络（Graph Neural Networks，GNN）综述 《Embeddings in Natural Language Processing》第4章有提 图嵌入（Graph embedding）综述 二、GNN在NLP中的应用]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 聊天机器人 》]]></title>
    <url>%2FSubMenu-Subdomain-ChatBot%2Findex.html</url>
    <content type="text"><![CDATA[ChatBot 对话系统分类 1. 行业发展 【2018- xx-xx】NAACL tutorial：Deep Learning for Conversational AI 【2018-11-18】CIIS2018演讲实录丨哈尔滨工业大学车万翔：任务型对话系统研究进展 【2018-08-31】黄民烈（清华）：人机对话中的挑战性问题 【2018-08-31】刘越（微软）：我们在小冰的探索和实战 【2018-08-31】周昊（清华）：Knowledge Aware Dialogue Generation 【2017-11-06】A Survey on Dialogue Systems：Recent Advances and New Fontiers 【2017-09-xx】聊天机器人的技术及展望 【2017-09-xx】人机对话中的情绪感知与表达 【2017-09-xx】对话式交互与个性化推荐 【2017-09-xx】对话智能与认知型口语交互界面 【2017-09-xx】对话系统评价技术进展及展望 【2017-03-18】微软首席AI科学家邓力：对话系统的分类与发展历程 2. 学习资源2.1 网站 中国人工智能学会 2.2 课程 CS224S / Linguist285 - Spoken Language Prcessing 2.3 研讨会2.4 学者 李纪为《Teaching Machines to converse》 2.5 零散资源 从0到1搭建聊天机器人（从产品角度审视Chatbot） 原网址 1_对话系统趋势分析 2.1_对话系统专业术语科普 2.2_对话系统分类 2.3_对话系统话术设计注意事项 2.4_五步创建一个对话系统 2.5_UNIT整体介绍 2.6_UNIT专业术语科普 3.1_为什么要定义对话系统 3.2_确定场景边界 3.3_梳理业务要素和知识库 3.4_撰写故事线 3.5_抽取对话流程 3.6_设计UNIT对话逻辑 4.1_富集数据资源 聊天系统]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 强化学习 》]]></title>
    <url>%2FSubMenu-Frame-ReinforcementLearning%2Findex.html</url>
    <content type="text"><![CDATA[Reinforcement Learning]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 指代消解 》]]></title>
    <url>%2FSubMenu-Subdomain-CoReferenceResolution%2Findex.html</url>
    <content type="text"><![CDATA[CoReference Resolution]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 弱监督学习 》]]></title>
    <url>%2FSubMenu-Frame-WeeklySupervisedLearning%2Findex.html</url>
    <content type="text"><![CDATA[Weekly-supervised Learning]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 迁移学习 》]]></title>
    <url>%2FSubMenu-Frame-TransferLearning%2Findex.html</url>
    <content type="text"><![CDATA[Transfer Learning 迁移学习综述 资源大全 Neural Transfer Learning for NLP]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 自监督学习 》]]></title>
    <url>%2FSubMenu-Frame-SelfSupervisedLearning%2Findex.html</url>
    <content type="text"><![CDATA[Self-supervised Learning]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 成分分析 》]]></title>
    <url>%2FSubMenu-Subdomain-ConstituencyParse%2Findex.html</url>
    <content type="text"><![CDATA[Constituency Parse]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 信息抽取 》]]></title>
    <url>%2FSubMenu-Subdomain-IE%2Findex.html</url>
    <content type="text"><![CDATA[Information Extraction 一、关系抽取二、事件抽取]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 意图识别 》]]></title>
    <url>%2FSubMenu-Subdomain-IntentRecognition%2Findex.html</url>
    <content type="text"><![CDATA[Intent Recognition 1. 意图识别的概念2. 意图搜索中的难点 输入不规范 多意图 数据冷启动 没有固定的评价标准 意图存在时效性变化 3. 意图识别分类3.1 搜索中的意图识别3.2 对话中的意图识别4. 方法分类4.1 基于规则模板的方法4.2 基于统计的方法4.3 基于语法的方法4.4 基于机器学习的方法4.5 基于深度学习的方法4.1 参考 Intent Recognition - papers with code NLP进化史系列之意图识别 自然语言处理（NLP）语义分析–文本分类、情感分析、意图识别 搜索引擎的查询意图识别（query理解） 如何来做用户意图识别 2018蚂蚁金服NLP用户意图的精准识别，复赛f1 = 0.7327 主题搜智能化-用户意图识别与主题生成 意图识别（规则模板解析、深度学习意图识别）]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 依存分析 》]]></title>
    <url>%2FSubMenu-Subdomain-DependencyParse%2Findex.html</url>
    <content type="text"><![CDATA[Dependency Parse]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 特征工程 》]]></title>
    <url>%2FSubMenu-Subdomain-FeatureEngineering%2Findex.html</url>
    <content type="text"><![CDATA[Feature Engineering 特征工程 《Feature Engineering for Machine Learning》 Feature Engineering 特征工程 使用sklearn做单机特征工程 中文文本挖掘预处理流程总结 英文文本挖掘预处理流程总结]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 多任务学习 》]]></title>
    <url>%2FSubMenu-Subdomain-MultitaskLearning%2Findex.html</url>
    <content type="text"><![CDATA[Multi-task Learning 1. 多任务学习的定义多任务学习（Multitask learning）定义：基于共享表示（shared representation），把多个相关的任务放在一起学习的一种机器学习方法。 2. 单任务学习 vs 多任务学习现在大多数机器学习任务都是单任务学习。对于复杂的问题，也可以分解为简单且相互独立的子问题来单独解决，然后再合并结果，得到最初复杂问题的结果。这样做看似合理，其实是不正确的，因为现实世界中很多问题不能分解为一个一个独立的子问题，即使可以分解，各个子问题之间也是相互关联的，通过一些共享因素或共享表示（share representation）联系在一起。把现实问题当做一个个独立的单任务处理，忽略了问题之间所富含的丰富的关联信息。多任务学习就是为了解决这个问题而诞生的。把多个相关（related）的任务（task）放在一起学习。这样做真的有效吗？答案是肯定的。多个任务之间共享一些因素，它们可以在学习过程中，共享它们所学到的信息，这是单任务学习所具备的。相关联的多任务学习比单任务学习能去的更好的泛化（generalization）效果。 图（01） 从图1中可以发现，单任务学习时，各个任务之间的模型空间（Trained Model）是相互独立的（图1上）。多任务学习时，多个任务之间的模型空间（Trained Model）是共享的（图1下）。 假设用含一个隐含层的神经网络来表示学习一个任务，单任务学习和多任务学习可以表示成如图2所示。 图（02） 从图2可以发现，单任务学习时，各个task任务的学习是相互独立的，多任务学习时，多个任务之间的浅层表示共享（shared representation）。 3. 多任务学习共享表示的方式 基于参数的共享（Parameter based）：比如基于神经网络的MTL，高斯处理过程; 基于约束的共享（regularization based）：比如均值，联合特征（Joint feature）学习（创建一个常见的特征集合）; 4. 多任务学习有效的原因 多人相关任务放在一起学习，有相关的部分，但也有不相关的部分。当学习一个任务（Main task）时，与该任务不相关的部分，在学习过程中相当于是噪声，因此，引入噪声可以提高学习的泛化（generalization）效果； 单任务学习时，梯度的反向传播倾向于陷入局部极小值。多任务学习中不同任务的局部极小值处于不同的位置，通过相互作用，可以帮助隐含层逃离局部极小值； 添加的任务可以改变权值更新的动态特性，可能使网络更适合多任务学习。比如，多任务并行学习，提升了浅层共享层（shared representation）的学习速率，可能，较大的学习速率提升了学习效果； 多个任务在浅层共享表示，可能削弱了网络的能力，降低网络过拟合，提升了泛化效果； 5. 任务相关性的定义相关（related）的具体定义很难，但我们可以知道的是，在多任务学习中，related tasks可以提升main task的学习效果，基于这点得到相关的定义： Related（Main Task，Related tasks，LearningAlg）= 1 LearningAlg（Main Task||Related tasks）&gt; LearningAlg（Main Task） （1） LearningAlg表示多任务学习采用的算法，公式（1）：第一个公式表示，把Related tasks与main tasks放在一起学习，效果更好；第二个公式表示，基于related tasks，采用LearningAlg算法的多任务学习Main task，要比单学习main task的条件概率概率更大。特别注意，相同的学习任务，基于不同学习算法，得到相关的结果不一样： Related（Main Task，Related tasks，LearningAlg1）不等于 Related（Main Task，Related tasks，LearningAlg2） 6. 提升多任务学习的因素 数据放大（data amplification）。相关任务在学习过程中产生的额外有用的信息可以有效方法数据/样本（data）的大小/效果。主要有三种数据放大类型：统计数据放大（statistical data amplification）、采样数据放大（sampling data amplification），块数据放大（blocking data amplification）。 Eavesdropping（窃听）。假设 属性选择（attribute selection） 表示偏移（representation bias） 预防过拟合（overfitting prevention） 7. 多任务学习的方法 基于特征共享（联合特征学习） 基于均值约束； 参数共享的高斯处理多任务学习； 低秩约束多任务学习； 较低结构优化多任务学习； … 8. 多人无学习与其他学习算法之间的关系多任务学习（Multitask learning）是迁移学习算法的一种，迁移学习之前介绍过。定义一个一个源领域source domain和一个目标领域（target domain），在source domain学习，并把学习到的知识迁移到target domain，提升target domain的学习效果（performance）。 多标签学习（Multilabel learning）是多任务学习中的一种，建模多个label之间的相关性，同时对多个label进行建模，多个类别之间共享相同的数据/特征。 多类别学习（Multiclass learning）是多标签学习任务中的一种，对多个相互独立的类别（classes）进行建模。这几个学习之间的关系如图3所示： 图（03） 9. 应用基于神经网络的多任务学习，尤其是基于深度神经网络的多任务学习（DL based Multitask Learning），适用于解决很多NLP领域的问题，比如把词性标注、句子句法成分划分、命名实体识别、语义角色标注等任务，都可以采用MTL任务来解决。 10. 参考 模型汇总-14 多任务学习-Multitask Learning概述 Multi-task Learning(Review)多任务学习概述 Caruana, R. (1997). Multitask Learning. Machine Learning, 28(1), 41–75. doi: 10.1023/A:1007379606734]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 机器翻译 》]]></title>
    <url>%2FSubMenu-Subdomain-ML%2Findex.html</url>
    <content type="text"><![CDATA[Machine Translation]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 自然语言推理 》]]></title>
    <url>%2FSubMenu-Subdomain-NLI%2Findex.html</url>
    <content type="text"><![CDATA[Natural Language Inference]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 语言模型 》]]></title>
    <url>%2FSubMenu-Subdomain-LanguageModel%2Findex.html</url>
    <content type="text"><![CDATA[Language Model 图1.《自然语言处理综论》第四章（图中的标号为章节顺序） 总结： 在阅读到“我们将会看到，如N元语法这样的预测器可以给下面可能出现的单词指派一个条件概率，也可以给下面可能出现的整个句子指派一个联合概率，在语音和语言处理中，不论是预测下面的单词还是预测个句子，N元语法模型都是非常重要的工具”这句话的时候，没有去深入思考单词的条件概率和句子的联合概率各自有什么具体的含义，没有意识到它们是两种不同的情况，可以嵌入到不同的应用，所以，在学习的过程中，应该积极主动地思考，而不是纯粹的被动的“浏览”； 在理解下面的公式和“链规则说明了整个单词序列的联合概率的计算与在前面给定单词的条件下一个单词的条件概率的计算之间的关系”这句话的时候没有留意到联合概率和条件概率之间的联系，而是觉得这与自己已经学过的联合概率和条件概率差不多也就一带而过了，公式中当k=1的时候，实际上是将$p\left( x_{1}\right)$的计算表示成了开头人工符号（下图中红色符号）推第一个单词的概率，这样统一的将整个句子的联合概率表示为了条件概率相乘，所以在学习的时候，不要总以为自己以前学过就一带而过，要仔细研究以前学过的公式在NLP中具体表示的是什么，有没有什么变化和改变； 在理解语言模型公式和N元语法公式的时候，并没有注意到它们之间的区别和递进关系，N元语法是用于近似地逼近语言模型而衍生出来的，因为“语言具有创造性，每一个特定的上下文都可能是在此之前从来都没有出现过的”，也就是说可能出现某个单词前面的句子没有出现过，也就是没有前面句子联合概率的情况，这种情况就计算不出出现下面指定单词的条件概率，所以语言模型和N元语法是近似地关系，N元语法的出现是为了解决上面这种情况的出现； 在学习“我们需要再句子末尾标一个结尾符号，以便使二元语法具有真正的概率分布。如果没有这样的结尾符号，那么，具有给定长度的所有句子的句子概率的总和将为1，而整个语言的概率将为无穷”时，把这句话的理解想得很难，一来就想了一个很长的句子，然后就不知道如何推敲到这个结论上来了，其实，如果把一个句子想得短一点，比如三个单词，这句话的推导就很容易了，所以，不要一来就把自己设置在一个复杂的“上下文”环境中，设置得简单点反而更容易促进解决问题的解决； 在学习中遇到书中提到的问题时，在接着往下看之前，应该自己思考，形成独立、主动地思考习惯和见解，比如，在遇到“二元语法究竟捕捉到了什么样的语法现象”，应该主动思考，其实，这句话的内容与语言模型对语料库的敏感性有一定的关系； “举一反三”能力的培养，在学习完二元语法的时候，我们应该思考，既然称为N元语法，那么还有更高阶的语法，那么，更高阶的语法如何表示，公式是怎样的，与低阶N元语法不同点在哪里，在这章中提示我们思考高阶语法的还有几处地方，我们应该培养这种“阅读敏感性”来扩展该知识点的深度和广度； 类似于“除了训练集和测试集之外，把数据进行其他方式的分解也常常是很有用的。”这样的内容性扩展句子，往往提供了更广泛的思考空间和场景需求，所以在遇到这种句子的时候，应该特别留意； 在理解“N元语法概率矩阵的数据非常稀疏。可能的二元语法组合的数量有V^2=844 000 000个，可能的四元语法组合的数量有V^2=700000000000000000个。因此，我们的生成系统对于前面4个词的四元语法（It cannot be but），后面可能接续的单词只有5个（that, I, he, thou 和 so）；对于很多包含4个单词的四元语法组合，它们后面的接续单词都只有1个。”这句话时，出现了理解偏差，把接续单词是5个和只有1个的场景混淆了，前面的5个是针对于生成系统（遍历所有组合，不管是否存在的）而言，而后面的1个是针对实际情况而言，所以理解句子的时候，看清上下文环境非常重要； 在学习困惑度一节的时候，遇到了很多问题，包括加权平均转移因子的理解、加权平均因子与困惑度的关系、这节的困惑度与以前所学的数学上的困惑度不同、计算单个句子或事例的困惑度结果导致理解歧义，虽然这些问题在书本上基本找不到回答，所以，应该反思，遇到这类问题如何寻找答案，自己思考出的办法是，首先寻找这个定义的原始论文出处（《统计自然语言处理》是一本很好的论文“目录”），如果没有就在网上寻找答案，当然，自己积累一些好的资源（包括好的一些类似于优秀知乎回答者、网站、书籍）也是非常好的办法之一，就算再优秀的书籍（即使是《Speech and Language Processing》）也有写得不是很清楚的地方，综合各方向上的资源一起来理解，也许能做到更加全面； 另外，在学习加权平均转移因子时，虽然许多语句在暗示加权平均转移因子是困惑度的一种度量方法，但是自己始终没有把它和困惑度联系起来，特别是在遇到“因此，虽然转移因子仍然是10，但是困惑度或加权转移因子要变得小一些。”这句话后，也可能是自己把转移因子和加权平均转移因子弄混淆了看作了是一个概念，所以在以后的学习过程中，一、要提高自己的细节注意力，少一个（几个）字的也许就不是一个概念了；二、要提高对于类似于上面这些语句的敏感性，这能帮助我们正确的理解内容，排除自己错误的理解；三、对于一些确定的东西，一定要坚信自己的理解，不要犹豫不决，含混不清的； 掌握每一种方法（包括模型方法、评测方法等）的优势、劣势、使用环境是非常重要的，这有助于我们在现实建模的时候的模型选择，比如评测方法困惑度，它本身就不是一个对于任何情况都非常准确的一个方法，书中也说了，只是与预测准确度“正相关”，所以不能把它作为唯一的评测标准； 如何由简入难渐进式的学习，这点很重要 在学习完每一个章节的内容时，都应该总结成图1所示的结构图，一方面系统了解这个知识点涉及的内容组成和功能，另一方面也便于记忆； 在画完上述结构图并理解记忆之后，应该使用费曼学习法对图中知识点进行更加细致的回忆式的学习和复习，以便查看哪些知识点还不熟悉和掌握的； 思考对于某些知识点不明白的根本原因； 不要花太多时间纠结于这一章的内容； 思考如何从纷杂的书中理出自己要学习的内容； 反思学习这章时候的状态； 等待深究的内容如何进行深究，先找寻好资料； 遗留的为题如何处理]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 自然语言生成 》]]></title>
    <url>%2FSubMenu-Subdomain-NLG%2Findex.html</url>
    <content type="text"><![CDATA[Natural Language Generation 【2019-08-24】万小军：自然语言生成研究进展]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 词性标注 》]]></title>
    <url>%2FSubMenu-Subdomain-POS%2Findex.html</url>
    <content type="text"><![CDATA[Post of Speech 1. 定义 2. 难点 词性兼类； 缺乏形态变换（eg：中文）]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 命名实体识别 》]]></title>
    <url>%2FSubMenu-Subdomain-NER%2Findex.html</url>
    <content type="text"><![CDATA[Named Entity Recognition 1. 定义找出构成专有名称的文本片段，并根据它们所指向的实体类别进行分类。命名实体的定义通常也会扩展到本身并不是实体的事物，比如日期、时间、有名事件，以及其他种类的时间表达式；还有尺寸、数量、价格和其他类别的数值表达式。 2. 难点 歧义： 同一名称可以指向同一个类型的不同实体； 同一个名称可以指代完全不同类型的实体，比如苹果既可以指互联网公司也可以指代水果； 3. 综述 A Survey on Deep Learning for Named Entity Recognition]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 表示学习 》]]></title>
    <url>%2FSubMenu-Subdomain-RepresentationLearning%2Findex.html</url>
    <content type="text"><![CDATA[Representation Learning I、Word Embedding 词嵌入 词向量构造流程 II、Sentence Embedding III、Document Embedding IV、Sense Embedding]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 问答系统》]]></title>
    <url>%2FSubMenu-Subdomain-QA%2Findex.html</url>
    <content type="text"><![CDATA[Question and Answer System 综合资源 1. 概念 2. 分类2.1 Knowledge-based QA 基于知识的问答系统 2.2 Table/List-based QA2.3 Text-based QA2.4 Comnunity-based QA2.5 Visual QA 3. 发展现状及趋势 4. 相关比赛 5. 数据集]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 预训练 》]]></title>
    <url>%2FSubMenu-Subdomain-PreTraining%2Findex.html</url>
    <content type="text"><![CDATA[Pre-trained 预训练 一、定义预训练是通过大量无标注的语言文本进行语言模型的训练，得到一套语言表示的模型参数。 二、进展及现状 第十九届中国计算语言学大会（2020-11-01）——预训练语言模型研究进展和趋势展望（刘群） 三、未来方向 更强大：大模型与大参数 更小巧：压缩与加速 更优秀：功能更多、性能更高、训练更快 更聪明：外部知识融入 更能干：跨界出圈 四、综述 Pre-trained Models for Natural Language Processing：A Survey 刘群：预训练语言模型的研究与应用（2019-10-31） 车万翔：预训练模型（2019-10-18） 五、参考 How to Generate a Good Word Embedding Deep Learning in NLP （一）词向量和语言模型 Embedding从入门到专家必读的十篇论文 Embedding在深度推荐系统中的3大应用方向 深度学习中不得不学的Graph Embedding方法 香侬读 | 怎样在小数据集下学习OOV词向量？ 小谈词向量对齐 词向量的计算与评价]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 阅读理解 》]]></title>
    <url>%2FSubMenu-Subdomain-ReadingComprehension%2Findex.html</url>
    <content type="text"><![CDATA[Reading Comprehension]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 语义分析 》]]></title>
    <url>%2FSubMenu-Subdomain-SemanticParsing%2Findex.html</url>
    <content type="text"><![CDATA[Semantic Parsing]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 分词 》]]></title>
    <url>%2FSubMenu-Subdomain-Segmentation%2Findex.html</url>
    <content type="text"><![CDATA[Segmentation 1. 定义 2. 难点 分词规范：目前为止并没有明确的定义，但很多规定里都含有“结合紧密，使用稳定”的要求； 歧义消解： 组合型歧义：A、B和AB都各自为词，eg：起身； 交集型歧义：AB、BC各自为词，A、B、C分别为汉字串， eg：结合成，结合与合成分别为词； 未登录词（新词）识别: 已有的词表中没有收录的词； 已有的训练语料中没有的词（也称为集外词，OOV）； 分词粒度：对于不同应用，对于粒度的要求不同； 错别字、谐音字规范化 3. 解决方案3.1 基于规则（基于字典） 定义：这种方法本质上就是字符串匹配的方法，将一串文本中的文字片段和已有的词典进行匹配，如果匹配到，则此文字片段就作为一个分词结果。 方法： 正向最大匹配法（从左到右） 逆向最大匹配法（从右到左） 双向最大匹配（进行从左到右、从右到左两次扫描，相同的作为确定词组，不相同的选择较长的词组作为划分，中心思想以划分出的词数量最小为原则） 全切分法：利用全切分词生成有限无环图DAG，然后利用不同的算法求出一条或多条不同的路径； 优点： 速度快，实现简单； 缺点： 未能解决歧义消解和未登陆词识别两个关键问题； 3.2 基于传统统计 定义：基于统计的分词方法是在给定大量已经分词的文本的前提下，利用统计机器学习模型学习词语切分的规律（称为训练），从而实现对未知文本的切分。 方法： 基于序列标注（HMM、MEMM、CRF、MaxEnt、结构化感知器）； 基于转移的分词（可以灵活融入各种特征） 基于无标注数据的半指导特征（eg：两个字串之间的互信息，字串左右标点符号频率，两个字的卡方统计） 基于自然标注数据的学习方法（eg：网页中含有大量的html标记） N-最短路径方法（全切分的beam-search方法）； 基于词的n元语法模型； 3.3 基于深度学习 方法： BiLSTM + CRF 4. 评测标准 Precision Recall F1 5. 相关库与软件 hanlp 哈工大：语言云LTP-Cloud 中科院张华平：NLPIR 波森科技：Boson 结巴分词 北大：PKUSeg 百度：paddle中的LAC（联合词法分析模型） 腾讯文智 阿里云NLP]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 情感分析 》]]></title>
    <url>%2FSubMenu-Subdomain-SentimentAnalysis%2Findex.html</url>
    <content type="text"><![CDATA[Sentiment Analysis]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 任务型对话机器人 》]]></title>
    <url>%2FSubMenu-Subdomain-TaskBot%2Findex.html</url>
    <content type="text"><![CDATA[Task-based Chatbot 面向任务的对话系统 任务型与问答型对话系统中的语言理解技术]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 文本分类 》]]></title>
    <url>%2FSubMenu-Subdomain-TextClassification%2Findex.html</url>
    <content type="text"><![CDATA[Text Classification 文本分类的种类 短文本分类 句子 标题 商品评论 情感分类 长文本分类 文章 风格分类：作文身份识别、文学作品流派分类等； 内容分类：文学、体育等； 应用 垃圾邮件的判定：是否为垃圾邮件； 根据标题为图文视频打标签：政治、体育、娱乐等； 根据用户阅读内容建立用户画像标签：教育、医疗等； 电商商品评论分析等：消极、积极； 自动问答中的问句分类； 文本涉黄审核； 法律文书量刑预测； 文本分类的模式 二分类 多分类 多标签分类 文本分类技术基于传统方法基本流程 文本预处理 中文文本挖掘预处理流程总结 中文NLP数据预处理程序分享 【结巴分词资料汇编】结巴中文分词源码分析(2) 可能使用到正则表达式； 特征选择 TF/IDF 互信息量 信息增益 卡方统计 文本表示 词袋模型 向量空间模型（VSM） 语义的文本表示方法 比如LDA主题模型、LSI/PLSI概率潜在语义索引等方法，一般认为这些方法得到的文本表示可以认为文档的深层表示； Word Embedding文本分布式表示方法； 分类器选择和分类 相关概念 BM25 基于深度学习方法经典论文 FastText 论文：Bag of Tricks for Efficient Text Classification 代码 TextCNN 论文：Convolutional Neural Networks for Sentence Classification 代码 对于短文本，CNN配合Max-pooling池化(如TextCNN模型)速度快，而且效果也很好。因为短文本上的关键词比较容易找到，而且Max-pooling会直接过滤掉模型认为不重要特征。具体工作机制是：卷积窗口沿着长度为n的文本一个个滑动，类似于n-gram机制对文本切词，然后和文本中的每个词进行相似度计算，因为后面接了个Max-pooling，因此只会保留和卷积核最相近的词。这就是TextCNN抓取关键词的机制。虽然Attention也突出了重点特征，但是难以过滤掉所有低分特征。而Capsules效果比CNN好，所以我个人觉得在短文本上LSTM/GRU+Capusules是一个不错模型，这也是目前Kaggle Quora比赛上(短文本分类)最好的baseline之一； TextRNN 论文：Recurrent Neural Network for Text Classification with Multi-task Learning 代码 RCNN 论文：Recurrent Convolutional Neural Networks for Text Classification (AAAI 2015) 代码 HAN 论文：Hierarchical Attention Networks for Document Classification (NAACL 2016) 对于长文本而言，TextCNN会比HAN模型泛化能力差很多。当然如果在TextCNN前加一层LSTM，这样效果可以提升很大； DPCNN 论文：Deep Pyramid Convolutional Neural Networks for Text Categorization (ACL 2017) 代码 SAC（Sentiment Analysis by Capsules (WWW 2018)） BERT Densely Connected CNN 论文：Densely Connected CNN with Multi-scale Feature Attention for Text Classification GNN：TextGCN 论文：Graph Convolutional Networks for Text Classification 代码 Capsule Networks 论文：Investigating Capsule Networks with Dynamic Routing for Text Classification 代码 Semi-supervised Text Classification 论文：Variational Pretraining for Semi-supervised Text Classification 代码 XLNet Transformable Convolutional Neural Network 论文：Transformable Convolutional Neural Network for Text Classification A Generative Explanation Framework for Text Classification 论文：Towards Explainable NLP: A Generative Explanation Framework for Text Classification 评价指标文本分类的性能评价指标主要是召回率（recall）、准确率（precision）、F1-measure，以及用于评价全局性能的宏平均（macro-average）和微平均（micro-average）。 二分类：accuracy，precision，recall，f1-score，… 多分类: Micro-Averaged-F1， Macro-Averaged-F1, … 多标签分类：Jaccard相似系数, … 网址参考 整体概述： 综述性论文 —— Text Classification Algorithms：A Survey 综述性论文 —— Deep Learning Based Text Classification：A Comprehensive Review 文本分类算法综述 文本分类概述（nlp） 中文文本分类：你需要了解的10项关键内容（主要针对传统算法） NLP基础任务:文本分类近年发展汇总,68页超详细解析 项目相关： 企业中的文本分类 如何到top5%？NLP文本分类和情感分析竞赛总结 用深度学习（CNN RNN Attention）解决大规模文本分类问题 - 综述和实践 基于tensorflow的几种深度学习文本分类器（FastText, TextCNN, TextRNN, TextBiRNN, TextAttBiRNN, HAN, RCNN, RCNNVariant） 基于Pytorch的几种深度学习文本分类器（TextCNN, TextRNN, FastText, TextRCNN, BILSTM_Attention, DPCNN, Transformer） 各种文本分类算法集锦，从入门到精通（含有一些传统算法相关库的使用） 来自kaggle文本分类银奖得主的参赛感悟]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 摘要 》]]></title>
    <url>%2FSubMenu-Subdomain-Summarization%2Findex.html</url>
    <content type="text"><![CDATA[Summarization]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 文本匹配 》]]></title>
    <url>%2FSubMenu-Subdomain-TextMatch%2Findex.html</url>
    <content type="text"><![CDATA[Text Match]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 文本纠错 》]]></title>
    <url>%2FSubMenu-Subdomain-TextErrorCorrection%2Findex.html</url>
    <content type="text"><![CDATA[Text Error Correction 一、概念二、种类三、技术四、应用五、参考 平安寿险 AI 团队 | 文本纠错技术探索和实践]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 文本预处理 》]]></title>
    <url>%2FSubMenu-Subdomain-TextProcessing%2Findex.html</url>
    <content type="text"><![CDATA[Text Pre-processing]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 计算机科学 》]]></title>
    <url>%2FSubMenu-Subject-CS%2Findex.html</url>
    <content type="text"><![CDATA[Computer Science 计算机科学地图 Tips： 这里提及的所有技术和推荐书目，主要针对软件工程师而言相对通用的技术，各个技术之间涉及的不同技术并未包含； 一、编程语言C++进阶路线 基础 《Essential C++》：以简单了解C++大概，快速上手为目标，缺少更多的深入讲解； 《C++ Primer》：经典中的经典，涵盖了几乎所有C++的内容； 中阶 《Effective C++》：提高C++实际编程能力； 《More Effective C++》：比《Effective C++》更高深的项目技巧； 高阶 《C++标准程序库》更高阶的功能； 《深度探索C++对象模型》：C++底层的一些根本性原理； Python推荐书籍 《流畅的Python》 《Python核心编程》 Java推荐书籍 《Java核心技术》卷一：基础知识 《Java核心技术》卷二：高级特性 《Java编程思想》 二、基础四大件数据结构与算法2.1 数据结构与算法 数据结构与算法 推荐书籍 C/C++：《大话数据结构》 java：《算法》 《算法导论》 计算机网络推荐书籍 《TCP/IP详解》卷一：协议 《TCP/IP详解》卷二：实现 《TCP/IP详解》卷三：TCP事务协议、HTTP、NNTP和UNIX域协议 计算机网络：自顶向下方法 操作系统推荐书籍 《深入理解计算机系统》 设计模式推荐书籍 《大话设计模式》 三、应用与编程实践编写和使用C++的环境一般都是Linux，所以主要针对Linux编程的工具介绍。 Linux操作系统推荐书籍 《鸟哥的Linux私房菜》 编译工具主要编译工具是GCC推荐书籍 《跟我一起写makefile》 调试工具主要调试工具GDB推荐书籍 《Debugging with gdb》中文版 Linux环境编程主要涉及Linux系统编程、多线程编程、网络编程推荐书籍 《UNIX环境高级编程》 《Linux高性能服务器编程》 《POSIX多线程程序设计》]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 信息检索 》]]></title>
    <url>%2FSubMenu-Subject-InformationRetrieval%2Findex.html</url>
    <content type="text"><![CDATA[Information Retrieval]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 认知学 》]]></title>
    <url>%2FSubMenu-Subject-Cognitive%2Findex.html</url>
    <content type="text"><![CDATA[Cognitive]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 语言学 》]]></title>
    <url>%2FSubMenu-Subject-Linguistic%2Findex.html</url>
    <content type="text"><![CDATA[Linguistic 剑桥大学Linguistics专业必读书单 与NLP相关书籍推荐 计算语言学与语言科技原文丛书 《自然语言生成系统的建造》 《语音语言处理导论》 《本体与词汇库 : 自然语言处理角度的解析》 《词义消歧 : 算法与应用》 《对话的逻辑》 《树库 : 句法分析语料库的构建和使用》 《口语机器翻译》 《词义的语言》 《文字书写系统的计算理论》 《基于记忆的语言处理》 《文本和语音处理系统评测》]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 心理学 》]]></title>
    <url>%2FSubMenu-Subject-Psychology%2Findex.html</url>
    <content type="text"><![CDATA[Psychology]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 推荐系统 》]]></title>
    <url>%2FSubMenu-Subject-RecommendedSystem%2Findex.html</url>
    <content type="text"><![CDATA[Recommended System]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 哲学 》]]></title>
    <url>%2FSubMenu-Subject-Philosophy%2Findex.html</url>
    <content type="text"><![CDATA[Philosophy]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 语音 》]]></title>
    <url>%2FSubMenu-Subject-Speech%2Findex.html</url>
    <content type="text"><![CDATA[Speech]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 计算机视觉 》]]></title>
    <url>%2FSubMenu-Subject-Vision%2Findex.html</url>
    <content type="text"><![CDATA[Computer Vision]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 数据增强 》]]></title>
    <url>%2FSubMenu-Theme-DataAugmentation%2Findex.html</url>
    <content type="text"><![CDATA[Data Augmentation 集合啦，NLP数据增强技术！超全资源汇总]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 文本挖掘 》]]></title>
    <url>%2FSubMenu-Subject-TextMining%2Findex.html</url>
    <content type="text"><![CDATA[Text Mining 文本挖掘与NLP的关系从本质上来讲，自然语言处理是文本挖掘的基础，学好自然语言理解能够更有效地设计出完美的文本挖掘的应用算法。但是，从学术领域讲，自然语言处理和文本挖掘是平行的，二者有交集，也有不同的地方。自然语言处理顾名思义更侧重于语言学，涉及词汇、语义、语法等方面的知识，而文本挖掘更侧重于技术手段，包括算法时间复杂性、算法空间复杂性、基于网络的应用、数据的存储等方面的内容。 相关地图 文本挖掘架构]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 低资源 》]]></title>
    <url>%2FSubMenu-Theme-FewShot%2Findex.html</url>
    <content type="text"><![CDATA[Few-shot Generalizing from a Few Examples A Survey on Few-Shot Learning]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 可解释性 》]]></title>
    <url>%2FSubMenu-Theme-Explainable%2Findex.html</url>
    <content type="text"><![CDATA[Explainable]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 知识 + 》]]></title>
    <url>%2FSubMenu-Theme-Knowledge%2Findex.html</url>
    <content type="text"><![CDATA[Knowledge + 【2019-08-24】刘知远：知识计算与语言理解 刘知远：知识指导的自然语言处理（2019-05-30）[video] 吴华：知识与自然语言处理（2019-05-04）]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 因果逻辑 》]]></title>
    <url>%2FSubMenu-Theme-Cause%2Findex.html</url>
    <content type="text"><![CDATA[Cause 三本经典书籍： 《The Book of Why：The New Science of Cause and Effect》 《Causal Inference in Statistics：A Primer》 《Elements of Causal Inference：Foundations and Learning Algorithms》 相关经典论文： Decision-theoretic foundations for statistical causality]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 模型压缩与加速 》]]></title>
    <url>%2FSubMenu-Theme-ModelCompression%2Findex.html</url>
    <content type="text"><![CDATA[Model Compression and Accelerate 一、概念二、方法2.1 蒸馏2.2 剪枝2.3 量化]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 富资源 》]]></title>
    <url>%2FSubMenu-Theme-RichSource%2Findex.html</url>
    <content type="text"><![CDATA[Rich Source]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 多模态 》]]></title>
    <url>%2FSubMenu-Theme-Multimodals%2Findex.html</url>
    <content type="text"><![CDATA[Multi-modals]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 零资源 》]]></title>
    <url>%2FSubMenu-Theme-ZeroShot%2Findex.html</url>
    <content type="text"><![CDATA[Zero-shot]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 资源和评估 》]]></title>
    <url>%2FSubMenu-Theme-SourceandEvaluation%2Findex.html</url>
    <content type="text"><![CDATA[Source and Evaluation]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 2021 足迹 》]]></title>
    <url>%2FMenu-Log%2F2021%2Findex.html</url>
    <content type="text"><![CDATA[2021年6月6.02 日常【悟】 学习的内容除了要考虑轻重缓急，还要从根本目的上去考虑是系统学习还是部分学习够用就行，不要一味追求完整而浪费了大量时间； 遇到比较专业的问题时，不要仅靠自己的思考和经验，有时候需要去查阅一些专业人士的建议，比如如何提高时间管理，如何保持经历旺盛等等；]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Flib%2Fpace%2FREADME.html</url>
    <content type="text"><![CDATA[Load bar at the top for NexT Installation Step 1 &rarr; Go to NexT dir Change dir to NexT directory. There must be layout, source, languages and other directories: 123$ cd themes/next$ lsbower.json _config.yml docs gulpfile.coffee languages layout LICENSE.md package.json README.md scripts source test Step 2 &rarr; Get module Install module to source/lib directory: 1$ git clone https://github.com/theme-next/theme-next-pace source/lib/pace Step 3 &rarr; Set it up Enable module in NexT _config.yml file: 1pace: true Update 12$ cd themes/next/source/lib/pace$ git pull]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 2020 足迹 》]]></title>
    <url>%2FMenu-Log%2F2020%2Findex.html</url>
    <content type="text"><![CDATA[2020年3月3.01 日常【悟】 关于CS224N的课程学习： 每个章节内容比较多，并且没有明显的框架，自己在学习每一章之后要学会总结，并写出框架； 课程中讲的只是一个大概的思路，很多东西需要自己去查看详细的论文和其他资料，对于这些原始论文，可以存在自己的手机中分门别类以方便确认主题，有空闲时间就看一下； 3.02 日常【悟】 关于CS224N的课程学习： 很多论文在开头都会引入一些与自己主题相关模型的研究脉络和发展思路并且附上了该方面的论文，说明了“前辈”们的各种缺点以及改进思路，看看这些思路自己就会对这个领域的内容有一定的了解； 阅读完ELMo的原论文再看看Transformer就能够更能理解transformer为什么要这样设计，每一层的含义是什么； 3.04 日常【悟】 AllenNLP是一个很好的学习框架，他的实现都有一些论文背景，自己可以跟着写，然后对比效果； 3.09 日常【悟】 所有开源学习框架都可以借鉴来学习，这是提升工程能力和理论理解非常好的一个途径； 3.11 日常【悟】 阅读论文是了解模型本质最快捷也是最有效的途径； 3.13 日常【悟】 对于深度学习来说，理解它产生的内容从可视化的角度是可行的，所以掌握一些可视化的技巧是必要的； 很多模型的理论原型都是用数学可以解释的，甚至就是以数学为根基产生的，所以持续不断地积累数学素养是有必要的； 2020年5月5.15 日常【悟】 在阅读资料时，遇到不懂的内容，要及时记录下来，记录的内容包括疑问的内容，疑问的出处（方便在查询理解之后返回原处对相关上下文进行深入理解），疑问产生的时间； 2020年6月6.24 日常【悟】 “性能优于ReLU，斯坦福用周期激活函数构建隐式神经表示”激活函数的持续研究表明即使是研究的很多很久的内容也可能并未达到真正应有的效果，也就是说并未抓住问题的实质； 很多新内容不太可能第一遍就理解得很深刻和全面，需要后续重复学习和补充，但是应该总结的是自己在第一遍学习的时候为什么没有注意到这些后面才注意到的细节内容或者说下次学习新内容的时候应该怎样注意到这些内容，或者说从哪些角度思考新知识，这是对学习方法的迭代； 随时将产生的问题记录于专门的地方，以便后来的解决和回顾； 2020年11月11.13 日常【悟】 学习某门学科时，不要将大部分精力放在提升广度上面，可以先花一定时间了解整体情况，然后就应该将主要精力放在某个子领域上去提升深度，在深度中慢慢扩张知识以提升广度，这样可以避免自己一直处于这门学科的低水平状态，同时也可以最大限度地提升知识吸收的边界效应。因为一开始就将大量的精力放在广度上，一方面可能不能将这么学科的所有面目穷尽，另一方面很多细节知识并不了解，无法知道各个知识点之间的联系和区别，这样也不容易形成整体体系； 不要想着从很多营销号里能提升自己的技能水平，因为绝大部分的内容都是底层的，翻来覆去并没有什么新意，反而将自己大部分时间浪费，还维持着低水平状态； 在学习某些模型或者其他重要内容时难免会遇到涉及其他科目的学科知识点，这时应该以理解和应用为首要目的，待之后看是否有需要系统学习相关科目知识的必要，当然，对于一些很基础的内容，像是微积分，线代，概率统计之类的必须要先打牢学科基础再往上堆积模型内容，因为这些都是常用的内容，如果零碎地学习，就需要反复地进行，一方面耽误时间，另一方面也不利于系统掌握； 11.13 日常【悟】 在不断地深入某个子领域时，自然会知道需要学习哪些内容，切忌在自己对这个领域不熟悉的时候盲目地对要学习的内容进行规划； 11.28 日常【悟】 面对一个问题时，如何了解其他人已经做过的工作，避免重复造轮子是一种能力；]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Flib%2Fpace%2Fpace-theme-big-counter.min.css</url>
    <content type="text"><![CDATA[.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace.pace-inactive .pace-progress{display:none}.pace .pace-progress{position:fixed;z-index:2000;top:0;right:0;height:5rem;width:5rem;-webkit-transform:translate3d(0,0,0)!important;-ms-transform:translate3d(0,0,0)!important;transform:translate3d(0,0,0)!important}.pace .pace-progress:after{display:block;position:absolute;top:0;right:.5rem;content:attr(data-progress-text);font-family:"Helvetica Neue",sans-serif;font-weight:100;font-size:5rem;line-height:1;text-align:right;color:rgba(34,153,221,.19999999999999996)}]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Flib%2Fpace%2Fpace-theme-center-atom.min.css</url>
    <content type="text"><![CDATA[.pace,.pace .pace-progress{z-index:2000;height:60px;width:100px}.pace .pace-activity,.pace .pace-progress:before{border-radius:50%;display:block;position:absolute}.pace.pace-inactive{display:none}.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none;position:fixed;margin:auto;top:0;left:0;right:0;bottom:0}.pace .pace-progress{position:absolute;-webkit-transform:translate3d(0,0,0)!important;-ms-transform:translate3d(0,0,0)!important;transform:translate3d(0,0,0)!important}.pace .pace-progress:before{content:attr(data-progress-text);text-align:center;color:#fff;background:#29d;font-family:"Helvetica Neue",sans-serif;font-size:14px;font-weight:100;line-height:1;padding:20% 0 7px;width:50%;height:40%;margin:10px 0 0 30px;z-index:999}.pace .pace-activity{font-size:15px;line-height:1;z-index:2000;-webkit-animation:pace-theme-center-atom-spin 2s linear infinite;-moz-animation:pace-theme-center-atom-spin 2s linear infinite;-o-animation:pace-theme-center-atom-spin 2s linear infinite;animation:pace-theme-center-atom-spin 2s linear infinite;border:5px solid #29d;content:' ';top:0;left:0;height:60px;width:100px}.pace .pace-activity:after,.pace .pace-activity:before{content:' ';display:block;position:absolute;top:-5px;left:-5px;height:60px;width:100px}.pace .pace-activity:after{border-radius:50%;border:5px solid #29d;-webkit-transform:rotate(60deg);-moz-transform:rotate(60deg);-o-transform:rotate(60deg);transform:rotate(60deg)}.pace .pace-activity:before{border-radius:50%;border:5px solid #29d;-webkit-transform:rotate(120deg);-moz-transform:rotate(120deg);-o-transform:rotate(120deg);transform:rotate(120deg)}@-webkit-keyframes pace-theme-center-atom-spin{0%{-webkit-transform:rotate(0)}100%{-webkit-transform:rotate(359deg)}}@-moz-keyframes pace-theme-center-atom-spin{0%{-moz-transform:rotate(0)}100%{-moz-transform:rotate(359deg)}}@-o-keyframes pace-theme-center-atom-spin{0%{-o-transform:rotate(0)}100%{-o-transform:rotate(359deg)}}@keyframes pace-theme-center-atom-spin{0%{transform:rotate(0)}100%{transform:rotate(359deg)}}]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Flib%2Fpace%2Fpace-theme-barber-shop.min.css</url>
    <content type="text"><![CDATA[.pace,.pace .pace-progress{width:100%;overflow:hidden}.pace,.pace .pace-activity{position:fixed;top:0;left:0}.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none;z-index:2000;height:12px;background:#fff}.pace-inactive{display:none}.pace .pace-progress{background-color:#29d;position:fixed;top:0;bottom:0;right:100%}.pace .pace-activity{right:-32px;bottom:0;-webkit-transform:translate3d(0,0,0);-moz-transform:translate3d(0,0,0);-ms-transform:translate3d(0,0,0);-o-transform:translate3d(0,0,0);transform:translate3d(0,0,0);background-image:-webkit-gradient(linear,0 100%,100% 0,color-stop(.25,rgba(255,255,255,.2)),color-stop(.25,transparent),color-stop(.5,transparent),color-stop(.5,rgba(255,255,255,.2)),color-stop(.75,rgba(255,255,255,.2)),color-stop(.75,transparent),to(transparent));background-image:-webkit-linear-gradient(45deg,rgba(255,255,255,.2) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.2) 50%,rgba(255,255,255,.2) 75%,transparent 75%,transparent);background-image:-moz-linear-gradient(45deg,rgba(255,255,255,.2) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.2) 50%,rgba(255,255,255,.2) 75%,transparent 75%,transparent);background-image:-o-linear-gradient(45deg,rgba(255,255,255,.2) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.2) 50%,rgba(255,255,255,.2) 75%,transparent 75%,transparent);background-image:linear-gradient(45deg,rgba(255,255,255,.2) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.2) 50%,rgba(255,255,255,.2) 75%,transparent 75%,transparent);-webkit-background-size:32px 32px;-moz-background-size:32px 32px;-o-background-size:32px 32px;background-size:32px 32px;-webkit-animation:pace-theme-barber-shop-motion .5s linear infinite;-moz-animation:pace-theme-barber-shop-motion .5s linear infinite;-ms-animation:pace-theme-barber-shop-motion .5s linear infinite;-o-animation:pace-theme-barber-shop-motion .5s linear infinite;animation:pace-theme-barber-shop-motion .5s linear infinite}@-webkit-keyframes pace-theme-barber-shop-motion{0%{-webkit-transform:none;transform:none}100%{-webkit-transform:translate(-32px,0);transform:translate(-32px,0)}}@-moz-keyframes pace-theme-barber-shop-motion{0%{-moz-transform:none;transform:none}100%{-moz-transform:translate(-32px,0);transform:translate(-32px,0)}}@-o-keyframes pace-theme-barber-shop-motion{0%{-o-transform:none;transform:none}100%{-o-transform:translate(-32px,0);transform:translate(-32px,0)}}@-ms-keyframes pace-theme-barber-shop-motion{0%{-ms-transform:none;transform:none}100%{-ms-transform:translate(-32px,0);transform:translate(-32px,0)}}@keyframes pace-theme-barber-shop-motion{0%{transform:none}100%{transform:translate(-32px,0)}}]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Flib%2Fpace%2Fpace-theme-bounce.min.css</url>
    <content type="text"><![CDATA[.pace{width:140px;height:300px;position:fixed;top:-90px;right:-20px;z-index:2000;-webkit-transform:scale(0);-moz-transform:scale(0);-ms-transform:scale(0);-o-transform:scale(0);transform:scale(0);opacity:0;-webkit-transition:all 2s linear 0s;-moz-transition:all 2s linear 0s;transition:all 2s linear 0s}.pace.pace-active{-webkit-transform:scale(.25);-moz-transform:scale(.25);-ms-transform:scale(.25);-o-transform:scale(.25);transform:scale(.25);opacity:1}.pace .pace-activity{width:140px;height:140px;border-radius:70px;background:#29d;position:absolute;top:0;z-index:1911;-webkit-animation:pace-bounce 1s infinite;-moz-animation:pace-bounce 1s infinite;-o-animation:pace-bounce 1s infinite;-ms-animation:pace-bounce 1s infinite;animation:pace-bounce 1s infinite}.pace .pace-progress{position:absolute;display:block;left:50%;bottom:0;z-index:1910;margin-left:-30px;width:60px;height:75px;background:rgba(20,20,20,.1);box-shadow:0 0 20px 35px rgba(20,20,20,.1);border-radius:30px/40px;-webkit-transform:scaleY(.3)!important;-moz-transform:scaleY(.3)!important;-ms-transform:scaleY(.3)!important;-o-transform:scaleY(.3)!important;transform:scaleY(.3)!important;-webkit-animation:pace-compress .5s infinite alternate;-moz-animation:pace-compress .5s infinite alternate;-o-animation:pace-compress .5s infinite alternate;-ms-animation:pace-compress .5s infinite alternate;animation:pace-compress .5s infinite alternate}@-webkit-keyframes pace-bounce{0%,100%,95%{top:0;-webkit-animation-timing-function:ease-in}50%{top:140px;height:140px;-webkit-animation-timing-function:ease-out}55%{top:160px;height:120px;border-radius:70px/60px;-webkit-animation-timing-function:ease-in}65%{top:120px;height:140px;border-radius:70px;-webkit-animation-timing-function:ease-out}}@-moz-keyframes pace-bounce{0%,100%,95%{top:0;-moz-animation-timing-function:ease-in}50%{top:140px;height:140px;-moz-animation-timing-function:ease-out}55%{top:160px;height:120px;border-radius:70px/60px;-moz-animation-timing-function:ease-in}65%{top:120px;height:140px;border-radius:70px;-moz-animation-timing-function:ease-out}}@keyframes pace-bounce{0%,100%,95%{top:0;animation-timing-function:ease-in}50%{top:140px;height:140px;animation-timing-function:ease-out}55%{top:160px;height:120px;border-radius:70px/60px;animation-timing-function:ease-in}65%{top:120px;height:140px;border-radius:70px;animation-timing-function:ease-out}}@-webkit-keyframes pace-compress{0%{bottom:0;margin-left:-30px;width:60px;height:75px;background:rgba(20,20,20,.1);box-shadow:0 0 20px 35px rgba(20,20,20,.1);border-radius:30px/40px;-webkit-animation-timing-function:ease-in}100%{bottom:30px;margin-left:-10px;width:20px;height:5px;background:rgba(20,20,20,.3);box-shadow:0 0 20px 35px rgba(20,20,20,.3);border-radius:20px;-webkit-animation-timing-function:ease-out}}@-moz-keyframes pace-compress{0%{bottom:0;margin-left:-30px;width:60px;height:75px;background:rgba(20,20,20,.1);box-shadow:0 0 20px 35px rgba(20,20,20,.1);border-radius:30px/40px;-moz-animation-timing-function:ease-in}100%{bottom:30px;margin-left:-10px;width:20px;height:5px;background:rgba(20,20,20,.3);box-shadow:0 0 20px 35px rgba(20,20,20,.3);border-radius:20px;-moz-animation-timing-function:ease-out}}@keyframes pace-compress{0%{bottom:0;margin-left:-30px;width:60px;height:75px;background:rgba(20,20,20,.1);box-shadow:0 0 20px 35px rgba(20,20,20,.1);border-radius:30px/40px;animation-timing-function:ease-in}100%{bottom:30px;margin-left:-10px;width:20px;height:5px;background:rgba(20,20,20,.3);box-shadow:0 0 20px 35px rgba(20,20,20,.3);border-radius:20px;animation-timing-function:ease-out}}]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 数学 》]]></title>
    <url>%2FSubMenu-Subject-Math%2Findex.html</url>
    <content type="text"><![CDATA[Mathematics 1. 学科概览1.1 概览地图纯数学与应用数学地图 各子领域交集地图 各子领域关系地图 各子领域关系演进地图 领域组成地图 2. 子领域2.1 维基百科数学分类数学主要的学科最先产生于商业上计算的需要、了解数字间的关系、测量土地及预测天文事件。这四种需要大致地与数量、结构、空间及变化（即算术、代数、几何及分析）等数学上广泛的子领域相关连着。除了上述主要的关注之外，亦有用来探索由数学核心至其他领域上之间的连结的子领域：至逻辑、至集合论（基础）、至不同科学的经验上的数学（应用数学）、及较近代的至不确定性的严格研究。 2.1.1 基础与哲学为了阐明数学基础，数学逻辑和集合论等领域被发展了出来。数学逻辑专注于将数学置在一坚固的公理架构上，并研究此一架构的结果。就数学逻辑本身而言，其为哥德尔第二不完备定理所属的领域，而这或许是逻辑中最广为流传的成果－总存在一不能被证明而又为真的定理。现代逻辑被分成递论、模型论和证明论，且和理论计算机科学有着密切的关连性。 2.1.2 纯粹数学2.1.2.1 数量（数字系统） 数量的研究起于计数，一开始为熟悉的自然数及整数与被描述在算术内的自然数及整数的算术运算。整数更深的性质于数论中有详细的研究，此一理论包括了如费马最后定理等著名的结果。数论还包括两个被广为探讨的未解问题：孪生素数猜想及哥德巴赫猜想。当数系更进一步发展时，整数被视为有理数的子集，而有理数则包含于实数中，连续的量即是以实数来表示的。实数则可以被进一步广义化成复数。数的进一步广义化可以持续至包含四元数及八元数。从自然数亦可以推广到超限数，它形式化了计数至无限的这一概念。另一个研究的领域为大小，这个导致了基数和之后对无限的另外一种概念：阿列夫数，它允许无限集合之间的大小可以做有意义的比较。 主要学科：？ 2.1.2.2 结构（代数） 许多如数及函数的集合等数学物件都有着内含的结构。这些物件的结构性质被探讨于群、环、域等抽象系统中，该些物件事实上也就是这样的系统。此为代数的领域。在此有一个很重要的概念，即广义化至矢量空间的矢量，它于线性代数中被研究。矢量的研究结合了数学的三个基本领域：数量、结构及空间。矢量分析则将其扩展至第四个基本的领域内，即变化。创立于二十世纪三十年代的法国的布尔巴基学派认为：纯粹数学，是研究抽象结构的理论。 结构，就是以初始概念和公理出发的演绎系统。 布尔巴基学派认为，有三种基本的抽象结构：代数结构（群，环，域……），序结构（偏序，全序……），拓扑结构（邻域，极限，连通性，维数……） 主要学科： 代数 概念：代数是一个较为基础的数学分支。它的研究对象有许多。诸如数、数量、代数式、关系、方程理论、代数结构等等都是代数学的研究对象。代数的研究对象不仅是数字，还有各种抽象化的结构。例如整数集作为一个带有加法、乘法和序关系的集合就是一个代数结构。在其中我们只关心各种关系及其性质，而对于“数本身是什么”这样的问题并不关心。常见的代数结构类型有群、环、域、模、线性空间等。并且,代数是几何的总称，代数是还可以用任何字母代替的。分类: （1）初等代数：学习以位置标志符（place holders）标记常数和变量的符号，与掌控包含这些符号的表示式及方程的法则，-来记录实数的运算性质。（通常也会涉及到中等代数和大学代数的部分范围。） （2）抽象代数：讨论代数结构的性质，例如群、环、域等，将基本代数和数的算术中的一些相似概念延广成更一般的概念。这些代数结构是在集合上定义运算而来，而集合上的运算则适合某些公理； （3）线性代数：专门讨论矢量空间，包括矩阵的理论； （4）泛代数：讨论所有代数结构的共有性质； （5）计算代数：讨论在电脑上进行数学的符号运算的算法； 数论 概念：是纯粹数学的分支之一，主要研究整数的性质。被誉为“最纯”的数学领域。正整数按乘法性质划分，可以分成质数，合数，1，质数产生了很多一般人能理解却又悬而未解的问题，如哥德巴赫猜想，孪生质数猜想等。即，很多问题虽然形式上十分初等，事实上却要用到许多艰深的数学知识。这一领域的研究从某种意义上推动了数学的发展，催生了大量的新思想和新方法。数论除了研究整数及质数外，也研究一些由整数衍生的数（如有理数）或是一些广义的整数（如代数整数）。整数可以是方程式的解（丢番图方程）。有些解析函数（像黎曼ζ函数）中包括了一些整数、质数的性质，透过这些函数也可以了解一些数论的问题。透过数论也可以建立实数和有理数之间的关系，并且用有理数来逼近实数（丢番图逼近）。卡尔·弗里德里希·高斯曾说：“数学是科学的皇后，数论是数学的皇后。”分类: （1）初等数论：意指使用不超过高中程度的初等代数处理的数论问题，最主要的工具包括整数的整除性与同余。重要的结论包括中国余数定理、费马小定理、二次互反律等等； （2）解析数论：借助微积分及复分析的技术来研究关于整数的问题，主要又可以分为积性数论与加性数论两类。积性数论借由研究积性生成函数的性质来探讨质数分布的问题，其中质数定理与狄利克雷定理为这个领域中最著名的古典成果。加性数论则是研究整数的加法分解之可能性与表示的问题，华林问题是该领域最著名的课题。此外例如筛法、圆法等等都是属于这个范畴的重要议题； （3）代数数论：引申代数数的话题，关于代数整数的研究，主要的研究目标是为了更一般地解决不定方程的问题，而为了达到此目的，这个领域与代数几何之间有相当关联，比如类域论（class field theory）就是此间的颠峰之作； （4）算术代数几何：研究有理系数多变数方程组的有理点，其结构（主要是个数）和该方程组对应的代数簇的几何性质之间的关系，有名的费马最后定理、莫德尔猜想（法尔廷斯定理）、Weil猜想，和千禧年大奖难题中的贝赫和斯维讷通-戴尔猜想都属此类； （5）几何数论：主要在于透过几何观点研究整数（在此即格子点）的分布情形。最著名的定理为闵可夫斯基定理； （6）计算数论：借助电脑的算法帮助数论的问题，例如素数测试和因数分解等和密码学息息相关的话题； （7）超越数论：研究数的超越性，其中对于欧拉常数与特定的黎曼ζ函数值之研究尤其令人感到兴趣； （8）组合数论：利用组合和几率的技巧，非构造性地证明某些无法用初等方式处理的复杂结论。这是由保罗·埃尔德什开创的思路； （9）模形式：数学上一个满足一些泛函方程与增长条件、在上半平面上的（复）解析函数； 组合数学 概念：广义的组合数学（英语：Combinatorics）就是离散数学，狭义的组合数学是组合计数、图论、代数结构、数理逻辑等的总称。但这只是不同学者在叫法上的区别。总之，组合数学是一门研究可数或离散对象的科学。随着计算机科学的日益发展，组合数学的重要性也日渐凸显，因为计算机科学的核心内容是使用算法处理离散数据。 序理论 2.1.2.3 空间（几何） 空间的研究源自于几何－尤其是欧几里得几何。三角学则结合了空间及数，且包含有著名的勾股定理。现今对空间的研究更推广到了更高维的几何、非欧几里得几何（其在广义相对论中扮演着核心的角色）及拓扑学。数和空间在解析几何、微分几何和代数几何中都有着很重要的角色。在微分几何中有着纤维丛及流形上的微积分等概念。在代数几何中有着如多项式方程的解集等几何物件的描述，结合了数和空间的概念；亦有着拓扑群的研究，结合了结构与空间。李群被用来研究空间、结构及变化。在其许多分支中，拓扑学可能是二十世纪数学中有着最大进展的领域，并包含有存在已久的庞加莱猜想，以及有争议的四色定理。庞加莱猜想已在2006年确认由俄罗斯数学家格里戈里·佩雷尔曼证明，而四色定理已在1976年由凯尼斯·阿佩尔和沃夫冈·哈肯用电脑证明，而从来没有由人力来验证过。 主要学科： 几何学 概念：几何学是数学的一个基础分支，主要研究形状、大小、图形的相对位置等空间区域关系以及空间形式的度量。分类: （1）平面几何：欧几里得几何指按照欧几里得的《几何原本》构造的几何学。平面几何指欧几里得几何中二维平面上的几何； （2）立体几何：三维欧几里得空间的几何的传统名称。实践上这大致上就是我们生活的空间。 （3）非欧几何：广义上泛指一切和欧几里得几何不同的几何学,狭义上（通常意义）只是指罗氏几何或黎曼几何； （4）解析几何：又称坐标几何或卡氏几何，是一种借助于解析式进行图形研究的几何学分支。解析几何通常使用二维的平面直角坐标系研究直线、圆、圆锥曲线、摆线、星形线等各种一般平面曲线，使用三维的空间直角坐标系来研究平面、球等各种一般空间曲面，同时研究它们的方程，并定义一些图形的概念和参数； （5）射影几何：研究在射影变换下不变的几何性质。与初等几何不同，射影几何有不同的设定、射影空间及一套基本几何概念； （6）仿射几何：在几何上，仿射几何是不涉及任何原点、长度或者角度概念的几何，但是有两点相减得到一个向量的概念。它位于欧氏几何和射影几何之间。它是在域K上任意维仿射空间的几何。K为实数域的情况所包含的内容足够使人了解其大部分思想; （7）代数几何：是数学的一个分支，经典代数几何研究多项式方程的零点。现代代数几何将抽象代数，尤其是交换代数，同几何学的语言和问题结合起来。代数几何的基本研究对象为代数簇。代数簇是由空间坐标的若干代数方程的零点集。常见的例子有平面代数曲线，比如直线、圆、椭圆、抛物线、双曲线、三次曲线（非奇异情形称作椭圆曲线）、四次曲线（如双纽线，以及卵形线）、以及一般n次曲线。代数几何的基本问题涉及对代数簇的分类，比如考虑在双有理等价意义下的分类，即双有理几何，以及模空间问题，等等。代数几何在现代数学占中心地位，与多复变函数论、微分几何、拓扑学和数论等不同领域均有交叉。始于对代数方程组的研究，代数几何延续解方程未竟之事；与其求出方程实在的解，代数几何尝试理解方程组的解的几何性质。代数几何的概念和技巧都催生了某些最深奥的数学的分支； （8）微分几何：微分几何研究微分流形的几何性质，是现代数学中一主流；是广义相对论的基础，与拓扑学、代数几何及理论物理关系密切。微分几何分支包括： - 黎曼几何：黎曼几何以黎曼流形为主要研究对象— 有额外结构的光滑流形，他们因此无穷小得看起来像欧几里得空间。这使得欧几里得几何的诸如函数的梯度，散度，曲线的长度等概念得到了推广；而无须假设空间整体上有这么对称； - 复几何：研究的对象是复流形。这是一类有着可积的近复结构的微分流形。因为非奇异的复代数簇自然的是复流形，因此与复代数几何有着紧密的联系； - 辛几何：这是研究辛流形的学科。一个辛流形是带有辛形式（也就是，一个闭的非退化2-形式）的微分流形； - 切触几何：这是辛几何在奇数维上的对应物； - 芬斯勒几何：芬斯勒几何以芬斯勒流形为主要研究对象— 这是一个有芬斯勒度量的微分流形，也就是切空间被赋予了巴拿赫范数。芬斯勒度量是比黎曼度量一般得多的结构； （9）计算几何：主要研究解决几何问题的算法； （10）拓扑学：是一门研究拓扑空间的学科，主要研究空间内，在连续变化（如拉伸或弯曲，但不包括撕开或黏合）下维持不变的性质。拓扑学是由几何学与集合论里发展出来的学科，研究空间、维度与变换等概念。拓扑学分支： - 一般拓扑学：建立拓扑的基础，并研究拓扑空间的性质，以及与拓扑空间相关的概念。一般拓扑学亦被称为点集拓扑学，被用于其他数学领域（如紧致性与连通性等主题）之中； - 代数拓扑学：运用同调与同伦群等代数结构量测连通性的程度； - 微分拓扑学：研究在微分流形上的可微函数，与微分几何密切相关，并一齐组成微分流形的几何理论； - 几何拓扑学：主要研究流形与其对其他流形的嵌入。几何拓扑学中一个特别活跃的领域为“低维拓扑学”，研究四维以下的流形。几何拓扑学亦包括“纽结理论”，研究数学上的纽结； （11）分形几何：又称碎形、残形，通常被定义为“一个粗糙或零碎的几何形状，可以分成数个部分，且每一部分都（至少近似地）是整体缩小后的形状”，即具有自相似的性质。 分形在数学中是一种抽象的物体，用于描述自然界中存在的事物，分形依据其自相似来分类： - 精确自相似：这是最强的一种自相似，分形在任一尺度下都显得一样。由迭代函数系统定义出的分形通常会展现出精确自相似来； - 半自相似：这是一种较松的自相似，分形在不同尺度下会显得大略（但非精确）相同。半自相似分形包含有整个分形扭曲及退化形式的缩小尺寸。由递推关系式定义出的分形通常会是半自相似，但不会是精确自相似； - 统计自相似：这是最弱的一种自相似，这种分形在不同尺度下都能保有固定的数值或统计测度。大多数对“分形”合理的定义自然会导致某一类型的统计自相似（分形维数本身即是个在不同尺度下都保持固定的数值测度）。随机分形是统计自相似，但非精确及半自相似的分形的一个例子； （12）三角学：三角学是数学的一个分支，主要研究三角形，以及三角形中边与角之间的关系； 2.1.2.4 变化（分析） 了解及描述变化在自然科学里是一普遍的议题，而微积分更为研究变化的有利工具。函数诞生于此，做为描述一变化的量的核心概念。对于实数及实变函数的严格研究为实分析，而复分析则为复数的等价领域。黎曼猜想－数学最基本的未决问题之一－便是以复分析来描述的。泛函分析注重在函数的（一般为无限维）空间上。泛函分析的众多应用之一为量子力学。许多的问题很自然地会导出一个量与其变化率之间的关系，而这在微分方程中被研究。在自然界中的许多现象可以被动力系统所描述；混沌理论则是对系统的既不可预测而又是决定的行为作明确的描述。 主要学科： 数学分析 概念：区别于其他非数学类学生的高等数学内容，是分析学中最古老、最基本的分支，一般指以微积分学、无穷级数和解析函数等的一般理论为主要内容，并包括它们的理论基础（实数、函数、测度和极限的基本理论）的一个较为完整的数学学科。它也是大学数学专业的一门基础课程。数学分析研究的内容包括实数、复数、实函数及复变函数。数学分析是由微积分演进而来，在微积分发展至现代阶段中，从应用中的方法总结升华为一类综合性分析方法，且初等微积分中也包括许多数学分析的基础概念及技巧，可以认为这些应用方法是高等微积分生成的前提。数学分析的方式和其几何有关，不过只要任一数学空间有定义邻域（拓扑空间）或是有针对两物件距离的定义（度量空间），就可以用数学分析的方式进行分析；分类: （1）实分析：是处理实数及实函数的数学分析。专门实数函数及数列的解析特性，包括实数数列的极限，实函数的微分及积分、连续性，光滑性以及其他相关性质。实分析常以基础集合论，函数概念定义等等开始； （2）复分析：是对从复平面到复平面的复数可微函数的研究，和复数的解析函数（或亚纯函数）有密切的关系。可以应用在许多不同的数学领域中，包括代数几何、数论、应用数学等，也广为应用在物理领域中，例如流体力学、热力学、机械工程、电机工程及量子场论； （3）泛函分析：是现代数学分析的一个分支，隶属于分析学，其研究的主要对象是函数构成的函数空间。泛函分析历史根源是由对函数空间的研究和对函数的变换（如傅立叶变换等）的性质的研究。这种观点被证明是对微分方程和积分方程的研究中特别有用； （4）傅里叶分析：是数学的一个分支领域。它研究如何将一个函数或者信号表达为基本波形的叠加。它研究并扩展傅里叶级数和傅里叶变换的概念。基本波形称为调和函数，调和分析因此得名。在过去两个世纪中，它已成为一个广泛的主题，并在诸多领域得到广泛应用，如信号处理、量子力学、神经科学等； （5）微分方程：是一种数学方程，用来描述某一类函数与其导数之间的关系。微分方程的解是一个符合方程的函数。只有少数简单的微分方程可以求得解析解。在无法求得解析解时，可以利用数值分析的方式，利用电脑来找到其数值解； （6）数值分析：是研究数学分析中相关问题（和离散数学不同）中有关数值近似（和符号运算不同）算法的研究。许多问题的解析解是很难求得的，数值分析不在意解析解，比较著重在可接受的误差范围内找到近似解； （7）凸分析：是有关凸集合及凸函数的研究; （8）随机分析：是针对随机过程进行的解析式方法； （9）可计算性分析：研究可以用可计算性理论进行的分析； （10）几何分析：将几何方法用来研究偏微分方程及将偏微分方程理论应用在几何学上； 向量分析（或向量微积分） 概念：是数学的分支，关注向量场的微分和积分，主要在3维欧几里得空间中。“向量分析”有时用作多元微积分的代名词，其中包括向量分析，以及偏微分和多重积分等更广泛的问题。向量分析在微分几何与偏微分方程的研究中起着重要作用。它被广泛应用于物理和工程中，特别是在描述电磁场、引力场和流体流动的时候。 动力系统 概念：是关于非线性系统在一定参数条件下展现分岔、周期运动与非周期运动相互纠缠，以至于通向某种非周期有序运动的理论。在耗散系统和保守系统中，混沌运动有不同表现，前者有吸引子，后者无（也称含混吸引子）。 混沌理论 概念：动力系统是一种固定的规则，它描述一个给定空间（如某个物理系统的状态空间）中所有点随时间的变化情况。例如描述钟摆晃动、管道中水的流动，或者湖中每年春季鱼类的数量，凡此等等的数学模型都是动力系统。 2.1.3 离散数学2.1.3.1 概念离散数学：是数学的几个分支的总称，研究基于离散空间而不是连续的数学结构。与连续变化的实数不同，离散数学的研究对象——例如整数、图和数学逻辑中的命题——不是连续变化的，而是拥有不等、分立的值。因此离散数学不包含微积分和分析等“连续数学”的内容。离散对象经常可以用整数来枚举。更一般地，离散数学被视为处理可数集合（与整数子集基数相同的集合，包括有理数集但不包括实数集）的数学分支。但是，“离散数学”不存在准确且普遍认可的定义。实际上，离散数学经常被定义为不包含连续变化量及相关概念的数学，甚少被定义为包含什么内容的数学。虽然离散数学的主要研究对象是离散对象，但是连续数学的分析方法往往也可以采用。数论就是离散和连续数学的交叉学科。同样的，有限拓扑（对有限拓扑空间的研究）从字面上可看作离散化和拓扑的交集。 2.1.3.2 包含主题 数理逻辑 概念：逻辑是对有效推理和推理原则，及其连续性、合理性和完整性的研究； 集合论 概念：集合论是研究集合的数学分支。集合是指一定对象的总和，例如：{蓝色，白色，红色}是一个有限集合；所有素数组成一个无限集合。 偏序关系和拥有其他关系特征的集合在多个数学领域都有应用； 信息论 概念：信息论涉及信息量化。与此密切相关的编码理论则用来设计高效可靠的数据传输和数据储存方法； 数论 概念：数论关注普通数字，特别是整数的特性。数论在密码学和密码分析中有应用，特别是关于素数和素性测试方面。在解析数论中，也使用连续数学的理论； 组合数学 概念：组合数学研究对象进行排列或组合的途径，包含组合设计、计数组合、计数、组合几何、组合拓扑等主题。图论是组合数学的重要部分，有很多实际应用。在组合分析和代数图论中也使用连续数学的理论，而且代数图论还与群论有着紧密联系； 图论 概念：图论是研究图和网络的数学分支，常被认为包含于组合数学中，但这一分支已经发展得足够庞大和有特点，并有自身领域所研究的问题，因此被视为一个独立的主题，在数学和科学的所有领域都有广泛的应用。例如：有名的七桥问题； 抽象代数 概念：代数结构既可以是离散的，也可以是连续的。离散代数包括逻辑门和编程中使用的逻辑代数、数据库中使用的关系代数、代数编码理论中重要的离散有限群、环和域、形式语言理论中的离散半群和幺半群； 理论计算机科学 概念：离散数学充分描述了计算机科学离散性的特点。理论计算机科学（Theoretical computer science）包含离散数学计算的领域，并特别注重图论和数理逻辑。理论计算机科学包括对计算数学结果的算法研究。可算性理论研究那些对象在原则上可被计算，和逻辑有密切联系。而复杂性则研究计算耗费的时间，自动机理论和形式语言理论与复杂性紧密联系。计算几何应用算法解决几何问题，而计算机图像分析则是应用算法在计算机中再现图像； 拓扑学 概念：虽然拓扑学是形式化和一般化物体“连续形变”的直觉概念的研究领域，其也包含很多离散主题，如拓扑变换时常取离散值，组合拓扑、拓扑图论、拓扑组合、计算拓扑、离散空间、有限拓扑空间等领域； 运筹学 概念：是一门应用数学学科，利用统计学和数学模型等方法，去寻找复杂问题中的最佳或近似最佳的解答。运筹学经常用于解决现实生活中的复杂问题，特别是改善或优化现有系统的效率。研究运筹学的基础知识包括矩阵论和离散数学；分支:（1）数学规划- 线性规划：特指目标函数和约束条件皆为线性的最优化问题；- 非线性规划：是求解由一系列未知实函数组成的组方程和不等式（统称为约束）定义的最优化问题，伴随着一个要被最大化或最小化的目标函数，只是一些约束或目标函数是非线性的。它是最优化处理非线性问题的一个子领域。- 整数规划：是指规划中的变量（全部或部分）限制为整数；- 目标规划- 动态规划：通过把原问题分解为相对简单的子问题的方式求解复杂问题的方法。动态规划常常适用于有重叠子问题[1]和最优子结构性质的问题，动态规划方法所耗时间往往远少于朴素解法；- 参数规划：参数规划是研究线性规划问题的最优解在一个或几个数据发生规定的连续性变化时所受影响的一种优化后分析方法；- 组合最优化- 随机规划：研究约束条件中的系数和目标函数中的参数均为随机变量时的线性规划问题；（2）图论（3）最优化（4）博弈论（5）决策论（6）搜索论（7）统筹论（8）排队论（9）存贮论 博弈论 概念：用于处理的问题比较复杂，通常这些选择成功与否取决于其他人的选择，因此如何作最好出一个最好的选择比较复杂。连续对策甚至也是存在的，如微分博弈。博弈论的主题包括拍卖理论和公平分配博弈； 决策论 概念：是有关判定特定决策的价值、不确定性、合理性以及最终能够确定的最优决策的理论； 效用理论 概念：研究内容是由各种商品和服务评估相对经济满足程度，或是评估各种商品和服务的希求程度； 离散化 概念：离散化关注将连续模型或等式转化为离散形式的过程，通常是基于简化计算的目的。数值分析是离散化一个重要实例； 连续数学的离散近似 概念：很多的连续数学概念都有离散数学的版本，例如:离散微积分、离散概率分布、离散傅里叶变换、离散几何、离散对数、离散微分几何、离散外微分、离散莫尔斯理论、差分方程、离散动力系统； 离散和连续混合数学 概念：时标微积分是差分方程理论与微分方程理论的统一，应用在需要创建离散和连续同步数据模型的领域； 2.1.4 应用数学2.1.4.1 概念应用数学：是以应用为目的的明确的数学理论和方法的总称，研究如何应用数学知识到其他范畴（尤其是科学）的数学分支，可以说是纯数学的相反，应用纯数学中的结论扩展到物理学等其他科学中，应用数学的发展是以科学为依据，作为科学研究的后盾。大部分应用数学是以作为物理分析的工具。计算数学有时也可视为应用数学的一部分。应用数学大部分的教学范畴都是以物理的模型为基础进行分析，当中或许搭配了各种数学工具，就为了更贴近物理的系统。图论应用在网络分析，拓扑学应用在电路分析，群论应用在结晶学，微分几何应用在规范场，自动控制理论应用在计算，黎曼几何应用于相对论，数理逻辑应用于计算机，最小二乘法应用于飞机起降时自动控制，利用数字合成计算机辅助的X射线断层成像技术（1979年数学家获得诺贝尔医学奖）数论应用在密码学，博弈论、概率论、统计学应用在经济学，线性规划用于生产安排调度，都可见数学在不同范畴的应用。 2.1.4.2 包含学科主要包含：线性代数、矩阵理论、向量分析、复变分析、微分方程、拉普拉斯变换、傅里叶分析、数值分析、概率论、随机过程、数理统计、运筹学、博弈论、控制理论、组合数学、信息论等许多数学分支，也包括从各种应用领域中提出的数学问题的研究。 2.2 国家标准数学分类 数学分支（国家标准学科代码） 2.3 子领域链接 学科 学科 学科 分析学 代数学 几何学与拓扑学 概率论 统计学 运筹学 数学历史 - - 3. 学习路线3.1 学习地图数学自学线路图 数学自学课程内容安排 3.2 学习顺序参考 给基础数学本科新生的选课建议 美国大学数学研究生基础课程参考书目 USTC基础数学修课指南 do$\&nbsp$Carmo书籍的学习顺序 从《曲线与曲面的微分几何》开始学起，这本书里的很多内容都直接对应着他的《黎曼几何》，平稳地过渡，其实不会觉得特别难。中间最好穿插着读一读他的《微分形式及其应用》。因为，《黎曼几何》的课后习题需要微分形式和积分相关的知识。 解析数论入门书籍及学习顺序 第一阶段（打基础）：华罗庚《数论导引》，哈代《An Introduction to the Theory of Numbers》；第二阶段（入门）：卡拉楚巴《Basic Analytic Number Theory》，apostol《Introduction to Analytic Number Theory》;第三阶段（深入）：lwaniec《Analytic Number Theory》，Montgomery《Multiplicative Number Theory I：Classical Theory》；$Tips$：学习解析数论需要傅里叶分析和复分析以及初等数论的知识作为铺垫； 抽象代数的前置课程 线性代数+初等数论1、掌握一点点初等数论再去学抽象代数的话能让你感受到语言转换的过程（抽象代数很大程度上就是干这个）。比如费马小定理，用群论就一句话；2、从直接相关的角度讲可能初等数论还要紧一点——交换群、域这两者很多例子大概都是比较容易从初等数论里找，费交换群、非交换环还有一些例子来自线性代数和矩阵，还有些算是组合数学/离散数学； 抽象代数、交换代数、同调代数、群表示论、李代数、代数拓扑的学习顺序应该是怎样的？ 参考一：抽象代数之后，接下来首先应当学习范畴论，以求从一个更高的观点去统一其它你想涉猎的分支。学范畴论不要硬学干学，而要带着明确目的、在广泛应用范畴论思维的场景里，自然而然地学。在我看来最佳环境就是代数拓扑。不必沉迷经典的代数拓扑；最好是透过几个特定场景里的同伦论，迅速积攒同伦直觉，然后进军抽象同伦论。在抽象同伦论的世界里，同调代数只是拓扑空间理论的阿贝尔化，研究的不过是阿贝尔范畴——主要是模范畴——里面的单纯对象（链复形）。看起来高大上的导出范畴和导出函子理论不过是范畴的局部化和Kan扩张。抽象同伦论的一大方向是谱代数（旧称brave new algebra）。谱代数的观点下，交换代数和李代数基本上是一个东西，研究的都是operad的代数和模，区别不过是commutative operad和Lie operad。看待群表示论的观点有好些，比方说脚踏实地看作群代数的模理论，然后用交换代数的工具处理；或者往高观点走看作群到范畴的一个函子。然后也许就不惊讶于幺半群的表示——实际上就是不限于可逆矩阵/变换；也不惊讶于范畴的表示——实际上就是放弃可复合性，就是不限方矩阵/变换的维数。在（高阶）范畴论和抽象同伦论的高岗上，从它们所提供的「大一统」式的视角，去俯瞰其它的代数分支，让你能够大致明白这些分支研究的代数对象分别是什么。如果抽象同伦论不足以完全吸引和满足你，自然可以进入任何一个你感兴趣的分支细细品味。它们之中的每个都是一个广袤的世界，而在其中无止境的细化则注定会使得抽象废话无用武之地。但这不代表这些抽象废话失去意义；恰恰相反，抽象废话帮你封装了普遍存在的繁琐细节，替你剥去了形式的外衣，剩下的必然是这个分支的独特的动人之处。从抽象废话失效的地方出发，往往能够迅速了解到这个分支独有的最深刻的思想。评论里看到你对数论感兴趣；如果你为代数几何在数论里的应用而感到惊奇，大概更应该学习抽象同伦，感受一下处在抽象最前沿的同伦思想，在最经典传统的数学分支里到底能够激起怎样的火花。反正哪怕是对数论一无所知的我，看到明年Arizona Winter School的主题时，确实是精神为之一振的。参考二：交换代数，同调代数，群表示论，李代数，代数拓扑 这几门课在学完抽代后可以同时学。可以同时学不是说一定要同时学，而是说他们不存在知识上的依赖关系，怎么学都行。群表示论，李代数本质都是线性代数的延伸；所以你会再次看到矩阵、特征值这些东西。本科的代数拓扑倒是用不到太多代数，也就万有系数定理那里用了一下Ext, Tor这两个函子，牵扯到一点同调代数。其余的大部分内容，知道群足够。 想自学数学，在教程顺序上有什么推荐？ 应该按照怎样的顺序来自学英文版本科及研究生数学书籍? 清华大学数学科学系：数学与应用数学专业、信息与计算科学专业本科培养方案 北京大学数学科学学院本科生教学手册 4. 学习参考4.1 学习方法指导$Tips:$ 掌握一个领域的历史发展脉络对于理解这个领域和把握领域发展方向是非常有帮助的； 不管经典与否，适合自己的才是最好的； 学习数学，主要学习其思想； 注意区分好古典与现代的理论，虽然思想不分时界，但是在易读性和实用性上有时会有很大差别； 书籍的学习建议由浅入深，不要觉得浅的内容太简单或者太高估自己直接学习进阶性的书籍，那样不但不能体会该领域的美妙和思想，反而会越学越痛苦； 针对同一子领域，可以买几本经典书籍，以其中一本为主线，相互对照着看，这样一方面可以从不同角度学习，另一方面避免了某本书的某个知识点看不懂就卡住了； 看完书做题也是非常关键的一环； 数学书籍按作用可分为科普读物、课程教材、子领域专业材料、数学历史书、人物传记； 该如何学习数学 大学教育一般都是放羊，导致很多人学习数学的时候不知道究竟该怎么学，尤其是教材学不懂的时候，没人告诉你该怎么办。这个时候我就要讲一句了：当你完全学不懂手上的这本教材的时候，说明你应该换一本低阶/简单的教材。当你完全学不懂手上的这本教材的时候，说明你应该换一本低阶/简单的教材。当你完全学不懂手上的这本教材的时候，说明你应该换一本低阶/简单的教材。很多人就是太老实，觉得参考教材是这个，我就要死磕，看不懂就是自己傻逼。这个时候就要参考一下美国的课程设计了。美国一般来说都是先上微积分，再有数学分析，然后还有honor的实分析（其实还是数分），甚至会开更多这种表面上区别真的不大的课程。为什么要这么做，讲道理按照国内直接给数学系开一门数学分析不就好了？因为每个人对知识的掌握程度不同，一刀切最可能的结果就是好学生觉得水，一般学生觉得难，直接就把人都劝退了。参考教材同理，美国这边各种数学教材和note这么多，不管他们是为了恰饭还是自己上课方便，客观上来说确实提供了很多种不同的选择。学数学就和爬楼梯一样，别看一步一步迈好像很慢，你强行一步跨八个楼梯，不难受才是见了鬼了。有些教材就是给最基础的初学者设计的（往往要求的先修课程非常少），有些教材是给一般基础的人设计的（需要一些了解），有些教材是给已经学过了的人总结设计的（这种书第一遍读会觉得自己宛如弱智），区分这三种书籍并选择适合自己的书非常重要。何况还有一个很关键的问题是taste，同样的一门课，偏分析和偏代数的人写出来的教材读起来绝对是两个世界。有些人写书喜欢直观（这种人的书读起来往往非常舒服），有些人写书非常严谨（虽然第一遍读起来会很累，但当你要真正掌握这门学科的时候，你必须要过这种硬功夫）。对不同taste的人来说，读这两种书的感受也会完全不同。最后总结一下，不要和一本教材死磕，你可能听很多人说“xx书就是这个方向的经典，读不会你怎么做这个方向”，然后发现自己读不懂这本书，开始怀疑自己。但你只知道他们发表了这样的言论，却不知道他们这么说的时候他们所处的知识背景。这么描述的书非常有可能是我之前所提到的第三类总结型的教材，直接上来读只会给自己带来无限的挫折感。（当然不排除确实有些人可以直接读这种教材，但一般情况下这些人往往已经打下了扎实的基础，直接或间接学习了很多和这门课有关的知识）当你先用一两本简单的教材学习了这门课之后，再回头去看所谓的经典教材，往往此时经典教材已经是你能稍费力气读懂的书了。 知乎大佬数学学习心得与讲解子各领域关系 原链接不要为了那些所谓高大上的名词而去学习数学，就像现在有很多人“过早”地去接触代数几何，学习GTM52，但是学了之后却不会算任何一个具体的例子。我觉得本科期间还是尽早确定自己喜欢的方向比较好，不要听别人告诉你的每个数学领域都要去学习，这样选择面广。很多时候当人去寻求中庸时，他往往会变得平庸。另外还要尽早看英文教材，我是仅仅看过一本国内翻译过来的线性代数教材，然后没看过一本国内编写的教材，都是看英文原版的了。大一要学数学分析跟线性代数，不要过分地去刷题，因为没意义，为什么？比如你数学分析学黎曼积分的时候，后面学实分析，它会告诉你黎曼积分是被淘汰了的(黎曼积分反常积分那一块不一样，它比勒贝格积分更普遍。)，Godement在他的Analysis II上面说了，教导黎曼积分只是为了满足教学需求。为了更快适应后面分析学的语言，建议尽早看点集拓扑，有了这方面的知识一些证明是非常简单的。比如证明一致收敛跟积分符号可以交换的命题时，把所有定义在[a,b]上的连续函数看做一个空间，范数用两个函数差的最大绝对值，那么它便是Banach空间，积分是一个定义在这个空间上的连续函数(事实上它是一个有界线性算子)，因此lim ∫ 等于 ∫ lim，这个就是Amann在他写的Analysis II里面的解答，跟国内教材比起来不知道简洁多少倍。然后线性代数不要沉迷于矩阵技巧，因为矩阵并不是线性代数的本质，它的本质是向量空间跟线性变换，你甚至完全可以从抽象代数角度去看线性代数，因为向量空间只是一个特殊的模而已。我建议你第一次先快速学完线性代数，然后看抽象代数，接着再看一遍线性代数，第二遍的线性代数其实是模理论了，主要是在主理想环上的模，可以看看Jacobson的抽象代数讲义II。对于抽象代数来说，我认为后者的内容跟风格会比我们国内用矩阵来贯穿线性代数更加本质。另外，泛函其实也不是什么很高大上的学科，你学完点集拓扑跟线性代数之后就可以看了。我们线性代数主要集中于有限维度向量空间，而泛函集中于无穷维度向量空间。有限维度跟无穷维度下空间差异明显，比如对任何有限维度空间，它的对偶空间(里面的元素叫泛函）的维度跟原空间相等，而无穷维度时会更大，紧接着泛函的专业领域是算子代数，这其实讲白了更像是高阶的线性代数，只是涉及更多的抽象代数知识。至于你说的复分析，我估计你是对复分析感兴趣了。复分析的学习要结合其他学科，而不要仅仅着眼于这个学科，事实上复分析启发了后来非常多的学科，比如解析数论，微分几何等。复分析更为深入的学习我觉得可以看看黎曼曲面，黎曼曲面是最简单的一种复流形，对它尤其是紧黎曼曲面，我们已经有了较为完备的理论了。其实，黎曼曲面跟很多几何学的联系是非常深入的，或者说主要是Riemann-Roch定理。至于留数计算之类的技巧内容我个人觉得是不适合过分深入的，因为这方面的东西本身跟后续内容无太大关系。然后如果要深入代数学习的话，你可以选择交换代数，同调代数跟表示论，其中表示论其实也适合学完线性代数并且有了抽象代数功底之后看。交换代数跟代数数论、代数几何联系紧密，它的起源跟Hilbert有密切联系。可以把交换代数看成是抽象的数论，假如不从几何观点出发的化，不过其实交换代数的几何背景很深，至少高斯证明的代数基本定理便可以归到交换代数跟几何的联系里面去，之后的Hilbert零点定理是对代数基本定理的抽象，更是联系起了代数跟几何，算是在学习代数几何过程中第一个非常重要的定理。至于同调代数则是跟代数拓扑有关系。代数拓扑跟点集拓扑没有太大关系，我们生活中听到的什么咖啡杯跟甜甜圈一样之类的话其实都来自代数拓扑，这个学科主要研究同伦跟同调两个概念。简单的说如果一个函数可以连续变化成另一个函数，那么这两个函数同伦。同调更多地是想研究空间中的“洞”，比如地上出现了一个洞，那我们就只能绕道走了，但也有时候你没法绕道。最开始推动代数拓扑发展的是Green定理，为了处理线积分跟曲面积分的问题。同时再展开也就有了德拉姆上同调(de Rham cohomology)的概念，这是关于微分形式的理论，微分形式一般用在流形里面，主要是为了代替平时的微分概念，来完成在流形上面的积分。同调代数最初的启发来自代数拓扑，但真正的发展是源于人们发现可以用所谓的resolution来得到相应模的信息，就是从这个模延伸出来的一组具有特殊性质的模来得到原本模的信息。然后再提醒你一点不要过分地去寻求技巧，比如数学分析我们国内跟俄罗斯那边的教材都讲了含参变量的积分，但是欧美的教材里面是不讲的(Rudin跟Amann的就没讲)，但是别人可以在讲多重积分、线积分的时候讲了微分形式，Amann的书上甚至有Poincare Lamma。就先讲这么多吧，其实还有很多内容是需要学习的，不过具体的选择要看你个人兴趣，比如我个人就对微分方程之类的无感，但事实上国内用偏微分方程来研究微分几何问题是非常热门的。具体的书籍需要你自己去寻找了，我就不推荐了，要记住的是适合别人的书不一定就适合自己，比如代数拓扑用Hatcher的书是标配，但我就不喜欢他的书。 数学的修习并非线性 不是从三级坦克出发，修满四级坦克，才可以升级五级。有的时候是四级修满一半，再继续修习五级的过程中，忽然发现对三级四级的事情有了不一样的体悟。 如果想对某一分支拥有深刻的见解，对其发展结构有充分的认识，想知道她到底讲了一个什么样的故事，那么仅仅拘泥于这一个分支还是远远不够的。就交换代数来说，很多概念比较抽象，但如果学了代数几何以后，就会发现那些抽象的概念都哗啦哗啦鲜活多彩起来了。例如实分析对于拓扑，线性代数对于量子力学，黎曼几何对于广义相对理论…. 在数学系读书的感受如何 5. 学习资料5.1 书籍 GTM系列 ❌|$_{001}$《Introduction to Axiomatic Set Theory》Gaisi Takeuti, Wilson M. Zaring (1982, 2nd ed.)❌|$_{002}$《Measure and Category - A Survey of the Analogies between Topological and Measure Spaces》John C. Oxtoby (1980, 2nd ed.)❌|$_{003}$《Topological Vector Spaces》H. H. Schaefer, M. P. Wolff (1999, 2nd ed.)❌|$_{004}$《A Course in Homological Algebra》Peter Hilton, Urs Stammbach (1997, 2nd ed.)✔️|$_{005}$《数学工作者必知的范畴学》Saunders Mac Lane (1998, 2nd ed.)❌|$_{006}$《Projective Planes》Daniel R. Hughes, Fred C. Piper, (1982)✔️|$_{007}$《算术教程》Jean-Pierre Serre (1996)❌|$_{008}$《Axiomatic Set Theory》Gaisi Takeuti, Wilson M. Zaring, (1973)✔️|$_{009}$《李代数和表示论导论》James E. Humphreys (1997)❌|$_{010}$《A Course in Simple-Homotopy Theory》Marshall. M. Cohen, (1973)❌|$_{011}$《Functions of One Complex Variable I》John B. Conway (1978, 2nd ed.)❌|$_{012}$《Advanced Mathematical Analysis》Richard Beals (1973)❌|$_{013}$《Rings and Categories of Modules》Frank W. Anderson, Kent R. Fuller (1992, 2nd ed.)❌|$_{014}$《Stable Mappings and Their Singularities》Martin Golubitsky, Victor Guillemin, (1974)❌|$_{015}$《Lectures in Functional Analysis and Operator Theory》Sterling K. Berberian, (1974)❌|$_{016}$《The Structure of Fields》David J. Winter, (1974)❌|$_{017}$《Random Processes》Murray Rosenblatt, (1974)✔️|$_{018}$《测度论》Paul R. Halmos (1974)❌|$_{019}$《A Hilbert Space Problem Book》Paul R. Halmos (1982, 2nd ed.)❌|$_{020}$《Fibre Bundles》Dale Husemoller (1994, 3rd ed.)❌|$_{021}$《Linear Algebraic Groups》James E. Humphreys (1998)❌|$_{022}$《An Algebraic Introduction to Mathematical Logic》Donald W. Barnes, John M. Mack (1975)❌|$_{023}$《Linear Algebra》Werner H. Greub (1981)❌|$_{024}$《Geometric Functional Analysis and Its Applications》Richard B. Holmes, (1975)❌|$_{025}$《Real and Abstract Analysis》Edwin Hewitt, Karl Stromberg (1975)❌|$_{026}$《Algebraic Theories》Ernest G. Manes, (1976)✔️|$_{027}$《普通拓扑学》John L. Kelley (1975)✔️|$_{028}$《交换代数 第1卷》Oscar Zariski, Pierre Samuel (1975)（已有英文原版）✔️|$_{029}$《交换代数 第2jaunty》Oscar Zariski, Pierre Samuel (1975)（已有英文原版）✔️|$_{030}$《抽象代数讲义 第1卷》Nathan Jacobson (1976)（已有英文原版第二版）✔️|$_{031}$《抽象代数讲义 第2卷》Nathan Jacobson (1984)（已有英文原版第二版）✔️|$_{032}$《抽象代数讲义 第3卷》Nathan Jacobson (1976)（已有英文原版第二版）❌|$_{033}$《Differential Topology》Morris W. Hirsch (1976)❌|$_{034}$《Principles of Random Walk》Frank Spitzer (2001)❌|$_{035}$《Several Complex Variables and Banach Algebras》Herbert Alexander, John Wermer (1998, 3rd ed.)❌|$_{036}$《Linear Topological Spaces》John L. Kelley, Isaac Namioka (1982)❌|$_{037}$《Mathematical Logic》J. Donald Monk (1976)❌|$_{038}$《Several Complex Variables》H. Grauert, K. Fritzsche (1976)❌|$_{039}$《An Invitation to ${\displaystyle C^{*}}$-Algebras》William Arveson (1976)❌|$_{040}$《Denumerable Markov Chains》John G. Kemeny, J. Laurie Snell, Anthony W. Knapp, D.S. Griffeath (1976)❌|$_{041}$《Modular Functions and Dirichlet Series in Number Theory》Tom M. Apostol (1989, 2nd ed.)✔️|$_{042}$《有限群的线性表示》Jean-Pierre Serre, Leonhard L. Scott (1977)❌|$_{043}$《Rings of Continuous Functions》Leonard Gillman, Meyer Jerison (1976)❌|$_{044}$《Elementary Algebraic Geometry》Keith Kendig (1977)✔️|$_{045}$《概率论 第1卷》M. Loève (1977, 4th ed)✔️|$_{046}$《概率论 第2卷》M. Loève (1978, 4th ed)❌|$_{047}$《Geometric Topology in Dimensions 2 and 3》Edwin E. Moise (1977)❌|$_{048}$《General Relativity for Mathematicians》R. K. Sachs, H. Wu (1983)❌|$_{049}$《Linear Geometry》K. W. Gruenberg, A. J. Weir (2010)❌|$_{050}$《Fermat’s Last Theorem: A Genetic Introduction to Algebraic Number Theory》Harold M. Edwards (2000)❌|$_{051}$《A Course in Differential Geometry》William Klingenberg, D. Hoffman (1983)✔️|$_{052}$《代数几何》Robin Hartshorne (2010)✔️|$_{053}$《数学家用的数理逻辑教程》Yu. I. Manin, Boris Zilber (2009, 2nd ed.)❌|$_{054}$《Combinatorics with Emphasis on the Theory of Graphs》Mark E. Watkins, Jack E. Graver (1977)❌|$_{055}$《Introduction to Operator Theory I: Elements of Functional Analysis》Arlen Brown, Carl Pearcy (1977)✔️|$_{056}$《代数拓扑导论》William S. Massey (1977)❌|$_{057}$《Introduction to Knot Theory》Richard H. Crowell, Ralph H. Fox (1977)❌|$_{058}$《p-adic Numbers p-adic Analysis, and Zeta-Functions》 Neal Koblitz (1984, 2nd ed.)❌|$_{059}$《Cyclotomic Fields》Serge Lang (1978)✔️|$_{060}$《经典力学的数学方法》V. I. Arnold, A. Weinstein, K. Vogtmann (1989, 2nd ed.)❌|$_{061}$《Elements of Homotopy Theory》George W. Whitehead (1978)❌|$_{062}$《Fundamentals of the Theory of Groups》M. I. Kargapolov, J. I. Merzljakov (1979)❌|$_{063}$《Graph Theory - An Introductory Course》Béla Bollobás (1979)❌|$_{064}$《Fourier Series - A Modern Introduction Volume 1》R. E. Edwards (1979, 2nd ed.)❌|$_{065}$《Differential Analysis on Complex Manifolds》Raymond O. Wells, Jr. (2008, 3rd ed.)❌|$_{066}$《Introduction to Affine Group Schemes》W. C. Waterhouse (1979)❌|$_{067}$《Local Fields》Jean-Pierre Serre (1979)❌|$_{068}$《Linear Operators in Hilbert Spaces》Joachim Weidmann [de] (1980)❌|$_{069}$《Cyclotomic Fields II》Serge Lang (1980)❌|$_{070}$《Singular Homology Theory》William S. Massey (1980)❌|$_{071}$《Riemann Surfaces》Herschel Farkas [de], Irwin Kra (1992, 2nd ed.)❌|$_{072}$《Classical Topology and Combinatorial Group Theory》John Stillwell (1980, 2ed 1993)✔️|$_{073}$《代数》Thomas W. Hungerford (1974)❌|$_{074}$《Multiplicative Number Theory》Harold Davenport, Hugh Montgomery (2000, 3rd ed.)❌|$_{075}$《Basic Theory of Algebraic Groups and Lie Algebras》G. P. Hochschild (1981)❌|$_{076}$《Algebraic Geometry - An Introduction to Birational Geometry of Algebraic Varieties》Shigeru Iitaka (1982)❌|$_{077}$《Lectures on the Theory of Algebraic Numbers》E. T. Hecke (1981)❌|$_{078}$《A Course in Universal Algebra》Burris, Stanley and Sankappanavar, H. P. (Online) (1981)❌|$_{079}$《An Introduction to Ergodic Theory》Peter Walters (1982)❌|$_{080}$《A Course in the Theory of Groups》Derek J.S. Robinson [de] (1996, 2nd ed.)❌|$_{081}$《Lectures on Riemann Surfaces》Otto Forster [de] (1981)✔️|$_{082}$《代数拓扑中微分形式》Raoul Bott, Loring W. Tu (1982)✔️|$_{083}$《割圆域导论》Lawrence C. Washington (1997, 2nd ed.)✔️|$_{084}$《现代数论经典引论》Kenneth Ireland, Michael Rosen (1990, 2nd ed.)❌|$_{085}$《Fourier Series - A Modern Introduction Volume 2》R. E. Edwards (1982, 2nd ed.)❌|$_{086}$《Introduction to Coding Theory》J. H. van Lint (3rd ed 1998)❌|$_{087}$《Cohomology of Groups》Kenneth S. Brown (1982)❌|$_{088}$《Associative Algebras》R. S. Pierce (1982)❌|$_{089}$《Introduction to Algebraic and Abelian Functions》Serge Lang (1982, 2nd ed.)❌|$_{090}$《An Introduction to Convex Polytopes》Arne Brondsted (1983)❌|$_{091}$《The Geometry of Discrete Groups》Alan F. Beardon [de] (1983, 2nd print 1995)❌|$_{092}$《Sequences and Series in Banach Spaces》J. Diestel (1984)✔️|$_{093}$《现代几何学方法和应用 第1卷》 B. A. Dubrovin, Anatoly Timofeevich Fomenko, Sergei Novikov (1992, 2nd ed.)❌|$_{094}$《Foundations of Differentiable Manifolds and Lie Groups》Frank W. Warner [de] (1983)❌|$_{095}$《Probability-1》Probability-2, Albert N. Shiryaev (2016, 2019, 3rd ed.)✔️|$_{096}$《泛函分析教程》John B. Conway (2007, 2nd ed.)❌|$_{097}$《Introduction to Elliptic Curves and Modular Forms》Neal I. Koblitz (1993, 2nd ed.)✔️|$_{098}$《紧李群的表示》Theodor Bröcker [de], Tammo tom Dieck (1985)❌|$_{099}$《Finite Reflection Groups》L.C. Grove, C.T. Benson (1985, 2nd ed.)❌|$_{100}$《Harmonic Analysis on Semigroups - Theory of Positive Definite and Related Functions》Christian Berg, Jens Peter Reus Christensen, Paul Ressel (1984)❌|$_{101}$《Galois Theory》Harold M. Edwards (1984)❌|$_{102}$《Lie Groups Lie Algebras, and Their Representations》 V. S. Varadarajan (1984)❌|$_{103}$《Complex Analysis》Serge Lang (1999, 4th ed.)✔️|$_{104}$《现代几何学方法和应用 第2卷》B. A. Dubrovin, Anatoly Timofeevich Fomenko, Sergei Novikov (1985)❌|$_{105}$《SL2(R)》Serge Lang (1985)❌|$_{106}$《The Arithmetic of Elliptic Curves》Joseph H. Silverman (2009, 2nd ed.)❌|$_{107}$《Applications of Lie Groups to Differential Equations》Peter J. Olver (1993, 2nd ed.)❌|$_{108}$《Holomorphic Functions and Integral Representations in Several Complex Variables》R. Michael Range (1986)❌|$_{109}$《Univalent Functions and Teichmüller Spaces》O. Lehto (1987)❌|$_{110}$《Algebraic Number Theory》Serge Lang (1994, 2nd ed.)❌|$_{111}$《Elliptic Curves》Dale Husemöller [de] (2004, 2nd ed.)❌|$_{112}$《Elliptic Functions》Serge Lang (1987, 2nd ed.)❌|$_{113}$《Brownian Motion and Stochastic Calculus》Ioannis Karatzas, Steven Shreve (2ed 2000)❌|$_{114}$《A Course in Number Theory and Cryptography》Neal Koblitz (2ed 1994)❌|$_{115}$《Differential Geometry: Manifolds Curves and Surfaces》 Marcel Berger, Bernard Gostiaux (1988)❌|$_{116}$《Measure and Integral — Volume 1》John L. Kelley, T.P. Srinivasan (1988)❌|$_{117}$《Algebraic Groups and Class Fields》Jean-Pierre Serre (1988)❌|$_{118}$《Analysis Now》Gert K. Pedersen (1989)✔️|$_{119}$《代数拓扑导论》Joseph J. Rotman, (1988)❌|$_{120}$《Weakly Differentiable Functions — Sobolev Spaces and Functions of Bounded Variation》William P. Ziemer (1989)❌|$_{121}$《Cyclotomic Fields I and II》Serge Lang (1990, Combined 2nd ed. ISBN 978-1-4612-6972-4)❌|$_{122}$《Theory of Complex Functions》Reinhold Remmert (1991)❌|$_{123}$《Numbers》Heinz-Dieter Ebbinghaus et al. (1990)✔️|$_{124}$《现代几何学方法和应用 第3卷》B. A. Dubrovin, Anatoly Timofeevich Fomenko, Sergei Novikov (1990)❌|$_{125}$《Complex Variables — An Introduction》Carlos A. Berenstein, Roger Gay (1991)❌|$_{126}$《Linear Algebraic Groups》Armand Borel (1991)❌|$_{127}$《A Basic Course in Algebraic Topology》William S. Massey (1991)❌|$_{128}$《Partial Differential Equations》Jeffrey Rauch (1991)✔️|$_{129}$《表示论基本教程》William Fulton, Joe Harris (1991)❌|$_{130}$《Tensor Geometry — The Geometric Viewpoint and its Uses》Christopher T. J. Dodson, Timothy Poston (1991, 2nd ed.)❌|$_{131}$《A First Course in Noncommutative Rings》T. Y. Lam (2001, 2nd ed.)❌|$_{132}$《Iteration of Rational Functions — Complex Analytic Dynamical Systems》Alan F. Beardon (1991)❌|$_{133}$《Algebraic Geometry》Joe Harris (1992)❌|$_{134}$《Coding and Information Theory》Steven Roman (1992)✔️|$_{135}$《高等线性代数》Steven Roman (2008, 3rd ed.)❌|$_{136}$《Algebra — An Approach via Module Theory》William Adkins, Steven Weintraub (1992)❌|$_{137}$《Harmonic Function Theory》Sheldon Axler, Paul Bourdon, Wade Ramey (2001, 2nd ed.)❌|$_{138}$《A Course in Computational Algebraic Number Theory》Henri Cohen (1996)❌|$_{139}$《Topology and Geometry》Glen E. Bredon (1993)❌|$_{140}$《Optima and Equilibria》Jean-Pierre Aubin (1998)❌|$_{141}$《Gröbner Bases — A Computational Approach to Commutative Algebra》Thomas Becker, Volker Weispfenning (1993)❌|$_{142}$《Real and Functional Analysis》Serge Lang (1993, 3rd ed.)❌|$_{143}$《Measure Theory》J. L. Doob (1994)❌|$_{144}$《Noncommutative Algebra》Benson Farb, R. Keith Dennis (1993)❌|$_{145}$《Homology Theory — An Introduction to Algebraic Topology》James W. Vick (1994, 2nd ed.)❌|$_{146}$《Computability — A Mathematical Sketchbook》Douglas S. Bridges (1994)❌|$_{147}$《Algebraic K-Theory and Its Applications》Jonathan Rosenberg (1994)✔️|$_{148}$《群论导论》Joseph J. Rotman (1995, 4th ed.)❌|$_{149}$《Foundations of Hyperbolic Manifolds》John G. Ratcliffe (2019, 3rd ed.)✔️|$_{150}$《交换代数》David Eisenbud (1995)❌|$_{151}$《Advanced Topics in the Arithmetic of Elliptic Curves》Joseph H. Silverman (1994)❌|$_{152}$《Lectures on Polytopes》Günter M. Ziegler (1995)❌|$_{153}$《Algebraic Topology — A First Course》William Fulton (1995)❌|$_{154}$《An Introduction to Analysis》Arlen Brown, Carl Pearcy (1995)❌|$_{155}$《Quantum Groups》Christian Kassel (1995)❌|$_{156}$《Classical Descriptive Set Theory》Alexander S. Kechris (1995)❌|$_{157}$《Integration and Probability》Paul Malliavin (1995)❌|$_{158}$《Field Theory》Steven Roman (2006, 2nd ed.)✔️|$_{159}$《单复变函数 第2卷》John B. Conway (1995)❌|$_{160}$《Differential and Riemannian Manifolds》Serge Lang (1995)❌|$_{161}$《Polynomials and Polynomial Inequalities》Peter Borwein, Tamas Erdelyi (1995)❌|$_{162}$《Groups and Representations》J. L. Alperin, Rowen B. Bell (1995)❌|$_{163}$《Permutation Groups》John D. Dixon, Brian Mortimer (1996)✔️|$_{164}$《加性数论：经典基》Melvyn B. Nathanson (1996)✔️|$_{165}$《加性数论：逆问题与和集几何》Melvyn B. Nathanson (1996)❌|$_{166}$《Differential Geometry — Cartan’s Generalization of Klein’s Erlangen Program》R. W. Sharpe (1997)✔️|$_{167}$《域和伽罗瓦理论》Patrick Morandi (1996)❌|$_{168}$《Combinatorial Convexity and Algebraic Geometry》Guenter Ewald (1996)❌|$_{169}$《Matrix Analysis》Rajendra Bhatia (1997)❌|$_{170}$《Sheaf Theory》Glen E. Bredon (1997, 2nd ed.)❌|$_{171}$《Riemannian Geometry》Peter Petersen (2016, 3rd ed.)❌|$_{172}$《Classical Topics in Complex Function Theory》Reinhold Remmert (1998)❌|$_{173}$《Graph Theory》Reinhard Diestel [de] (2017, 5th ed.)❌|$_{174}$《Foundations of Real and Abstract Analysis》Douglas S. Bridges (1998)❌|$_{175}$《An Introduction to Knot Theory》W. B. Raymond Lickorish (1997)❌|$_{176}$《Introduction to Riemannian Manifolds》John M. Lee (2018, 2nd ed.)❌|$_{177}$《Analytic Number Theory 》Donald J. Newman (1998)❌|$_{178}$《Nonsmooth Analysis and Control Theory》Francis H. Clarke, Yuri S. Ledyaev, Ronald J. Stern, Peter R. Wolenski (1998)❌|$_{179}$《Banach Algebra Techniques in Operator Theory》Ronald G. Douglas (1998, 2nd ed.)❌|$_{180}$《A Course on Borel Sets》S. M. Srivastava (1998)❌|$_{181}$《Numerical Analysis》Rainer Kress (1998)❌|$_{182}$《Ordinary Differential Equations》Wolfgang Walter (1998)❌|$_{183}$《An Introduction to Banach Space Theory》Robert E. Megginson (1998)✔️|$_{184}$《现代图论》Béla Bollobás (1998)❌|$_{185}$《Using Algebraic Geometry》David A. Cox, John Little, Donal O’Shea (2005, 2nd ed.)❌|$_{186}$《Fourier Analysis on Number Fields》Dinakar Ramakrishnan, Robert J. Valenza (1999)❌|$_{187}$《Moduli of Curves》Joe Harris, Ian Morrison (1998)❌|$_{188}$《Lectures on the Hyperreals》Robert Goldblatt (1998)✔️|$_{189}$《模与环讲义》Tsit-Yuen Lam (1999)❌|$_{190}$《Problems in Algebraic Number Theory》M. Ram Murty, Jody Indigo Esmonde (2005, 2nd ed.)❌|$_{191}$《Fundamentals of Differential Geometry》Serge Lang (1999)❌|$_{192}$《Elements of Functional Analysis》Francis Hirsch, Gilles Lacombe (1999)❌|$_{193}$《Advanced Topics in Computational Number Theory》Henri Cohen (2000)❌|$_{194}$《One-Parameter Semigroups for Linear Evolution Equations》Engel, Nagel (2000)❌|$_{195}$《Elementary Methods in Number Theory》Melvyn B. Nathanson (2000)❌|$_{196}$《Basic Homological Algebra》M. Scott Osborne (2000)❌|$_{197}$《The Geometry of Schemes》Eisenbud, Joe Harris (2000)❌|$_{198}$《A Course in p-adic Analysis》Alain M. Robert (2000)❌|$_{199}$《Theory of Bergman Spaces》Hakan Hedenmalm, Boris Korenblum, Kehe Zhu (2000)❌|$_{200}$《An Introduction to Riemann-Finsler Geometry》David Bao, Shiing-Shen Chern, Zhongmin Shen (2000)❌|$_{201}$《Diophantine Geometry》Marc Hindry, Joseph H. Silverman (2000)✔️|$_{202}$《拓扑流形引论》John M. Lee (2011, 2nd ed.)❌|$_{203}$《The Symmetric Group — Representations》Combinatorial Algorithms, and Symmetric Functions, Bruce E. Sagan (2001, 2nd ed.)❌|$_{204}$《Galois Theory》Jean-Pierre Escofier (2001)❌|$_{205}$《Rational Homotopy Theory》Yves Félix, Stephen Halperin, Jean-Claude Thomas (2000)❌|$_{206}$《Problems in Analytic Number Theory》M. Ram Murty (2007, 2nd ed.)❌|$_{207}$《Algebraic Graph Theory》Chris Godsil, Gordon Royle (2001)❌|$_{208}$《Analysis for Applied Mathematics》Ward Cheney (2001)❌|$_{209}$《A Short Course on Spectral Theory》William Arveson (2002)❌|$_{210}$《Number Theory in Function Fields》Michael Rosen (2002)✔️|$_{211}$《代数》Serge Lang (2002, Revised 3rd ed)❌|$_{212}$《Lectures on Discrete Geometry》Jiří Matoušek (2002)❌|$_{213}$《From Holomorphic Functions to Complex Manifolds》Klaus Fritzsche [de], Hans Grauert (2002)❌|$_{214}$《Partial Differential Equations》Jürgen Jost, (2013, 3rd ed.)❌|$_{215}$《Algebraic Functions and Projective Curves》David M. Goldschmidt, (2003)❌|$_{216}$《Matrices — Theory and Applications》Denis Serre, (2010, 2nd ed.)❌|$_{217}$《Model Theory: An Introduction》David Marker, (2002)✔️|$_{218}$《光滑流形导论》John M. Lee (2012, 2nd ed.)❌|$_{219}$《The Arithmetic of Hyperbolic 3-Manifolds》Colin Maclachlan, Alan W. Reid, (2003)❌|$_{220}$《Smooth Manifolds and Observables》Jet Nestruev, (2003)❌|$_{221}$《Convex Polytopes》Branko Grünbaum (2003)❌|$_{222}$《Lie Groups》Lie Algebras, and Representations - An Elementary Introduction, Brian C. Hall, (2015, 2nd ed.)❌|$_{223}$《Fourier Analysis and its Applications》Anders Vretblad, (2003)✔️|$_{224}$《微分几何中的度量结构》Walschap, G (2004)❌|$_{225}$《Lie Groups》Daniel Bump, (2013, 2nd ed.)❌|$_{226}$《Spaces of Holomorphic Functions in the Unit Ball》Kehe Zhu, (2005)❌|$_{227}$《Combinatorial Commutative Algebra》Ezra Miller, Bernd Sturmfels, (2005)❌|$_{228}$《A First Course in Modular Forms》Fred Diamond, J. Shurman, (2006)❌|$_{229}$《The Geometry of Syzygies》David Eisenbud (2005)❌|$_{230}$《An Introduction to Markov Processes》Daniel W. Stroock, (2014, 2nd ed.)❌|$_{231}$《Combinatorics of Coxeter Groups》Anders Björner, Francisco Brenti, (2005)❌|$_{232}$《An Introduction to Number Theory》Everest, Graham Ward, T (2005)❌|$_{233}$《Topics in Banach Space Theory》Albiac, F Kalton, N. J (2016, 2nd ed.)❌|$_{234}$《Analysis and Probability — Wavelets》Signals, Fractals, Jorgensen, P. E. T (2006)✔️|$_{235}$《紧李群》M. R. Sepanski, (2007)（已有国外数学系列影印版）❌|$_{236}$《Bounded Analytic Functions》Garnett, J (2007)❌|$_{237}$《An Introduction to Operators on the Hardy-Hilbert Space》Ruben A. Martinez-Avendano, Peter Rosenthal, (2007)❌|$_{238}$《A Course in Enumeration》Aigner, M (2007)✔️|$_{239}$《数论 第1卷》Cohen, H (2007)✔️|$_{240}$《数论 第2卷》Cohen, H (2007)❌|$_{241}$《The Arithmetic of Dynamical Systems》Joseph H. Silverman, (2007)❌|$_{242}$《Abstract Algebra》Grillet, Pierre Antoine, (2007)❌|$_{243}$《Topological Methods in Group Theory》Geoghegan, Ross, (2007)❌|$_{244}$《Graph Theory》Adrian Bondy, U.S.R. Murty, (2008)❌|$_{245}$《Complex Analysis: Introduced in the Spirit of Lipman Bers》Gilman, Jane P Kra, Irwin, Rodríguez, Rubí E. (2007)❌|$_{246}$《A Course in Commutative Banach Algebras》Kaniuth, Eberhard, (2008)❌|$_{247}$《Braid Groups》Kassel, Christian, Turaev, Vladimir, (2008)❌|$_{248}$《Buildings Theory and Applications》Abramenko, Peter, Brown, Ken (2008)✔️|$_{249}$《经典傅里叶分析》Loukas Grafakos (2014, 3rd ed.)✔️|$_{250}$《现代傅里叶分析》Loukas Grafakos (2014, 3rd ed.)❌|$_{251}$《The Finite Simple Groups》Robert A. Wilson (2009)❌|$_{252}$《Distributions and Operators》Gerd Grubb, (2009)❌|$_{253}$《Elementary Functional Analysis》MacCluer, Barbara D (2009)❌|$_{254}$《Algebraic Function Fields and Codes》Henning Stichtenoth [de], (2009)❌|$_{255}$《Symmetry》Representations, and Invariants, Goodman, Roe, Wallach, Nolan R (2009)❌|$_{256}$《A Course in Commutative Algebra》Kemper, Gregor, (2010)❌|$_{257}$《Deformation Theory》Robin Hartshorne, (2010)❌|$_{258}$《Foundations of Optimization in Finite Dimensions》Osman Guler, (2010)❌|$_{259}$《Ergodic Theory - with a view towards Number Theory》Thomas Ward, Manfred Einsiedler, (2011)❌|$_{260}$《Monomial Ideals》Jürgen Herzog, Hibi Takayuki(2010)❌|$_{261}$《Probability and Stochastics》Erhan Cinlar, (2011)❌|$_{262}$《Essentials of Integration Theory for Analysis》Daniel W. Stroock, (2012)❌|$_{263}$《Analysis on Fock Spaces》Kehe Zhu, (2012)❌|$_{264}$《Functional Analysis》Calculus of Variations and Optimal Control, Francis H. Clarke, (2013)❌|$_{265}$《Unbounded Self-adjoint Operators on Hilbert Space》Konrad Schmüdgen, (2012)❌|$_{266}$《Calculus Without Derivatives》Jean-Paul Penot, (2012)❌|$_{267}$《Quantum Theory for Mathematicians》Brian C. Hall, (2013)❌|$_{268}$《Geometric Analysis of the Bergman Kernel and Metric》Krantz, Steven G (2013)❌|$_{269}$《Locally Convex Spaces》M Scott Osborne, (2014)❌|$_{270}$《Fundamentals of Algebraic Topology》Steven Weintraub, (2014)❌|$_{271}$《Integer Programming》Michelangelo Conforti, Gérard P. Cornuéjols, Giacomo Zambelli, (2014)❌|$_{272}$《Operator Theoretic Aspects of Ergodic Theory》Tanja Eisner, Bálint Farkas, Markus Haase, Rainer Nagel, (2015)❌|$_{273}$《Homotopical Topology》Anatoly Fomenko, Dmitry Fuchs, (2016, 2nd ed.)❌|$_{274}$《Brownian Motion》Martingales, and Stochastic Calculus, Jean-François Le Gall, (2016)❌|$_{275}$《Differential Geometry - Connections Curvature, and Characteristic Classes》Loring W. Tu (2017)❌|$_{276}$《Functional Analysis Spectral Theory, and Applications》 Manfred Einsiedler, Thomas Ward (2017)❌|$_{277}$《The Moment Problem》Konrad Schmüdgen (2017)❌|$_{278}$《Modern Real Analysis》William P. Ziemer (2017, 2nd ed.)❌|$_{279}$《Binomial Ideals》Jürgen Herzog, Takayuki Hibi, Hidefumi Ohsugi (2018)❌|$_{280}$《Introduction to Real Analysis》Christopher Heil (2019)❌|$_{281}$《Intersection Homology &amp; Perverse Sheaves with Applications to Singularities》Laurenţiu G. Maxim (2019)❌|$_{282}$《Measure Integration &amp; Real Analysis》 Sheldon Axler (2020)❌|$_{283}$《Basic Representation Theory of Algebras》Ibrahim Assem, Flávio U Coelho (2020)❌|$_{284}$《Spectral Theory》David Borthwick (2020) 美国数学会经典影印系列 ✔️|$_{001}$《拟共形映射讲义，第二版》Lars V.Ahlfors✔️|$_{002}$《度量几何学教程》Dmitri Burago, Yuri Burago, Sergei Ivanov✔️|$_{003}$《极小曲面教程》Tobias Holck Colding, William P.Minicozzi II✔️|$_{004}$《傅里叶分析》Javier Duoandikoetxea✔️|$_{005}$《复分析与几何引论》John P.D’Angelo✔️|$_{006}$《$h$-原理引论》Y.Eliashberg, N.Mishachev✔️|$_{007}$《偏微分方程，第二版》Lawrence C.Evans✔️|$_{008}$《单复变函数论，第三版》Robert E.Greene, Steven G.Krantz✔️|$_{009}$《微分几何中嘉当的活动标架法和外微分系统初步》Thomas A.Ivey, J.M.Landsberg✔️|$_{010}$《代数群表示论，第二版》Jens Carsten Jantzen✔️|$_{011}$《轨道法讲义》A.A.Kirllov✔️|$_{012}$《经典数论中的1001个问题》Jean-Marie De Koninck, Armel Mercier✔️|$_{013}$《实定理的复证明》Peter D.Lax, Lawrence Zalcman✔️|$_{014}$《Markov链与混合时间》David A.Levin, Yuval Peres, Elizabeth L.Wilmer✔️|$_{015}$《$J$-全纯曲线和辛拓扑，第二版》Dusa McDuff, Dietmar Salamon✔️|$_{016}$《不变测度》John von Neumann✔️|$_{017}$《连续和离散动力系统引论，第二版》R.Clark Robinson✔️|$_{018}$《 $\epsilon$ 空间 I：实分析（第三年的数学博客选文）》Terence Tao✔️|$_{019}$《 $\epsilon$ 空间 II：第三年的数学博客选文》Terence Tao✔️|$_{020}$《测度论引论》Terence Tao✔️|$_{021}$《高阶傅里叶分析》Terence Tao✔️|$_{022}$《庞加莱的遗产，第一部分》Terence Tao✔️|$_{023}$《庞加莱的遗产，第二部分》Terence Tao✔️|$_{024}$《最优输运理论专题，第二版》Cedric Villani✔️|$_{025}$《金融数学引论》R.J.Williams✔️|$_{026}$《域上二次型引论》T.Y.Lam✔️|$_{027}$《量子群讲义》Jens Carsten Jantzen✔️|$_{028}$《经典自守形式专题》Henryk Iwaniec✔️|$_{029}$《微分几何、李群和对称空间》Sigurdur Helgason✔️|$_{030}$《算子理论教程》John B.Conway✔️|$_{031}$《BGG范畴 $O$ 中半单李代数的表示》James E.Humphreys✔️|$_{032}$《C*-代数和有限维逼近》Nathanial P.Brown, Narutaka Ozawa✔️|$_{033}$《曲面上点的Hilbert概型讲义》Hiraku Nakajima✔️|$_{034}$《现代几何结构和场论》S.P.Novikov, I.A.Taimanov✔️|$_{035}$《自由边界问题的几何方法》Luis Caffarelli, Sandro Salsa✔️|$_{036}$《临界点理论中的极小极大方法及其在微分方程中的应用》Paul H.Rabinowitz✔️|$_{037}$《谱图论》Fan R.K.Chung✔️|$_{038}$《Hopf 代数及其在环上的作用》Susan Montgomery✔️|$_{039}$《紧流形上的割补术，第二版》C.T.C.Wall✔️|$_{040}$《方程组实数解的几何方法》Frank Sottile✔️|$_{041}$《Grobner基和凸多胞体》Bernd Sturmfels✔️|$_{042}$《非线性色散方程：局部和整体分析》Terence Tao✔️|$_{043}$《环簇》David A.Cox, John B.Little, Henry K.Schenck✔️|$_{044}$《调和测度：几何与分析的观点》Luca Capogna, Carlos E.Kenig, Loredana Lanzani✔️|$_{045}$《完全非线性椭圆方程》Luis A.Caffarelli, Xavier Cabre✔️|$_{046}$《代数群和微分Galois理论》Teresa Crespo, Zbigniew Hajto✔️|$_{047}$《Grothendieck《基础代数几何学(FGA)》解读》Barbara Fantechi, Lothar Gottsche✔️|$_{048}$《$p$ 进 Teichmüller 理论基础》Shinichi Mochizuki✔️|$_{049}$《齐性流、模空间及算术》Manfred Leopold Einsiedler, David Alexandre Ellwood✔️|$_{050}$《Grassmann流形、模空间和向量丛》David A.Ellwood, Emma Prevato✔️|$_{051}$《解析几何与代数几何：相同问题，不同方法》Jeffery McNeal, Mircea Mustata✔️|$_{052}$《代数曲线与密码学》V.Kumar Murty✔️|$_{053}$《$L$ 函数》James Arthur, James W.Cogdell, Steve Gelbart✔️|$_{054}$《代数曲线和黎曼面》Rick Miranda✔️|$_{055}$《$\theta$ 常数, 黎曼面和模群》Hershel M.Farkas, Irwin Kra✔️|$_{056}$《非线性波动方程，奇点的形成》Fritz John✔️|$_{057}$《解析数论》Henryk Iwaniec, Emmanuel Kowalski✔️|$_{058}$《椭圆偏微分方程的解的精细正则性》Jan Maly, William P.Ziemer✔️|$_{059}$《量子群和晶体基引论》Jin Hong, Seo-Jin Kang✔️|$_{060}$《平面曲线和焦散曲线的拓扑不变量》V.I.Arnold❌|$_{061}$《$J$-全纯曲线和辛拓扑》Dusa McDuff, Dietmar Salamon（已购买第二版）✔️|$_{062}$《调和映射中的精选论题》James Eells, Luc Lemaire✔️|$_{063}$《Frobenius流形、量子上同调和模空间》Yuri I.Manin✔️|$_{064}$《多项式方程组的求解》Bernd Sturmfels✔️|$_{065}$《Seiberg-Witten理论讲义》Liviu I.Nicolaescu✔️|$_{066}$《对称函数和正交多项式》I.G.Macdonald✔️|$_{067}$《紧闭包及其应用》Craig Huneke✔️|$_{068}$《矩映射、配边和Hamilton群作用》Victor Guillemin, Viktor Ginzburg, Yael Karshon✔️|$_{069}$《Fourier分析及其应用》Gerald B.Folland✔️|$_{070}$《Lyapunov指数和光滑遍历理论》Luis Barreira, Yakov B.Pesin✔️|$_{071}$《线性算子分解和Banach空间的几何》Gilles Pisier✔️|$_{072}$《二次型的代数和几何理论》Richard Elman, Nikita Karpenko, Alexander Merkurjev✔️|$_{073}$《代数几何中的相交理论引论》William Fulton✔️|$_{074}$《生成函数讲义》S.K.Lando✔️|$_{075}$《不变量理论与超代数》Frank D.Grosshans, Gian-Carlo Rota, Joel A.Stein✔️|$_{076}$《非线性偏微分方程的弱收敛方法》Lawrence C.Evans✔️|$_{077}$《约化 $p$ 进群上的容许不变分布》Harish-Chandra✔️|$_{078}$《混合 Motives》Marc Levine✔️|$_{079}$《表示论和Knizhnik-Zamolodchikov方程》Pavel I.Etingof, Igor B.Frenkel, Alexander A.Kirillov✔️|$_{080}$《随机矩阵、Frobenius特征值和单值性》Nicholas M.Katz, Peter Sarnak✔️|$_{081}$《C*-代数例析》Kenneth R.Davidson✔️|$_{082}$《对合之书》Max-Albert Knus, Alexander Merkurjev, Markus Rost, Jean-Pierre Tignol✔️|$_{083}$《编码与曲线》Judy L.Walker✔️|$_{084}$《紧Kähler流形的基本群》J.Amoros, M.Burger, K.Corlette, D.Kotschick, D.Toledo✔️|$_{085}$《实验数学》V.I.Arnold✔️|$_{086}$《数学利息理论，第二版》Leslie Jane Federer Vaaler, James W.Daniel✔️|$_{087}$《线性代数习题集》Paul R.Halmos✔️|$_{088}$《常微分方程：定性理论》Luis Barreira, Claudia Valls✔️|$_{089}$《随机矩阵论》Terence Tao✔️|$_{090}$《常微分方程与动力系统》Gerald Teschl✔️|$_{091}$《随机微分方程导论》Lawrence C.Evans✔️|$_{092}$《量子力学中的数学方法：Schrodinger 算子的应用，第二版》Gerald Teschl✔️|$_{093}$《偏微分方程：理论和应用》Andras Vasy✔️|$_{094}$《应用随机分析》Weinan E, Tiejun Li, Eric Vanden-Eijnden✔️|$_{095}$《组合学：导论》David Bressoud✔️|$_{096}$《实分析的基本方法》David Bressoud✔️|$_{097}$《Riemann zeta 函数讲义》H.Iwaniec✔️|$_{098}$《Hilbert第五问题及相关论题》Terence Tao✔️|$_{099}$《水波问题：数学分析与渐近》David Lannes✔️|$_{100}$《金融学中的概率论：Black-Scholes公式的数学指南，第二版》Sean Dineen✔️|$_{101}$《复分析：几何观点，第二版》Steven G.Krantz✔️|$_{102}$《连续上同调、离散子群与约化群表示，第二版》A.Borel, N.Wallach✔️|$_{103}$《非欧几何，第六版》H.S.M.Coxeter 国外数学名著系列 ✔️|$_{01}$《拓扑学Ⅰ：总论》S.P.Novikov✔️|$_{02}$《代数学基础》Igor R.Shafarevich✔️|$_{03}$《现代数论导引》（第二版）Yu.I.Manin, A.A.Panchishkin✔️|$_{04}$《现代概率论基础》（第二版）Olav Kallenberg✔️|$_{05}$《数值数学》Alfio Quarteroni, Riccardo Sacco, Fausto Saleri❌|$_{06}$《数值最优化》Jorge Nocedal, Stephen J.Wright（已购买第二版）✔️|$_{07}$《动力系统》Jürgen Jost✔️|$_{08}$《复杂性理论》Ingo Wegene✔️|$_{09}$《计算流体力学原理》Pieter Wesseling✔️|$_{10}$《计算统计学基础》James E.Gentle✔️|$_{11}$《非线性时间序列：非参数与参数方法》Jianqing Fan, Qiwei Yao✔️|$_{12}$《函数型数据分析》（第二版）J.O.Ramsay, B.W.Silverman✔️|$_{13}$《矩阵迭代分析》（第二版）Richard S.Varga✔️|$_{14}$《偏微分方程的并行算法》Petter Bjørstad, Mitchell Luskin✔️|$_{15}$《非线性问题的牛顿法：仿射不变性和自适应算法》Peter Deuflhard✔️|$_{16}$《区域分解算法：算法与理论》A.Toselli, O.Widlund✔️|$_{17}$《常微分方程的解法Ⅰ：非刚性问题》（第二版）E.Hairer, S.P.Nørsett, G.Wanner✔️|$_{18}$《常微分方程的解法Ⅱ：刚性与微分代数问题》（第二版）E.Hairer, G.Wanner✔️|$_{19}$《偏微分方程与数值方法》Stig Larsson, Vidar Thomée✔️|$_{20}$《椭圆型微分方程的理论与数值处理》W.Hackbusch✔️|$_{21}$《几何拓扑：局部性、周期性和伽罗瓦对称性》Dennis P.Sullivan✔️|$_{22}$《图论编程—分类树算法》Victor N.Kasyanov, Vladimir A.Evstigneev✔️|$_{23}$《经济、生态与环境科学中的数学模型》Natali Hritonenko, Yuri Yatsenko✔️|$_{24}$《代数数论》Jürgen Neukirch✔️|$_{25}$《代数复杂性理论》Peter Bürgiss, Michael, M.Amin Shokrollahi✔️|$_{26}$《一致双曲性之外的动力学：种整体的几何学的与概率论的观点》Christian Bonatti, Lorenzo J.Díaz✔️|$_{27}$《算子代数理论Ⅰ》Masamichi Takesaki✔️|$_{28}$《离散几何中的研究问题》Peter Brass, William Moser, János Pach✔️|$_{29}$《数论中未解决的问题》（第三版）Richard K.Guy✔️|$_{30}$《黎曼几何》（第二版）Peter Petersen✔️|$_{31}$《递归可枚举集和图灵度：可计算函数与可计算生成集研究》Robert I.Soare✔️|$_{32}$《模型论引论》David Marker✔️|$_{33}$《线性微分方程的伽罗瓦理论》Marius van der Put, Micheal F.Singer✔️|$_{34}$《代数几何Ⅱ：代数簇的上同调，代数曲面》I.R.Shafarevich✔️|$_{35}$《伯克利数学问题集》（第三版）Paulo Ney de Souza, Jorge-Nuno Silva✔️|$_{36}$《陶伯理论：百年进展》Jacob Korevaar✔️|$_{37}$《同调代数方法》（第二版）Sergei I.Gelfand, Yuri I.Manin✔️|$_{38}$《图像处理与分析：变分，PDE，小波及随机方法》Tony F.Chan, Jianhong Shen✔️|$_{39}$《稀疏线性系统的迭代方法》Yousef Saad✔️|$_{40}$《模型参数估计的反问题理论与方法》Albert Tarantola✔️|$_{41}$《常微分方程和微分代数方程的计算机方法》Uri M.Ascher, Linda R.Petzold✔️|$_{42}$《无约束最优化与非线性方程的数值方法》J.E.Dennis Jr, Robert B.Schnabel✔️|$_{43}$《代数几何Ⅰ：代数曲线，代数流形与概型》I.R.Shafarevich✔️|$_{44}$《代数几何Ⅲ：复代数簇，代数曲线及雅可比行列式》A.N.Parshin, I.R.Shafarevich✔️|$_{45}$《代数几何Ⅳ：线性代数群，不变量理论》A.N.Parshin, I.R.Shafarevich✔️|$_{46}$《代数几何Ⅴ：Fano簇》A.N.Parshin, I.R.Shafarevich✔️|$_{47}$《交换调和分析Ⅰ：总论，古典问题》V.P.Khavin, N.K.Nikol’skij✔️|$_{48}$《复分析Ⅰ：整函数与亚纯函数，多解析函数及其广义性》A.A.Gonchar, V.P.Havin, N.K.Nikol’skij✔️|$_{49}$《计算不变量理论》Harm Derksen, Gregor Kemper✔️|$_{50}$《动力系统Ⅴ：分歧理论和突变理论》V.I.Arnol’d✔️|$_{51}$《动力系统Ⅶ：可积系统，不完整动力系统》V.I.Arnol’d, S.P.Novikov✔️|$_{52}$《动力系统Ⅷ：奇异理论Ⅱ：应用》V.I.Arnol’d✔️|$_{53}$《动力系统Ⅸ：带有双曲性的动力系统》D.V.Anosov✔️|$_{54}$《动力系统Ⅹ：旋涡的一般理论》Valery V.Kozlov✔️|$_{55}$《几何Ⅰ：微分几何基本思想与概念》R.V.Gamkrelidze✔️|$_{56}$《几何Ⅱ：常曲率空间》E.B.Vinberg✔️|$_{57}$《几何Ⅲ：曲面理论》Yu.D.Burago, V.A.Zalgaller✔️|$_{58}$《几何Ⅳ：非正规黎曼几何》Yu.G.Reshetnyak✔️|$_{59}$《几何Ⅴ：最小曲面》R.Osserman✔️|$_{60}$《几何Ⅵ：黎曼几何》M.M.Postnikov✔️|$_{61}$《李群与李代数Ⅰ：李理论基础，李交换群》A.L.Onishchik✔️|$_{62}$《李群与李代数Ⅱ：李群的离散子群，李群与李代数的上同调》A.L.Onishchik, E.B.Vinberg✔️|$_{63}$《李群与李代数Ⅲ：李群与李代数的结构》A.L.Onishchik, E.B.Vinberg✔️|$_{64}$《经典力学与天体力学中的数学问题》（第三版）Vladimir I.Arnold, Valery V.Kozlov, Anatoly I.Neishtadt✔️|$_{65}$《数论Ⅳ：超越数》A.N.Parshin, I.R.Shafarevich✔️|$_{66}$《偏微分方程Ⅳ：微局部分析和双曲型方程》Yu.V.Egorov, M.A.Shubin✔️|$_{67}$《拓扑学Ⅱ：同伦与同调，经典流形》S.P.Novikov, V.A.Rokhlin✔️|$_{68}$《组合代数拓扑》Dmitry Kozlov✔️|$_{69}$《算法拓扑学及三维流形的分类》（第二版）Sergei Matveev✔️|$_{70}$《弦拓扑与环同调》Ralph L.Cohen, Kathryn Hess, Alexander A.Voronov✔️|$_{71}$《紧李群》Mark R.Sepanski✔️|$_{72}$《初等Dirichlet级数和模形式》Goro Shimura✔️|$_{73}$《混沌动力系统的概念和结果》Pierre Collet, Jean-Pierre Eckmann✔️|$_{74}$《微分方程数值方法引论》Mark H.Holmes✔️|$_{75}$《偏微分方程引论》（第二版）Michael Renardy, Robert C.Rogers✔️|$_{76}$《生物信息学中的数学方法引论》（第二版）Alexander Isaev✔️|$_{77}$《图论教程》R.Balakrishnan, K.Ranganathan✔️|$_{78}$《数论导引》Graham Everest, Thomas Ward✔️|$_{79}$《费马大定理：代数数论的原始导引》Harold M.Edwards✔️|$_{80}$《傅里叶分析及其应用》Anders Vretblad✔️|$_{81}$《数值最优化》（第二版）Jorge Nocedal，Stephen J.Wright Classical$\&nbsp$Topics$\&nbsp$in$\&nbsp$Mathematics ✔️|$_{01}$《椭圆模函数理论讲义，第一卷》✔️|$_{02}$《椭圆模函数理论讲义，第二卷》✔️|$_{03}$《自守函数理论讲义，第一卷》✔️|$_{04}$《自首函数理论讲义，第二卷》✔️|$_{05}$《二十面体和5次方程的解的讲义》✔️|$_{06}$《微分几何中的 Bochner 技术》✔️|$_{07}$《微分方程和微分几何》✔️|$_{08}$《Jacquet-Langlands 理论》✔️|$_{09}$《Kuga簇》✔️|$_{10}$《算术群和约化理论》 Elements$\&nbsp$of$\&nbsp$Mathematics$\&nbsp$（Bourbaki学派） 布尔巴基合作者协会网站部分书籍详尽目录法文版：❌| 《Theory of sets, chapters 1 to 4》 352 p 1970 (reprint in 1998)❌| 《Algebra, chapters 1 to 3》 654 p 1970❌| 《Algebra, chapters 4 to 7》 432 p 1981❌| 《Algebra, chapters 8》 489 p 2012❌| 《Algebra, chapter 9》 212 p 1959 (new edition in 1973)❌| 《Algebra, chapter 10》 224 p 1980❌| 《General Topology, chapters 1 to 4》 376 p 1971 (reprint in 1990)❌| 《General Topology, chapters 5 to 10》 334 p 1974❌| 《Functions of a Real Variable, chapters 1 to 7》 336 p 1976❌| 《Topological Vector Spaces, chapters 1 to 5》 400 p 1981❌| 《Integration, chapters 1 to 4》 284 p 1965 (new edition in 1973)❌| 《Integration, chapter 5》 154 p 1967❌| 《Integration, chapter 6》 106 p 1959❌| 《Integration, chapters 7 and 8》 222 p 1963❌| 《Integration, chapter 9》 134 p 1969❌| 《Commutative algebra, chapters 1 to 4》 364 p 1968 and 1969 (reprint in 1985)❌| 《Commutative algebra, chapter 5 to 7》 352 p 1964 and 1965 (reprint in 1985)❌| 《Commutative algebra, chapters 8 and 9》 208 p 1983❌| 《Commutative algebra, chapter 10》 187 p 1998❌| 《Differential and analytical varieties (results booklet)》 198 p 1971 (reprint in 1998)❌| 《Lie groups and algebras, chapter 1》 146 p 1971❌| 《Lie groups and algebras, chapters 2 and 3》 320 p 1972❌| 《Lie groups and algebras, chapters 4 to 6》 288 p 1968 (reprint in 1981)❌| 《Lie groups and algebras, chapters 7 and 8》 272 p 1975 (reprint in 1998)❌| 《Lie groups and algebras, chapter 9》 144 p 1982❌| 《Spectral theories, chapters 1 and 2》 336 p 2019 (second edition, recast and augmented)❌| 《Elements of the history of mathematics》 376 p 1974 (reprint in 1984)❌| 《Algebraic topology, chapters 1 to 4》 512 p 2016英文版❌| 《Topological Vector Spaces chapters 1-5》 1987❌| 《Algebra I, chapters 1-3》 1989❌| 《Algebra II, chapters 4-7》 1990❌| 《Commutative algebra, chapters 1-7》 1989❌| 《Lie groups and Lie algebras, chapters 1-3》 1989❌| 《General Topology, chapters 1-4》 1989❌| 《General Topology, chapters 5-10》 1989❌| 《Elements of the history of mathematics》 1994 Princeton$\&nbsp$Landmarks$\&nbsp$in$\&nbsp$Mathematics$\&nbsp$and$\&nbsp$Physics ✔️|$_{01}$《Convex Analysis : Analysis》Ralph Tyrell Rockafellar✔️|$_{02}$《Topology from the Differentiable Viewpoint》John Willard Milnor✔️|$_{03}$《General Theory of Relativity》P.A.M.Dirac❌|$_{04}$《Mathematical Foundations of Quantum Mechanics》John von Neumann❌|$_{05}$《Theory of Lie Groups》Claude Chevalley❌|$_{06}$《Introduction to Mathematical Logic》Alonzo Church✔️|$_{07}$《The Classical Groups : Their Invariants and Representations》Hermann Weyl❌|$_{08}$《Non-standard Analysis》Abraham Robinson✔️|$_{09}$《The Topology of Fibre Bundles》Norman Steenrod✔️|$_{10}$《Homological Algebra》Henri Cartan❌|$_{11}$《PCT, Spin and Statistics, and All That》Raymond F.Streater，Arthur S.Wightman✔️|$_{12}$《Representation Theory of Semisimple Groups : An Overview Based on Examples》Anthony W.Knapp❌|$_{13}$《Algebraic Theory of Numbers》Hermann Weyl❌|$_{14}$《Linear Programming and Extensions》George Dantzig❌|$_{15}$《Mathematical Methods of Statistics》Cramer，Harald❌|$_{16}$《Dynamic Programming》Richard E.Bellman❌|$_{17}$《Flows in Networks》L.R.Ford Jr，D.R.Fulkerson❌|$_{18}$《Continuous Geometry》John von Neumann❌|$_{19}$《Stable and Random Motions in Dynamical Systems : With Special Emphasis on Celestial Mechanics》Jurgen Moser❌|$_{20}$《Angular Momentum in Quantum Mechanics》A.R.Edmonds✔️|$_{21}$《Riemannian Geometry》Eisenhart UTM系列 ✔️|$_{001}$《Finite-Dimensional Vector Spaces》Halmos, Paul R (1974)❌|$_{002}$《Lectures on Boolean algebras》Halmos, Paul Richard (1974)✔️|$_{003}$《Naive Set Theory》Halmos, Paul R (1974)❌|$_{004}$《The Foundations of Geometry and the Non-Euclidean Plane》Martin, George E (1975)❌|$_{005}$《Finite Markov Chains: With a New Appendix: “Generalization of a Fundamental Matrix”》Kemeny, John G.; Snell, J. Laurie (1976)❌|$_{006}$《Lecture Notes on Elementary Topology and Geometry》Singer, I. M.; Thorpe, J. A (1976)✔️|$_{007}$《Introduction to Analytic Number Theory》Apostol, Tom M (1976)❌|$_{008}$《Algebra》Sigler, L. E (1976)❌|$_{009}$《Functions of Several Variables》Fleming, Wendell (1977)❌|$_{010}$《Basic Concepts of Algebraic Topology》Croom, F. H (1978)❌|$_{011}$《Introduction to College Mathematics with A Programming Language》LeCuyer, Edward J (1978)❌|$_{012}$《Dynamic Topology》Duda, E.; Whyburn, G (1979)❌|$_{013}$《Join Geometries: A Theory of Convex Sets and Linear Geometry》Jantosciak, J.; Prenowitz, W (1979)❌|$_{014}$《Introduction to Mathematical Logic: Set Theory - Computable Functions - Model Theory》Malitz, Jerome (1979)❌|$_{015}$《Much Ado About Calculus: A Modern Treatment with Applications Prepared for Use with the Computer》Wilson, R. L (1979)❌|$_{016}$《Elementary Topics in Differential Geometry》Thorpe, John A (1979)❌|$_{017}$《Methods of Mathematical Economics: Linear and Nonlinear Programming. Fixed-Point Theorems》Franklin, Joel (1980)❌|$_{018}$《Introduction to Optimal Control Theory》Macki, Jack; Strauss, Aaron (1981)❌|$_{019}$《Optimization Techniques: An Introduction》Foulds, L. R (1981)❌|$_{020}$《Intermediate Real Analysis》Fischer, E (1982)❌|$_{021}$《Transformation Geometry: An Introduction to Symmetry》Martin, George E (1982)❌|$_{022}$《The Foundations of Geometry and the Non-Euclidean Plane》Martin, George E (1983)❌|$_{023}$《A First Course in the Mathematical Foundations of Thermodynamics》Owen, David R (1983)❌|$_{024}$《Primer of Modern Analysis: Directions for Knowing All Dark Things, Rhind Papyrus, 1800 B.C》Smith, K. T (1983)✔️|$_{025}$《Basic Topology》Armstrong, M. A (1983)❌|$_{026}$《General Topology》Dixmier, Jacques (1984)❌|$_{027}$《Intermediate Calculus》Morrey, Charles B. Jr.; Protter, Murray H (1984)❌|$_{028}$《Linear Algebra: An Introductory Approach》Curtis, Charles W (1984)❌|$_{029}$《Why Math?》Driver, R.D (1984)❌|$_{030}$《Combinatorial Optimization for Undergraduates》Foulds, L. R (1984)❌|$_{031}$《Topology》Jänich, Klaus (1984)❌|$_{032}$《From Fermat to Minkowski: Lectures on the Theory of Numbers and Its Historical Development》Bühler, W. K.; Cornell, G.; Opolka, H.; Scharlau, W (1985)❌|$_{033}$《Calculus I》Marsden, Jerrold; Weinstein, Alan (1985)❌|$_{034}$《Calculus II》Marsden, Jerrold; Weinstein, Alan (1985)❌|$_{035}$《Calculus III》Marsden, Jerrold; Weinstein, Alan (1985)❌|$_{036}$《Introduction to Linear Algebra (2nd ed.)》Lang, Serge (1986)❌|$_{037}$《Constructive Combinatorics》Stanton, Dennis; White, Dennis (1986)❌|$_{038}$《Aspects of Calculus》Klambauer, Gabriel (1986)❌|$_{039}$《A First Course in Calculus (5th ed.)》Lang, Serge (1986)❌|$_{040}$《Topological and Uniform Spaces》James, I. M (1987)❌|$_{041}$《Calculus of Several Variables》Lang, Serge (1987)❌|$_{042}$《Linear Algebra (3rd ed.)》Lang, Serge (1987)❌|$_{043}$《The Mathematics of Nonlinear Programming》Peressini, Anthony L.; Sullivan, Francis E.; Uhl, J.J. Jr (1988)❌|$_{044}$《Projective Geometry》Samuel, Pierre (1988)✔️|$_{045}$《Groups and Symmetry》Armstrong, Mark A (1988)❌|$_{046}$《An Introduction to Probabilistic Modeling》Brémaud, Pierre (1988)❌|$_{047}$《Factorization and Primality Testing》Bressoud, David M (1989)❌|$_{048}$《Mathematical Introduction to Linear Programming and Game Theory》Brickman, Louis (1989)❌|$_{049}$《Linear Programming and Its Applications》Strayer, James K (1989)❌|$_{050}$《Calculus Two: Linear and Nonlinear Functions (2nd ed.)》Flanigan, Francis J.; Kazdan, Jerry L (1990)❌|$_{051}$《Elementary Stability and Bifurcation Theory (2nd ed.)》Iooss, Gerard; Joseph, Daniel D (1990)❌|$_{052}$《Numerical Mathematics - Hoffmann, Kar》einz; Hämmerlin, Günther (1991)❌|$_{053}$《A First Course in Real Analysis (2nd ed.)》Morrey, Charles B. Jr.; Protter, Murray H (1991)❌|$_{054}$《Second Year Calculus: From Celestial Mechanics to Special Relativity》Bressoud, David M (1991)❌|$_{055}$《Geometry: A Metric Approach with Models (2nd ed.)》Millman, Richard S.; Parker, George D (1991)❌|$_{056}$《An Introduction to Complex Function Theory》Palka, Bruce P (1991)❌|$_{057}$《Linear Algebra Through Geometry (2nd ed.)》Banchoff, Thomas; Wermer, John (1992)❌|$_{058}$《The Joy of Sets: Fundamentals of Contemporary Set Theory (2nd ed.)》Devlin, Keith (1993)❌|$_{059}$《Topology of Surfaces》Kinsey, L. Christine (1993)❌|$_{060}$《Linear Algebra: An Introduction to Abstract Mathematics》Valenza, Robert J (1993)❌|$_{061}$《Mathematical Logic (2nd ed.) - Ebbinghaus, H.》.; Flum, J.; Thomas, W (1994)❌|$_{062}$《A First Course in Real Analysis》Berberian, Sterling K (1994)❌|$_{063}$《Linear Algebra》Jänich, Klaus (1994)❌|$_{064}$《A First Course in Analysis》Pedrick, George (1994)❌|$_{065}$《Elements of Algebra: Geometry, Numbers, Equations》Stillwell, John (1994)❌|$_{066}$《Mathematics: A Concise History and Philosophy》Anglin, W.S (1994)❌|$_{067}$《A Brief on Tensor Analysis (2nd ed.)》Simmonds, James G (1994)❌|$_{068}$《The Heritage of Thales》Anglin, W.S.; Lambek, J (1995)❌|$_{069}$《The Pleasures of Probability》Isaac, Richard (1995)❌|$_{070}$《An Accompaniment to Higher Mathematics》Exner, George R (1996)❌|$_{071}$《Variational Calculus and Optimal Control: Optimization with Elementary Convexity (2nd ed.)》Troutman, John L (1996)❌|$_{072}$《Mathematical Analysis: An Introduction》Browder, Andrew (1996)❌|$_{073}$《Topological Spaces: From Distance to Neighborhood》Buskes, Gerard; Rooij, Arnoud Van (1997)❌|$_{074}$《The Fundamental Theorem of Algebra》Fine, Benjamin; Rosenberger, Gerhard (1997)❌|$_{075}$《Limits: A New Approach to Real Analysis》Beardon, Alan F (1997)❌|$_{076}$《Discrete Probability》Gordon, Hugh (1997)❌|$_{077}$《Introduction to Coding and Information Theory》Roman, Steven (1997)❌|$_{078}$《Rings, Fields, and Vector Spaces: An Introduction to Abstract Algebra via Geometric Constructibility》Sethuraman, Bharath (1997)❌|$_{079}$《Undergraduate Analysis (2nd ed.)》Lang, Serge (1997)❌|$_{080}$《Mathematical Reflections: In a Room with Many Mirrors》Hilton, Peter; Holton, Derek; Pedersen, Jean (1997)❌|$_{081}$《Geometric Constructions》Martin, George E (1998)❌|$_{082}$《Basic Elements of Real Analysis》Protter, Murray H (1998)❌|$_{083}$《Calculus: A Liberal Art (2nd ed.)》Priestley, W. M (1998)❌|$_{084}$《Geometry: Plane and Fancy》Singer, David A (1998)❌|$_{085}$《Linear Algebra (3rd ed.)》Smith, Larry (1998)❌|$_{086}$《Applied Abstract Algebra (2nd ed.)》Lidl, Rudolf; Pilz, Günter (1998)❌|$_{087}$《Numbers and Geometry》Stillwell, John (1998)❌|$_{088}$《Mathematical Expeditions: Chronicles by the Explorers》Laubenbacher, Reinhard; Pengelley, David (1999)❌|$_{089}$《An Introduction to Wavelets Through Linear Algebra》Frazier, Michael W (1999)❌|$_{090}$《The Laplace Transform: Theory and Applications》Schiff, Joel L (1999)❌|$_{091}$《The Lebesgue-Stieltjes Integral: A Practical Introduction》Brunt, B. van; Carter, M (2000)❌|$_{092}$《Inside Calculus》Exner, George R (2000)❌|$_{093}$《Geometry: Euclid and Beyond》Hartshorne, Robin (2000)❌|$_{094}$《The Geometry of Spacetime: An Introduction to Special and General Relativity》Callahan, James J (2000)❌|$_{095}$《A Course in Modern Geometries (2nd ed.)》Cederberg, Judith N (2001)❌|$_{096}$《Complex Analysis》Gamelin, Theodore W (2001)❌|$_{097}$《Vector Analysis》Jänich, Klaus (2001)❌|$_{098}$《Counting: The Art of Enumerative Combinatorics》Martin, George E (2001)❌|$_{099}$《Mathematical Vistas: From a Room with Many Windows》Hilton, Peter; Holton, Derek; Pedersen, Jean (2002)❌|$_{100}$《Beginning Functional Analysis》Saxe, Karen (2002)❌|$_{101}$《Short Calculus: The Original Edition of “A First Course in Calculus”》Lang, Serge (2002)❌|$_{102}$《Practical Analysis in One Variable》Estep, Donald (2002)❌|$_{103}$《Glimpses of Algebra and Geometry (2nd ed.)》Toth, Gabor (2002)❌|$_{104}$《Elementary Probability Theory: With Stochastic Processes and an Introduction to Mathematical Finance (4th ed.)》Aitsahlia, Farid; Chung, Kai Lai (2003)❌|$_{105}$《Topics in the Theory of Numbers》Erdös, Paul; Suranyi, Janos (2003)❌|$_{106}$《Discrete Mathematics: Elementary and Beyond》Lovász, L.; Pelikán, J.; Vesztergombi, K (2003)❌|$_{107}$《Elements of Number Theory》Stillwell, John (2003)❌|$_{108}$《Introduction to Cryptography (2nd ed.)》Buchmann, Johannes (2004)❌|$_{109}$《Integers, Polynomials, and Rings: A Course in Algebra》Irving, Ronald S (2004)❌|$_{110}$《Differential Equations: An Introduction with Mathematica (2nd ed.)》Ross, Clay C (2004)❌|$_{111}$《Difference Equations: From Rabbits to Chaos》Cull, Paul; Flahive, Mary; Robson, Robby (2005)❌|$_{112}$《A Field Guide to Algebra - Chamber》oir, Antoine (2005)❌|$_{113}$《An Introduction to Difference Equations (3rd ed.)》Elaydi, Saber (2005)❌|$_{114}$《Undergraduate Algebra (3rd ed.)》Lang, Serge (2005)❌|$_{115}$《Linearity, Symmetry, and Prediction in the Hydrogen Atom》Singer, Stephanie Frank (2005)❌|$_{116}$《The Four Pillars of Geometry》Stillwell, John (2005)❌|$_{117}$《Conics and Cubics: A Concrete Introduction to Algebraic Curves (2nd ed.)》Bix, Robert (2006)❌|$_{118}$《Notes on Set Theory (2nd ed.)》Moschovakis, Yiannis (2006)❌|$_{119}$《Mathematical Masterpieces: Further Chronicles by the Explorers》Knoebel, Art; Laubenbacher, Reinhard; Lodder, Jerry; Pengelley, David (2007)❌|$_{120}$《Combinatorics and Graph Theory (2nd ed.)》Harris, John M.; Hirst, Jeffry L.; Mossinghoff, Michael (2008)❌|$_{121}$《Naive Lie Theory》Stillwell, John (2008)❌|$_{122}$《Analysis by its History》Hairer, Ernst; Wanner, Gerhard (2008)❌|$_{123}$《Measure, Topology, and Fractal Geometry (2nd ed.)》Edgar, Gerald (2008)❌|$_{124}$《Mathematical Biology: An Introduction with Maple and Matlab (2nd ed.)》Herod, James; Shonkwiler, Ronald W (2009)❌|$_{125}$《Explorations in Monte Carlo Methods》Mendivil, Frank; Shonkwiler, Ronald W (2009)❌|$_{126}$《Elementary Number Theory: Primes, Congruences, and Secrets: A Computational Approach》Stein, William (2009)❌|$_{127}$《Childs, Lindsay N (ed.). A Concrete Introduction to Higher Algebra (3rd ed.)》Childs, Lindsay N (2009)❌|$_{128}$《Introduction to Boolean Algebras》Halmos, Paul R.; Givant, Steven (2009)❌|$_{129}$《Complex Analysis (3rd ed.)》Bak, Joseph; Newman, Donald J (2010)❌|$_{130}$《The Art of Proof: Basic Training for Deeper Mathematics》Beck, Matthias; Geoghegan, Ross (2010)❌|$_{131}$《Advanced Calculus: A Geometric View》Callahan, James J (2010)❌|$_{132}$《Linear Optimization: The Simplex Workbook》Hurlbert, Glenn (2010)❌|$_{133}$《Mathematics and Its History (3rd ed.)》Stillwell, John (2010)❌|$_{134}$《A Course in Multivariable Calculus and Analysis》Ghorpade, Sudhir R.; Limaye, Balmohan V (2010)❌|$_{135}$《Real Analysis and Applications: Theory in Practice》Davidson, Kenneth R.; Donsig, Allan P (2010)❌|$_{136}$《Reading, Writing, and Proving: A Closer Look at Mathematics (2nd ed.)》Daepp, Ulrich; Pamela, Gorkin (2011)❌|$_{137}$《Proofs and Fundamentals: A First Course in Abstract Mathematics (2nd ed.)》Bloch, Ethan D (2011)❌|$_{138}$《Ordinary Differential Equations》Adkins, William A.; Davidson, Mark G (2012)❌|$_{139}$《Geometry by Its History》Ostermann, Alexander; Wanner, Gerhard (2012)❌|$_{140}$《Linear Algebra》Petersen, Peter (2012)❌|$_{141}$《Introduction to the Mathematics of Finance: Arbitrage and Option Pricing》Roman, Steven (2012)❌|$_{142}$《Introduction to Mathematical Structures and Proofs (2nd ed.)》Gerstein, Larry J (2012)❌|$_{143}$《Real and Convex Analysis》Vanderbei, Robert J.; Çinlar, Erhan (2013)❌|$_{144}$《An Invitation to Abstract Mathematics》Bajnok, Bela (2013)❌|$_{145}$《First Steps in Differential Geometry》McInerney, Andrew (2013)❌|$_{146}$《Elementary Analysis: The Theory of Calculus》Ross, Kenneth A (2013)❌|$_{147}$《The Real Numbers: An Introduction to Set Theory and Analysis》Stillwell, John (2013)❌|$_{148}$《A Course in Point Set Topology》Conway, John B (2014)❌|$_{149}$《Introduction to Partial Differential Equations》Olver, Peter J (2014)❌|$_{150}$《More Calculus of a Single Variable》Mercer, Peter R (2014)❌|$_{151}$《An Introduction to Mathematical Cryptography (2nd ed.)》Hoffstein, Jeffrey; Pipher, Jill; Silverman, Joseph H (2014)❌|$_{152}$《Calculus with Applications (2nd ed.)》Terrell, Maria Shea; Lax, Peter D (2014)❌|$_{153}$《Linear Algebra Done Right (3rd ed.)》Axler, Sheldon (2015)❌|$_{154}$《Computing the Continuous Discretely: Integer-point Enumeration in Polyhedra (2nd ed.)》Beck, Matthias; Robins, Sinai (2015)❌|$_{155}$《Real Analysis: Foundations and Functions of One Variable》Laczkovich, Miklós; Sós, Vera T (2015)❌|$_{156}$《Real Mathematical Analysis (2nd ed.)》Pugh, Charles C (2015)❌|$_{157}$《A First Course in Differential Equations (3rd ed.)》Logan, David J (2015)❌|$_{158}$《Rational Points on Elliptic Curves (2nd ed.)》Silverman, Joseph H.; Tate, John (2015)❌|$_{159}$《Real Analysis via Sequences and Series》Little, Charles; Kee, Teo; van Brunt, Bruce (2015)❌|$_{160}$《Understanding Analysis (2nd ed.)》Abbott, Stephen (2015)❌|$_{161}$《Ideals, Varieties, and Algorithms: An Introduction to Computational Algebraic Geometry and Commutative Algebra (4th ed.)》Cox, David; Little, John; O’Shea, Danal (2015)❌|$_{162}$《Applied Partial Differential Equations (3rd ed.)》Logan, David J (2015)❌|$_{163}$《Differential Geometry of Curves and Surfaces》Tapp, Kristopher (2016)❌|$_{164}$《Introduction to Calculus and Classical Analysis (4th ed.)》Hijab, Omar (2016)❌|$_{165}$《Calculus and Analysis in Euclidean Space》Shurman, Jerry (2016)❌|$_{166}$《Real Analysis: Series, Functions of Several Variables, and Applications》Laczkovich, Miklós; Sós, Vera T (2017)❌|$_{167}$《Multivariable Calculus with Applications》Lax, Peter D.; Terrell, Maria Shea (2017)❌|$_{168}$《Applied Linear Algebra and Matrix Analysis (2nd ed.)》Shores, Thomas S (2018)❌|$_{169}$《Applied Linear Algebra (2nd ed.)》Olver, Peter J.; Shakiban, Chehrzad (2018)❌|$_{170}$《Algebraic Combinatorics: Walks, Trees, Tableaux, and More (2nd ed.)》Stanley, Richard P (2018)❌|$_{171}$《A Course in Calculus and Real Analysis (2nd ed.)》Ghorpade, Sudhir R.; Limaye, Balmohan V (2018)❌|$_{172}$《Complex Analysis with Applications》Asmar, Nakhle H.; Grafakos, Loukas (2018)❌|$_{173}$《A Readable Introduction to Real Mathematics (2nd ed.)》Rosenthal, Daniel; Rosenthal, David; Rosenthal, Peter (2018)❌|$_{174}$《A Pythagorean Introduction to Number Theory - Taklo》ighash, Ramin (2018)❌|$_{175}$《Inquiry-Based Enumerative Combinatorics: One, Two, Skip a Few… Ninety-Nine, One Hundred》Petersen, T. Kyle (2019)❌|$_{176}$《Mathematics of Finance: An Intuitive Introduction》Saari, Donald G (2019)❌|$_{177}$《Introduction to Discrete Mathematics via Logic and Proof》Jongsma, Calvin (2019)❌|$_{178}$《Geometry: from Isometries to Special Relativity》Lee, Naoon (2020)❌|$_{179}$《An Invitation to Abstract Mathematics》Bajnok, Bela (2020)❌|$_{180}$《Mathematics and Its History》Stillwell, John (2020) 数学概览 ❌|$_{01}$《代数基本概念》I.R.Shafarevich✔️|$_{02}$《直观几何，共2册》D.希尔伯特，S.康福森（拥有英文原版）❌|$_{03}$《关于概率的哲学随笔》P.S.拉普拉斯✔️|$_{04}$《Klein数学讲座》F.克莱因❌|$_{05}$《泛函分析史》迪厄多内✔️|$_{06}$《Milnor眼中的数学和数学家》J.W.Milnor❌|$_{07}$《数学欣赏：论数与形》H.拉德马赫❌|$_{08}$《生命·艺术·几何》M.吉卡❌|$_{09}$《惠更斯与巴罗,牛顿与胡克 : 数学分析与突变理论的起步,从渐伸线到准晶体》В. И. 阿诺尔德✔️|$_{10}$《langlands纲领和他的数学世界》R.朗兰兹❌|$_{11}$《Littlewood数学随笔集&gt;J.E.李特尔伍德❌|$_{12}$《数学的世界，共6册》J.R.纽曼✔️|$_{13}$《对称的观念在19世纪的演变-Klein和Lie》I.M.Yaglom❌|$_{14}$《圆与球》W.布拉施克❌|$_{15}$《数学杂谈》高木贞治❌|$_{16}$《数学简史，第四版》D.J.斯特罗伊克✔️|$_{17}$《Gromov的数学世界，共2册》Mikhail Gromov❌|$_{18}$《近世数学史谈》高木贞治❌|$_{19}$《KAM的故事 : 经典Kolmogorov-Arnold-Moser理论的历史之旅》H.S.杜马斯 法兰西数学精品译丛 ✔️|$_{01}$《微分几何：流形、曲线和曲面》M.贝尔热，B.戈斯丢✔️|$_{02}$《拓扑学教程：拓扑空间和距离空间、数值函数、拓扑向量空间》G.肖盖✔️|$_{03}$《微分学》H.嘉当✔️|$_{04}$《解析函数论初步》H.嘉当（拥有英文原版）✔️|$_{05}$《广义函数论》施瓦兹✔️|$_{06}$《无穷小计算》J.迪厄多内✔️|$_{07}$《代数学教程》R.哥德门特✔️|$_{08}$《谱理论讲义》J.迪斯米埃❌|$_{09}$《解析与概率数论导引》G.特伦鲍姆✔️|$_{10}$《拟微分算子和Nash-Moser定理》S.阿里纳克，P.热拉尔❌|$_{11}$《概率与位势，第1卷：可测空间》✔️|$_{12}$《线性与非线性泛函分析及其应用，共2册》Philippe，G.Ciarlet❌|$_{13}$《分析与代数原理，共2册》Pierre Colmez✔️|$_{14}$《分布系统的精确能控性、摄动和镇定，第1卷》J.L.利翁斯✔️|$_{15}$《有限群导引》Jean-Pierre Serre（拥有英文影印版） HEP$\&nbsp$World's$\&nbsp$Classics ❌|$_{01}$《思维规律的研究》G.布尔❌|$_{02}$《大自然的肖像》Alexander von Humboldt✔️|$_{03}$《自然哲学的数学原理，共2册》Isaac Newton❌|$_{04}$《关于两门新科学的对话》Galileo Galilei，Henry Crew，Alfonso de Salvio✔️|$_{05}$《曲面的一般研究》Carl Friedrich Gauss❌|$_{06}$《高等数学引论：第1卷》华罗庚，萧文杰❌|$_{07}$《牛顿光学》Sir Isaac Newton❌|$_{08}$《惠更斯光论》Christiaan Huygens，Silvanus P.Thompson❌|$_{09}$《线性偏微分方程中的柯西问题讲义》J.阿达马✔️|$_{10}$《热的解析理论》J.傅里叶❌|$_{11}$《生态学中的营养动力论》R.L.林德曼❌|$_{12}$《天体运行论》哥白尼✔️|$_{12}$《数学在19世纪的发展，第一卷》Felix Klein 一些已经译成中文的数学大师著作 Gauss：《算术探究》✔️Riemann：《黎曼全集》✔️Felix Klein：《数学在19世纪的发展（两卷）》✔️《高观点下的初等数学》✔️《初等几何的著名问题》✔️《Klein数学讲座》✔️Poincaré：《最后的沉思》✔️《科学的价值》✔️《科学与方法》✔️《科学与假设》✔️Hilbert：《几何基础》✔️《几何直观》✔️《数学物理方法（据说其实都是柯朗写的）》❌Dieudonné：《为了人类心智的荣耀》❌《无穷小计算》✔️《现代分析基础》❌《泛函分析史》❌《如果说他还有什么中文译本的话，那就是作为EGA第二作者而被人忽视》✔️Atiyah：《交换代数导引》❌《数学的统一性》❌Kolmogorov：《函数论与泛函分析初步》✔️《概率论导引》✔️Weyl：《诗魂数学家的沉思》✔️《对称》✔️《数学与自然科学之哲学》❌Wei：《数论：从汉穆拉比到勒让德的历史导引》❌Milnor：《从微分几何看拓扑》✔️《莫尔斯理论》✔️Chern：《微分几何讲义》✔️Yau：《微分几何讲义》✔️《调和映照讲义》❌《大宇之形》❌小平邦彦：《微积分入门1和2》Courant：《微积分和数学分析引论》✔️《数学物理方法》❌Gelfand：《线性代数学》✔️《广义函数》❌Shafarevich：《代数基本概念》❌Arnold：《经典力学的数学方法》✔️《常微分方程》✔️《常微分方程绪论》❌《数学分析与突变论起步》❌《突变理论》❌Serre：《数论教程》❌《有限群的线性表示》✔️Grothendieck：《EGA》✔️H.Cartan：《解析函数论初步》✔️《微分学》✔️施瓦兹：《广义函数论》✔️斯梅尔：《微分方程》❌《动力系统与混沌导论》❌E.Artin：《伽罗瓦理论》✔️CL西格尔：《突变论》❌Peter Lax：《泛函分析》✔️《线性代数及其应用》❌Stein：《奇异积分与函数的可微性》❌Tao：《陶哲轩实分析》✔️格里菲斯：《代数曲线（张筑生等人根据听课笔记整理）》❌《代数几何学原理》✔️Hardy：《哈代数论》✔️《纯数学教程》✔️《三角级数论》❌《不等式》✔️LittleWood：《数学随笔集》❌高尔斯：《普林斯顿数学指南（主编）》✔️ 格致方法•定量研究系列 ❌|$_{01}$《社会统计的数学基础》✔️|$_{02}$《理解回归假设》✔️|$_{03}$《虚拟变量回归》✔️|$_{04}$《多元回归中的交互作用》✔️|$_{05}$《回归诊断简介》✔️|$_{06}$《现代稳健回归方法》✔️|$_{07}$《固定效应回归模型》✔️|$_{08}$《用面板数据做因果分析》✔️|$_{09}$《多层次模型》❌|$_{10}$《分位数回归模型》✔️|$_{11}$《空间回归模型》✔️|$_{12}$《删截、选择性样本及截断数据的回归模型》✔️|$_{13}$《应用 logistic 回归分析》✔️|$_{14}$《logit 与 probit：次序模型和多类别模型》✔️|$_{15}$《定序因变量的 logistic 回归模型》❌|$_{16}$《对数线性模型》❌|$_{17}$《流动表分析》❌|$_{18}$《中介作用分析》❌|$_{19}$《关联模型》✔️|$_{20}$《因子分析：统计方法与应用问题》✔️|$_{21}$《非递归因果模型》❌|$_{22}$《评估不平等》✔️|$_{23}$《分析复杂调查数据（第二版）》❌|$_{24}$《分析复杂调查数据》❌|$_{25}$《世代分析（第二版）》❌|$_{26}$《纵贯研究（第二版）》✔️|$_{27}$《多元时间序列模型》✔️|$_{28}$《潜变量增长曲线模型》✔️|$_{29}$《缺失数据》❌|$_{30}$《社会网络分析（第二版）》✔️|$_{31}$《广义线性模型导论》❌|$_{32}$《基于行动者的模型》✔️|$_{33}$《基于布尔代数的比较法导论》✔️|$_{34}$《微分方程：一种建模方法》❌|$_{35}$《模糊集合理论在社会科学中的应用》✔️|$_{36}$《图解代数：用系统方法进行数学建模》❌|$_{37}$《项目功能差异（第二版）》✔️|$_{38}$《Logistic 回归入门》✔️|$_{39}$《解释概率模型：Logit、Probit 以及其他广义线性模型》❌|$_{40}$《抽样调查方法简介》❌|$_{41}$《计算机辅助访问》✔️|$_{42}$《协方差结构模型：LISERL 导论》✔️|$_{43}$《非参数回归：平滑散点图》✔️|$_{44}$《广义线性模型：一种统一的方法》✔️|$_{45}$《Logistic 回归中的交互效应》✔️|$_{46}$《应用回归导论》❌|$_{47}$《档案数据处理：生活经历研究》✔️|$_{48}$《创新扩散模型》✔️|$_{49}$《数据分析概论》✔️|$_{50}$《最大似然估计法：逻辑与实践》✔️|$_{51}$《指数随机图模型导论》❌|$_{52}$《对数线性模型的关联图和多重图》✔️|$_{53}$《非递归模型：内生性、互反关系与反馈环路》✔️|$_{54}$《潜类别尺度分析》✔️|$_{55}$《合并时间分析》✔️|$_{56}$《自助法：一种统计推断的非参数估计法》❌|$_{57}$《评分加总量表构建导论》❌|$_{58}$《分析制图与地理数据库》❌|$_{59}$《应用人口学概论：数据来源与估计技术》✔️|$_{60}$《多元广义线性模型》✔️|$_{61}$《时间序列分析：回归技术（第二版）》❌|$_{62}$《事件史和生存分析（第二版）》✔️|$_{63}$《样条回归模型》❌|$_{64}$《定序题项回答理论：莫坎量表分析》✔️|$_{65}$《LISERL 方法：多元回归中的交互作用》✔️|$_{66}$《蒙特卡罗模拟》✔️|$_{67}$《潜类别分析》❌|$_{68}$《内容分析法导论（第二版）》✔️|$_{69}$《贝叶斯统计推断》 Lecture Notes in Mathematics universitext Classics in Mathematics Springer Texts in Statistics Graduate Studies in Mathematics Classics in Mathematics 华章数学译丛 图灵数学 · 统计学丛书 经典原版书库 数学名著译丛 数学与人文丛书系列 芝加哥大学本科数学分类 哈尔滨工业大学出版社 Steel奖获奖数学家及著作 数学书籍推荐—数学分析篇 数学书籍推荐—代数篇 数学书籍推荐—余下的那些篇 5.2 讲义和短小精干的教材5.2.1 讲义 J.S. Milne’s Mathematics Site Misha Gromov’s Home page 5.2.2 短小精干的教材教材的短小精悍有利于学习者迅速掌握主要内容而不必太关注细节问题，主要是起整体性的了解作用。 弗里德曼 《Selected Applications of Geometry to Low-Dimensional Topology》 —&gt; 拓扑学 贾高 《变分法基础与Sobolev空间》136页 —&gt; PDE Palais 《Morse theory on Hilbert manifolds》42页 —&gt; 无限维流形的莫尔斯理论，拓扑变分学的重要基础 Todd 《函数构造论导引》 Gromov 《Manifolds：Where Do We Com From ? What Are We ? Were Are We Going》 格里菲斯 《代数曲线》 Hitchin 《Manifolds&gt; Snape 《Applications of Elliptic Functions in Classical and Algebraic Geometry》 Garding 《分析学中的若干问题及其历史》 Atiyah 《An introduction to commutative algebra》 5.3 课程 MIT OpenCourseWare（OCW） 6. 相关问题的一些探讨 以数学史的观点来看，集合论是如何成为数学基础的？ 原链接回答1：现代集合论起源于康托。康托用对角线法证明了实数集与自然数集不等势，从而在历史上第一次提出“无穷集合也存在不同的大小”这种观点，由此才产生出后来的公理集合论——公理集合论并非只有ZFC一种方案。现代集合论其实就是对无穷集合的研究。其实集合论、数理逻辑都是非常年轻的学科，“不可数集”这个概念大概也就一百多年的历史。在柯西或者傅立叶的时代，大家脑子里可没什么“不可数集”“连续统假设”这种概念，那个年代的数学其实和现在非常不一样。其实“数学需要有个基础”这种观念，大约也是19世纪末、20世纪才得到重视。17，18世纪的数学实际上不是独立学科，那个时代的数学家往往又是力学家、物理学家，他们对学科之间没做那么明确的区分。到19世纪末，20世纪，后来又受到布尔巴基学派的影响，大家开始整理数学自身的内容，开始出现结构主义，开始意识到有必要从逻辑的层面出发理清数学知识的脉络。所以这个时代希尔伯特写了 几何学的基础，这在17，18世纪看来估计是不可思议的事情——欧氏几何谁不知道，有必要对这种东西进行严格的公理化么？然后后来又有罗素等人的努力，慢慢把集合论公理建立起来，并且基于集合论强大的描述能力，大家开始把集合论作为整个数学体系的根基。—— 当然也像其他答主提到的那样，集合论并不适用于描述所有数学，比如范畴论的某些部分，又比如Grothendieck universe这种东西，其实都是超越了ZFC所能描述的范围的。对数学基础的历史探讨，本身和数理逻辑、数学哲学的发展是紧密相关的，而这些领域绝大部分进展都出现在20世纪。包括范畴论、类型论等更新的替代集合论作为数学基础的方案，也都出现在20世纪。还是那句话，“数学基础”本身就是个属于20世纪以后的现代数学命题。不过还是要说一句，也不是所有数学家都认同集合论作为数学基础。姑且不论范畴论、类型论，这个世界上甚至还有ultrafinitists，他们抵制任何形式的无穷，坚持使用只涉及有限的语言来描述数学。——而且只使用“有限”的语言，其实是能够描述很大一部分数学的。当然，其实更多的数学家，他们根本不关心集合论 数学基础这些“底层架构”，他们只关心自己做的那一部分“具体数学”；数学基础你随便找一个自洽的，能够描述他们所关心的数学的就行。就好比换个操作系统，同一个软件还是同一个软件。【回答补充：第二段读起来感觉有点乱。希尔伯特在布尔巴基之前。19、20世纪之交，受分析严格化的影响，那个时代的数学家对数学的基础可能更看重一些。罗素悖论使人认识到集合论需要有公理化基础，哥德尔不完备定理发现纯形式化方法的局限，所以现在大家都是实用主义态度，不太关心抽象的基础问题了。】回答2：虽然，你去问一个学数学的人，什么是数学的基础，得到的答案或多或少会提到集合论这个词，但是这其实是一个有争议的回答（因为大多数回答的人也不是很确信这件事情，我自己也曾被问到这个问题，我的答复是不知道，如果非要我说个答案的话，大概是集合论吧！）。你会听到这个答复大多数情况是因为这个问题没有“标准答案”，而集合不但引发了数学危机还成为了数学中一个不可或缺的概念，仅此而已。大多数的数学家其实并不怎么关心什么数学的基础这件事情，如果你用foundation of mathematics这个关键词在搜索引擎里检索，你会发现很多搜到的结果看着并不怎么数学，反倒是可能充斥着哲学意味。不过关于“集合”以及“集合论”的发展历程确实是很值得去品味的。因此，我补充一些个人觉得挺有趣的参考文献，以供感兴趣的读者参考。1. 首先推荐感兴趣的读者去翻阅《From the calculus to set theory, 1630–1910. An introductory history》，这是一本由六位研究数学史的学者合写的著作，书的内容如标题所示，内容介绍也可参考Robin E. Rider写的review。2. 关于集合论的历史，其实还有一本不那么好读的著作，José Ferreirós的《Labyrinth of Thought： A History of Set Theory and Its Role in Modern Mathematics》，个人觉得labyrinth这个词用的挺好，感兴趣的话，可以先看看R. Cooke写的review 。这是一本内容丰富的书，我自己出于兴趣偶尔翻翻，零零散散地看过一些，里面有一些挺有趣的“故事”，但又不能完全不带脑子去看故事，我个人觉得这本书并不适合零零散散地看，但你如果不是真的对相关的历史感兴趣，想认真地读下来应该是比较费时间的一件事情。最后，给我的感觉就是这本书很好，但估计没多少业余爱好者会看。3. 说道数学基础这个概念，不得不提的一个人就是Hilbert。大家都知道有一句广为流传的据说是Poincaré关于集合论的话“Later generations will regard Mengenlehre (set theory) as a disease from which one has recovered.”不管这句话是否真的有，从这个流传度多多少少能反映出集合论诞生之初很多数学家对这个新事物的态度。但Hilbert对于集合论的态度就非常“友善了”，虽然集合论理没有“Hilbert定理”，但Hilbert对其发展功不可没。更详细的描述可以参考Gregory H. Moore的文章Hilbert on the Infinite- The Role of Set Theory in the Evolution of Hilbert’s Thought ，关于公理化这件事情，还可以参考Foundations of Mathematics and Physics One Century After Hilbert，知道这本书是因为John C. BAEZ的文章。4. 关于Hilbert可以参考：《HILBERT》Reid，《David Hilbert’s Lectures on the Foundations of Arithmetic and Logic 1917-1933》。关于Cantor（集合论的创建者）可以参考《Georg Cantor: His Mathematics and Philosophy of the Infinite》，个人是比较喜欢这本书的封面的。5. 大家都知道ZFC（C是choice的意思），感兴趣的可以去翻翻Zermelo（ZFC中的Z）的传记：Heinz Dieter Ebbinghaus, Volker Peckhaus 《Ernst Zermelo - An Approach to His Life and Work》，关于Fraenkel（ZFC中的F）可以参考《Recollections of a Jewish Mathematician in Germany》，Fraenkel的学生Azriel Lévy关于集合论的工作可以参考Akihiro Kanamori的文章。还有一本最近出的书（我没看过）可供参考《Gödel’s Theorems and Zermelo’s Axioms》。6. 听过公理化的人就一定听过Gödel的著名工作。Gödel这个人的一生也是非常具有传奇色彩的，关于他的书很多(比如王浩先生的著作)，鉴于大多数我自己都没咋读过就不做推荐了。 哪种理论更适合作为数学的基础？ 回答1：试图作为数学基础的理论多了去了，类型论也有一堆，罗素类型论、Church带类型的Lambda演算、Martin-Lof类型论、HoTT之类的。。。集合论也有很多很多系统，ZFC、NBG、Quine的NF之类的。。。范畴论也有Lawvere的ETCS、CCAF之类的。。。更哲学的还有Mereology之类的。。。它们彼此之间相对一致性、表达力、证明力等的比较有各种各样的结果，不过没见过系统的综述，分散在各种论文里。。。只截取片段的对应也有Curry-Howard-Lambek对应这种漂亮的结果。。。不过，虽然都号称是作为“数学基础”，但是，各种“数学基础”从来都不是在同一个意义上讨论的，比如Penelope Maddy的这篇文章What do we want a foundation to do?就谈到了一堆标准：Risk Assessment, Metamathematical Corral, Generous Arena, Shared Standard, Proof Checking, Essential Guidance。。。HoTT肯定更擅长proof checking，范畴论肯定更擅长essential guidance。 普通人对于现代数学各个分支的理解难度，从高到低排名是怎样的？ 原链接回答1：我觉得最难理解的应该是最基础的：集合论(set theory)、模型论(model theory)、范畴论(category theory)、泛代数(universal algebra)还有证明论(proof theory)。这几可以说是最抽象的，毕竟最接近底层就越脱离常识，也和哲学越像。一般人连 ZFC 的 C 都用不上，哪能理解模型论学家搞个不可达基数(inaccessible cardinals)是要干什么？其次我觉得应该是代数学。代数本质上是抽象的，并且一般无法在现实中举出一个实质性的例子（比如几何学一般可以举嵌在 里的例子，分析学里很多函数也是可视或局部可视的），以至于不从公理和定义开始看的小朋友基本没有理解的基础。一般来讲，必须要从群(group)、环(ring)、域(field)一个个开始理解。随着结构的增加，我们有模(module)、线性空间(linear space)、张量代数(tensor algebra)、外代数(exterior algebra)、李代数(Lie aglebra)、合冲模(syzygy module)等等等等的代数结构，对于一个甚至没接触过群论的小朋友，后面这些是基本没有对他们解释的基础的。从上面一段我们已经看出，一个难理解的学科的(一个)特性在于，对于一个没有基础的小朋友，我们缺乏向他解释后面概念的方式。什么是好理解的呢？比如一个不知道流形(manifold)和向量从(vector bundle)定义的小朋友甚至有能力直接计算一些流型的曲率(curvature)，并且我知道很多学物理的小朋友都是这样的。那么再仔细想一想，能这么做有两个原因：1、这些数学结构是嵌在$\mathbb{R}^{n}$里的;2、这些数学结构是可视可想象的；甚至我觉得，上面这两个原因是同一个原因。很幸运，这之后要讲的数学分支里都有很大一部分是可视的。回答2：其实不能说“理解难度高低”，只能说不同分支的学习方式、思维方式是不一样的，给人的感觉也是不一样的。代数几何被认为难的主要原因是他有一套非常庞大的语言体系和知识体系。你如果去上代数几何的课就知道，第一个学期基本都在学习各种定义和基本的性质，你可以整整一个学期都在学什么是代数蔟，但是除了仿射空间和CP^n这种最基本的例子以外，你甚至没见过一个具体的、实实在在的代数簇的例子。你知道一个多项式方程定义了一个超曲面，但是整整一个学期你都没有处理过一个由具体的多项式定义的具体的超曲面。整整一个学期，你都在理解这套语言、这套机制；在你熟悉了这套语言之后，就可以开始干一些有趣的事情了。（注：有些教授上代数几何课也不完全会按照代数几何的那种标准讲法来讲。比如我上学期上的复代数几何，老师就不怎么注重严格性，讲了大量的例子，很多结论都没有证明，或者只是给了个证明的直观想法。。这种讲法的好处是，你终于知道代数几何到底在干些什么了，但是你却在细节方面就过不了关。很多结论你能理解大概的意思，但是却不会证。。）数论是一个神奇的分支。数论里面的很多结论讲的真的就是“正整数的性质”，所以真的是小学生都能理解。但是证明过程却可以用到很复杂的数学工具。比如今天早上听别人讲一个整数分解成平方和有多少种分法，然后是根据分法数目凑出了一个模形式，然后用模形式的理论去反过来求解原来的问题。PDE是被黑得很惨的一个学科。大部分黑点无非是水论文多什么的。我个人的看法是，PDE这个学科，入门并不算特别困难（所以浑水摸鱼的也多），但是真要做相关研究，内容可是相当、相当丰富的。大大小小的工程问题可以产生形形色色的微分方程，物理和数学本身也能产生大量的PDE。PDE要研究是研究不完的，而且不同的方程的处理方法又各有千秋。而且做PDE是真要自己认认真真去想、去算、去试的，需要很多硬功夫，并不像有些黑子黑的那么简单。组合也算是被黑的比较多的一个分支。组合问题的问题表述形式和数论有相似之处，就是很多问题都浅显易懂。比如说组合计数，说白了就是数数嘛～然后图论什么的，图谁不会画～然后组合里面似乎也喜欢折腾各种多项式、各种矩阵什么的，也都是看起来简单、做起来需要智商的问题。需要指出的是，组合不是初等数学，组合里面也可以用到很多高级数学工具（比如代数几何）。在数学的其他分支中，组合结构也非常常见，比如代数几何里面的tropical geometry。组合其实算是一种基本的数学结构。听别人说过：“数学家真正能操作的事情，其实就只有线性代数和组合（或许也可以加上微积分）”。数学家通过他们庞大的语言体系和工具体系，把一个个问题约化成更容易处理的问题，约化到最后，其实就是一些基本的数学结构。然后还有逻辑。逻辑在国内算是比较小众的方向，常常被人认为是非主流。其实在美国这边，很多学校数学系都有专门做逻辑的组。个人认为做逻辑需要脑子比较清楚、比较“能转”、对抽象概念和形式化推导有较强的耐受能力。另外逻辑是可以应用到其他数学分支的。我知道比较典型的应用有ultrafilter在组合当中的应用，还有model theory在valuation theory、anabelian geometry（对，就是望月新一搞的那一套anabelian geometry）中的应用。然后还有概率。概率总被认为是测度论的一个分支。。但是你真正去学概率的话，会觉得他和实分析的操作方式还是不太一样的。。虽然说随机变量就是可测函数，求期望就是求积分，但是你真正去操作随机变量的时候，还是会觉得把它当成一个“随机取值的数”在认知上更容易接受一些。。概率论本身就代表了一种看待问题的新角度，而且和数学其他分支也有联系，比如我知道有什么 概率几何 之类的东西。最后讲讲我学的微分几何。微分几何是一个比较古老的分支，在高斯那个年代主要是研究曲线曲面的，在被黎曼嘉当陈省身等诸位大神层层升级之后，又被物理学（比如广义相对论和弦论）用力推了一波，现在已经变成研究抽象的空间（比如高维的流形、orbifold、Alexander space等等）上比较抽象的几何性质、几何量了。不过微分几何的抽象程度还是远远不及代数几何，基本本科生学一学黎曼几何之后就可以上手看论文了。主要的难度还是在技术和idea。几何分析大量依赖PDE的技术，其他方面的则要求对拓扑、李群李代数之类的工具比较熟悉。OK，写到这里我光荣宣布本答案烂尾了～现代数学体系极为庞大，按大方向分可以分出十几个大方向，下面细分小方向、子问题可以分出几十个上百个。要对他们系统阐述远远超出我的能力范围。真有兴趣的人可以去看看《普林斯顿数学指南》、《一万个科学难题之数学卷》等（有些人强行编出来的）数学类百科全书，以便一窥现代数学之概貌。在知乎这个平台上，我觉得更靠谱的做法可能是不同人具体介绍自己的研究方向（和目前关心的问题），这样才方便提供更专业、更有价值的信息。我已经写过一篇极粗略的介绍微分几何的文章了，没什么要多说的。 数学最基础的知识是什么？ 原链接回答1：从现代数学的构造角度看，集合论可被当作基石。但集合是各种数学结构的推广，所以集合论不适合被当做数学学习的起点。如同其它学科，从特殊情况入手再进行推广是一种合适的路线。而对于数学，自然数就是一种合适的入口。把自然数的运算进行推广就能发掘出代数、群论以及范畴论。而把0和无穷大的概念深究就能接触到数学分析。即使不往数学方向发展，自然数也和现实生活更加贴近，毕竟数学本身就是从计数问题发展出来的。当然计数问题继续深入也会发展出组合学和统计学。综上，集合论是构造数学知识体系的基石，而自然数一个合理的入口。 抽象代数、同调代数、交换代数、代数拓扑有什么关系？ 原链接 初中生如何安排数学学习?已读Bourbaki？ 原链接回答1：作为一个布尔巴基骨灰粉，也许我可以分享一些我的看法。首先，楼主的数学天赋是毋庸置疑的。在肯定这一点的同时，需要指出以下几点：1、布尔巴基精神的精华其实是前六本（当然不是说交换代数和李群李代数就没那么好），后来的书是新一辈成员写的，限于种种限制，恐怕与布尔巴基的精神未必一致（比如说前六本从逻辑上说是完全自洽的，但后边的书放弃了这一标志性的要求，就题主目前的状况看，李群里的一些结论就很难完全在布尔巴基的体系里自洽的证出，比如说所有$C^1$的李群都有唯一一个相容的解析结构，因为布尔巴基的流形的著作只有结论的总结而没有证明）。前六本的重要性并不在于它可以教给你前沿的数学知识（实际上它往往不能），而是在于它可以让你养成一种好的数学品味和态度，以及一些非常规的，使你可以在以后做研究遇到瓶颈时可以仍然泰然处之的独特视角。私以为，这里面最重要的一点就是本质主义，布尔巴基所追求的一般性只是本质主义自然的产物。在读的时候，最好有自己的思考和偏好，比如说对某一块内容的传统讲法的强烈不满（楼主说读了交换代数，那么第四章讲准素分解的内容就是一个极好的例子，因为通常的书，即使权威到Eisenbud这样的，相关的内容跟布尔巴基的讲法比都远远不及（no offence to Eisenbud, but Bourbaki is just too many excellent people, Chevalley, Samuel, Serre, Cartier etc.），PS. 交换代数后面讲局部环的精华内容恐怕现在还只有法文版，楼主应该没有读到，当然EGA 4里也会有所涉及，但真正想初步读懂，比如说valuation与局部域和相关的Haar测度及抽象调和分析乃至进一步与Tate的数论博士论文的联系，恕我直言，楼主还欠火侯）。2、布尔巴基实际上是写给数学家重新学数学的。很多证明（比如说用一致空间的Mittag-Leffler定理来证单复变函数里的同名定理），只有在对数学中很多理论和技巧的复杂繁琐乃至为了逻辑上正确而不美观有了充分的认识后才能欣赏，而且好多这样的东西都写在不显眼的例子里（刚才提到的ML定理就是），它们甚至可以毫无困难的推广到一般得多的情形（比如说ML的布尔巴基的纯点集拓扑证明完全适用于一般的黎曼面），但这些往往要求读者不仅具备足够的知识，而且要有长期独立，有充分根据的思考的习惯。3、要成为布尔巴基的继承者，现在恐怕必须要先学好法语，仅仅使用英语是完全不够的（英文版交换代数的第一道习题就是错的，而法语的新版就没有问题），一方面是因为老的布尔巴基著作很多都未翻译成英语，另一方面新的著作（比如今年刚刚出版了代数拓扑的前四章)仍旧用法语写成。4、Dieudonné 的分析书是很好，但是看完前两本就够了（甚至第二本也不是很必要），该书比别的处理好的地方基本都在第一本，后面的内容虽然也还好，但是Dieudonné已无法按照第一本的水准来处理了（且不说后几卷只有法语版），比如说测度论只讲了局部紧可度量的情形，完全不如去读布尔巴基的积分论和谱论。如果你是想按照布尔巴基的精神理解数学，不若多花点时间把正常学校的本科课程先大概学一边（比如华罗庚的高数引论），然后回过头了认真读布尔巴基，相信更有收获的多。至于其后的关于微分算子的部分，我虽然不懂，但绝对相信Hormander要好得多。事实上，Dieudonné这套书是因为布尔巴基一直没有完成对分析学令人满意的系统论著而产生的，而布尔巴基没有完成分析著述（它当然很好地，甚至是无可匹敌地论述了一般拓扑，拓扑向量空间，很好的且富有争议的讲了积分论（因为并不是从测度讲起的），中规中居的讲了单变量微积分和一点特殊函数论）是有原因的！分析学如此深刻和庞大，即使伟大如Dieudonné，也并不能很好地处理其各个方面。5、至于EGA，现在去读可能还略早。虽然Grothendieck明确地在EGA的前言中告诉读者对经典代数几何无任何要求，甚至对经典代数几何过于熟悉会阻碍学习概形的语言，但是同时他要求读者熟悉Godement的topologie algébrique et théorie des faisceaux，他自己的Sur quelques points d’algèbre homologique和Cartan &amp; Eilenberg的Homological algebra或者和这些同等程度的内容。另外有玩笑说EGA是为了读懂Serre的Faisceaux algébriques cohérents而写出来的，所以先读读Serre的这篇文章是很有好处的。6、我自己也读过一部分EGA，但是我不得不说任何一个负责的博士生导师恐怕都不会严肃地主动要求自己的学生仔细研读EGA并以此为主业。一方面是因为EGA太长（其实只有不到2000页），另一方面想要作研究，按照EGA的学法太慢，至少还要再读很多SGA的内容才算入了门。但是如果题主如此年轻且确实想做偏算术的代数几何，我建议读博之前啃完EGA绝对利远大于弊。但是从功利的角度讲，现在做算术几何，数论之类的很难拿到职位，因为有很多有才华有天赋的年轻人都在扎堆做Langlands，然而这个方向未来恐怕没有多少职位可以放出来。以上是我对题主读了的和想读的一些书的看法。再说说和这些书关系不大的。首先数学并不只是代数几何这一个主流方向，老的布尔巴基对其成员的著名要求是要对一切（好的）数学感兴趣，这一点从布尔巴基讨论班（至今仍活跃在巴黎的庞加莱研究所）的报告人必须讲自己不熟悉的内容（至少以前是这样）可以看出来。退一步讲，代数几何之所以重要，很大一部分原因是因为它和其他数学分支都有联系（比如我是做非交换几何中的量子群的，我的领域最早的发起人之一Drinfield就是基于代数群的表示的考虑才引入这一研究对象的）。我讲这些的目的是想建议楼主年轻时不必急着把方向定下来，多看些书，多做些思考，多跟别人交流，总是没有坏处的（当然有很多很好的数学家很早就确定了自己要做什么并且很早就做出了出色的工作，我并不是说楼主不要学他们，只是要指出一个布尔巴基风格的数学家绝不应该满足于一个狭小的领域，而应该着眼于数学的整体！）。再说上学的问题，因为个人的经历，像之前有的答案一样，我推荐楼主可以尝试一下考科大的少年班。这不是说科大可以给你一流的数学教育，而是说如果成功的话可以以此为跳板尽快考巴黎高师，毕竟法国甚至巴黎才是布尔巴基精神的核心。我对美国的状况不了解，但是我基本上可以保证一个好的数学家很难找得到在数学上可以和巴黎平起平坐的地方了（比如说巴黎六大和七大的imj-prg研究所有两百多个终身职位的数学家，他们的研究水平国际公认，且总的来书研究面非常宽广，基本上做什么的都有）。最后分享一些学习方法上的看法。学得快固然好，然而从长远看，这并不那么重要。学得扎实要重要的多，尤其是基础的部分，这往往成为决定一个数学家可以走多远的重要因素之一（所有的Fields奖得主都有很强的technique)。大家反感名词党，但是有些名词党看上去却还混得不错，有些这样的人可以很快地拿到不错的成绩，甚至很快地拿到学位毕业，但是最后真正能做出一流工作的即使有，也寥寥无几。这就是为什么我强烈推荐年轻的数学工作者如果有可能多读一读布尔巴基。在打下一个真正好的数学基础的过程中，我想数学品味和鉴赏力自然没有问题了（至少读布尔巴基会是这样，尽管它的内容确实有一部分很过时，但是应该记住，布尔巴基是用来relearn，而不是用来learning的）。另外需要注意的是要慢慢养成自己做数学的风格，这是往往是更加困难的。好的数学家之间，即使有很密切的师承关系（比如Grothendieck和Deligne， Gauss和Riemann等），对数学的看法也往往千差万别。这大概是因为非凡的数学工作往往需要独特的数学视角。不得不说，好的数学风格的形成是一个漫长的过程，甚至可能持续整个数学生涯，但是好的风格的共同点是一定要有独立持续深入有根据的思考的习惯（甚至有时候你会深信自己就是全世界最懂这一部分数学的人，因为你完全明白理解到这个地步要付出什么样的努力，有什么样的机遇，需要哪些灵感），而这一点是任何学校都不能直接交给我们的，我们必须自己付出长期的努力。 学习古典微分几何的意义在哪 回答1：如果从学黎曼几何的角度，不是必须学，但是曲面论其实也不一定非从度量的角度学。2维是个特殊的维度，曲面都是局部共形平坦的（等温坐标存在性），度量的共形类跟曲面上的复结构一一对应——于是我们得到了黎曼曲面。黎曼曲面既是复一维的复流形，也是2维的黎曼流形；复分析的技巧可以应用在黎曼面上。黎曼面也是1维的光滑代数簇，又是代数几何中的最基本几何对象。黎曼面上最重要的定理，Riemann-Roch，其实已经可以看出代数几何思维的一些雏形。所以，我想说的重点是，认真学习曲面论，你不仅仅能学到古典微分几何，也能学到最基本的复几何和代数几何，其实也可以从曲面出发学习（最初等的）辛几何。所以这其实是整个现代几何学的一个入口。另外，单纯从微分几何自身的角度来说，$R^3$中的曲面论还有很多未解决的问题。典型的比如极小曲面，包括$R^3$中的整张极小曲面和$B^3$中的自由边界极小曲面，都有很多很多未解决的问题，现在还是研究的热点。最后，强烈建议非数学专业理工科学生去学学古典曲面论，以及黎曼曲面论。这是真正看得见摸得着的数学，而且在工程里面应该也有实际应用。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Flib%2Fpace%2Fpace-theme-center-radar.min.css</url>
    <content type="text"><![CDATA[.pace,.pace .pace-activity{z-index:2000;height:90px;width:90px}.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none;position:fixed;margin:auto;top:0;left:0;right:0;bottom:0}.pace.pace-inactive .pace-activity{display:none}.pace .pace-activity,.pace .pace-activity:before{position:absolute;display:block;border-color:#29d transparent transparent;border-radius:50%}.pace .pace-activity{left:-30px;top:-30px;border-width:30px;border-style:double;-webkit-animation:spin 1s linear infinite;-moz-animation:spin 1s linear infinite;-o-animation:spin 1s linear infinite;animation:spin 1s linear infinite}.pace .pace-activity:before{content:' ';top:10px;left:10px;height:50px;width:50px;border-width:10px;border-style:solid}@-webkit-keyframes spin{100%{-webkit-transform:rotate(359deg)}}@-moz-keyframes spin{100%{-moz-transform:rotate(359deg)}}@-o-keyframes spin{100%{-moz-transform:rotate(359deg)}}@keyframes spin{100%{transform:rotate(359deg)}}]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Flib%2Fpace%2Fpace-theme-fill-left.min.css</url>
    <content type="text"><![CDATA[.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background-color:rgba(34,153,221,.19999999999999996);position:fixed;z-index:-1;top:0;right:100%;bottom:0;width:100%}]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Flib%2Fpace%2Fpace-theme-center-circle.min.css</url>
    <content type="text"><![CDATA[.pace,.pace .pace-progress{z-index:2000;left:0;top:0;height:6rem}.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none;-webkit-perspective:12rem;-moz-perspective:12rem;-ms-perspective:12rem;-o-perspective:12rem;perspective:12rem;position:fixed;width:6rem;margin:auto;right:0;bottom:0}.pace.pace-inactive .pace-progress{display:none}.pace .pace-progress{display:block;position:absolute;width:6rem!important;line-height:6rem;font-size:2rem;border-radius:50%;background:rgba(34,153,221,.8);color:#fff;font-family:"Helvetica Neue",sans-serif;font-weight:100;text-align:center;-webkit-animation:pace-theme-center-circle-spin linear infinite 2s;-moz-animation:pace-theme-center-circle-spin linear infinite 2s;-ms-animation:pace-theme-center-circle-spin linear infinite 2s;-o-animation:pace-theme-center-circle-spin linear infinite 2s;animation:pace-theme-center-circle-spin linear infinite 2s;-webkit-transform-style:preserve-3d;-moz-transform-style:preserve-3d;-ms-transform-style:preserve-3d;-o-transform-style:preserve-3d;transform-style:preserve-3d}.pace .pace-progress:after{content:attr(data-progress-text);display:block}@-webkit-keyframes pace-theme-center-circle-spin{from{-webkit-transform:rotateY(0)}to{-webkit-transform:rotateY(360deg)}}@-moz-keyframes pace-theme-center-circle-spin{from{-moz-transform:rotateY(0)}to{-moz-transform:rotateY(360deg)}}@-ms-keyframes pace-theme-center-circle-spin{from{-ms-transform:rotateY(0)}to{-ms-transform:rotateY(360deg)}}@-o-keyframes pace-theme-center-circle-spin{from{-o-transform:rotateY(0)}to{-o-transform:rotateY(360deg)}}@keyframes pace-theme-center-circle-spin{from{transform:rotateY(0)}to{transform:rotateY(360deg)}}]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Flib%2Fpace%2Fpace-theme-loading-bar.min.css</url>
    <content type="text"><![CDATA[.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none;-webkit-box-sizing:border-box;-moz-box-sizing:border-box;-ms-box-sizing:border-box;-o-box-sizing:border-box;box-sizing:border-box;-webkit-border-radius:10px;-moz-border-radius:10px;border-radius:10px;-webkit-background-clip:padding-box;-moz-background-clip:padding;background-clip:padding-box;z-index:2000;position:fixed;margin:auto;top:12px;left:0;right:0;bottom:0;width:200px;height:50px;overflow:hidden}.pace .pace-progress{-webkit-box-sizing:border-box;-moz-box-sizing:border-box;-ms-box-sizing:border-box;-o-box-sizing:border-box;box-sizing:border-box;-webkit-border-radius:2px;-moz-border-radius:2px;border-radius:2px;-webkit-background-clip:padding-box;-moz-background-clip:padding;-webkit-transform:translate3d(0,0,0);transform:translate3d(0,0,0);display:block;position:absolute;right:100%;margin-right:-7px;width:93%;top:7px;height:14px;font-size:12px;background:#29d;color:#29d;line-height:60px;font-weight:700;font-family:Helvetica,Arial,"Lucida Grande",sans-serif;-webkit-box-shadow:120px 0 #fff,240px 0 #fff;-ms-box-shadow:120px 0 #fff,240px 0 #fff;box-shadow:120px 0 #fff,240px 0 #fff}.pace .pace-progress:after{content:attr(data-progress-text);display:inline-block;position:fixed;width:45px;text-align:right;right:0;padding-right:16px;top:4px}.pace .pace-progress[data-progress-text="0%"]:after{right:-200px}.pace .pace-progress[data-progress-text="1%"]:after{right:-198.14px}.pace .pace-progress[data-progress-text="2%"]:after{right:-196.28px}.pace .pace-progress[data-progress-text="3%"]:after{right:-194.42px}.pace .pace-progress[data-progress-text="4%"]:after{right:-192.56px}.pace .pace-progress[data-progress-text="5%"]:after{right:-190.7px}.pace .pace-progress[data-progress-text="6%"]:after{right:-188.84px}.pace .pace-progress[data-progress-text="7%"]:after{right:-186.98px}.pace .pace-progress[data-progress-text="8%"]:after{right:-185.12px}.pace .pace-progress[data-progress-text="9%"]:after{right:-183.26px}.pace .pace-progress[data-progress-text="10%"]:after{right:-181.4px}.pace .pace-progress[data-progress-text="11%"]:after{right:-179.54px}.pace .pace-progress[data-progress-text="12%"]:after{right:-177.68px}.pace .pace-progress[data-progress-text="13%"]:after{right:-175.82px}.pace .pace-progress[data-progress-text="14%"]:after{right:-173.96px}.pace .pace-progress[data-progress-text="15%"]:after{right:-172.1px}.pace .pace-progress[data-progress-text="16%"]:after{right:-170.24px}.pace .pace-progress[data-progress-text="17%"]:after{right:-168.38px}.pace .pace-progress[data-progress-text="18%"]:after{right:-166.52px}.pace .pace-progress[data-progress-text="19%"]:after{right:-164.66px}.pace .pace-progress[data-progress-text="20%"]:after{right:-162.8px}.pace .pace-progress[data-progress-text="21%"]:after{right:-160.94px}.pace .pace-progress[data-progress-text="22%"]:after{right:-159.08px}.pace .pace-progress[data-progress-text="23%"]:after{right:-157.22px}.pace .pace-progress[data-progress-text="24%"]:after{right:-155.36px}.pace .pace-progress[data-progress-text="25%"]:after{right:-153.5px}.pace .pace-progress[data-progress-text="26%"]:after{right:-151.64px}.pace .pace-progress[data-progress-text="27%"]:after{right:-149.78px}.pace .pace-progress[data-progress-text="28%"]:after{right:-147.92px}.pace .pace-progress[data-progress-text="29%"]:after{right:-146.06px}.pace .pace-progress[data-progress-text="30%"]:after{right:-144.2px}.pace .pace-progress[data-progress-text="31%"]:after{right:-142.34px}.pace .pace-progress[data-progress-text="32%"]:after{right:-140.48px}.pace .pace-progress[data-progress-text="33%"]:after{right:-138.62px}.pace .pace-progress[data-progress-text="34%"]:after{right:-136.76px}.pace .pace-progress[data-progress-text="35%"]:after{right:-134.9px}.pace .pace-progress[data-progress-text="36%"]:after{right:-133.04px}.pace .pace-progress[data-progress-text="37%"]:after{right:-131.18px}.pace .pace-progress[data-progress-text="38%"]:after{right:-129.32px}.pace .pace-progress[data-progress-text="39%"]:after{right:-127.46px}.pace .pace-progress[data-progress-text="40%"]:after{right:-125.6px}.pace .pace-progress[data-progress-text="41%"]:after{right:-123.74px}.pace .pace-progress[data-progress-text="42%"]:after{right:-121.88px}.pace .pace-progress[data-progress-text="43%"]:after{right:-120.02px}.pace .pace-progress[data-progress-text="44%"]:after{right:-118.16px}.pace .pace-progress[data-progress-text="45%"]:after{right:-116.3px}.pace .pace-progress[data-progress-text="46%"]:after{right:-114.44px}.pace .pace-progress[data-progress-text="47%"]:after{right:-112.58px}.pace .pace-progress[data-progress-text="48%"]:after{right:-110.72px}.pace .pace-progress[data-progress-text="49%"]:after{right:-108.86px}.pace .pace-progress[data-progress-text="50%"]:after{right:-107px}.pace .pace-progress[data-progress-text="51%"]:after{right:-105.14px}.pace .pace-progress[data-progress-text="52%"]:after{right:-103.28px}.pace .pace-progress[data-progress-text="53%"]:after{right:-101.42px}.pace .pace-progress[data-progress-text="54%"]:after{right:-99.56px}.pace .pace-progress[data-progress-text="55%"]:after{right:-97.7px}.pace .pace-progress[data-progress-text="56%"]:after{right:-95.84px}.pace .pace-progress[data-progress-text="57%"]:after{right:-93.98px}.pace .pace-progress[data-progress-text="58%"]:after{right:-92.12px}.pace .pace-progress[data-progress-text="59%"]:after{right:-90.26px}.pace .pace-progress[data-progress-text="60%"]:after{right:-88.4px}.pace .pace-progress[data-progress-text="61%"]:after{right:-86.54px}.pace .pace-progress[data-progress-text="62%"]:after{right:-84.68px}.pace .pace-progress[data-progress-text="63%"]:after{right:-82.82px}.pace .pace-progress[data-progress-text="64%"]:after{right:-80.96px}.pace .pace-progress[data-progress-text="65%"]:after{right:-79.1px}.pace .pace-progress[data-progress-text="66%"]:after{right:-77.24px}.pace .pace-progress[data-progress-text="67%"]:after{right:-75.38px}.pace .pace-progress[data-progress-text="68%"]:after{right:-73.52px}.pace .pace-progress[data-progress-text="69%"]:after{right:-71.66px}.pace .pace-progress[data-progress-text="70%"]:after{right:-69.8px}.pace .pace-progress[data-progress-text="71%"]:after{right:-67.94px}.pace .pace-progress[data-progress-text="72%"]:after{right:-66.08px}.pace .pace-progress[data-progress-text="73%"]:after{right:-64.22px}.pace .pace-progress[data-progress-text="74%"]:after{right:-62.36px}.pace .pace-progress[data-progress-text="75%"]:after{right:-60.5px}.pace .pace-progress[data-progress-text="76%"]:after{right:-58.64px}.pace .pace-progress[data-progress-text="77%"]:after{right:-56.78px}.pace .pace-progress[data-progress-text="78%"]:after{right:-54.92px}.pace .pace-progress[data-progress-text="79%"]:after{right:-53.06px}.pace .pace-progress[data-progress-text="80%"]:after{right:-51.2px}.pace .pace-progress[data-progress-text="81%"]:after{right:-49.34px}.pace .pace-progress[data-progress-text="82%"]:after{right:-47.48px}.pace .pace-progress[data-progress-text="83%"]:after{right:-45.62px}.pace .pace-progress[data-progress-text="84%"]:after{right:-43.76px}.pace .pace-progress[data-progress-text="85%"]:after{right:-41.9px}.pace .pace-progress[data-progress-text="86%"]:after{right:-40.04px}.pace .pace-progress[data-progress-text="87%"]:after{right:-38.18px}.pace .pace-progress[data-progress-text="88%"]:after{right:-36.32px}.pace .pace-progress[data-progress-text="89%"]:after{right:-34.46px}.pace .pace-progress[data-progress-text="90%"]:after{right:-32.6px}.pace .pace-progress[data-progress-text="91%"]:after{right:-30.74px}.pace .pace-progress[data-progress-text="92%"]:after{right:-28.88px}.pace .pace-progress[data-progress-text="93%"]:after{right:-27.02px}.pace .pace-progress[data-progress-text="94%"]:after{right:-25.16px}.pace .pace-progress[data-progress-text="95%"]:after{right:-23.3px}.pace .pace-progress[data-progress-text="96%"]:after{right:-21.44px}.pace .pace-progress[data-progress-text="97%"]:after{right:-19.58px}.pace .pace-progress[data-progress-text="98%"]:after{right:-17.72px}.pace .pace-progress[data-progress-text="99%"]:after{right:-15.86px}.pace .pace-progress[data-progress-text="100%"]:after{right:-14px}.pace .pace-activity{position:absolute;width:100%;height:28px;z-index:2001;box-shadow:inset 0 0 0 2px #29d,inset 0 0 0 7px #FFF;border-radius:10px}.pace.pace-inactive{display:none}]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Flib%2Fpace%2Fpace-theme-corner-indicator.min.css</url>
    <content type="text"><![CDATA[.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace .pace-activity{display:block;position:fixed;z-index:2000;top:0;right:0;width:300px;height:300px;background:#29d;-webkit-transition:-webkit-transform .3s;transition:transform .3s;-webkit-transform:translateX(100%) translateY(-100%) rotate(45deg);transform:translateX(100%) translateY(-100%) rotate(45deg);pointer-events:none}.pace.pace-active .pace-activity{-webkit-transform:translateX(50%) translateY(-50%) rotate(45deg);transform:translateX(50%) translateY(-50%) rotate(45deg)}.pace .pace-activity::after,.pace .pace-activity::before{-moz-box-sizing:border-box;box-sizing:border-box;position:absolute;bottom:30px;left:50%;display:block;border:5px solid #fff;border-radius:50%;content:''}.pace .pace-activity::before{margin-left:-40px;width:80px;height:80px;border-right-color:rgba(0,0,0,.2);border-left-color:rgba(0,0,0,.2);-webkit-animation:pace-theme-corner-indicator-spin 3s linear infinite;animation:pace-theme-corner-indicator-spin 3s linear infinite}.pace .pace-activity::after{bottom:50px;margin-left:-20px;width:40px;height:40px;border-top-color:rgba(0,0,0,.2);border-bottom-color:rgba(0,0,0,.2);-webkit-animation:pace-theme-corner-indicator-spin 1s linear infinite;animation:pace-theme-corner-indicator-spin 1s linear infinite}@-webkit-keyframes pace-theme-corner-indicator-spin{0%{-webkit-transform:rotate(0)}100%{-webkit-transform:rotate(359deg)}}@keyframes pace-theme-corner-indicator-spin{0%{transform:rotate(0)}100%{transform:rotate(359deg)}}]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Flib%2Fpace%2Fpace-theme-center-simple.min.css</url>
    <content type="text"><![CDATA[.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none;z-index:2000;position:fixed;margin:auto;top:0;left:0;right:0;bottom:0;height:5px;width:200px;background:#fff;border:1px solid #29d;overflow:hidden}.pace .pace-progress{-webkit-box-sizing:border-box;-moz-box-sizing:border-box;-ms-box-sizing:border-box;-o-box-sizing:border-box;box-sizing:border-box;-webkit-transform:translate3d(0,0,0);-moz-transform:translate3d(0,0,0);-ms-transform:translate3d(0,0,0);-o-transform:translate3d(0,0,0);transform:translate3d(0,0,0);max-width:200px;z-index:2000;display:block;position:absolute;top:0;right:100%;height:100%;width:100%;background:#29d}.pace.pace-inactive{display:none}]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Flib%2Fpace%2Fpace-theme-flash.min.css</url>
    <content type="text"><![CDATA[.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#29d;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}.pace .pace-progress-inner{display:block;position:absolute;right:0;width:100px;height:100%;box-shadow:0 0 10px #29d,0 0 5px #29d;opacity:1;-webkit-transform:rotate(3deg) translate(0,-4px);-moz-transform:rotate(3deg) translate(0,-4px);-ms-transform:rotate(3deg) translate(0,-4px);-o-transform:rotate(3deg) translate(0,-4px);transform:rotate(3deg) translate(0,-4px)}.pace .pace-activity{display:block;position:fixed;z-index:2000;top:15px;right:15px;width:14px;height:14px;border:2px solid transparent;border-top-color:#29d;border-left-color:#29d;border-radius:10px;-webkit-animation:pace-spinner .4s linear infinite;-moz-animation:pace-spinner .4s linear infinite;-ms-animation:pace-spinner .4s linear infinite;-o-animation:pace-spinner .4s linear infinite;animation:pace-spinner .4s linear infinite}@-webkit-keyframes pace-spinner{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@-moz-keyframes pace-spinner{0%{-moz-transform:rotate(0);transform:rotate(0)}100%{-moz-transform:rotate(360deg);transform:rotate(360deg)}}@-o-keyframes pace-spinner{0%{-o-transform:rotate(0);transform:rotate(0)}100%{-o-transform:rotate(360deg);transform:rotate(360deg)}}@-ms-keyframes pace-spinner{0%{-ms-transform:rotate(0);transform:rotate(0)}100%{-ms-transform:rotate(360deg);transform:rotate(360deg)}}@keyframes pace-spinner{0%{transform:rotate(0)}100%{transform:rotate(360deg)}}]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Flib%2Fpace%2Fpace-theme-mac-osx.min.css</url>
    <content type="text"><![CDATA[.pace,.pace .pace-progress{width:100%;height:12px;overflow:hidden}.pace,.pace .pace-activity{position:fixed;top:0;left:0}.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none;z-index:2000;background:#fff}.pace-inactive{display:none}.pace .pace-progress{background-color:#0087E1;position:fixed;top:0;right:100%;-webkit-border-radius:0 0 4px;-moz-border-radius:0 0 4px;-o-border-radius:0 0 4px;border-radius:0 0 4px;-webkit-box-shadow:inset -1px 0 #00558F,inset 0 -1px #00558F,inset 0 2px rgba(255,255,255,.5),inset 0 6px rgba(255,255,255,.3);-moz-box-shadow:inset -1px 0 #00558F,inset 0 -1px #00558F,inset 0 2px rgba(255,255,255,.5),inset 0 6px rgba(255,255,255,.3);-o-box-shadow:inset -1px 0 #00558F,inset 0 -1px #00558F,inset 0 2px rgba(255,255,255,.5),inset 0 6px rgba(255,255,255,.3);box-shadow:inset -1px 0 #00558F,inset 0 -1px #00558F,inset 0 2px rgba(255,255,255,.5),inset 0 6px rgba(255,255,255,.3)}.pace .pace-activity{right:-28px;bottom:0;-webkit-background-image:radial-gradient(rgba(255,255,255,.65) 0,rgba(255,255,255,.15) 100%);-moz-background-image:radial-gradient(rgba(255,255,255,.65) 0,rgba(255,255,255,.15) 100%);-o-background-image:radial-gradient(rgba(255,255,255,.65) 0,rgba(255,255,255,.15) 100%);background-image:radial-gradient(rgba(255,255,255,.65) 0,rgba(255,255,255,.15) 100%);-webkit-background-size:28px 100%;-moz-background-size:28px 100%;-o-background-size:28px 100%;background-size:28px 100%;-webkit-animation:pace-theme-mac-osx-motion .5s linear infinite;-moz-animation:pace-theme-mac-osx-motion .5s linear infinite;-ms-animation:pace-theme-mac-osx-motion .5s linear infinite;-o-animation:pace-theme-mac-osx-motion .5s linear infinite;animation:pace-theme-mac-osx-motion .5s linear infinite}@-webkit-keyframes pace-theme-mac-osx-motion{0%{-webkit-transform:none;transform:none}100%{-webkit-transform:translate(-28px,0);transform:translate(-28px,0)}}@-moz-keyframes pace-theme-mac-osx-motion{0%{-moz-transform:none;transform:none}100%{-moz-transform:translate(-28px,0);transform:translate(-28px,0)}}@-o-keyframes pace-theme-mac-osx-motion{0%{-o-transform:none;transform:none}100%{-o-transform:translate(-28px,0);transform:translate(-28px,0)}}@-ms-keyframes pace-theme-mac-osx-motion{0%{-ms-transform:none;transform:none}100%{-ms-transform:translate(-28px,0);transform:translate(-28px,0)}}@keyframes pace-theme-mac-osx-motion{0%{transform:none}100%{transform:translate(-28px,0)}}]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Flib%2Fpace%2Fpace-theme-minimal.min.css</url>
    <content type="text"><![CDATA[.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#29d;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Flib%2Fpace%2Fpace.min.js</url>
    <content type="text"><![CDATA[/*! pace 1.0.2 */ (function(){var a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X=[].slice,Y={}.hasOwnProperty,Z=function(a,b){function c(){this.constructor=a}for(var d in b)Y.call(b,d)&&(a[d]=b[d]);return c.prototype=b.prototype,a.prototype=new c,a.__super__=b.prototype,a},$=[].indexOf||function(a){for(var b=0,c=this.length;c>b;b++)if(b in this&&this[b]===a)return b;return-1};for(u={catchupTime:100,initialRate:.03,minTime:250,ghostTime:100,maxProgressPerFrame:20,easeFactor:1.25,startOnPageLoad:!0,restartOnPushState:!0,restartOnRequestAfter:500,target:"body",elements:{checkInterval:100,selectors:["body"]},eventLag:{minSamples:10,sampleCount:3,lagThreshold:3},ajax:{trackMethods:["GET"],trackWebSockets:!0,ignoreURLs:[]}},C=function(){var a;return null!=(a="undefined"!=typeof performance&&null!==performance&&"function"==typeof performance.now?performance.now():void 0)?a:+new Date},E=window.requestAnimationFrame||window.mozRequestAnimationFrame||window.webkitRequestAnimationFrame||window.msRequestAnimationFrame,t=window.cancelAnimationFrame||window.mozCancelAnimationFrame,null==E&&(E=function(a){return setTimeout(a,50)},t=function(a){return clearTimeout(a)}),G=function(a){var b,c;return b=C(),(c=function(){var d;return d=C()-b,d>=33?(b=C(),a(d,function(){return E(c)})):setTimeout(c,33-d)})()},F=function(){var a,b,c;return c=arguments[0],b=arguments[1],a=3f;f++)if(c=d[f])for(a in c)Y.call(c,a)&&(e=c[a],null!=b[a]&&"object"==typeof b[a]&&null!=e&&"object"==typeof e?v(b[a],e):b[a]=e);return b},q=function(a){var b,c,d,e,f;for(c=b=0,e=0,f=a.length;f>e;e++)d=a[e],c+=Math.abs(d),b++;return c/b},x=function(a,b){var c,d,e;if(null==a&&(a="options"),null==b&&(b=!0),e=document.querySelector("[data-pace-"+a+"]")){if(c=e.getAttribute("data-pace-"+a),!b)return c;try{return JSON.parse(c)}catch(f){return d=f,"undefined"!=typeof console&&null!==console?console.error("Error parsing inline pace options",d):void 0}}},g=function(){function a(){}return a.prototype.on=function(a,b,c,d){var e;return null==d&&(d=!1),null==this.bindings&&(this.bindings={}),null==(e=this.bindings)[a]&&(e[a]=[]),this.bindings[a].push({handler:b,ctx:c,once:d})},a.prototype.once=function(a,b,c){return this.on(a,b,c,!0)},a.prototype.off=function(a,b){var c,d,e;if(null!=(null!=(d=this.bindings)?d[a]:void 0)){if(null==b)return delete this.bindings[a];for(c=0,e=[];cQ;Q++)K=U[Q],D[K]===!0&&(D[K]=u[K]);i=function(a){function b(){return V=b.__super__.constructor.apply(this,arguments)}return Z(b,a),b}(Error),b=function(){function a(){this.progress=0}return a.prototype.getElement=function(){var a;if(null==this.el){if(a=document.querySelector(D.target),!a)throw new i;this.el=document.createElement("div"),this.el.className="pace pace-active",document.body.className=document.body.className.replace(/pace-done/g,""),document.body.className+=" pace-running",this.el.innerHTML='\n \n\n',null!=a.firstChild?a.insertBefore(this.el,a.firstChild):a.appendChild(this.el)}return this.el},a.prototype.finish=function(){var a;return a=this.getElement(),a.className=a.className.replace("pace-active",""),a.className+=" pace-inactive",document.body.className=document.body.className.replace("pace-running",""),document.body.className+=" pace-done"},a.prototype.update=function(a){return this.progress=a,this.render()},a.prototype.destroy=function(){try{this.getElement().parentNode.removeChild(this.getElement())}catch(a){i=a}return this.el=void 0},a.prototype.render=function(){var a,b,c,d,e,f,g;if(null==document.querySelector(D.target))return!1;for(a=this.getElement(),d="translate3d("+this.progress+"%, 0, 0)",g=["webkitTransform","msTransform","transform"],e=0,f=g.length;f>e;e++)b=g[e],a.children[0].style[b]=d;return(!this.lastRenderedProgress||this.lastRenderedProgress|0!==this.progress|0)&&(a.children[0].setAttribute("data-progress-text",""+(0|this.progress)+"%"),this.progress>=100?c="99":(c=this.progress=100},a}(),h=function(){function a(){this.bindings={}}return a.prototype.trigger=function(a,b){var c,d,e,f,g;if(null!=this.bindings[a]){for(f=this.bindings[a],g=[],d=0,e=f.length;e>d;d++)c=f[d],g.push(c.call(this,b));return g}},a.prototype.on=function(a,b){var c;return null==(c=this.bindings)[a]&&(c[a]=[]),this.bindings[a].push(b)},a}(),P=window.XMLHttpRequest,O=window.XDomainRequest,N=window.WebSocket,w=function(a,b){var c,d,e;e=[];for(d in b.prototype)try{e.push(null==a[d]&&"function"!=typeof b[d]?"function"==typeof Object.defineProperty?Object.defineProperty(a,d,{get:function(){return b.prototype[d]},configurable:!0,enumerable:!0}):a[d]=b.prototype[d]:void 0)}catch(f){c=f}return e},A=[],j.ignore=function(){var a,b,c;return b=arguments[0],a=2=0)return!0}return!1},k=function(a){function b(){var a,c=this;b.__super__.constructor.apply(this,arguments),a=function(a){var b;return b=a.open,a.open=function(d,e){return J(d)&&c.trigger("request",{type:d,url:e,request:a}),b.apply(a,arguments)}},window.XMLHttpRequest=function(b){var c;return c=new P(b),a(c),c};try{w(window.XMLHttpRequest,P)}catch(d){}if(null!=O){window.XDomainRequest=function(){var b;return b=new O,a(b),b};try{w(window.XDomainRequest,O)}catch(d){}}if(null!=N&&D.ajax.trackWebSockets){window.WebSocket=function(a,b){var d;return d=null!=b?new N(a,b):new N(a),J("socket")&&c.trigger("request",{type:"socket",url:a,protocols:b,request:d}),d};try{w(window.WebSocket,N)}catch(d){}}}return Z(b,a),b}(h),R=null,y=function(){return null==R&&(R=new k),R},I=function(a){var b,c,d,e;for(e=D.ajax.ignoreURLs,c=0,d=e.length;d>c;c++)if(b=e[c],"string"==typeof b){if(-1!==a.indexOf(b))return!0}else if(b.test(a))return!0;return!1},y().on("request",function(b){var c,d,e,f,g;return f=b.type,e=b.request,g=b.url,I(g)?void 0:j.running||D.restartOnRequestAfter===!1&&"force"!==J(f)?void 0:(d=arguments,c=D.restartOnRequestAfter||0,"boolean"==typeof c&&(c=0),setTimeout(function(){var b,c,g,h,i,k;if(b="socket"===f?e.readyStatec;c++){if(K=i[c],K instanceof a){K.watch.apply(K,d);break}k.push(void 0)}return k}},c))}),a=function(){function a(){var a=this;this.elements=[],y().on("request",function(){return a.watch.apply(a,arguments)})}return a.prototype.watch=function(a){var b,c,d,e;return d=a.type,b=a.request,e=a.url,I(e)?void 0:(c="socket"===d?new n(b):new o(b),this.elements.push(c))},a}(),o=function(){function a(a){var b,c,d,e,f,g,h=this;if(this.progress=0,null!=window.ProgressEvent)for(c=null,a.addEventListener("progress",function(a){return h.progress=a.lengthComputable?100*a.loaded/a.total:h.progress+(100-h.progress)/2},!1),g=["load","abort","timeout","error"],d=0,e=g.length;e>d;d++)b=g[d],a.addEventListener(b,function(){return h.progress=100},!1);else f=a.onreadystatechange,a.onreadystatechange=function(){var b;return 0===(b=a.readyState)||4===b?h.progress=100:3===a.readyState&&(h.progress=50),"function"==typeof f?f.apply(null,arguments):void 0}}return a}(),n=function(){function a(a){var b,c,d,e,f=this;for(this.progress=0,e=["error","open"],c=0,d=e.length;d>c;c++)b=e[c],a.addEventListener(b,function(){return f.progress=100},!1)}return a}(),d=function(){function a(a){var b,c,d,f;for(null==a&&(a={}),this.elements=[],null==a.selectors&&(a.selectors=[]),f=a.selectors,c=0,d=f.length;d>c;c++)b=f[c],this.elements.push(new e(b))}return a}(),e=function(){function a(a){this.selector=a,this.progress=0,this.check()}return a.prototype.check=function(){var a=this;return document.querySelector(this.selector)?this.done():setTimeout(function(){return a.check()},D.elements.checkInterval)},a.prototype.done=function(){return this.progress=100},a}(),c=function(){function a(){var a,b,c=this;this.progress=null!=(b=this.states[document.readyState])?b:100,a=document.onreadystatechange,document.onreadystatechange=function(){return null!=c.states[document.readyState]&&(c.progress=c.states[document.readyState]),"function"==typeof a?a.apply(null,arguments):void 0}}return a.prototype.states={loading:0,interactive:50,complete:100},a}(),f=function(){function a(){var a,b,c,d,e,f=this;this.progress=0,a=0,e=[],d=0,c=C(),b=setInterval(function(){var g;return g=C()-c-50,c=C(),e.push(g),e.length>D.eventLag.sampleCount&&e.shift(),a=q(e),++d>=D.eventLag.minSamples&&a=100&&(this.done=!0),b===this.last?this.sinceLastUpdate+=a:(this.sinceLastUpdate&&(this.rate=(b-this.last)/this.sinceLastUpdate),this.catchup=(b-this.progress)/D.catchupTime,this.sinceLastUpdate=0,this.last=b),b>this.progress&&(this.progress+=this.catchup*a),c=1-Math.pow(this.progress/100,D.easeFactor),this.progress+=c*this.rate*a,this.progress=Math.min(this.lastProgress+D.maxProgressPerFrame,this.progress),this.progress=Math.max(0,this.progress),this.progress=Math.min(100,this.progress),this.lastProgress=this.progress,this.progress},a}(),L=null,H=null,r=null,M=null,p=null,s=null,j.running=!1,z=function(){return D.restartOnPushState?j.restart():void 0},null!=window.history.pushState&&(T=window.history.pushState,window.history.pushState=function(){return z(),T.apply(window.history,arguments)}),null!=window.history.replaceState&&(W=window.history.replaceState,window.history.replaceState=function(){return z(),W.apply(window.history,arguments)}),l={ajax:a,elements:d,document:c,eventLag:f},(B=function(){var a,c,d,e,f,g,h,i;for(j.sources=L=[],g=["ajax","elements","document","eventLag"],c=0,e=g.length;e>c;c++)a=g[c],D[a]!==!1&&L.push(new l[a](D[a]));for(i=null!=(h=D.extraSources)?h:[],d=0,f=i.length;f>d;d++)K=i[d],L.push(new K(D));return j.bar=r=new b,H=[],M=new m})(),j.stop=function(){return j.trigger("stop"),j.running=!1,r.destroy(),s=!0,null!=p&&("function"==typeof t&&t(p),p=null),B()},j.restart=function(){return j.trigger("restart"),j.stop(),j.start()},j.go=function(){var a;return j.running=!0,r.render(),a=C(),s=!1,p=G(function(b,c){var d,e,f,g,h,i,k,l,n,o,p,q,t,u,v,w;for(l=100-r.progress,e=p=0,f=!0,i=q=0,u=L.length;u>q;i=++q)for(K=L[i],o=null!=H[i]?H[i]:H[i]=[],h=null!=(w=K.elements)?w:[K],k=t=0,v=h.length;v>t;k=++t)g=h[k],n=null!=o[k]?o[k]:o[k]=new m(g),f&=n.done,n.done||(e++,p+=n.tick(b));return d=p/e,r.update(M.tick(b,d)),r.done()||f||s?(r.update(100),j.trigger("done"),setTimeout(function(){return r.finish(),j.running=!1,j.trigger("hide")},Math.max(D.ghostTime,Math.max(D.minTime-(C()-a),0)))):c()})},j.start=function(a){v(D,a),j.running=!0;try{r.render()}catch(b){i=b}return document.querySelector(".pace")?(j.trigger("start"),j.go()):setTimeout(j.start,50)},"function"==typeof define&&define.amd?define(["pace"],function(){return j}):"object"==typeof exports?module.exports=j:D.startOnPageLoad&&j.start()}).call(this);]]></content>
  </entry>
  <entry>
    <title><![CDATA[《 2019 足迹 》]]></title>
    <url>%2FMenu-Log%2F2019%2Findex.html</url>
    <content type="text"><![CDATA[2019年3月3.17 链表(t) + 词嵌入(t)【行】 《数据结构与算法：Python语言描述》线性表（链表）章节的代码实现和理解； 【悟】 集中时间和精力做最重要的事； 代码的规范性影响了代码的阅读和使用 ; —&gt; 编码规范 学习如何系统的设计编码非常重要，像今天这种编码就比较随意，解决问题的效率较低，从明天开始学习《剑指Offer》解决上述问题，在学习这本书的时候，结合自己刚刚学的数据结构或者算法进行配合学习，顺带提高自己对该知识点的理解和掌握； 通过练习发现，练习目的之一是更好的理解和掌握数据结构的特性，比如链表这个数据结构中，最重要的特性就是找到头指针或者尾指针就能够牵出所有的 元素，而不用想像顺序表一样，一眼就能看到整个表的全貌; 设计编程方案是应该结合数据结构或者算法本身的特点，比如在学习列表反转的时候，链表实现的反转可以通过表头插入和删除操作时间复杂度为O(1)来进行启发式的思考，而顺序表可以利用其查找元素为O(1)的时间复杂度来启发性地思考解决方案； 在学习书中的例子时，最好自己先思考解决方案甚至实现，这样才能理解某些书中方案的巧妙之处从而自己学习提高； 选择代码理解时尽量选择高手的代码或者官方的源码，这样既学习了算法，也能学习编程技巧，杂七杂八的代码看多了影响自己的编程感觉； 写代码可以用jupyter notebook，调试代码可以用pycharm或者vscode； 【待】 学习词嵌入已经好几天了，但是原理始终没有理解透彻，明天先从理解CBOW的两种实现原理开始学习，然后开始使用词嵌入现成的软件，了解都干了些什么，能用在哪些应用上，然后再来看自己是否需要自己实现，这个模式以后在学习其他算法和模型的时候也可以借鉴参考； 3.18 链表(c) + 词嵌入(t)【行】 《word2vec中的数学》40页全部学习完毕； 《剑指Offer》第一章 面试的流程 《数据结构与算法：Python语言描述》线性表 一章的总复习； 【悟】 在刚开始学DeepLearning.ai中的词嵌入的时候，对词嵌入有了一个初步的了解，相对全面地理解了词嵌入中的一些概念，但是还是有很多地方流程讲得并不是很清楚，比如： 提到的词嵌入矩阵其实是作为一个类似于隐藏层的存在； 提到的语言模型用神经网络来实现，其实就是神经语言模型，但是它对神经语言模型的具体实现流程并没有讲明白； 提到的skip-gram没有细致的数学原理，导致具体如何训练并不清楚，也就说这个时候只知道词向量的一些模糊的流程； CBOW并没有仔细讲； 负采样的流程讲了，但是并没有讲原理是怎样的，也就是说为什么这样做是有效的； 词向量除偏并没有具体的推导，只讲了大概的流程； 这些问题的存在导致了对词向量的理解并不是很深刻甚至有时候是错误的理解，只了解大概的样子，但是已经有了相对系统的了解，知道了具体应该有哪些知识点。 课程看了之后也查了一些网络上的资料，但是基本上都是讲个大概，并没有细致的讲解和推理，直到遇到《word2vec中的数学》之后，情况才开始好起来，这本资料仔细地推导了词向量训练的数学原理，词向量中skip-gram、CBOW两种方法和hierachical softmax、negative sampling两种优化方法的关系，神经语言模型和两种方法之间的关系、负采样的原理等等，但是，这个资料中也有讲得不明白甚至错误的地方，比如： 预备知识逻辑回归的损失函数讲解并不清楚； 语言模型的计算采用n-gram的具体原因是某个长句出现的概率很可能为0，而不是它的统计有多复杂； 整体来说，之所以在学习《word2vec中的数学》时比较顺畅地理解内容，很大原因在于之前学过Andrew Ng的词嵌入课程，在遇到某些讲得不是很清楚的概念时，能够借鉴到Andrew讲的内容，同时，《word2vec中的数学》又对Andrew课程进行了更为细致的推导和细节扩充，这个学习过程给了我如下的启发： 选择专业研究员（比如Andrew Ng)所设计的资料很大程度上能够正确、准确地帮助我们了解概念，网络上的资料虽然有一定的借鉴和启发作用，但是其理解的正确性和深度都有待考证，所以学习资料的选择很重要，在看网络博文的时候，我们可以从博文长度、有无目录、作者是否有大量其他文章看出作者的专业程度从而判断资料的可靠性； 选择参考资料的时候尽量选择讲解得比较系统的，这种资料一方面可以体现作者对这部分知识点了解透彻，有时候能学习大不同的角度来理解算法模型，另一方面可以从一些细节方面对算法进行补充； 再专业的资料也有它 没有涉及到 或者 没有讲明白 甚至 讲错了的 地方，所以需要多多阅读相关方面的其他资料大胆质疑，同时也可以从其它角度理解模型； 在学习过程中，要学会区分知识点的重要程度，例如词嵌入，在未学习之前，只是将它看作一个小小的算法或者表示方法，并未觉得它有多重要，所以在学习的时候也打算快速略过，但到后来才明白它在深度学习中非常非常重要，甚至是必要的基础，所以，在学习知识点的时候，需要培养自己对重要知识点的敏感性和区分能力，例如，在学习这个知识点之前，就了解到词嵌入是NLP的里程碑之一，而且从Andrew Ng在深度学习课程中的目录来看，专门花了一周的时间来讲，但自己都没有引起重视，这都是自己敏感性和区分能力不强的体现； 【遗】 顺序表的分离式结构是用的一个指针数组+元素存储区还是两个指针数组+元素存储区，元素存储区是分开的还是连续的； Glove词向量还并没有明白原理； 【待】 简单实现词嵌入，功能实现上虽然比较简单，但是要考虑到复杂的细节问题； 3.19 链表(c) + 词嵌入(c)【行】 词嵌入具体编程实现； 链表刷题“复制复杂的链表“； 【悟】 上半天刷链表题，在一道“复制复杂链表”的题上纠结很久，慢 是今天主要问题，总结有如下几个方面的原因： 题目的解读方面： “指向任意节点”以为是不确定的指向，但如果仔细一想，不确定的话也就没有办法做了； “复制”一个链表的含义，复制是如果操作的，没弄清楚就开始思考如何设计； C++语言夹杂题中干扰理解，应该直接搜网上python题目的描述； “不返回参数中的节点引用”开始不理解，主要是对哪些是参数，引用是什么没有理解透彻；其实《数据结构与算法：Python语言描述》绪论一章中的“交叉路口的红绿灯安排”就是一个很好的程序设计模板，应该仔细反复阅读理解； 问题的分析方面： 此题的问题关键在于分析复制原链表之后的random指针复制问题，一般能想到的简单的方法这个环节的复杂度都在$O(n^2)$,所以优化应该优化这个环节，找到这个环节之后就应该考虑用哪个数据结构，这时候对各种数据结构的效率的熟悉程度能够很大程度上为自己提供解决方案备选； 找到方案之后评估算法复杂度是一个重要环节，今天就是因为把复杂度弄错了导致理解了半天； 特殊情况的考虑自己今天在设计程序时没有考虑，又是一拿到题就开始做，《剑指Offer》中程序的设计流程又忘了，这个应该在以后每次考虑问题时都要遵守流程，防止自己漏掉重要环节，导致程序的鲁棒性差； 编程方面： 变量的命名不够言简意赅； 调试方法不够熟练（准确来说是基本没有用到专业的方法），这个在前几天就说过了，但依旧没有开始使用，还在使用自己的比较笨的办法(添加print())； （改：这种print()方法不是笨，反而有时候很有必要，所以这只是所适应的情况不同而已。） 在搜到的样本代码中涉及到了map函数，这本应该在python语言学习中学过的，但是到现在也没有复习到那里（廖雪峰python教程），这个得利用空隙时间抓紧复习； 在写某个算法或者说模型的时候，遇到还没有学过的，不重要的模块，可以直接找现成的使用，没有必要 非黑即白 非要个人全部实现或者全部照着别人的代码打，可以部分使用已有的“轮子”，把主要精力放在关键原理的实现上； 今天的代码基本上都是照着别人的代码敲的，自己还没有完全独立的实现； 【待】 复杂链表复制的那道题中样本代码的递归解法没有理解，哈希解法也没有看完； 3.20 链表(c) + 词嵌入(c)【行】 《剑指Offer》刷题 以$O(1)$时间删除指定链表节点 弄清word2vec 实现的一些细节； 【悟】 刷题的时候思路应该突破常规，学习解题方法是从哪些角度突破常规的； — 3.21 阶段性小结 —学习路线及所购书籍存在问题及解决对策： 浮躁，这是最大的问题，没有能静下心来沉淀一些东西； 暂停学习，每次连续学习的时候，都会出现一段时间的学习中断，主要原因可能是兴趣不高，只把这个学习过程当成一种任务来完成，所以如何提高兴趣是关键，把模型应用于实践是一个提高兴趣的方式； 对于很多课程和书籍上的内容，都只是停留在了理论阶段，理解得本来不一定准确到位，但是这又是一个工程性、实践性比较强的领域，所以导致了很多概念在学习了不久之后就忘了；另一方面，只停留在理论上一定程度地减少了学习的兴趣，实现一个模型应用于实际往往能提高对这个领域的兴趣； 在学习的过程中经常将精力花在“形式”方面的东西，比如制作一个图表，花大把时间去美化这个表等等诸如类似的行为，没有把主要精力和时间放在重点内容上，本末倒置了； 购买学习资料很多时候都不是立马所需的，买的资料很多都没有看完甚至是没有看，没有根据自己现阶段的需求进行购买； 学习资料的选择很重要，尽量避免培训式课程； 花时间打牢基础比追求最新进度更为重要； 3.22 栈(t) + 循环序列模型(t)【行】 《数据结构与算法：Python结构描述》栈理论一节 Andrew Ng的DeepLearning第五门课第一周内容 - 循环序列模型 【悟】 学习高级数据结构的底层实现或者说其他知识点的底层实现，更有利于理解和运用高层次的知识技能，比如在学习栈一节的时候，递归与非递归之间的转换底层其实就是通过栈来存储中间数据来实现，所以，学习知识点要抓住本质； 今天在学习吴恩达的深度学习循环神经网络一节的时候，明显没有以前那么困难了，归结原因主要有两点： 主动性思考，主动思考原理中的参数是代表什么，对于模糊的地方进行推理，记住存在的可能性有几种，加深对原理的理解； 基础知识掌握比较牢固，以前学习这个的时候，对于标准的神经网络中的公式不能够完全理解，在重新复习掌握一遍之后，今天对于RNN中很多东西就能够自己快速理解了； 【待】 栈的编程实现 循环序列模型的理论完善和实现 3.23 栈(c) + RNN和LSTM(t)【行】 RNN和LSTM理论深入细节 【悟】 学习《数据结构与算法：Python语言描述》中的结构、算法、例题时，学习思考结构设计的分析过程也非常重要，这里面的例题都比较经典； 【遗】 RNN和LSTM及GRU的门控制是为了什么还是没有弄得太清楚； 栈的应用中实现的后缀表达式例题代码还是有点问题； 【待】 错误处理类的学习； print()函数输出变量写法； 写一个像前段时jieba简单版的程序框架，熟悉整体布局和设计； 练习调试节点的设置，增强debug能力； 3.24 队列(t) + seq2seq和注意力机制(t)【行】 学习《数据结构与算法：Python语言描述》中的队列及其相关概念 Andrew Ng的DeepLearning第五门课第三周内容 - 序列模型和注意力机制 【悟】 数据结构和算法的很多思想可以迁移到某些模型的计算设计中，比如递归算法的思想可以用到动态规划的维特比算法最初的设计启发中； 学习深度学习相关章节时，有点浮躁，急着想看完视频； 【待】 进一步学习RNN、LSTM、GRU、seq2seq、注意力机制的细节问题； 完成队列相关内容的编程，完善栈未debug完的后缀表达式例题； 3.25 栈(c) + 队列(c) + 注意力模型(t)【行】 Attention机制深入理解 门函数理解 复习吴恩达DeepLearning第五门课第三周内容 “实现”栈的debug、背包问题、简单队列、迷宫 【悟】 养成 独立地分析问题，完成整个代码 的习惯，不要总照着样本代码敲，可以先看资料上问题的分析流程，然后尝试着自己写代码，如果写不出来，再参考部分样本代码的实现，然后接着自己再写，这样反复循环这个过程，直到写出整个功能实现，再回过头来对比自己的代码和样本代码，分析自己和样本代码的区别； — 3.26 短期计划 —应聘模块： 搜集学习成篇的面试内容，抓住常考重点； 查看招聘信息总结重点； 编程模块：把更多的时间分配到刷题上面，适当减少纯阅读学习的时间，必须保证每天刷题，以下为重点： 训练解题思路（注意高压下的训练）； 熟悉Python语言； 熟悉数据结构与算法； NLP模块： 常用算法：HMM、最大熵模型、CRF、EM、PCFG、LDA 基本环节：文本预处理、分词、词性标注、命名实体识别、句法依存分析、句法浅层分析、语义角色标注 常见任务：文本分类、主题建模、信息抽取、实体识别、情感分析 应用层面：问答、对话 开源工具NLTK等的使用 深度学习模块： Tensorflow框架的学习 深度学习基础的学习（Andrew Ng深度学习的第2门课 4.8h） 机器学习策略的学习（Andrew Ng深度学习的第3门课 3.4h） 深度学习简单应用系统的搭建（参考CS224n课程） TextCNN ？ 机器学习模块： scikit-learn的使用; 常用算法：SVM、决策树、朴素贝叶斯、KNN、Kmeans; 其他概念：过拟合、偏差与方差、正则化（L1和L2）、查准率和查全率、损失函数 3.26 栈和队列(c) + 深度学习(t) + Python(t)【行】 栈和队列的刷题 Andrew Ng的DeepLearning第二门课第一周的内容； Python装饰器 【悟】 记录刷题的时候每道题所用的时间； 在写代码的过程中，经常忘了给函数加“（）”调用符号，导致一些不好查找的非语法错误； 刷题具体分析题目时，一定要一步步分析，而不是像下面自己操作的那样“跳着走”； 遗问： 梯度和步长 3.27 刷题(c) + 深度学习(t) + 机器学习(t)【行】 《剑指Offer》刷一题 Andrew Ng的DeepLearning 第二门课第二周 EM公式推导 重新理解梯度、梯度为何能求损失函数 python语言 【悟】 深入理解Python语言各数据结构的特性和功能才能更好更快地编码； 多用Geogebra，建立空间概念； 学习某种算法时，弄清楚基本数学组件后，理解模型才能得心应手，理解清楚每一步在做什么，每个数学符号的含义，这样才能更顺畅地理解，例如今天重新学习推理EM（最大期望值）算法的过程，再有今天推导公式时重要的经验之一就是符号的书写、排版可能影响到了思考思路； 分段记录刷题时的分析时间，编码时间； 刷题时理解透彻，思路清晰之后再编码，不要急着编码思路都不清楚； 学习某种算法或者模型前，最好先把其中涉及到的预备知识点都学习好，避免学习模型途中产生理解断点； 3.28 Python(t) + 二叉树(t) + EM算法(t) + 刷题(c) + 深度学习(t)【行】 Python语言 《数据结构与算法：Python描述》二叉树相关章节 EM算法理解和公式推导及实例推导 《剑指Offer》刷题 Andrew Ng的DeepLearning第二门课第三周内容 【悟】 分析题目时先举例子试着“走几步”进行分析，然后再写白板编程或者中文描述代码流程，最后再编代码； 先写测试用例，再写程序，保证程序的健壮性、鲁棒性； 刷题时注意算法复杂度的分析，不要只顾着相处解决方案就了事； 系统复习Python重要数据结构的属性和功能函数，在最近的编码中都发现了对基本的list、tuple、字符串、set、dict功能函数和属性都不熟悉； 【遗】 batch-normalization了解得不是很透彻，需要以后再理解； 3.29 EM算法(t) + 刷题(c)【行】 Python语言 EM算法公式的深入理解 《剑指Offer》刷题 【悟】 积累一些好的网络资源，比如看到一些好的博文，可以顺带看看博文的参考资料，看看博主的其他文章和博主关注的一些好的博文或者其他博主； 注意复习刚学过的东西，避免又忘了，思考遗忘的根本原因； 找一些提高记忆力的方法； 保持精力充沛-注意睡眠、运动、饮食的调整，学习时间、精力的管理，这点可以看看德鲁克的管理类书籍； 状态有些松懈； 3.30 HMM(t)【行】 Python语言 HMM模型深入全面性理解 【悟】 状态有些松懈； 学习不是按部就班的工厂流水线，有些细节需要一气呵成。这句话更能体现专注和兴趣； 【待】 思考为什么比原来理解数学更深更快了； 3.31 深度学习(t)【行】 Andrew Ng的深度学习第三门课第一周 1.4-1.7节 【待】 思考是否更针对面试来学习知识； 2019年4月— 4.01 短期计划 —应聘模块：加分项： ML策略 Linux工作环境 Coding模块： 《剑指Offer》 《数据结构与算法：Python语言描述》散列表、图、排序、查找、平衡二叉树 ML模块： SVM、朴素贝叶斯、决策树、K-means、KNN、提升算法、感知机、逻辑回归、SVD ML库Scikit-learn –&gt; 莫烦 NLP模块： HMM、EM、MaxEnt、CRF、LDA、PCFG 分词、标注、实体识别、浅层句法 应用：文本分类（《Python文本分析》)、流程（预处理+ … ） DL模块： Word-Embedding、RNN、LSTM、GRU、Attention、Transformer、自编码器（非监督学习）、递归神经网络 框架选择： Pytorch –&gt; 莫烦Tensorflow CNN –&gt; Andrew Ng 第三门课前两周视频 4.01 最大熵模型(t) + 方向导数和梯度(t)【行】 《自然语言处理综论》最大熵模型一节 方向导数和梯度（网络PPT） 【悟】 做事不果断，没有分清主次； 4.02 拉格朗日乘子法与对偶性(t)【行】 拉格朗日乘子法与对偶性(博文学习) 修改4.01短期计划 4.03 深度学习(t) + PyTorch(c)【行】 Andrew Ng 深度学习 第三门课第一周内容 PyTorch莫烦系列（前17个短视频） 4.04 修改短期计划 + 深度学习(t) + PyTorch(c) + 《自然语言处理综论》(t)【行】 Andrew Ng 深度学习 第四门课第一周内容 Pytorch莫烦系列编码 《自然语言处理综论》 第22章 信息抽取 修改短期计划优先度：(1) 数据结构算法和刷题是必要先做的，笔试必考，TCP/IP三次握手掌握；(2) 项目经验：文本分析应用;(3) NLP算法、机器学习算法；（上网搜考点）(4) PyTorch、深度学习编码；(5) 粗览《自然语言处理综论》中的摘要和对话章节； 4.05 字典(t) + 刷题(c) + CRF(t)【行】： 《数据结构与算法：Python语言描述》字典一节 《剑指Offer》面试题：矩阵中的路径 CRF算法学习 4.06 散列表(t) + 刷题(c) + CRF/MaxEnt复习(t)【行】 《数据结构与算法：Python语言描述》散列表一节 《剑指Offer》面试题：机器人的运动范围 弄懂CRF/MaxEnt模型 【悟】 日本人写的书籍大多比较精细，可以多看看他们的书籍和资料等等； 【待】 IIS迭代算法； HMM训练问题； 在谷歌浏览器一个收藏的书签中学习判别式模型和生成式模型； 补充学习指数族分布； 4.07 集合(t) + 字符串(t) + 朴素贝叶斯(t)【行】 《数据结构与算法：Python语言描述》集合一节 《数据结构与算法：Python语言描述》字符串一节（未完） 《统计学习方法》朴素贝叶斯复习 【悟】 在学《数据结构与算法：Python语言描述》一书中，总觉得懂得模式设计非常重要； 要记录在学习过程中因为某些原因跳过的内容，并且记录为什么跳过； 对于学过的知识点应该温故而”知新”，这个新是指更深层次或者更多角度的理解； 精读好的书籍，了解它们的思路和细节，并且知道它们各自的优缺点： 《统计学习方法》 –&gt; 精细而不够全面 《机器学习》 –&gt; 全面而不够精细 《自然语言处理综论》 –&gt; 全面而精细，但是有点“过时” 每本讲模型和算法的书都基本会在目录的附近写有自己公式中各个字母的含义，而这些解释恰恰是理解公式的前提，以前自己都忽略了，以至于在理解公式的时候总是猜测几种可能然后验证，但这样浪费太多时间而且有可能理解出现偏差； 以慢为快 理解、吃透前面的知识点和基础，再往后面进行，不要一味图快； 4.08 字符串(t) + 刷题(c) + SVM(t)【行】 《数据结构与算法：Python语言描述》字符串一节 《剑指Offer》二进制中1的个数、剪绳子 结合《统计学习方法》、Andrew Ng机器学习、黄志洪机器学习、《数据挖掘导论》综合学习SVM，但有些问题依旧没有弄得很清楚； 【悟】 结合不同的书籍理解同一个概念，每本书的侧重点都有所不同，像今天理解《统计学习方法》中SVM一节，纯数学公式太多，并且李航本身用的符号表示比较复杂，所以导致不能够很好理解，然后再看Andrew Ng的机器学习课程，讲得比较通俗，但是很多细节方面的东西没有讲到，接着又看了黄志洪的机器学习，他讲得有些地方也比较抽象，最后看了他介绍的《数据挖掘导论》这本书上的SVM讲解，总算理解得比较全面和深入了，所以说，理解某些知识点，最好结合多个方向的资料，最好是比较权威的那种来帮助理解，这样能各取所长，综合学习； 多参加一些比赛，了解行业状况，不管能不能获奖，吸取经验是关键； 最近一两年，应该把学习重点放在数学方向； 4.09 刷题(c) + Pytorch(t) + 依存句法分析(t)【行】 Leetcode刷题 Pytorch使用 依存句法分析 【悟】 正则表达式是一种语言表达； 4.10 刷题(c) + Pytorch(c)【行】 刷Leetcode Pytorch使用手册查看 【悟】 规范代码格式，适当书写注释； 熟记错误代码； 提醒查看《具体数学》经典书籍； 4.11 应聘计划编码环节： 《剑指Offer》结合LeetCode刷题：在LeetCode官网上按照《剑指Offer》的模块进行有针对性、目的性地刷题，并形成解题思路和总结，不要在一道题上纠缠过多的时间，要多刷，刷几遍； 数据结构与算法重要顺序： 第一梯队：复杂度分析、链表、二叉树、二分查找、快速排序、归并排序、回溯法、动态规划、分治 第二梯队：栈、队列、堆、图 {DFS遍历、BFS遍历、最大（小）生成树算法（Kruskal、Prim）、最短路径（Dijkstra、Floyd）} 第三梯队：哈希、集合 这个阶段的复习不用看《数据结构与算法：Python语言描述》了，不懂的就上网查一下，关于Python语言的研究也可以暂时停止，因为在这个阶段主要是学习算法，python中的一些高级结构封装了算法，不适合在这里使用； 项目环节： 选择 信息抽取 作为学习项目；因为信息抽取一方面集合了许多底层的基础知识比如分词、词性标注、实体识别、消歧等等，另一方面，它又作为了许多更高级的应用的基础，现在研究这些高级应用能力还不够，所以先从信息抽取开始，并且在招聘中，信息抽取是许多公司要求的； 文本分类（情感分类）作为加分项，因为招聘中也有许多公司对这方面有需求，这方面的知识知道具体流程和方法就行了，没有必要编程； NLP知识环节 HMM、EM、MaxEnt、CRF、LDA：重点记忆理解其中的数学公式； 分词、标注、实体识别、依存句法分析：了解主要的方法有哪些，做成结构图进行记忆； 熟悉一种自然语言处理软件的使用； DL知识环节： Word-Embedding（最为重要）及genism的使用、RNN、LSTM、GRU、Attention、Transformer、自编码器（非监督学习）、递归神经网络：重点记住数学公式； 框架 Pytorch：利用莫烦的视频进行简单学习，结合Pytorch官网进行学习； CNN –&gt; Andrew Ng 第四门课第二周视频 CS224n的实现代码作为NLP在Pytorch中的实现和练习； ML知识环节： 找ML面试题进行学习； SVM、朴素贝叶斯、决策树、K-means、KNN、提升算法、感知机、逻辑回归、SVD ML库Scikit-learn –&gt; 莫烦 加分环节和其他环节 计算机网络知识 ML策略 Linux工作环境 4.12 刷题(c) + 信息抽取(t)【行】 《剑指Offer》结合牛客网刷题 《自然语言处理综论》信息抽取一章 【悟】 总结刷题的各种技巧和思路启发式怎样的； 4.13 刷题(c) + 信息抽取及其NLP他应用了解(t)【行】 《剑指Offer》结合牛客网刷题 上网查各种信息抽取、文本分析、文本挖掘等等NLP的领域应用，考虑发展方向 【悟】 认真思考为什么想要做这行，到底追求些什么东西，然后再来行动； 4.15 刷题(c) + Pytorch学习(t)【行】 《剑指Offer》刷题，递归类题目 Pytorch熟悉流程和函数 4.16 应聘计划(修改)戒躁，踏踏实实学好每一个知识点编码环节： 《剑指Offer》结合LeetCode刷题：在LeetCode官网上按照《剑指Offer》的模块进行有针对性、目的性地刷题，并形成解题思路和总结，不要在一道题上纠缠过多的时间，要多刷，刷几遍； 数据结构与算法重要顺序： 第一梯队：复杂度分析、链表、二叉树、二分查找、快速排序、归并排序、回溯法、动态规划、分治、正则表达式使用 第二梯队：栈、队列、堆、图 {DFS遍历、BFS遍历、最大（小）生成树算法（Kruskal、Prim）、最短路径（Dijkstra、Floyd）} 第三梯队：哈希、集合 这个阶段的复习不用看《数据结构与算法：Python语言描述》了，不懂的就上网查一下，关于Python语言的研究也可以暂时停止，因为在这个阶段主要是学习算法，python中的一些高级结构封装了算法，不适合在这里使用，这里学习的应该是所有语言通用的实现方式； 项目环节： 文本分类（情感分类）； 分词、标注、实体识别、依存句法分析； NLP知识环节 HMM、EM、MaxEnt、CRF、LDA：重点记忆理解其中的数学公式； 熟悉一种自然语言处理软件的使用（NLTK）和一种中文NLP软件LTP的使用； DL知识环节： Word-Embedding（最为重要）及genism的使用、RNN、LSTM、GRU、Attention、Transformer、自编码器（非监督学习）、递归神经网络：重点记住数学公式； 框架 Pytorch：利用莫烦的视频进行简单学习，结合Pytorch官网进行学习； CNN –&gt; Andrew Ng 第四门课第二周视频 CS224n的实现代码作为NLP在Pytorch中的实现和练习； ML知识环节： 找ML面试题进行学习； SVM、朴素贝叶斯、决策树、K-means、KNN、提升算法、感知机、逻辑回归、SVD、PCA ML库Scikit-learn –&gt; 莫烦 加分环节和其他环节 计算机网络知识 ML策略 Linux工作环境 Python语言自身 4.22 写给快28岁的自己 不知不觉，来到这个世界已经近28个年头，好像自己什么都没做，什么也没有做成，本该是工作了几年的自己，如今却仍未工作，究其缘由只是因为还没有找到属于自己的路。近段段时间的AI兴起，让自己自己好像突然有了方向，但奈何多重原因，至今也未有个实质性的进展，同时也浪费了大量时间。最近结了婚，有了妻子，似乎下定决定要改变这一现状，但现实是心态浮躁，仍未工作。自我感觉不能够再这样下去了，为了老婆，也为了自己。现对以前的自己做如下总结和规划，希望能够从中吸取教训，收拾行囊，重新出发！ Q：为什么选择NLP作为以后的工作方向？ NLP涉及了哲学、认知、心理等物种（不仅仅是人类）层面最根本性的东西，它的推进，将有利于推进人类发展的进程，这是一件很酷的事情； 选择AI中的的NLP是因为NLP在AI中属于认知层面的，相对于与感知层面的技术比如语音和视觉，它仍处于萌芽的状态，很多技术都不成熟，这就为自己赶上前沿技术走在前列争取了时间； 人工智能正在深刻地改变人们的工作、生活方式，这是一个将来非常重要的领域，每个人都应该在一定程度上了解甚至掌握这门技术; 从事这个领域的薪资待遇也非常不错； Q：为什么学了这么长时间的NLP却还是没能够掌握？ 只重视理论，不重视实践。在学习的时候，可能理解了知识点，但基本上很少用代码去实现，这样就造成了以下几个结果： (a) 理论知识可能没有正确理解，本来在编程环节可以发现的（也就是说编程可以促进理解），但是没有编程，导致了可能理解错误；(b) 不懂得如何去实现理论，即使是造好的轮子，也不知道该使用哪些软件工具；(c) 遗忘知识点，理解不深刻，没有编程，自然而言导致记忆不深刻； 不重视基础，基础理论没有吃透（例如EM算法在网络博文中有一篇提到了九层理解境界，但自己却止步于一二层），而高级模型正是有这些“积木”搭建起来的，基础不牢，导致的结果有以下几个： (a) 理解慢：要花很长时间去理解高级模型；(b) 延展性差：针对不同的应用场景，很难去修改高级模型细节去适应新场景； Q：学习或者生活中影响做事的习惯或者思想有哪些？ 做事情拖沓； 时间和精力的分配管理做得很差，经常是做一件事的时候会分神去做与这件事可能不相关或者相关但不重要事情上去，本末倒置把主要的精力和时间浪费了； 学习停滞，缺乏持续性学习的兴趣； 总结了很多学习的方式方法，但从来不去应用； 工作与生活分界不清，抽取独立的时间陪伴家人； 每个阶段的目标性不强，没有进行更为细致的规划，导致在一些问题上精力不集中，造成了时间的浪费； 没有积累的习惯，写代码的时候没有分类存储的长期习惯，总是在一段时间后就把前面的代码删除； Q：如何从NLP领域脱颖而出？ 兴趣（长期性原动力） 基础 视野 英语能力 4.23 刷题(c) + 词嵌入复习和gensim使用(c)【行】 《剑指Offer》刷题 复习词嵌入 练习使用gensim的word2vec 4.24 刷题(c) + 词嵌入复习和gensim使用(c)【行】 《剑指Offer》刷题 归并排序编程 复习词嵌入 练习使用gensim的word2vec 2019年5月5.01 刷题(c)【行】 《剑指Offer》刷题 【悟】 在足迹和遗留问题列表中同时记录问题； 各种排序算法的复杂度； 递归结构复杂度分析； — 5.03 找工作计划 —以基础项目促进复习和学习，顺便积累项目经验；笔试类： 数据结构与算法 Linux系统使用 Python语言本身 少量的计算机网络知识 面试类： 项目： （1）在实践中，必须涉及到NLP主流算法模型的使用，包括传统方法和深度学习方法； （2）系统的编码，要按照正规系统的布局方式来设计（可参考jieba分词系统） （3）多看看Andrew Ng在deeplearning中的机器学习策略，这是获取经验的捷径，也是能表现得像个很多经验者的方法； 序列标注：分词系统、词性标注、命名实体识别系统 ==&gt; (bi)LSTM+CRF序列标记项目（设计gensim使用产生词向量，LSTM可以更换为RNN和GRU，CRF训练需要用到HMM中的训练方法，CRF原理与最大熵模型极其相似，使用Pytorch深度学习框架）（参考【ipynb】Deep Learning for Natural Language Processing with Pytorch） 最新中文分词改进版网址 复旦大学邱锡鹏教授：词法、句法分析研究进展综述 ==&gt; MaxEnt字标注（复习+NLTK的使用） 句法分析系统（主要是依存句法分析） ==&gt; 基于图的依存句法分析 ==&gt; 基于转移的依存句法分析 语义分析系统 ==&gt; 指代消解问题 文本聚类与分类（以《Python文本分析》为指导） ==&gt; （1）文本特征的选择方法（涉及TF-IDF、信息增益、卡方统计、互信息） ==&gt; （2）分类器设计（涉及朴素贝叶斯、SVM、KNN、决策树、逻辑回归等机器学习方法，并且熟悉使用sklearn库） 软件（库）使用： sklearn、Pytorch、NLTK、Spacy等几个常用NLTK库的对比 NLTK（Python自然语言工具包）用于诸如标记化、词形还原、词干化、解析、POS标注等任务。该库具有几乎所有NLP任务的工具。 Spacy是NLTK的主要竞争对手。这两个库可用于相同的任务。 Scikit-learn为机器学习提供了一个大型库。此外还提供了用于文本预处理的工具。 Gensim是一个主题和向量空间建模、文档集合相似性的工具包。 Pattern库的一般任务是充当Web挖掘模块。因此，它仅支持自然语言处理（NLP）作为辅助任务。 Polyglot是自然语言处理（NLP）的另一个Python工具包。它不是很受欢迎，但也可以用于各种NLP任务。 结论：在文中，我们比较了几个流行的自然语言处理库的一些功能。虽然它们中的大多数都提供了重叠任务的工具，但有一些可以使用独特的方法来解决具体的问题。当然，目前NLP库中最受欢迎的软件包是NLTK和Spacy。他们在NLP领域是主要竞争对手。在我们看来，它们之间的区别在于解决问题的方法不同。NLTK更具学术性。用户可以使用它来尝试不同的方法和算法，将它们组合起来。相反，Spacy为每个问题提供了一个开箱即用的解决方案。用户不必考虑哪种方法更好：Spacy的编写者已经解决了这个问题。此外，Spacy的执行速度非常快（比NLTK快几倍）。但Spacy的一个缺点是所支持的语言数量有限。但其支持的语言数量将会一直增加。所以，我们认为Spacy在大多数情况下是用户的最佳选择，但如果用户想尝试一些特别的东西，可以使用NLTK。尽管这两个库很受欢迎，但还有许多不同的选项，NLP工具包的选择取决于用户必须解决的具体问题。 面试常考内容（题库问答类应聘）?????????? 涉及到的内容： 数据结构与算法 第一梯队：复杂度分析、链表、二叉树、栈、队列、二分查找、快速排序、归并排序、回溯法、动态规划、分治 第二梯队：堆、正则表达式、图 {DFS遍历、BFS遍历、最大（小）生成树算法（Kruskal、Prim）、最短路径（Dijkstra、Floyd）} 第三梯队：哈希、集合 NLP传统模型 HMM、EM、MaxEnt、CRF、LDA N-gram NLP深度学习 Word-Embedding（最为重要）及genism的使用、RNN、LSTM、GRU、Attention、Transformer、encode-decoder、递归神经网络 ML SVM、朴素贝叶斯、决策树、K-means、KNN、提升算法、感知机、逻辑回归、SVD、PCA 自己的优势… 5.07 刷题(c) + 深度学习复习(t)【行】 《剑指Offer》刷了两道题和第三道题的理解与构思； 复习DNN的反向传递原理； RNN的反向传递原理； GRU和LSTM原理； 梯度爆炸与梯度消失深层理解； 【悟】 学习《剑指Offer》及类似题相关步骤： 理解问题； 自己构思算法； 参考样本算法； 自己写代码； 参考样本代码； 在实现算法时，现在自己最大的问题就是没有习惯将大的复杂的算法块分解为较小的功能单一的算法块，总习惯于一次性解决所有问题，将各种细节糅杂在一起，这样既不利于思考，也不利于实现； 增加代码的简洁性和可读性是必要的（比如变量命名、恰当的写注释），这点可以参考一些相关类的书籍； 对于python语言中内置的数据结构和算法应该熟悉其复杂度，也就是知道其内部实现原理（这点不一定必要），这样对于设计新的模块时计算自己的复杂度心里才有数； 算法没有固定的设计，任何算法，模式都有相当大的自由度，不要局限于已有的东西，开阔思路，“自定义”才是王道； 掌握其他的排序算法； 注意预防颈椎病； 待阅：对近期的项目比较有帮助 一些自然语言处理基本模型Demo [EMNLP18]用序列标注来进行成分句法分析 5.08 pytorch熟悉使用(c)【行】 熟悉pytorch的使用 【悟】 利用好零碎时间，不要见缝插针地玩手机； 想要改变自己，必须改变自己的一些习惯； 学到一大类算法时，不必每个算法都去实现，实现其中的一个算法就行了，其他的都是触类旁通，简单修改细节就行了，这样既提高了理解力，也提高了实践能力； 每次看别人写的代码的时候应该注意先关心什么，再关心什么，每次重读代码的时候目的应该是不一样的，比如，第一遍是了解整个大概，第二遍，研究算法细节，第三遍，可以把不熟悉的语言函数或者其他没学过的东西拿来研究，做其他事情也应该这样，每次有每次的关注点，而不是大而全地所有都去关注，这样目的性更强，针对性更强，能学到更多的东西； 待优化： pytorch 的tensor grad梯度下降机制待考察 5.09 pytorch熟悉使用(c)【行】 《剑指Offer》刷了一道题 熟悉pytorch的使用 【悟】 尽量用显式的代码指出逻辑顺序，隐式的（比如顺序式+判断式）的算法会隐藏隐患； 数学公式恐惧感，刚开始看offer里面的讲解时，感觉地推公式完全就是数学化的东西，一瞬间就感觉很难，之后也没有仔细分析，我觉得这就是自己存在的对数学公式的恐惧感，但之后经过自己分析和研究发现这个公式的来源并不是凭空想象的，而是经过一步步思考一步步构建而来的，而每一步构建的过程并不难，所以要克服这种对数学的恐惧感； 没有头绪就烦躁，做些其他事情来转移注意力，结果浪费了更多的时间； 看到自己的进展才有兴趣，不清楚自己掌握了哪些东西，掌握的程度怎么样，好像什么都没有学到一样，只有在提起的时候可能会想起来，这个不利于积极的促进作用，应该学完每个知识点之后都有自己的总结和见解； 5.10 刷题(c)【行】 《剑指Offer》刷了两道题 【悟】 看到一些好的讲座或者其他博文的时候，可以写写读后感，把自己的体会记录下来，也可以记录其中很有启发性的东西，思维方式，行业发展方向，开创性模型等等，学习学者在某些问题、模型上的理解，开拓自己的思维。比如在听了微软亚洲研究院刘铁岩的“形成机器学习研究的闭环”演讲后，自己就收益良多，一方面看到了很多他对于行业中某些现象，比如BERT、GPT等“大力出奇迹”（使用巨量计算资源进行训练）的理解，另一方面也看到了他们在机器学习上的创新，比如对偶学习、博弈学习、Coopertitve Learning、Lightweight Learning（与“大力出奇迹”相对）、改进的分布式学习等等。对于这些可能的优秀的方式方法、模型、理解角度等等应该系统地记录下来，供自己以后留出时间来学习； 在解决某些问题时，我们应该尽可能掌握所有已有的信息，自己有个缺点就是对于已有的信息，经常是记忆错误，或者因为略读忽略了重要信息，在不了解上下文环境的情况下就开始行动，结果导致大量的时间浪费、精力浪费还得不到结果； 动态规划是有固定的处理流程和使用条件的； 对于刷题，没有形成规范化的、系统化的总结，尽管自己有时候刷题对某个类型题进行了总结，但是在遇到相似题型时又总结了一些东西，但这两次总结的东西都没能合在一起，比较，分析，形成成套的解决方案，导致以后再遇到这种问题的时候自己依然凌乱没有思路，这就是有积累但很分散的结果，既不利于记忆，也不利于应用，比如在刷动态规划题的时候，做了几道相关题目，依然不能形成清晰的解题思路（实际情况是动态规划本身有适用的环境和解题规范，自己不知道）； 对自己的期待应该更高，而不是仅仅满足于现状，这样才能提高自己的能力； 更好地利用好的资源，比如github，它其实是一个很大的网站，自己只了解了一部分0内容； 改掉思考过程中不好的习惯，比如想写字，让思维更专注； 刷题方式，画出思路树图，统计图中所需要的变量，考虑变量表达形式； 习惯总结，不要用重复训练的方式来形成思路“感觉”，要用总结的方式减少重复性练习，重复性训练可以在总结之后作为巩固，但不是代替总结； 5.12 随机思索【悟】 要习惯用记事本记录自己要做的事，定闹钟提醒，这样可以减少自己对这些东西的记忆，把精力集中做事； 还有这么多好玩的东西要学，还有时间去浪费吗，抓紧时间进步； 自己已经是起步比较晚了，如何加快步伐学习（并不是走捷径，而是更努力地抓紧时间学习）形成适合自己的高效的学习方法，选择正确的学习资源和路线需要仔细考虑清楚，我认为提高效率的方式之一是学习经典内容，减少对含金量低的内容的学习，通过反复琢磨经典的学习资源，从而快速掌握内容的核心，含金量低的内容包括各种网络来源不可靠的视频教程、博文等等； 不仅要学习与NLP相关的知识，计算机视觉、语音、机器学习也一样要学习，从整个AI行业的角度思考学习方向，这样才能全面而富有远见性，并且在其他领域的算法可能也能迁移到NLP中； 快速解决学习中不懂知识点的能力： 在网络快速准确地搜索的能力； 询问同行业者得到问题答案的效率； 在学习或者工作中如何持续集中精力： 从生理上、时间安排上考虑，比如进行体育锻炼也许有助于提高精力集中或者精神兴奋性； 从思想上考虑，如何引起注意力等等； 待阅： 如何有效地做算法题 机器学习算法优缺点对比及选择 5.14 刷题(c) + MaxEnt复习(t) + KNN复习和实现(c)【行】 《剑指Offer》刷题两道 KNN复习并用sklearn实现训练 MaxEnt复习 【悟】 坚持做算法题的目的： 保持思维敏捷。非常重要，状态好才能保持对编程的热情。 对基础的数据结构、查找和排序保持熟练。能解决日常开发中的性能相关问题。 积累对问题域的探索。只有对问题域有足够的探索，才可能举一反三，迸发灵感。 调整作息时间，避免困倦； 5.15 刷题(c) + HMM、CRF、MaxEnt复习(t) + 决策树复习(t)【行】 《剑指Offer&gt;刷题一道 HMM、CRF、MaxEnt复习 决策树复习 【悟】 编码习惯：代码必要的注解： 各代码块的注解； 对于含义模糊的变量的解释； 刷第二遍《剑指Offer》，总结题型和规律； 从刷题中的启示，反复复习经典的内容，有利于更深入的理解和应用； 每个经典算法模型并不是从吴恩达机器学习课程中学的那么简单，深入下去有很多细节性的内容； 随时提醒自己是为了找工作而复习，所以复习的时候针对性复习，该忽略的地方就忽略； 遗问： 决策树一节在以后有时间的时候结合《机器学习》一书进行深入学习，决策树一节在以后有时间的时候结合《机器学习》一书进行深入学习； knn的kd搜索树原理 HMM的训练方法和后向算法原理没有弄明白，训练方法在《自然语言处理综论》P160页红色标记处不懂； CRF的训练方法没有仔细研究； 5.16 复习刷过的题(c) + Pytorch使用建模(c) + AdaBoost复习(t)【行】 复习《剑指Offer》刷过的题两道 使用Pytorch建立词向量和N元语法模型； 复习AdaBoost模型（简单复习） 【悟】 在复习刷题中使用计时； 在设计算法前考虑测试用例； 运用某种已掌握的算法时要注意在其他的环境中，哪些地方是不一样的，比如边界值在原有算法中计入，但是在新环境中需要计入，这些都需要仔细考虑； pycharm的断点使用练习； 读书笔记的勾、画总结应该尽量简短，精炼； 在以后深入研究机器学习时，使用《统计方法学习》一书时，可以把每章后面的参考文献拿来仔细研究，看看最本质的思想； 简历里面添加英文阅读能力； 将查询过的英语单词放入有道单词本，经常复习； 了解pytorch的框架对使用pytorch很有帮助； pytorch中的各种参数使用形式要记，不然有时候出错在哪根据错误信息自己完全不知道； 5.17 复习刷过的题(c) + Pytorch使用建模(c)【行】 复习《剑指Offer》刷过的题两道和二叉树的各种遍历 使用Pytorch实现LSTM和使用LSTM进行词性标记 【悟】 lstm、rnn等的纯手工实现 官方文档是最权威的查询资料； 深入了解算法的本质原理才能活用，比如以下简单的模型有多层的理解： kNN 的花式用法(link) EM算法的九层境界：​Hinton和Jordan理解的EM算法(link) ① 分类 ① EM就是 E + M ② 回归 ② EM 是一种局部下限构造 ③ One-class识别 ③ K-Means是一种Hard EM算法 ④ 搭配核函数 ④ 从EM 到 广义EM ⑤ 搭配空间分割技术 ⑤ 广义EM的一个特例是VBEM ⑥ 超球体空间分割 ⑥ 广义EM的另一个特例是WS算法 ⑦ 冗余样本剔除 ⑦ 广义EM的再一个特例是Gibbs抽样算法 ⑧ WS算法是VAE和GAN组合的简化版 ⑨ KL距离的统一 简单的招数练到极致就是绝招关键词：深入立即基础算法+结合其他优异性能的算法 5.18 2017-2019 ACL各子领域论文统计【行】 刘知远关于2019ACL投稿情况的分析报告 5.23 休息【悟】 清楚做每件事的目的，提高效率； 从ACL的论文领域可以看出，NLP的基础问题研究并没有结束； 提高单位时间的效率，增加学习时间； 学习的时候对于没有学完的东西，应该记录学到什么层次了，学到什么地方了； 5.27 Think of NLP as a Life . . .【悟】 可以从CSRanking中查询NLP领域各个大学的排名，并且，更重要的是可以查到每个大学发文的排名和个人网站； 可以根据NLP关键字查询最相关的学者，格式如：“label:machine_learning”、“label:information_extraction”，这是根据标签进行的查询，注意下划线是必要的，根据上述格式搜索出的学者有些是给出了学者的个人网页的。如果没有“label:”这个，搜索的就是论文而不是学者； 5.28 刷题【行】 《剑指Offer》刷题 【悟】 与NLP相关的网站基本上都是英文、外国的为主，所以提高英文能力是非常必要的，虽然国内也有相关网站，但很少有高质量的，并且国内学术风气比较浮躁且利益性太重，不适合拓展眼界和培养科研品味； 阅读最前沿科技论文的最基本要求是基础要扎实。刚开始阅读科技文献的时候，不要选难度太大的，最好选经典的文献，一方面对基础原理讲述比较清楚，另一方面有很多人阅读过这篇文献，做了不少笔记，这些笔记可以帮助自己理解，因为刚开始肯定有许多地方是不能够理解的，这样慢慢培养阅读能力； 在使用super关键字的时候，以前就没有学得很透彻，反过来又学一遍，联想到还有python基础相关的其他关键字以及扩展开来python的更多基础内容并没有学得更扎实，这在方法上属于举一反三能力，在知识的掌握上属于未系统性的学习； 再在在学习吴恩达的视频的时候，很多细节性的内容和扩展性的内容都没有讲到（比如讲RNN的变形的时候，就有多对多、多对一、一对多、一对一四种模型，但自己并没有花时间去钻研每种模型的使用场景和条件），包括在学习《自然语言处理综论》中的内容，虽然已经够详细了，但还是有些内容没有讲详细，需要自己去扩充学习，这些都导致了基础内容掌握并不扎实； 基础内容第一遍不一定掌握得很全面，所以在以后的学习中，看到有不同的理解时（前提是记得以前所学的知识点），需要再次进行学习，深度挖掘，再次学习的重点是深层次的理解，而并非浅层次的因为遗忘而再次复习； 间歇性地停止学习产生的可能原因： 因为恐惧感，感到要学的东西太多了，而时间又不够，还不一定学得好，干脆就停止去干其他事了； 看不到有什么实际应用，能产生什么效果，产生厌倦感； 在平时浏览网页的时候，经常会看到很多自己不知道但又需要掌握的内容，然后就会产生焦虑情绪，这也是可能是导致自己间歇性停止学习的原因之一，其实本质怕太多反而产生厌烦情绪，然后停止学习，白白耽误了更多时间，学习其实怕的不是慢，而是停止，其实解决办法也很简单，自己开始一点一点的学习，并记录学习进度，这样看到自己的进步就能逐渐淡化这种“恐惧”心理。对于看到的不懂的内容，可以将其记录在某个记事本上，平时利用零散时间进行学习，其实这种零散时间很多，真到了零散时间了，又不愿意看，害怕没有做笔记或者不能演算进而不能掌握得很好； 学会用简短精炼的语句讲述自己所学的，所感的内容，尽量不要大段大段引用别人的话； 5.30 找工作计划主要考虑一下几点： 以尽快找到工作为目的，不能再完全准备好了再找了，要边找边学习； 对准备找工作过程中学习的每个知识点都尽量掌握完整； 以经典资料为学习内容，尽量避免接触零散的、不确定来源可靠性的资料，不要被网络上各种各样的资料看花眼； 2019年6月6.25 反思状态、制定计划【悟】 很多博文下面的评论有时也是经典的理解方向； youtube具有更丰富的视频资源； 6.26 刷题 + 分词项目 + 概率学习【行】 调试pycharm，设置界面； 分词项目总结查询，准备实施； 学习叶丙成的《机率》 【悟】 在学习台湾教授叶丙成的课程中体会到，一方面结合实际例子理解基础概念，这是非常重要的，但另一方面，自己已经是第三遍学习概率论了，已经有了一定的基础，不能再只停留于表面，如何结合已会的概念深度系统地学习是个值得思考的问题，在叶丙成的这门课中，使用的是《Probability and Statistics》这本书，这次的学习是否应该结合这本书开始深度研究概率论呢这个值得思考； 6.27 刷题 + 感知机学习 + 概率学习【行】 感知机的深入学习； 感知机的代码编程； 各种代码操作的温故； 叶丙成《机率》的学习； 林轩田的学习基石； 【悟】 现阶段主要复习要用到的数学，而不是系统巩固旧知识； 今天在学习过程中的主动思考的行为减少了，这要注意； 养成良好的写代码习惯，代码写成模块（函数、类别、包）等形式，这是从下载的github上关于《统计学习方法》代码实现上对比自己编写的感知机代码得出的结论； 刷题优先安排时间，今天在时间安排上存在问题； 学会写明日事情安排，并且在第二天晚上写日志的时候检查完成程度，目的在于提高规划能力和执行力； 在学习林轩田的视频的时候，发现其实并不那么简单，需要一定的机器学习基础和数学知识，但他从另外一些角度展示了机器学习的理解，这与吴恩达的入门级知识不同，与李航的《统计学习方法》数学方法为主也不同，从中可以看出，选一些经典的资料有助于自己开阔眼界，增加对知识的理解深度； 遗问： PLA为甚么称作在线学习，它也需要检验一遍所有样本，并且在不能正确划分样本的情况下还需要迭代； 明日安排： 刷题； 完成对感知机的理解，包括为什么有限次数后会收敛，但对于对偶的问题（相对复杂），先不用弄清楚； 完成对分词的归纳总结，并且设定好需要写的项目； 零星时间可以学习叶丙成的《机率》 6.28 刷题 + 感知机学习 + 复习中文分词系统【行】 刷题，并复习python相关知识； 理解感知机的1/||w||为什么可以在损失函数中省略； 明白了损失函数的批量梯度下降和随机梯度下降原理； 理解了什么叫结构化的感知机和结构化的SVM； 理解基于无标注数据的半指导特征分词方法，卡方分布，边界熵； 理解基于新词识别的切分方法； 【悟】 《python3学习笔记》一书的学习放在后面进行学习，在应聘时如果觉得python没有必要先深入，马上用到的知识可以先学习，没有使用急切性的就放在工作以后再学习，如果在面试时觉得有必要，就边学边找，这种类型的书籍完全可以利用零星时间进行学习，对于《数据结构与算法 Python语言描述》这类书才需要花整块时间研究，这是按照对于工作中重要性、核心性来分类的； 异常的python处理； 不要有标准答案的思想； 遗问： 对于感知机的次数收敛问题的证明不是很明白； 明日安排： 刷题； 复习深度学习和条件随机场的基本内容，为项目做准备； 熟悉中文分词哪些软件比较好用； 6.29 休整【行】 简单复习了学过的叶丙成的《机率》； 打印线性代数、机器学习基石、机器学习技法的课件； 任务完成度：0； 【悟】 学习数学基础需要大量练习和测试，而MIT官网上就有，尽量不要看答案，就像叶丙成说的，逼一逼自己，锻炼下自己的韧性； 对于未完成的任务，必须加到明日安排中，观察任务的执行能力； 明日安排： 学习《机率》； 刷题； 复习深度学习和条件随机场的基本内容，为项目做准备； 熟悉中文分词哪些软件比较好用； 6.30 学习《机率》【行】 学习《机率》，基本上复习有1/2的内容； 【悟】 叶丙成的课非常基础，但是缺乏一些系统性的练习，结合《Probability and Statistics(Fourth)》这本书进行系统性的学习和练习比较好，它们之间相互补充，叶丙成的课提供基础讲解，这本书提供练习、系统化和深化知识结构； 注意自己一些习惯，比如把某些事留到以后做的习惯，这个要思考是否真的有必要现在不做； 有些知识点明明没有掌握得很好却要继续往下学，这个习惯不好； 叶丙成很好的观点是学以致用，学习了就拿来使用，深化对概念的理解； 面对未知问题需要的东西：再尝试的勇气和信心，多样化的解题能力； 除了专业之外应该有自己的爱好和广泛的知识； 任务完成度：0； 遗问： 《机率》中进击的钞票一题没做； 明日安排： 学习《机率》； 刷题； 复习深度学习和条件随机场的基本内容，为项目做准备； 熟悉中文分词哪些软件比较好用； 2019年7月7.01 学习《机率》【行】 学习《机率》，基本上学习有1/4的内容； 【悟】 反复对比学习，忘了就重新翻，重新算，巩固加深记忆； 任务完成度：0； 明日安排： 学习《机率》； 刷题； 复习深度学习和条件随机场的基本内容，为项目做准备； 熟悉中文分词哪些软件比较好用； 7.02 学完《机率》【行】 学习完叶丙成的《机率》； 【悟】 在学习完《机率》之后的一些总结： 学习理论知识一定要以实际的例子进行练习和应用，不仅仅要在学习理论之后要结合实例进行练习巩固，在学习理论的过程中结合例子也能够提高理解的效率和深度，特别的，在学习理论之前也可以用例子作为引导，比如在学MGF之前，通过“红娘转换场景促成恋爱”的例子中就首先用例子进行了过程的形象描述，这为后面理解MGF整个流程打下了框架基础，但这一点是针对于给别人讲课或者别人通过例子来引导我们的时候； 多做习题，它的作用有以下几个： 巩固所学的东西，深刻理解理论； 纠正错误的理解，理解不正确的在做题的过程中会出现与预期不同的结果； 学以致用，提高建模能力； 学习的时候要对比学习，忘了就重新翻查，重新计算，这样能提高对知识点的记忆； 在学习中的主动性思考非常重要； 基础理论一定要学好，这是走向复杂，解决更多难题的根本，比如在阅读英文书籍的时候，往往可能因为语言问题而理解不了某些概念，但是如果某些基础概念比较清楚，就会促进自己从公式的形式上结合自己基础知识进行猜测学习，然后就是通过例题来进行验证； 打印课件的时候要增加页数和目录，方便翻阅查找，在每章的结束位置插入空白页方便自己进行相应的知识整理； 缺少了对每一章节的系统整理，各种知识在头脑里比较零碎； 前面学的知识学好了再往后面学，不然可能会弄得糊里糊涂的，反而耽误了更多时间； 对于书上没有讲或者讲得不清楚的概念需要自己在网站查，因为它涉及的知识点可能还包括其他内容，了解它们对于了解知识点、拓宽知识面有很大帮助，比如X的$n^{th}$moment是什么意思刚开始就没怎么弄懂，以为就是n次方的意思，结果实际上它表示的是数学中“矩”的概念，而n阶的矩表示不同的含义； 许多概念依然不是很熟，概念的区分依旧存在问题，需要后续继续翻阅理解和记忆，比如多项式组合； 某些知识点的推导很重要，有时候它能启发其他知识点的推导，比如连续函数中密度函数的推导； 《机率》这门课只是讲了一些比较基础性的、必要的知识点，很多其他更全面、更深入的知识需要结合其他相关书籍进行深化； 有些证明依然没有完成，比如各种函数分布的期望、方差公式推导，各种函数的MGF推导，有些题也没有做，比如“进击的钞票”； 对于长期计划的东西，比如数学，应该每天积累一点，不要等有整块时间了才来学习，这样的整块时间往往很少； 要敢于突破固有习惯生活学习，比如在时间分配方面，总是担心如果把时间花在了其他不是学习的方面就会得不偿失，把做其他事情的时间压缩在很小的范围内，其实做其他事情，比如运动，练琴、看书等等，也许会促进学习的进行，因为大脑注意力得到了转移，没有长时间做一件事情而感觉乏味、疲劳； 7.03 刷题 + 《统计学习方法》复习【行】 刷题； 深入阅读《统计学习方法》第一章和第六章； 【悟】 给事情分急迫性和重要性分等级； 学着克服自己的不好的习惯； 在看书学习的过程中，纸上应该记录什么东西； 看书学习的时候经常不仔细，某些符号的意思想当然地认为或者直接忽略了该符号，导致理解出现偏差，这个习惯要改； 《机率》的学习和复习使得在重新阅读《统计学习方法》时很多原来不清楚的概念更容易理解了，并且对ML的学习理解更深入了，所以基础性知识非常重要； 在学习《统计学习方法》的过程中，看到有在复习了监督学习的基本框架后，再回顾各种模型，发现都是大同小异，所以框架的根本思想掌握非常重要，它就像一个指导，在学习新的类似的模型时指导自己套用学习、对比； 如何有效地在书上做笔记，可以根据自己回看笔记，哪些是重点通过自己的勾画或者描述讲清楚了，哪些是没有必要勾画的以免把书弄得太乱； 记录在学习过程中遇到的暂时不能够解决或者暂时没时间解决的问题； 任务完成度：0.2; 遗问： 《统计学习方法》P87-92 明日安排： 学习《线性代数》1小时； 刷题； 复习深度学习和条件随机场的基本内容，为项目做准备； 熟悉中文分词哪些软件比较好用； 7.04 刷题 + 《统计学习方法》复习【行】 刷题； 复习《统计学习方法》中HMM和CRF章节； 【悟】 MIT《线性代数》的讲课中有很多引导性思考，这可以培养自己的自主探索能力； 即使你能跟上视频的速度，你也需要留点时间给自己思考，因为学习往往就在此刻发生； 写好的《剑指offer》要在牛客网或者leetcode上刷，看是否能通过，因为自己有很多地方可能没有考虑到，这也是锻炼代码鲁棒性的方法； 对于概念的理解、字母的含义、公式的推导，需要结合各个已有的信息，而自己经常忘记甚至跟没没注意书上写的； 在刷题的时候，先是白板编程，再是实际编程，但是在实际编程的时候有些地方又经常修改，这应该是在白板编程的时候注意这些问题； 任务完成度：0.5； 明日安排： 学习《线性代数》1小时； 刷题； 复习深度学习和条件随机场的基本内容，为项目做准备； 熟悉中文分词哪些软件比较好用； 7.05 刷题 + deeplearning复习【行】 刷题； 复习吴恩达的deeplearning； 任务完成度：0.7； 【悟】 学习MIT的《线性代数》，感觉虽然能够提供一些理解的新角度，但是，课堂上讲的并不系统，甚至有时候比较错乱，想要系统一些需要额外地看《Introduction to Linear Algebra》全英文的书籍，并且可能是英文书籍有时候概念并不能理解，感觉学下来要花很多的时间和精力，然而，回到最初的学习目的AI，线性代数可能提供的只是在计算方面的内容，也许偶尔会有应用原理性的知识点，但是这也是相当有限的，而对于AI来讲，更重的是概率论与数理统计，所以我认为在学习这些不是非常重要的领域时，不要太过追求完美、追求系统性的学习而牺牲了大量的时间，这些知识点也许只要会用就行，微积分其实也一样，应该把大量的时间花在概率统计、机器学习这些非常关键的内容上； 代码顺序上的调整也许可以省略很多不必要的代码； 在设计代码的时候，思路应该尽量简洁，复杂的设计思路会带来其他的一些问题，不仅仅是繁杂，比如在刷《合并两个排序的链表》的题时，就在两个链表的有相同值的处理时选择了将&lt;=的情况合并处理，分开处理时情况已经比较复杂，但是在实现的时候，隐藏的链表指针的变动产生了更为复杂的情况，结果导致写代码的时间过长，并且程序还运行有问题，其实这也是观察没有到位的结果，其实在设计的时候&lt;=的情况完全可以分开处理，并且后续发生的实际情况与原有思路一致，修正思路之后一遍就把代码写了出来，所以设计时观察规律，简单的试算几步，也许情况就没有那么复杂了； 写代码时，即使想不出来最聪明的方案，也不要忘了最笨的方法； 明日安排： 学习《线性代数》1小时； 刷题； 复习深度学习基本内容，为项目做准备； 熟悉中文分词哪些软件比较好用； 7.06 休整 + 刷题 + deeplearning复习【行】 学习《线性代数》1小时； 刷题 deeplearning简单复习 任务完成度：0.5； 明日安排： 学习《线性代数》1小时； 刷题； 复习深度学习基本内容，为项目做准备； 熟悉中文分词哪些软件比较好用； 7.07 休整 + 线代 + deeplearning复习【行】 学习《线性代数》1小时； deeplearning复习； 任务完成度：0.2； 【悟】 马辉的“线性代数”中节奏比较快，缺乏更多的练习，所以在每开始一天的学习的时候要复习前面的内容，加深对学过东西的理解，必要时加入一些其他例子尽心运算，这个例子也告诉我要根据不同视频的教学特点来调整自己的学习方式； 在学习“线性代数”的时候难度逐级递增，理解的时间花费更长，所以在以后学习安排时间的时候，要这样考虑时间长短，而不是将所有章节的学习时间作为均匀分布； 在今天的学习中我感觉到，国外的教学方式和国内教学方式与人才培养的不同，国内课程纯概念居多，定理居多，计算居多，而对于本质上的东西讲解较少，国外相反，对于本质上的讲解，推导、理解、应用居多，而要应用于实际，对于概念本质理解是必不可少的，相对于国外，要掌握国内的讲解方式所讲的东西的本质，一种要求是需要较高悟性的人，这就在无形中提高了对于学习者的要求（所谓的高智商），另一种要求就是多练习，达到的只是“熟练度”的提升或者理解的那么一点点提升，其实这也不仅仅局限于国内教学和国外教学，国内也就讲解的很好的，但是方式基本都类似于国外的方法，所以从学习方式的本质上来说，对于基础概念本质上的理解才是应用知识去解决世界问题的根本； 关于刷题的方法，一方面要动手实践写代码，另一方面，需要没事的时候就看看其他题，看看各种解题思路，减少遇到不会题的可能性； 明日安排： 学习《线性代数》1小时； 刷题； 复习深度学习基本内容，为项目做准备； 熟悉中文分词哪些软件比较好用； 7.08 线代 + deeplearning复习【行】 学习线性代数3小时； deeplearning； 刷题； 【悟】 线性代数时间安排过多，目前主要是花在准备面试和夯实基础上面； 《线性代数》分配时间不合理，在规定时间的时候，应该把理解的时间也投入在内，而不是以视频的时间多少为主线，不然这个时间就不好控制了，学完一个视频，理解了其中的内容，然后再看下一个视频，这样时间上的出入不会太大； 畏惧问题的心理才是效率、解题的关键，这是长期养成的，应该思考如何改变； 学习知识时就应该相对系统地学习，零散地、片面地反复学习浪费了更多的时间，从基础开始，一步一步来，一定会比零散的要强； 明日安排： 学习《线性代数》1小时； 刷题； 复习深度学习基本内容，为项目做准备； 熟悉中文分词哪些软件比较好用； 7.09 休整 + 线代【行】 学习《线性代数》1小时； 任务完成度：0.1； 【悟】 补数学基础知识的时候，有些公理应该自己证，这样可以提高自己的数学能力，但是现在面临找工作，所以先不把时间花在证明上面，以后有时间再证明，但有一点，对于线性代数这类计算类学科，真的有必要花时间证明定理吗； 明日安排： 刷题； 复习深度学习基本内容，为项目做准备； 熟悉中文分词哪些软件比较好用； 7.10 制定学习计划【行】 任务完成度：0； 【悟】 缺乏自制力，应该学习如何提高自制力； 补数学基础知识的时候，有些公理应该自己证，这样可以提高自己的数学能力，但是现在面临找工作，所以先不把时间花在证明上面，以后有时间再证明，但有一点，对于线性代数这类计算类学科，真的有必要花时间证明定理吗； 明日安排： 刷题； 写序列标注项目； 熟悉中文分词哪些软件比较好用； 7.15 Nothing【行】 任务完成度：0； 【悟】 自信力不够； 以点带面，前提是对点的各个细节和扩展都比较透彻了； 7.16 &lt; 再见，过去 &gt; 分解目标； 充满自信； 竭尽全力； 强迫自己改变； 给自己加油，不断告诉自己别放弃； 适当给自己压力； 到底结果会怎样？ 自己潜力有多大？ 不要骗自己； 坚持，不知道得到的是什么，但是，不坚持，知道自己会后悔； 让这个世界更美好； 你， 要怎么样的度过这一生？ 别再浪费时间， 哪怕一分一秒； 懒惰久了，努力一下就以为字拼尽了全力； 凡是不能将我毁灭的，必将使我变得更强； 给自己坚毅的眼神； 做些疯狂的事； 勇敢去做，勇敢去尝试，活出精彩； 7.17 刷题 + Pytorch复习【行】 刷题； 复习数据结构：树； Pytorch基础编程练习； 明日安排： 刷题； 完成用深度学习进行序列标注； 总结分词系统； 7.18 刷题 + Pytorch中LSTM学习 + 词性标注【行】 刷题； Pytorch中LSTM学习 完成一半用LSTM对词性进行标注； 【悟】 在实践中才能发现更多的问题，比如今天在使用Pytorch中的LSTM建立词性标注模型的时候，就发现了很多问题，比如训练性能如何提高、超参数如何调整、模型存储及加载等等，在今天的实践中也学到了很多东西，比如各种函数的使用，如何检查代码的运行是否正常等等； 自己写过的代码应该系统化地保存，不要随便删掉； 如何使大脑更灵活、更灵动，加强运动还是多看些其他东西，或者其他什么方式； 利用jupyter notebook写代码不好的地方在于没有定义成类或者函数，不好调用； Ruder.io这个网站应该经常去； 任务完成度：0.6； 明日安排： 刷题； 完成用深度学习进行序列标注； 总结分词系统； 7.19 刷题 + Pytorch中LSTM学习 + 词性标注【行】 开始战胜自己 刷题； Pytorch中LSTM学习 完成LSTM对词性进行标注； 锻炼身体 【悟】 在使用某些库的时候，如果想更清楚一些原理，最好阅读官方文档和源码； 阅读好的代码能提高自己的编程水平； 理清思路再编码，否则可能陷入各种细节修改的局部最优解而无法获得全局最优解； 每天的日志必须当天写完，这也能帮助自己克服拖延的习惯； 锻炼身体的关键在于： 要感受到锻炼位置的肌肉在发力； 动作要标准，速度不是关键； 养成良好的饮食习惯； 规划的刷题内容应该更加具体； 任务完成度：0.6； 明日安排： 二分查找、快速排序、归并排序、图复习； 使用pytorch建立以LSTM+CRF的命名实体系统；； 总结词法系统； 7.20 刷题 + Pytorch中LSTM学习 + 深度学习复习【行】 又一次战胜了自己 刷题； Pytorch中LSTM学习； 深度学习内容复习； 锻炼身体； 【悟】 读书与游戏的不同 分层奖励：游戏里的奖励能让人开心，欲罢不能，分层奖励让不同的人，都能获得相应的奖励，让玩家有动力持续玩下去。读书获得奖励的门槛高，不容易获得知识带来的快乐、等级提升的体验感。 虚拟化身的成长：游戏里角色的升级、英雄的成长、段位的提升，会让人有代入感，在乎输赢。读书不会看到肉眼的成长，语言晦涩，难有代入感。 角色互动：游戏提供了一个很好的游戏互动平台、社交平台，全方位提供游戏乐趣。读书是一件孤单的事情，没有互动性，以读书做社交很难。 改进学习方法——将学习游戏化 分层奖励——奖惩机制：设置简单有效的奖惩机制以及针对自己实际情况设置合理的奖励，要得是自己想要的、要有仪式感、要分级，要安排人员监督。 虚拟化身——学以致用：看完书或者学习技能后，去网上社区、论坛，帮助别人解决问题，获得成就感。 参与感——学习伙伴：要让伙伴对自己知识的输出做出反应，创造出互动的感觉。 任务完成度：0.6； 明日安排： 归并排序、图复习、刷递归类题； 使用pytorch建立以LSTM+CRF的命名实体系统；； 总结词法系统； 7.21 《Python3学习笔记》 + LSTM词性标记总结【行】 《Python3学习笔记》阅读； LSTM词性标记项目总结； 锻炼身体 【悟】 状态有点松懈，单位时间的产出比较少，专注度有所降低； 对于以前做的总结没有在回顾，总结应该至少一周回顾一次，并最后汇总在专门的“总结”网页中； 如何快速追赶？ 多花时间 * 提高单位时间产出； 更新方法； 选对方向； 实践中或者学习中的草稿能够看清自己走的路线，所以在学习或者实践没有进行最后总结之前，不能乱扔，此外，草稿中还有自己的书写习惯，格式习惯等等信息，这些信息对于提高思考力、纠正思考方式也许有用； 将公式、模型化为直观的、形象的图形，能够大大帮助自己理解，这就像费曼学习法一样，化为通俗易懂的事物（这里就是图）更能增加易懂性； 在刷题时找规律的方法往往是试运行几步，看看结果，最好将运行过程画出来，更为直观，更易寻找规律； 刷题过程中如果出现循环嵌套，一定要注意内部循环时的数值更新是否已经超出了外循环的条件； 刷题过程中端处理一定要单独拿出来考虑； 将学习过程中产生的问题（暂时没有时间去解决的）或者说需要学习的内容记录下来，一定要醒目； “以点带面”式的学习方法（或者说是“辐射式”学习法），如何能带动面，前提是把项目的每个细节都研究得比较透彻，比较彻底，加以扩展实验，这才能带动面，下图这个例子不是很全面，但是具有一定的方向性； LSTM项目总结： 结合了以前学习的吗，以前学习的起到了什么作用？ 用到了很多以前在“理论”上学习过的东西，以往自己陷入了学习停止不前，始终在已经学过的内容里面重复的学习，根本原因在于自己仅仅停留在了理论阶段，没有进行实践，对于学习的内容理解不深，许多在学习过程中遇到的细节很可能并没有正确理解，导致理解的扭曲，感觉到别扭，甚至说错误理解之后根本没有察觉，感到不对，过一段时间之后，就又忘了，然后又重新复习一遍，并没有在实践中纠正这些错误的理解，并且加深对正确理解角度的记忆，模型的性能、适用性也没有得到验证，回想自己学习过的机器学习课程、深度学习课程均是如此； 从项目出发去学习固然是好的，但是应该建立在对该领域有一定的全局观的基础上，所以，在学习的时候，基础性的知识了解、概览性的了解是应该有的，不然完全根据项目区学习，知识点有点过于零碎、凌乱了，不好整合在一起，如果有一个全局性的掌握，就相当于有一定的指导性去学习，然后再补充填充各种细节，这样我觉得效果可能会更好，当然，从实用的角度和最终目的的角度出发，只要能完成目标是最好，但是从更长远的角度出发，应该具备全局观、体系性和完整性； 这些细节问题应该是现在才考虑到的吗，还是在学机器学习的时候就应该考虑到？ 在以前学习机器学习和深度学习理论的时候就应该掌握和理解，当然，现在也是一个重新理解的机会； 深度学习框架中提供的损失函数远远多于自己在理论中学习的，这是工业与学界的区别，这能为自己提供哪些信息？ 在理解RNN的反向传递中，参数的梯度计算一直是难以理解的，即便是在查了一些资料之后知道了有时间上的误差传递和空间上的误差传递之后也不能完全理解，其实在于对损失函数的理解，模型的损失应该是总体损失最小化，而不在于每个单体的损失最小化，也就是说在于每句话、或者说每个batch的最小化，而不在于每个词的损失最小化，这样就能够将计算所有使用相同参数矩阵的梯度求出，而不是单个考虑单词，然后就不知道如何更新梯度了； 如何修改、设计模型？ OOV词如何处理？ 超参数如何调整？ 根据吴恩达的机器学习策略进行调整； 单独上网查询调整策略和方法； 雅克比矩阵是哪两个矩阵相乘仍然不清楚，其实是刚看学习过的，但是没有仔细去研究，这也体现了自己的一种随意的态度； 正确的做法应该是，学一个就掌握一个，努力做到不再重新学习一遍,实践是最好的掌握方法； 为何项目进度控制不准确： 压力感不强； 基础不牢； 不要陷入各种项目中，要时刻提醒自己最终的目标； 上午不该做什么，下午该做什么，明确的目标会指导行为选择； 从NLTK软件的角度学习NLP； 使用-理解-修改是学习数学和模型的几个阶段，其中，前面两个的顺序根据所学内容而定； 买回来的书应该都大致看下目录的内容，在学习某一资料的时候可以互为补充，不然买回来了不知道有哪些东西还不如不买； 在批量修改文件名的时候突然想起字符串操作应该直接能使用python中的函数进行直接操作而不是自己再写函数，这反映了基础数据类型都没掌握好，基础薄弱啊； 感觉什么都没学好的原因在于基础不扎实，浮躁； 任务完成度：0.6； 明日安排： 完成LSTM+CRF的NER； 总结词法分析； 刷题，具体包括复习图模型，然后刷关于递归的题型； 锻炼身体； 7.22 《Python3学习笔记》 + LSTM词性标记总结【行】 《Python3学习笔记》阅读； 刷题 LSTM+CRF命名实体理论学习； 锻炼身体 【悟】 十一点之前必须睡觉，不然第二天精神不好； 记录时间行程； 做事专注，不要做些其他杂七杂八的小事，比如喝水，剪指甲，收拾桌面； 自主思考性； 学习复杂模型的时候，每次都以为懂了大部分之后就没有在仔细专研其他部分了，特别是解码、优化实现等类似问题之后 明日安排： 完成LSTM+CRF的NER； 总结词法分析； 刷题，具体包括复习图模型，然后刷关于递归的题型； 锻炼身体； 7.23 刷题 + CRF、HMM、Maxent【行】 刷题 CRF命名实体理论学习； 锻炼身体 【悟】 又一次战胜了自己 明日安排： 完成LSTM+CRF的NER； 总结词法分析； 刷题，具体包括复习图模型，然后刷关于递归的题型； 锻炼身体； 7.24 刷题 + 最大熵模型数学公式推导 + IIS算法【行】 刷题 最大熵模型数学公式推导 + IIS算法 锻炼身体 【悟】 又一次战胜了自己 时间安排中如果安排上午刷2小时题，下写项目，感觉安排合理，但是如果换一下，上午写项目，下午选2小时来刷题，感觉就不好，这是为什么呢？ 学习的时候有时候会遇到些问题或者不理解，然后就到处去查资料，其实，很多时候都可以通过自己的思考自己解决的，比如在学习NLTK最大熵分类器的时候，模型训练完了，理解模型的各种设置时，遇到有一个set_weights的函数，从字面上理解，就是设置自己的参数向量，但随后自己又在想，这不就可以添加自己的特征并赋予它定制化的权值吗，也就是加入先验知识，但是仔细一想如果要自己添加特征函数，向量中倒是可以多增加一个，但是其对应的特征名称无法添加，因为没有给出添加模板，然后自己就到处查资料如何添加，结果都没有讲，其实，回头仔细一想，其实这个添加特征的操作根本就不对，特征应该是从特征模板里生成的，这样每个特征自然可以对应于一个权值，通过训练得到，即使要添加特征，也应该是在模板里修改，在训练数据中做好相应标记，然后训练得到，而不是自己随意添加值； 昨天pytorch安装提示版本不对，别人有提示语，但是自己根本没有仔细琢磨，只看了python是3.7.4没注意是32位的，结果浪费了很多时间解决这个问题，我觉得这也是自己欠缺独立思考问题能力的体现； 明日安排： 学习使用CRF做NER的代码，学习模块化编程，学习好的开源项目的架构； 刷题，具体包括复习图模型，然后刷关于与或非数的题； 锻炼身体； 7.25 刷题【行】 刷题 【悟】 又一次战胜了自己 IDE有它的好处，使用快捷工具节省时间，比如阅读代码的时候有各种小工具可以快速定位、查看和返回； 自己索要用到的功能，别人早就可能想到了，甚至实现了，特别是在IDE里面，所以只需要上网找它的这个功能在哪就行了； 明日安排： 学习使用CRF做NER的代码，学习模块化编程，学习好的开源项目的架构； 刷题，具体包括复习图模型，然后刷关于与或非数的题； 锻炼身体； 7.26 EM、HMM、MaxEnt、MEMM、CRF 通览【行】 EM、HMM、MaxEnt、MEMM、CRF 通览 【悟】 又一次战胜了自己 在理解HMM、MaxEnt、MEMM、CRF几个模型时，学习相当的慢，总结有如下原因： 数学基础不扎实，特别是概率与统计方面的数学知识，对于各种分布的理解不透彻直接导致了学习这些模型的时候相当的慢，理解了这部分知识点，那部分知识点又不理解，即使各部分都了解了也不会整合到一起，这就体现了知识的不系统化，不能体现知识之间的关联；比如理解马尔科夫随机场，这个知识点出现在的是图论中，自己也没有学习过这方面的知识，在看些相关资料时也是丈二和尚； 在学习过程中查了很多的网络博文，其实，写这些博文的人水平参差不齐，很多人根本没有理解模型的数学意思，都只是按着自己的理解来写，结果导致自己在学习的时候出现了很多矛盾的地方不能解决；- 没有对这些模型进行实现，很多细节以为自己理解了，其实还是有一定的偏差；解决方法： （1）打牢数学基础； （2）尽量查看原始论文，即提出这个模型的原始出处； （3）尽量自己实现这个模型，才知道很多细节方面的理解； 以最自然、最直觉的方式理解事物，打牢基础； 提高兴趣度，想象能用在学的知识点做些什么，因为它确实能实实在在地影响行为和专注度； 明日安排： 总结词级别存在的各种主要问题和应对方法； 刷题 7.27 句法级复习【行】 句法级复习，cky 【悟】 又一次战胜了自己 明日安排： 总结词级别存在的各种主要问题和应对方法； 句法级复习； 刷题 7.28 休息【悟】 造成学习断断续续的原因： 领域涉及知识点很多，而自身基础不牢固； 长期处在舒适区造成习惯性的逃避，一遇到难的模型，在学习时间过长的情况下，就会容易松懈，放弃，选择逃避干些其他无关紧要的事，觉得自己该休息一下，事实上只是并不是自己累了，只是习惯性地想待在舒适区，过几天或者一段时间过后，遇到些其他易学、感兴趣的或者觉得更要紧的知识时，又开始学习那部分东西，把原有计划的学习体系打乱，结果学习新知识点时又没有去实现，或者重复上面的过程，导致自己根本没学到什么东西，觉得要学的东西依旧那么多，索性又开始绝望，开始用其他事情吸引自己的注意力，导致大量时间的浪费，以后基本就是重复上面的状态； 工作尚未找到，心理比较慌； 有时候学知识不单单是学模型之类的，更重要的是思想，比如今天看最大熵模型的IIS算法，它就体现了一种逼近的思想； 手机里准备视频零碎时间看； 厉害的人可能就是把各种信息、技巧烂熟于心，在要用的时候能够直接蹦出来，而一般人也需要经历练习的过程才能把这些信息存起来，只有经过反复的练习将其内化才能在用的时候蹦出来； 根据阅读的目的要会选择阅读的内容，自己的行为也是同样道理； 现有东西不是万能的，要有能写自己定制化功能的能力，包括程序库、模型等等； 在学习的时候一定要知道正在学习的这个知识点在实际生活中是用于干什么的，没有目的地学习更会让人产生疲倦感，甚至反感； 像从语言学角度看词嵌入模型这类好论文从哪可以找到； 明日安排： 总结词级别存在的各种主要问题和应对方法； 句法级复习； 刷题 7.29 哈希结构 + N元语法 + 句法【行】 复习数据结构哈希结构； N元语法中平滑弄清楚； PCFG句法复习完； 【悟】 不要养成学习任何东西都从头看的习惯，如果自己对前面的知识点已经掌握了，就直接看自己需要的那部分，否则会浪费大量时间； 专注度不够； pytorch官网有很多小项目可以学习； 做事干脆点； 明日安排： 完成LSTM+CRF命名实体； 总结词级别存在的各种主要问题和应对方法； 句法级复习； 7.30 Pytorch官网中LSTM+CRF作NER【行】 理解Pytorch官网中LSTM+CRF作NER 【悟】 今天只用在了上述收入中，并且尚未完全理解，时间利用率有点低； Micheal Collin 的课是很好的，特别是他的slide； 时刻记住每个阶段的重点； 如何处理一下子理解不了的问题； 理解的方式、习惯、思路如何改进； 记录每天的时间分配情况； 明日安排： 完成LSTM+CRF命名实体； 总结词级别存在的各种主要问题和应对方法； 句法级复习； 刷题； 7.31 依存句法 + 感知机扩展 + HMM估计参数复习【行】 HMM估计参数复习； 依存句法； 平均感知机； 结构化感知机； 多分类感知机； 明日安排： 总结词级别存在的各种主要问题和应对方法； 依存句法学习； 刷题； 2019年8月8.01 基于结构化平均感知机的标注器【行】 研究基于《A Good Part-of-Speech Tagger in about 200 Lines of Python》论文感知机标注器源代码； 【悟】 要思考如何解决单本书或者单个视频教程带来的片面性理解； 使模糊的模型、数学关系变得清晰，这是理解一个模型的标志； 博客可以作为别人评判你水平的标志之一； 8.08 28岁，启程 . . .0. Tips 面试流程 以项目带动基础知识复习和学习，传统方法和深度学习方法交替使用； 工作相关关键字：NLP研究员、NLP算法工程师、NLP工程师、自然语言处理、机器学习； 提高有效工作时间； 写博客、参加比赛，积累证明自己能力的途径； 考虑自己与其他求职者最大的不同； 展现活力、积极与真诚； 简历上不要写自己不太懂的东西； 1. 编程类数据结构与算法：一方面要自己实现算法，另一方面要积累各种各样的解题思路 第一梯队：复杂度分析、链表、二叉树、二分查找、快速排序、归并排序、回溯法、动态规划、分治、贪心、枚举 第二梯队：正则表达式、字符串、栈、队列、堆、数组、图 {DFS遍历、BFS遍历、最大（小）生成树算法（Kruskal、Prim）、最短路径（Dijkstra、Floyd）} 第三梯队：哈希、集合； python语言： python语言自身的优缺点需要掌握； 各种常用类库的掌握和运用； 熟悉bug调试的技巧； 熟悉PyCharm的使用技巧； Linux操作系统： 会使用简单的命令； 使用python进行编程； 数据库： 数据库操作语句； 计算机网络知识： TCP三次握手； 2. 自然语言处理要求： 掌握 从头到尾的各个环节（包括特征工程（文本预处理））以及各个环节主要的解决方法，各自的优缺点有哪些； 从各环节的实现开始建立自己的NLP系统（提高整合能力）； 深入了解模型所用的算法及其原理和推导，算法本身的优劣性，使用的条件限制是什么； 练习使用NLTK、Spacy、Gensim、Pytorch、FastText等相关软件 内容： 传统模型：N元模型、HMM、MaxEnt、CRF、EM、MMseg、PCFG、PLSA、LDA 词级别：分词（基于离散特征的CRF、BILSTM-CRF）、词性标注、命名实体识别 句级别：浅层句法分析、依存分析、词义级分析（重点掌握内容）、句义级分析 篇级别：文本分类、情感分类 规划的项目： 项目列表：分词、词性标记、实体识别、依存句法分析、短语句法分析、文本分类、文本聚类、词义消歧、句义消歧、情感分析、相似度计算、意图识别、文本摘要； 选择标准： 尽量包含常用内容； 包含内容较为全面最好； 候选项目 常见30种NLP任务的练手项目 邱锡鹏建议的几个小项目 自然语言处理从上手到进阶【项目资源库汇总】 Github 上 Star 过千的 NLP 相关项目 一些NLP项目资源 NLP领域最优秀的8个预训练模型（附开源地址） 规划项目： 序列标注：分词系统、词性标注、命名实体识别系统 (bi)LSTM+CRF序列标记项目（设计gensim使用产生词向量，LSTM可以更换为RNN和GRU，CRF训练需要用到HMM中的训练方法，CRF原理与最大熵模型极其相似，使用Pytorch深度学习框架）（参考【ipynb】Deep Learning for Natural Language Processing with Pytorch） 最新中文分词改进版网址 复旦大学邱锡鹏教授：词法、句法分析研究进展综述 MaxEnt字标注（复习+NLTK的使用） 句法分析系统（主要是依存句法分析） 基于图的依存句法分析 基于转移的依存句法分析 语义分析系统 指代消解问题 文本聚类与分类 文本特征的选择方法（涉及TF-IDF、信息增益、卡方统计、互信息） 分类器设计（涉及朴素贝叶斯、SVM、KNN、决策树、逻辑回归等机器学习方法，并且熟悉使用sklearn库） 3. 机器学习模型:SVM算法（最为常用和权威的分类方法）、感知机（神经网络的基础组件部分）、朴素贝叶斯、决策树（涉及信息学方面的内容）、逻辑回归（比较简单和常用）、K近邻算法K-means、提升算法（集成算法的一种） 策略:参考吴恩达的深度学习系列课程中关于结构化机器学习项目和其其新书《Machine Learning Yearing》，参考其中在实践方面的经验和策略； 过拟合（欠拟合）以及如何解决 偏差与方差（机器学习系统的设计和建议） 正则化 查准率与查全率 特征稀疏问题解决方法 各种损失函数及其适用场景 要求:Scikit-learn、Numpy、Pandas、Matplotlib、Seaborn的使用 评估:指标包括：F1、Precision、Recall 4. 深度学习内容： Word-Embedding、RNN、LSTM、GRU、Attention、Seq2Seq、Transformer、encode-decoder、递归神经网络； 在吴恩达的课程中，涉及到了机器学习项目策略的问题和各种评判指标，这对于实践来说非常重要，也是需要仔细学习的内容； 要求： 熟练使用Pytorch软件； 5. 应聘 面试体会|微软、头条、滴滴、爱奇艺NLP面试感想 BAT三公司NLP实习offer共勉 别求面经了！小夕手把手教你斩下NLP算法岗offer原文链接 暑期实习NLP算法岗面经总结 8.09 动态规划 + 文本分类【行】 刷题动态规划 文本分类项目开头 【悟】 别人研究了很久设计出来的算法，你凭什么能用很短时间就以为理解了，会用不能说明是理解了原理和思想，所以在学习某些前人的经典算法时，需要静下心来体会设计者是如何一步步思考的，其中的思想精髓是什么； 建立自己的各种沟通方式，例如LightSmile’blog并且将所学的知识点实现，集成系统化，一方面，检验自己所学知识是否扎实，提高实现能力，系统化集成能力，另一方面广泛的沟通和交流； 领域技术各式各样，如何挑选性价比高的技术，理论进行学习，这个值得思考； 很多模型已经有实现了，所以不用自己再造轮子，但是，别人的轮子是否好用，是否有缺陷，需要加以考量。并不是说有了轮子自己就不用造了，在前期的学习过程中，自己学着写轮子还是很有必要的，它有助于我们理解知识点和知道有哪些缺陷； 这个项目应该达到的目的有哪些： 练习使用各种传统分类器，以及如何将传统二分类器转换为多分类器； 学习文本分类的各个流程和技术； 学习将深度技术应用于文本分类中； 在利用TF-IDF进行特征选择的时候，维基百科上面很清楚的写了一部分关于它的理论和缺陷； 真正喜欢一样东西是什么感觉，是什么状态，网络搜索一下: 像打游戏一样，但怎么才能做到像打游戏一样呢？ 先学会使用轮子，和学习其基本原理，等工作了再考虑是否需要自己实现一遍； 8.11 CS224N第01讲【行】 CS224N第一课 规划下一阶段的学习内容； 【悟】 写博客的目的在哪？应该记录哪些内容？分清笔记和博客的作用？ 将学习的体系性的课程、每天的体会感悟记录在博客上； 将零散的、补充性的知识点笔记记在笔记中； 利用好自己独处的时间学习和提高，把娱乐的时间留在跟亲朋在一起； python的学习并不是最主要的内容，因为它的被替代性很强，python中其实大部分的库都很少有机会用到，所以对于常用的要熟悉，对于不常用的，有个印象就行了，不要把大把时间花在研究python本身上面，花在更为重要的地方； 下一阶段的主要学习内容、选择参考以及注意点： 内容： 2017年的CS224N中文版课程； 参考因素： 成体系化且比较初级，可以作为DeepNLP生涯的展开； 现在一般使用的都是基于深度学习的NLP，能跟上时代的步伐，并且能适应工作的需要； 有教授讲解，理解更为透彻，迅速，这是从书本学习不具有的优势； 注意： 传统NLP方法依然要学习，只不过时间不应该在这个阶段，因为传统学习提供了另一些理解NLP的视角，并且它也拥有自己的优势，可以与DeepNLP对比学习； 要慢慢改掉原来的学习习惯：（1）一定要阅读相关文章；（2）一定要自己亲自实践； 一步一个脚印，走扎实了，争取不再回锅； 8.12 CS224N第02、03讲【行】 CS224N第02、03讲，词向量模型； 【悟】 在从视频资源进行学习的时候，特别是英文资源，因为自己听力不是很好，所以有时候只顾着看中文字幕而忽视了PPT里的内容； 喜欢代码这种整齐划一的表现形式； 喜欢这种利用强大工具延伸自己能力的方式； 8.14 CBOW + Hierarchecal Softmax 实现词向量【行】 实现CBOW+Hierarchecal Softmax的词向量； 【悟】 对数据的观察很重要，每个语料集都有自己的特点，模型需要根据这些特点调整参数以便更好地模拟语料； 对比已有的库，训练同样的语料，看自己的差距在哪里； 要知道如何调整，要有策略，从machine learning yearing上学； 明日安排： 理解词向量到底捕捉的是语言的什么信息，是怎样捕捉的； 完善CBOW+Hierarchecal模型，实现模块化、系统化，考虑是否需要把一个长句分成短句进行训练； 开始写Skip-Gram+Negative sampling模型； 8.15 CBOW + Negative Sampling 实现词向量【行】 实现CBOW+Negative Sampling的词向量； 【悟】 笔记《Word2Vec中的数学》写得很好，从预备知识到背景知识再到模型的原理，模型的实践细节，待处理问题，优缺点都有，参考资料，这个可以作为自己写博客的一个模板； 自己应该更加注重细节的问题，在学习《Word2vec中的数学》中基于Negative Sampling的模型（28页）一节时，明明在第一段就写了Negative Sampling是NCE（Noise Contrastive Estimation）的一个简化版本，这本可以提醒自己在理解上可以从NCE出发，结果学习的时候直接忽视了这句，到后来不能理解的时候又从网上才看到了关于NEG的根本性原理NCE，这应该是提醒自己做科研一定要细心，不能粗枝大叶； 再把CS224N前面学过的看一遍，对softmax loss求导进行全面推导； numpy库的掌握很重要； 明日安排： 将CBOW的两种实现方式集成； 写出Skip-Gram的两种实现方式； 集成实现CBOW、Skip-Gram的两种实现方式； 8.21 词向量项目总结【行】实现了一下相关模型： CBOW + Hierachecal Softmax； CBOW + Negative Sampling； Skip Gram + Hierarchecal Softmax; Skip Gram + Negative Sampling; Glove; 【悟】 编程会提高对知识的理解，我认为其中的原理之一可能是编程的过程其实就是让自己慢下来，有更多的时间思考模型的原理和意义； 了解教学视频要求的知识背景很重要，否则会浪费很多时间反复地、零散化地去补课程所涉及到的基础知识，再一次强调了基础的重要性； 每个模型背后的思想才是最重要的东西； 观察数据很重要，任何数据都有自己的特点； 结果有问题时要仔细分析可能出现问题的原因，如果模型没有问题，就调整参数，如果调整参数得不到相近答案，则调整方法； 分析各类学习资源的优缺点，比如视频资源，虽然有些细节讲得很好，但是缺乏系统性，所以在学完视频时自己还需要从其他资料获取对这部分知识的完整理解；再比如书，虽然具有一定的系统性和细节性，但是它具有延迟性；论文资源，虽然具有时效性，但是细节不一定讲得很明白，跨语言理解的准确性有待考证； 顺着主要路线走，对于路线中需要的支路线，找时间补就行，没有必要为了支路线的内容而将本该用于主路线的时间花在支路线上； 博客应该是自己的学习笔记，可以供其他人浏览和评价； 对于实现某些模型的时候，用jupyter noteboo完全就可以了，但要注意的是，尽量写成模块的形式以便于自己可以快速的把这些模型转换为可以通用的模块； 自然语言中运用了很多的数学模型去模拟某些现实中中的情境，这都是人们基于对数学的个人理解从而运用的，很多时候都没有完全的理论依据，所以给人的想象空间很大，但是，也不是凭空想象的，是基于对数学知识、模型的理解而来的，所以数学才是根本； 要注意在循环中的索引变量 i ，可能与其他变量名字相同； 注意jupyter notebook会存储以前的变量，在编程测试的时候尤为需要注意； 写项目时，分清哪些是内在参数和外部调用参数； 在写项目的时候最好先用简单的实例验证局部模块是否完全正确； 模仿好的库的架构； 数据的预处理应该根据实际任务和数据的实际情况而调整，不应该一成不变； 模块中私有变量和其他变量的权限处理； 在写模型的时候任何想法总结先记录； 如何利用好公众号、知乎、paperweekly等实时资源； 词向量模型是别人研究了好几个月甚至好几年的模型，在研究过程中遇到了各式各样的细节性问题，在研究这些细节的时候增加了对模型的理解，而自己在学习这些词向量模型的时候，首先看的是原理，接着是短时间的实现，实现的过程中，遇到的问题远远少于研究者遇到的问题，导致了很多未见到的细节都没有得到足够的优化，最后效果的累积起来就导致了差距的产生，所以在学习的初期阶段，不用太深入地去了解，行程一定的理解并实践已经足够，这时候的目标是了解深度学习在整个nlp领域的应用，最后再回过头来深入研究自己选择的领域； 8.28 建站【悟】 阅读博文时可能会提到另一些知识点（比如今天读到的特征为什么要离散化和怎么离散化）而自己不太清楚甚至不知道，对于这些知识点，我们可以单独拿出来研究，在知乎上搜索理解，而一些高分回答的作者，往往对这个行业有很深的理解，我们又可以去看看他们的博文从而积累更多的知识，从零散的知识点逐渐积累成系统性知识点； 思考自己为什么做项目为什么老是延迟预计完成时间； LR是一种在线学习（动态扩展）的算法，自己以前却不知道，或者在知道感知机是在线学习算法的时候自己也没有去思考在线学习到底有哪些特点，哪些算法属于在线学习； softmax公式推导的启示： 对于算法公式的理解，由于自己的知识限制，可能理解得有偏差，这时候就需要积累一些纠正这些偏差理解的方法，比如： 利用编程实现算法，通过结果验证理解； 利用高价值博文、评论验证； 原来对于softmax的理解是只求目标类的梯度，也就是one-hot为1的梯度，其实这是错误理解了，因为自己把one-hot代入了损失函数然后才来求导，结果导致one-hot为0的类的梯度通通为0，这里明显是把损失函数和梯度求导搞混了，也体现了自己数学不扎实的缺点； 学着从舒适区里走出来； 【待】 jupyter lab实用的魔术命令； 2019年9月9.02 计划【悟】 缺乏一种独立思考的能力； 简单计划—&gt;上路—&gt;在路上观察自己所需内容—&gt;学习内容—&gt;接着走，在自己对这个领域并没有深刻认识的情况下，不要忙着搜集大量相关内容写详细的计划，因为自己并不知道重点、难点在哪里，特别是在没有人指导的情况下，这种计划用一个经济学领域的话来说就是“计划经济”，而先简单计划，边干活边观察需要的东西，然后按需学习，这种计划更像是“市场经济”，显然，市场经济更能适应社会； 在B站看外国教学视频时很多英文的字幕，于是很多人在评论区抱怨没有中文字幕，我觉着这也是限制自己能力，依靠他人的一种做法，如果真的想变得厉害，我觉得应该学习英文； 多个逻辑回归和softmax的使用区别； 9.06 Do Nothing【悟】 测试在前（即想到测试用例用于验证程序小部件正确性，用于提前发现问题），开发在后； 代码调试功底，如何快速地找出错误——熟练设置断点、单步跟踪、查看内存、分析调用栈； 思考清楚再编码，否则只会越改越乱； 良好的代码命名和缩进对齐习惯； 简历中要注意“了解”、“熟悉”和“精通”几个词的使用； 9.15 计划【悟】 不管学习什么东西，都应该把每个细节都全部弄明白，从头到尾自己推导一遍（不是跟着书），对于有些细节不要看一眼以为自己懂了就不去深究，这就是所谓地打牢基础，避免日后遇到之后就跟没有学过一样，或者完全想不起原理，这就浪费了更多的时间，从原理上弄明白了之后最好实践一下，这样能够更清楚使用的效果、适用的范围等等，同时也是对理论地加深； 9.16 学习CS224N（2017版）【行】 学习CS224N（2017版）Lecture9和Lecture10 【悟】 学习基于传统ML的NLP能够帮助我们了解模型的组成和各个细节，因为在基于DL的NLP中，很多原来手工设计的特征会被自动提取出来，但是很多时候提取的特征是什么意思并不十分明确，借助对传统ML中NLP手工设计特征的学习来帮助理解深度学习自动提取特征是很有帮助的，它帮助我们明白DeepNLP底层到底是在做什么； 每个课程的侧重点或者理解方式不一样，比如在讲解LSTM各个门的作用时，吴恩达的课程并没有很清楚的讲解其中的具体作用，可能只是为了普及模型，而CS224N课程类的LSTM则把各个门的作用讲解得比较透彻，了解课程的适用对象和特点很重要； 将视频课程中比较重要的语句记录在书中，不要光凭记忆，好记性不如烂笔头； 模型是干什么的，由什么推导而来的，有什么优势，有什么局限； 9.17 学习CS224N（2017版）【行】 学习CS224N（2017版）Lecture11、Lecture13、Lecture14 【悟】 学习模型的时候到底该掌握什么内容； 对于CS224N课程，从上课的内容来看，很多时候如果没有以前的NLP积累，并不是那么容易明白，而在课堂上的提问环节，很多学生能够提出比较关键的问题，我认为这可能是他们在上课前就对相关知识进行了学习，也就是预习，所以在上课时，一方面对自己已经理解的内容进行确认，另一方面重点关注了自己没有明白的内容，这样的学习方式值得自己思考，另一个问题是，课堂上的内容往往讲得比较精简，很多细节和拓展并没有讲，但是给了很多阅读参考资料需要学生自己去学习，我觉得这也是锻炼学生自主学习、理解细节和拓展的方法，锻炼学生独立学习和继续深入下去的能力； 在学习CS224N时，最重要的参考是hanck的课程笔记，看了她的整个网站，结合自己学习时的问题，总结如下： 基础知识（包括数学知识，机器学习知识，深度学习知识，NLP知识）决定了我们的吸收速度，同时让我们不再关心基础结构而关注模型思想、创新点等根本性重点； 语言问题，绝大部分的优秀的讲解视频时基于英文的，虽然也有翻译过来的，但是因为翻译者的水平参差不齐导致了翻译的准确性得不到稳定的保证，所以加紧时间学习英语也是一个迫切的问题，特别是需要阅读大量的英文论文； 看视频的习惯问题，对于不太明白的内容没有反复地去观看和揣摩，并且在学习的过程中没有记录笔记，在学习的过程中只是被动的被领着走，并没有主动的探索和思考，这对于知识的吸收并不好； 云计算租赁提高效率； 9.18 学习CS224N（2017版）【行】 学习CS224N（2017版）Lecture15、Lecture16、Lecture17、Lecture18 【悟】 建立自己的一套读书笔记系统，从《自然语言处理综论》、《统计方法学习》中开始设计，这两本书笔记和记号较多，记号中最好只是形式的不同而非颜色的不同，这样能最大化较少对外部工具的需求；可以参考英文书籍中旁边的段落总结符号； 是否考虑将英语作为主要研究语言，第一、英文是使用最为广泛的语言；第二、英文较中文而言，没有那么复杂，并且研究者也非常多； 在理解递归神经网络的升级版时，线性代数的矩阵特点使特征能够转换，这是数学的力量，在理解树结构和水平线性结构结合提高了树结构的运行效率使之能够并行运行，这是数据结构的力量，在指代消解过程中，利用各种语言学的知识，较少了运算量，提高了效率和准确率，这是语言学的力量，所以说，对涉及各个重要学科有扎实地了解能够帮助自己建解决各种遇到的困难，为解决他们提供了丰富的工具，也在解决问题提供了更多的思路； 大量阅读各种各样的论文，开阔自己的眼界，眼界是决定创新程度的关键因素，并且，大量阅读还可以积累各种各样解决问题的办法，以及各种新颖的思考问题的角度； 提高工程能力，快速迭代模型，把更多时间留给思考和创新； 学习课程，应该做的是把课程讲的内容通过查阅更多资料了解完整细节、再通过代码实践式地加厚，而不是简单了解、浏览式甚至跳阅地压薄（除了带了某种专门的目的学习除外）； 2019年10月10.01 学习【行】 刷《剑指Offer》链表两题； 整理英文学习资料； 10.16 找工作复习实践计划1. 工程数据结构和算法 学习面试经验； 内容掌握： 链表、二叉树、归并排序、快速排序、二分查找； 回溯法、动态规划、分治、递归等算法思想； 栈、队列、堆、图 {DFS遍历、BFS遍历、最大（小）生成树算法（Kruskal、Prim）、最短路径（Dijkstra、Floyd）} 字符串、正则表达式； 哈希、集合； 编程语言Linux系统数据库与网络知识 2. 理论自然语言处理 工程上的处理： 文本预处理环节（中文和英文）可以参考《Python文本分析》； 找工作前必完成任务（参考《自然语言处理综论》、《统计自然语言处理》、《基于深度学习的自然语言处理》、CS224N课程和Andrew Ng的深度学习课程第五门课，可以参考高阶书籍《多语自然语言处理》）： 序列标注（Segmentation、POS、NER）； 句子分析（包括语法分析和依存分析）； 文本分类、聚类； 对话系统； 找工作进行时完成任务； 文本摘要； 语义分析； 要求： 清楚每个任务的难点在哪； 清楚每个模型的优缺点，对于缺点需要想一些改进措施； 清楚每个任务的传统方法和深度学习方法； 清楚每个任务目前最优的方案是什么； 清楚每个任务的评测标准； 清楚哪些库可以实现相应任务的功能； 深度学习 主要是对自然语言处理相关的内容进行复习； 熟悉框架Pytorch； 清楚各种激活函数的优缺点及所用之处； 清楚超参数调参、正则化以及优化，这部分可以参考Andrew Ng的深度学习课程； 机器学习 主要参考《统计学习方法》 原因： 本书包括了最为常用的机器学习方法； 有详尽的数学推导，便于理解深层原理； 基本上学习过一遍，再过一遍主要是为了实践从而有更深的理解和记忆，并且效率与更高； 要求： 理解基本原理； 使用scikit-learn进行实践； 清楚各种损失函数； 模型复习顺序： SVM（连带感知机） –&gt; 决策树 –&gt; k近邻 –&gt; 提升方法 –&gt; EM 机器学习的策略，评估方法 特征工程 后续内容： 《统计学习方法》主要从数学推导的视角讲解的模型，更多的相关视角可以从其他机器学习相关书籍中寻找； 深入模型的数学原理上的假设限制，适用条件等等； 数学 微积分： 导数、偏导数、梯度； 雅克比矩阵（一阶求导）和海森矩阵（二阶求导）； 线性代数： 矩阵乘法； 矩阵分解； 概率与统计： 2019年11月11.14 日常【悟】 对于已买的书，即使没有时间将内容全部或者部分看完，至少看完目录和前言，了解书里大致讲的内容，同时也扩展一下自己的概念库，知道概念对应于哪些内容，要用到的时候有个印象，也不至于要用的这些知识点的时候一点也不知道，书也白买了； 11.16 日常【悟】 如何提高对自然语言处理的兴趣，让自己达到一种痴迷的地步，可以类比于看自己感兴趣的小说有时候能够不想睡觉地看，找到兴趣点； 选择是自己的事，可以用20分钟来打一把王者荣耀，也可以用20分钟来学习弱对偶性，今天的选择决定了明天的高度； 把自然语言处理技术作为主线来抓，而不是数学或者是机器学习，在实际的技术探索过程中，应用学到的数学知识或者机器学习知识并不是很多，只占了一小部分，更多的是思考如何改进或者创新，数学和机器学习只应该作为辅线来抓，它们的作用主体现在以下方面： 理解模型理论方法； 启发改善或者创新思路； 为改善或者创新提供理论依据； 11.18 BERT学习【行】 Transformer的学习 【悟】 学习一个知识点就争取一次性把它学好，学彻底，不要再想着以后再来深入； 并不是要学的内容太多，而是没有行动，执行力是个问题； 学习某系比较复杂的知识点（由多个知识点组成的）时，解决一个知识点就记录一个知识点的来源位置以便于最后做总的梳理，但是不要在学习这个知识点之后就开始记录，要等到整个复杂知识点学习完毕之后，因为这样可以最有效地学习这个复杂的知识点避免自己开始就花大量的时间在局部知识点的记录上而淡忘了前面所学的知识点从而不能够很好的整体把握； 了解模型的缘由非常重要，从One-hot到Word2Vec，再到Elmo，再到GPT最后到BERT，每一个模型的产生都是为了克服现有模型的缺点而产生，每一次的缺点都有不同，同时也可以积累处理这些缺点的方法； 11.19 BERT学习【行】 Transformer的学习 Normalization的学习 11.23 BERT学习【悟】 遇到某些知识点不懂的时候，以往的查询就是直接google，然后看查到的博文，对于博文参考的文献通常视而不见，其实参考的文献很有可能才是关键内容，因为它包含原有的思想和初衷，而引用者通常水平不高，语言描述也不够深刻，所以导致了思想的传递出现偏差，所以对于不懂的知识点或者模型，我们应该尽量找原始论文或者阅读量高的解释性博文； 在学习过程中遇到有不懂的算法或者模型，不应该浅尝辄止，应该刨根问底、追根溯源，这样才能真正学得深学得扎实。比如在BERT的学习过程中，对于BERT的训练方法Mask Language Model，了解的深度仅限于知道如何操作，但是至于为什么要这样操作，这样的原理是什么，并没有深究，直到后面看到有关BERT和其他预训练模型对比的博文，知道有预训练模型有自回归和自编码两种类型，自回归好理解，但是对于自编码，不是很理解，然后就开始查阅资料，了解自回归的基本概念和作用，知道自编码有几种变种，其中一种就是DAE（降噪自编码器），而这个DAE正是Mask Language Model的根本思想，这也就解释了它在BERT的训练中为什么可以这么做，所以遇到问题，多问为什么，多查资料，查原始资料才是最好的学习路径；另一个例子是关于Word2Vec的负采样学习方法，关于这个方法，在当时自己学完了也并没有理解根本原理，直到后来再次学习，追根溯源查到了它的根本原理是噪音对比估计，所以深究非常重要，同时这两个例子也告诉我，应该广泛的涉猎，不应该局限于NLP这一个领域，广泛的涉猎也许能为自己在NLP的创新带来灵感和解决问题的启示； 在查找资料，学习资料的过程中基本上都是阅读理解为主（被动思考，很少主动探索模型的产生和改进方式）； 学习一种模型或者算法，应该从纵向和横向两个方向进行掌握： 纵向： 掌握所有关于模型本身的细节和涉及的知识点； 探索算法的优点和缺点； 横向： 理清模型的发展脉络和轨迹，掌握各种历史模型的优缺点及改进思路； 比较各种具有同样功能的模型各自的优缺点； 掌握模型的变种及其变种思路； 2019年12月12.02 日常【悟】 学会在学习过程中记录问题，分辨知识点，记录关键，整合零散类，分类资料； 起步较晚，在有限的时间里把握更核心的内容而不是可有可无锦上添花的内容才能赶上别人； 利用间隙时间活动腰和脖子； 学会阅读源码； 数据的形式能够帮助阅读源码； 英语学习需要有指导（中英对照的），因为很多常用结构不知道该怎么翻译； 要逐渐形成自己的一套固定的学习方法，并在后续的学习过程中持续迭代和微调； 避免重复学习，浪费时间； 12.15 日常【悟】 强化学习更类似于人的学习行为，这个框架应该提早接触； 即使没有大量时间仔细系统学习某个框架，比如GAN，也可以花少量时间进行简单学习了解；]]></content>
  </entry>
</search>
